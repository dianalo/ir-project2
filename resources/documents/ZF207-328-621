<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-328-621  </DOCNO><DOCID>07 328 621.andM;</DOCID><JOURNAL>Datamation  Feb 1 1989 v35 n3 p47(4)* Full Text COPYRIGHT Cahners Publishing Co. 1989.andM;</JOURNAL><TITLE>Toward an equitable benchmark. (on-line transaction processing)(includes related article on difficulty of on-line transactionprocessing benchmarks)</TITLE><AUTHOR>Serlin, Omri.andM;</AUTHOR><SUMMARY>The Transaction Processing Performance Council (TPC) was formed torevise current benchmarks used to measure the on-line transactionprocessing performance of various hardware and software systems.andO;The Council includes 26 hardware and software manufacturers, andothers may be added.andP;  The committee is already working on itsfirst standard effort, revising the DebitCredit benchmark.andP;  Thebenchmark measures a single bank account demand deposit activitycontrolled by a manned teller support system.andP;  The non-proprietarybenchmark works in a variety of environments.andP;  The council isworking on a better definition of the standard and a consensusmeasurement device.andP;  The committee expects those employing thestandard measurement to make full disclosure of all circumstancesof the test.andP;  The purpose of the standard is to avoid confusingperformance reviews for users.andM;</SUMMARY><DESCRIPT>Topic:     On-Line Transaction ProcessingOn-LineBenchmarksPerformance MeasurementStandards.andO;Feature:   illustrationtable.andO;Caption:   How the TPC was formed. (table)andM;</DESCRIPT><TEXT>Toward an Equitable BenchmarkandM;The formation last August of the Transaction Processing Performance Council(TPC) culminated a chain of events that was largely launched by a DATAMATIONarticle more than three years earlier (see &quot;A Measure of TransactionProcessing Power,&quot; April 1, 1985, p.andP;  112).andP;  Elements of that originalDebitCredit benchmark are being evaluated for inclusion in a new performancestandard, to be called TPC Benchmark A.andP;  (TPC Benchmark is a trademark of theTPC.)andM;At this writing, the 26 member organizations in the TPC include all of theleading domestic computer vendors, among them IBM, Digital Equipment Corp.,andO;Unisys Corp., Hewlett-Packard Co., NCR Corp., Tandem Computers Inc., DataGeneral Corp., Control Data Corp., Wang Laboratories Inc., Prime ComputerInc., and Sun Microsystems Inc.andP;  Five database suppliers are members:Cullinet Software, informix Software, Oracle Corp., Relational TechnologyInc., and Sybase.andP;  International members include ICL of the U.K.;andO;Honeywell-Bull, a joint enterprise of Honeywell, Groupe Bull, and NEC; andFujitsu America, a wholly owned subsidiary of Fujitsu Ltd. More domestic andinternational organizations plan to join the council early this year.andM;To any knowlede, this is the first time in the history of the computerindustry that so many competing companies have voluntarily joined together toestablish standards and criteria in computer performance measurement.andO;Confounding widespread skepticism, the initial TPC experience indicates thatcompeting vendors may be able to agree on such standards and criteria, evenin an area as fraught with difficulties as on-line transaction processing(OLTP).andM;DebitCredit, the initial target of the TPC's standardization effort, is anOLTP benchmark that has many of the earmarks of a successful standard OLTPtest.andP;  Its requirements have been available publicly since 1985; it is not aproprietary, vendor-controlled benchmark.andP;  It has a clear definition of thesingle transaction type it employs.andP;  The transaction represents ademand-deposit bank account activity performed on a manned-teller supportsystem; it contains many of the typical operations encountered on most OLTPsystems.andP;  Response time of under one second is specified for 95% of alltransactions.andP;  However, the benchmark does not claim to be an accuraterepresentation of any particular user's environment.andM;DebitCredit was defined in functional terms to encourage test sponsors tochoose the most appropriate hardware platform, operating system, databasesystem, and programming language, while ensuring that equivalent user-levelwork is performed on all systems.andM;The original benchmark, which did not specify the configuration of computingresources necessary to execute the test, specifies that system cost be usedto normalize results across widely differing systems.andP;  It requires reportingcost per tps (transactions per second), using a five-year cost-of-ownershipformula for computing this value.andP;  Should an abnormally large system be usedto obtain high tps ratings, the fact will be clearly visible in a poorcost-per-tps figure.andM;Unfortunately, DebitCredit suffers from two serious limitations.andP;  First, itsoriginal, informal statement left many significant aspects either undefinedor open to multiple interpretations.andP;  Second, in its original form itrepresented merely the private point of view of its authors; it did not havethe force of a standard formulated by industry consensus.andP;  The TPC isattempting to remedy both limitations.andM;Probably the most notorious DebitCredit variation is the one that hasrecently become known as TP1.andP;  TP1 tests have most often been executed byvendors of database products.andP;  Their key interest, of course, is to measurethe performance of the database, separate from any other system components.andO;While TP1 tests use the DebitCredit transaction, they have generally ignoredthe entire &quot;front end&quot; of the sysem; that is, the terminal, communications,and transaction management components involved in getting the transaction infrom the remote terminal, queuing it to an appropriate transactionapplication program, and scheduling that application.andM;The TP1 SimplificationandM;TP1 tests replace the front end with one or more &quot;transaction generator&quot;programs, which create transactions as fast as they can.andP;  The transactiongenerators may run on the System Under Test (SUT) itself, delivering theirtransactions directly to main memory.andP;  Or, the generators can run on aseparate driver system, delivering transactions to the SUT in very largeblocks through high-speed connections such as a 10Mbps Ethernet.andP;  In eithercase, the key simplification being made in TP1 tests is that the SUT is notburdened with any of the overhead associated with maintaining separatesessions on each of a large number of terminals.andM;This terminal management overhead involved in full DebitCredit tests usuallyrepresents a considerable load on the system.andP;  Simplified TP1 tests, whichignore this issue, have often been run with smaller-than-required file sizesas well, and therefore are able to deliver much higher tps ratings.andP;  On theother hand, in a TP1-type test, the location of the transaction generatorsdoesn't much alter the load on the SUT; one database vendor reports thatusing transaction generators across an Ethernet results merely in a 10% lowertps rating than running the generators on the SUT.andM;The Sawyer-Serlin proposed standard (see &quot;How the TPC Was Formed&quot;) attemptedto combine DebitCredit and TP1 tests by employing a degree-of-compliancepoint rating system.andP;  This proposal stipulated a set of mandatoryrequirements more or less equivalent to a TP1 test; meeting theserequirements would earn the test sponsor 70 points.andP;  Tests could earn 30additional points by performing full terminal emulation with random arrivals,and by ensuring the log file single-point-of-failure protection.andM;This rating scheme was unanimously rejected by the TPC.andP;  Instead, the councilendorsed an approach under which two completely separate standards are to bedeveloped.andP;  One, called TPC Benchmark A, will codify a whole-system test,similar to the original intent of the DebitCredit test.andP;  TPC Benchmark B, thenext candidate for standardization, is expected to be more like thedatabase-only Tp1 test.andM;File sizing is one of the key areas in which liberties have been taken inpast executions of the DebitCredit benchmark.andP;  The original benchmarkincorporates automatic scaling of the three key files--the so-called ABT(accounts, branch, and teller) files.andP;  For each tps presented to the system,a specified number of ABT records must exist.andP;  Thus, for systems claiminghigher tps ratings, larger files must be used.andP;  Especially critical is theaccounts file, which should have 100,000 records of 100 bytes each for eachtps.andP;  Thus, a test reporting 100 tps should have used 10 million accountsrecords, occupying at least 1GB of disk space.andM;A number of DebitCredit and TP1 tests have been performed with one-tenth therequired number of accounts records.andP;  The principal reason is that today,main memory of 100MB or more is becoming common.andP;  A system with that amountof main memory might be able to buffer in main memory all, or a substantialportion of, the reduced-size accounts file.andP;  This usually improvesperformance, because data in main memory is accessible much faster thandisk-resident data.andM;Main memory buffering can, however, sometimes result in lower or merelyequivalent performance.andP;  The reason is that most database systems today canlocate disk-resident data rapidly by using either indexing or hashing,whereas a search for records residing in main memory caches often must bedone as a linear scan.andP;  When the amount of data cached in main memory exceedsa certain limit, the linear scan required to locate the desired record inmain memory may actually take longer than a hashed or indexed disk access.andM;Variations on Response TimeandM;Response time is another requirement of the DebitCredit that is oftenviolated.andP;  As originally stated, the benchmark specified that 95% of alltransactions must meet a response time of one second or less.andP;  Several testshave been run with response times of two seconds for 90% of all transactions,a much weaker constraint that leads to much higher tps ratings.andP;  Some testsponsors have reported only the average response time for all transactions.andO;That is a very weak constraint; up to half of the transactions may haveexperienced much longer than average response.andM;How to measure response time is a key difficulty.andP;  DebitCredit meant responsetime to be measured at the &quot;central system,&quot; without taking into accountdelays across the communications lines and whatever multiplexers orconcentrators might be present.andP;  Thus, DebitCredit specifies response time asthe period from the receipt of the last incoming bit to the appearance of thefirst response bit on the central system's I/O facilities.andP;  As it turns out,this is next to impossible to measure; test sponsors have often resorted tomeasuring response time at the driver system and extrapolating back to thecentral system.andP;  Some have argued that measuring at the driver system is moreproper, because it is closer to what the terminal user might actuallyexperience.andM;A particularly subtle issue is the transaction rate of arrival.andP;  DebitCreditmerely specifies the &quot;think time&quot; at each terminal (100 seconds pertransaction), but says nothing else.andP;  It turns out that system performance isadversely affected when transactions arrive in unpredictable, randompatterns.andP;  Queuing theory can be used to show that a constant transactionarrival rate might lead to twice the tps rating that would be obtained underthe same average arrival rate, but with random arrivals.andM;In the original DebitCredit definition, there is an implicit relationshipbetween the number of terminals that must be present or emulated and thetransaction throughput.andP;  Each terminal generates a transaction once every 100seconds; stated another way, there must be 100 terminals for each reportedtps.andP;  Thus, a test reporting 100 tps must have configured or emulated 10,000terminals.andP;  Many vendors consider this an onerous and unrealisticrequirement; in fact, no one has ever executed a DebitCredit test with thatmany terminals.andP;  The TPC is considering proposals for a more moderate numberof terminals in TPC Benchmark A.andM;DebitCredit specifies a sequential &quot;90-day history&quot; file, to which everytransaction adds a 50-byte record of its activity.andP;  (This &quot;audit trail&quot; iscritically important in the banking environment, where arithmetic errorscannot be tolerated.)andP;  This innocuous-looking provision is actually one ofDebitCredit's toughest requirements.andP;  In the first place, at high transactionrates this file, which grows at the rate of 2.5 million records per tps, canbecome gargantuan.andP;  Worse still, because all transactions concurrentlyattempt to append data at the end of this file, that point becomes a &quot;hotspot&quot; that can seriously degrade system performance.andM;Handling the History FileandM;Several clever technologies can sometimes be used to alleviate problems ofthis type, including group COMMIT and escrow transactions.andP;  In group COMMIT,the log records of several transactions are accumulated in a buffer, which isthen flushed to disk in one access.andM;In a heavily loaded system, this entails only a minor degradation in responsetime, in exchange for a large improvement in the tps rating.andP;  Escrowtransactions remove the need for locking by recognizing that the order ofapplying additions and deletions to a &quot;balance&quot; amount is immaterial, as longas the final value is correct.andP;  In a sense, escrow locking endows thedatabase manager with a limited form of artificial intelligence; that is,knowledge of the internal workings of the application.andM;A less clever trick often employed is to break the history file into multiplesegments and have specific subgroups of transactions direct their historyrecords to specific segments.andP;  This relieves the hot spot by making multiplehistory files available.andP;  Computing 5-year system cost for reporting cost pertps is a deceptively simple process with many potential pitfalls.andP;  Whatshould be included in the cost?andP;  The original DebitCredit worried only about&quot;computer room&quot; costs; it did not consider the possible unloading of centralsystem functions into front-end small systems and remote but intelligentterminal controllers.andP;  If such remote equipment is to be included, shouldn'tthe costs of the communications lines and the terminals themselves beincluded as well?andP;  What type of maintenance support should be included--fullon-site or just remote support? Should price discounts be disallowed, even ifthey would normally be earned by any customer buying a system of aparticularsize?andP;  These are just some of many questions that the TPC may berequired to tackle.andM;In the past, some test sponsors have hired independent consultants or publicaccounting firms as auditors to validate DebitCredit test results.andP;  Due tothe lack of a rigorous specification, the auditors have had to improvise andmake personal judgments.andP;  Once a firm standard is approved, the work of theindependent auditors will become more structured; there will then be an addedincentive for all test sponsors to go to the trouble and expense ofindependent validation.andM;Standards and Full DisclosureandM;There is substantial agreement within the TPC that some form of &quot;fulldisclosure&quot; should be made part of the standard, whether or not the test isindependently audited.andP;  The council has yet to deal with the details.andP;  Onereason for such a requirement may be to enable a competent, independentobserver to pass judgment on how well the test met the requirements of thestandard, providing an added check on the work of the auditor.andP;  Another maybe to allow an end user to replicate the vendor's test.andM;The importance of standardizing the full-disclosure requirements was recentlyunderscored when IBM and DEC reported widely divergent tps and cost figuresfor a DebitCredit test performed on a virtually identical configuration of anIBM 9377-90 system.andP;  Due to insufficient full-disclosure data, it wasimpossible to precisely determine the sources of these substantialdiscrepancies.andM;The council is under no illusion that DebitCredit and TPl are sufficient tocharacterize OLTP performance.andP;  Most member organizations have expressedinterest in defining additional standards; some of these organizations areexpected to make concrete proposals to the council, once work on the initialtwo standards is reasonably complete.andM;While competitive pressures aren't ever likely to disappear entirely, thereis reason to hope that in the not-too-distant future, the standardsestablished by the TPC will reduce the volume of conflicting performanceclaims and allow end users to make sense of such claims.andO;</TEXT></DOC>