<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO> AP890810-0191 </DOCNO><FILEID>AP-NR-08-10-89 1222EDT</FILEID><FIRST>a a BC-EXP--NeuralChip Adv14   08-10 0994</FIRST><SECOND>BC-EXP--Neural Chip, Adv 14,1019</SECOND><HEAD>$adv14</HEAD><HEAD>For release Monday, Aug. 14, and thereafter</HEAD><HEAD>Chip Emulating Brain Signals New Computer Era</HEAD><HEAD>With LaserGraphic</HEAD><BYLINE>By WILLIAM McCALL</BYLINE><BYLINE>Associated Press Writer</BYLINE><DATELINE>PORTLAND, Ore. (AP) </DATELINE><TEXT>   In the beginning, there were digitalcomputers. They were big, slow and very stupid. A half-centurylater, digital computers are very small and fast, but they're stillhopeless idiots compared to humans.   The main problem was, and still is, that computers just can'tthink.   But what if computer circuits could be made to resemble ourbrains? What if they could learn from their mistakes?   Hundreds of tiny companies have sprung up in the past threeyears hoping to answer, and cash in on, those questions with anapproach called neural networks after the neurons that are thebasic structure of the human nervous system.   Carlos Tapang, a 36-year-old Filipino physicist who left IntelCorp. to start Syntonic Systems Inc., shipped what he believes isthe first commercially available neural network chip toElectrodyne, a Japanese company, in May.   The chip is called DENDROS-1, a reference to dendrites, thehighly branched filaments of nerve or brain cells that let thecells communicate. It simulates neurons by combining a variety ofsignals to come up with a single result.   Tapang compares it to measuring the flow of water through a vastnetwork of different-sized pipes by emptying them into a singlepool. Such a system of computing values is called ``analog,'' whichimplies a continuous form of measurement, like the sweep secondhand on a watch.   Digital computers, like digital watches, chop time and numbersinto tiny bits and add them up one at a time. In fact, ``bits'' arethe smallest unit of information in the binary system that is the``brain'' of a digital computer.   The great advantage of today's digital computers is that theycan add those bits incredibly fast, even if it is done only one bitat a time.   There is some evidence from research on animals and people thatthe neural cells in our brains use a kind of digital system totransmit signals. These on-off pulses, called spikes, confusedearly researchers and led some to believe that the brain relied ona digital model to process information.   Instead, they found it was only a tiny portion of a complexelectrochemical system that channels signals the way Tapang istrying to imitate. ``A neuron by itself is dumb, but the totalityof that network of neurons in our skull is probably the mostintelligent machine in the universe,'' he said.   The key word is ``network.'' It is the interaction of neurons inour brains that gives rise to thought, not the action of a singleneuron.   In that sense, Tapang said, digital computers are doomed to beelectronic dunces because their chips were designed to be solitarydevices called central processing units, channeling all operationsthrough one electronic ``pipe.''   Even if CPUs are connected, the result is only a faster dunce.   However, some computer scientists and industry analysts areskeptical.   Neural networks will ``be a fine addition to what we've got nowbut they'll just supplement it,'' said Esther Dyson, editor andpublisher of Release 1.0, a New York-based computer newsletter.``They'll never replace the mathematically precise logic of adigital system.   ``I fundamentally disagree with this `baited breath' attitude inthe industry about the next breakthrough being neural chips ornetworks. They're good at things like pattern recognition but stillcannot cope with our kind of `fuzzy thinking.' A lawyer might ask,`Colonel North, why did you do that?' and accept a fuzzy answer,but a computer can't.''   One San Jose, Calif.-based company, Synaptics, has used neuralnetwork technology to develop what it calls a Silicon Retina. Anarray of photo sensors emulates the light receptors in the eye, andan analog computer processes the image for display on a videomonitor.   Tapang uses capacitors to simulate neurons, which rely onchemicals to transmit signals between synapses. Capacitors storeand release electricity in much the same way. DENDROS-1 has onefixed connection and 22 variable ones that simulate synapses. Itcan be layered with other chips to create an overlapping network ofcommunicating capacitors that ``fire'' signals to each other.   As in the brain, the firing of one electronic neuron affects theothers. An important feature is each neuron's ability to damp itsneighbors, creating a pattern. The variable interaction is acrucial part of the network.   The applications for Tapang's chip include things like patternrecognition.   Dyson agrees the best uses for neural chips and networks wouldbe tasks like analyzing seismic patterns to predict earthquakes andhunt for oil or gas, analyzing brain waves, identifyingfingerprints or other classification chores.   But she remains skeptical about their potential. So does DaveWaltz, of Thinking Machines Corp. in Cambridge, Mass., which makesa supercomputer built of up to 64,000 digital processors harnessedtogether.   The problem with neural networks is that you can't keepexpanding them, Waltz said. ``The whole field of neuropsychologysays that increasing the scale means greater complexity. If youscale up the size of a neural net you increase the complexity ofsolving the problems you give it.''   Mathematicians claim they can use mathematical functions toachieve the same effect as neural networks, and such formulas canbe readily understood, he said. ``The main problem with neuralnetworks is that we just don't understand how they really work anymore than we understand how the brain really works.''   Waltz believes the boom in neural network research will slow butthat interest will continue, because it is ``easier to writeprograms for neural nets than for any other system. Almost anybodycan play the game.''   ``The digital age is over and the analog era is here,'' Tapangsaid. ``The next step is making computer chips that can communicatewith each other and this is a step in that direction.''</TEXT><NOTE>End Adv for Aug. 14</NOTE></DOC>