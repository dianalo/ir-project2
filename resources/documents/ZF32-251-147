<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO> ZF32-251-147 </DOCNO><DOCID>11 194 659</DOCID><JOURNAL>IBM Journal of Research and Development  Jan-March 1991 v35 n1-2p45(14)* Full Text COPYRIGHT International Business Machines Corp. 1991.andM;</JOURNAL><TITLE>Data visualization using a general-purpose renderer. (technical)</TITLE><AUTHOR>Doi, Akio; Aono, Masaki; Urano, Naoki; Sugimoto, Kazutoshi.andM;</AUTHOR><SUMMARY>This paper describes a general approach to data visualization,based on the Rendering Subroutine Package (RSP).andP;  RSP is ageneral-purpose polygon-based renderer, and is IBM's firstrendering application programming interface (API) for users whowish to develop their own applications.andP;  We present an overview ofthe system, details of the image synthesis tools, and severalexamples of the application of RSP to architectural CAD, moleculargraphics, and computer tomography.andP;  (Reprinted by permission ofthe publisher.)andM;</SUMMARY><DESCRIPT>Topic:     RenderingComputer GraphicsApplications Programming InterfaceVisualizationShape.andO;Feature:   illustrationgraphchart.andO;Caption:   Image quality and processing time. (graph)System overview using RSP. (chart)Example of the structure of plan, object, and face. (chart)andM;</DESCRIPT><TEXT>IntroductionandM;In recent years, CAD/CAM, computer graphics animation (CF, CM), andpresentation graphics have become big business as a result of the progress ofcomputer graphics technology.andP;  Data visualization of large numericalsimulations has also become important for the understanding of simulationresults.andP;  As a result, the user needs a variety of representations, flexibleinteractive operation, and high-quality and realistic image displaycapability in a wide range of application fields.andP;  In order to satisfy thisrequirement, we have developed a general-purpose polygon-based renderer, theRendering Subroutine Package (RSP).andM;It is easy to imagine the ideal rendering system that most users would liketo use for visualization.andP;  It would provide good-quality pictures quickly.andO;Although many rendering methods, for example [1-15andrsqb;, have been proposed, itis very difficult to satisfy the requirements for all applications.andP;  This isnot surprising, because there is always a trade-off between the quality ofthe generated picture and the time taken to generate the picture.andP;  Thus, oneof the best answers is to provide several different types of renderingsoftware.andM;We therefore provide users with three rendering methods (a list-prioritymethod, a scan-line method, and a ray-tracing method) that cover most oftheir needs.andP;  Figure 1 shows the relationship among the methods in terms ofimage quality and processing time.andP;  The user can select any of them, takingaccount of the trade-off between rendering time and quality.andP;  Both scan-lineand ray-tracing support a new texture-mapping technique, which we call&quot;attribute mapping.&quot;andP;  It can generate more realistic images and runs moreefficiently than ordinary texture-mapping techniques for surfaces withcomplex textures.andP;  In this paper, we give a system overview of RSP, detailsof the functions, and several examples of the application of RSP toarchitectural CAD, molecular graphics, and computer tomography.andM;System overview of RSPandM;Figure 2 shows an overview of the functions of the RSP system.andP;  RSP usespolygonal models as geometry models, and can treat convex and concavepolygons with holes and surface anomalies.andP;  The polygon data are defined bythe RSP data format, which has two file formats: a character file format anda binary file format.andP;  The character file format is used to edit values inthe files on a terminal.andP;  The binary file format is used to read and writerapidly from large polygonal data files.andP;  The use of a polygonal modelgreatly simplifies shaded-image synthesis, interactive operation on objects,and data conversion from other data models such as boundary representation(B-Rep), constructive solid geometry (CSG), and free-surface models.andO;Consequently, the user can easily generate polygon data or write a program tocovert data from other systems.andP;  In fact, RSP has reinforced existingmodelers used by IBM, such as CADAM, (1) CATIA, (2) and CAEDS.andP;  (3)andM;The editing functions of RSP (inquiry, setting, memory allocation, and memorydeletion) allow users to access the RSP data model, which can be used forinteractive operations.andP;  The user can build a suitable system or userinterface in the field by means of the editing functions.andM;As mentioned before, three rendering methods have been used to control thequality of the image and the purpose, and are executed on the same datamodel.andP;  A list-priority method gives an application the capability to displayshaded graphics in near real time.andP;  The idea of the method is to draw (i.e.,andO;to geneate components of the image in a controlled sequence) from thefurthest polygons to the nearest polygons to remove hidden surfaces; a drawnpolygon &quot;paints over&quot; some parts of the polygons behind it.andP;  The method ismost suited to a set of data of about a thousand polygons.andP;  Hence, it is goodfor editing a small part of an object interactively.andP;  On the other hand, itis not suitable for displaying an object with a very large volume of data.andP;  Ascan-line method is better for a large volume of polygon data.andP;  Our scan-linemethod gives an application the capability to generate shaded color imageswith shadowing.andP;  The user can obtain pictures within a reasonable responsetime.andP;  Ray-tracing is a rendering method that can treat reflection,refraction, and translucence.andP;  Our ray-tracing method is accelerated by athree-dimensional digital analyzer (3DDA) on the voxel data structure [11].andO;The detaiils of each rendering method are described later.andM;In addition to the rendering functions, RSP supports color image quantizationand dither functions for display devices with a color lookup table (CLUT) andimage composition functions.andM;RSP is written in the C language, and is now running on VM/CMS, MVS/SP, (4)MVS/XA, (4) and AIX (5) operating systems.andM;Data structureandM;* Geometry data structureandM;In this section, the geometric data of the system are discussed.andP;  Althoughrendering of 3D objects is the major goal of the system, the design of thegeometric data structure is very important, because it is one of the mostessential parts of the interface between an application and the system.andP;  Therendering system is often used with another system that yields 3D geometricdata to be visualized, such as a modeling system.andP;  The following wereconsidered as the minimum criteria for the geometric structure of the system:andM;* Cost of converting geometric data for the rendering system.andM;* Richness of representability of 3D geometric data.andM;* Manageability of the 3D geometric data by the user.andM;Some geometric data in the user's model must be converted, because it isimpossible to have exactly the same geometric structure for everyapplication.andP;  The first criterion is that the conversion should be miminized.andO;The second criterion is that it should be possible to represent evencomplicated 3D geometric data efficiently.andP;  The third criterion is that theuser should be able to edit the 3D geometric data locally, so that there isno need to convert all the data again when there is only a small change.andP;  Inview of the above criteria, questions must be answered about the design ofthe geometric data structure for a visualization system.andP;  One question iswhat kind of geometric primitives should be supported, and another is how therelationship among them should be represented.andM;In our system, polygon-based data were chosen as the geometric primitives,because it is usually easy to convert any user's models to polygon data.andO;This does not cost too much and it satisfies the first criterion.andP;  However,simple polygon data alone cannot represent a common object efficiently.andP;  Itis more natural for the user to represent a face (surface) with a hole by oneprimitive rather than multiple primitives.andP;  Thus the idea of faces, seals,and holes, which is described later, is introduced in this system.andP;  Thesegeneralities allow a user to convert data without any trouble.andP;  Thus, thesepolygon-based primitives satisfy in most cases the first and second criteriadescribed above.andM;To satisfy the third criterion, a hierarchy for representing the relationsamong geometric data was introduced into the structure.andP;  The user candynamically edit this hierarchy, using the functions provided by the system.andO;Five entities are introduced to represent the geometric data of the renderingsystem:  plan, object, face, seal and hole.andP;  The plan is the largest entityand consists of several objects.andP;  The object consists of several faces.andP;  Theface is a polygon that includes some seals and holes.andM;PlanandM;The plan, which is the largest entity, is normally used as a project unitfrom the user's viewpoint.andP;  A user can have several plans in the system,where they are stored as a list structure (Figure 3).andM;ObjectandM;The object is a unit under a plan.andP;  There are hierarchical relations amongobjects.andP;  A parent object can have several children.andP;  Each child can be aparent of other objects.andP;  A parent object may not have any faces, butotherwise an object consists of a group of faces (Figure 3).andM;Each object has its own coordinate system.andP;  The coordinate system isrepresented by a transformation matrix with respect to the parent'scoordinate system.andM;Each object has its own display flag.andP;  By setting the value of the flag, auser can control the visibility of the object.andP;  The flag controls threestates:  displaying faces and seals, displaying faces only, and displayingneither.andM;The system provides a user area for each object.andP;  The user area can serve asthe user's own attribute for the object.andP;  It may be a physical property ofthe object.andM;A root object is automatically generated by the system when the usergenerates a plan and its object.andP;  This root object is employed when the userwants to manipulate all the objects under the plan.andP;  For example, the usersets the transformation matrix to move and rotate everything under the plan.andM;Face, seal, and holeandM;The face data represent the object's geometry and have a list structure.andP;  Aface element consists of the polygon of the face, the seals on the face, andthe holes inside the face (Figure 4).andP;  The face is an area-defining geometricprimitive which is defined by the face polygon.andP;  The polygon can have anynumber of edges as long as they do not intersect.andP;  The seal is an area insidethe face and can have its own attributes.andP;  The seal has higher visibilitythan the face.andP;  The hole is an area inside the face that is alwaystransparent.andP;  In other words, the seal and the hole are those areas whoseattributes are different from those of the face.andP;  Multiple seals and holesare also allowed for the face.andP;  The seal data and the hole data are alsopolygonal lists.andP;  The polygons of the face, the seal, and the hole arerepresented by a list of vertices (Figure 5).andM;The face has an edge attribute and a face attribute.andP;  The edge attributecontrols the appearance of the outer lines of the face.andP;  The face attributecontrols the appearance of the face inside the edges.andP;  Since it is useful todistinguish the front and the back of the face, the face can have a differentattribute for each side.andP;  The seal has attributes similar to those of theface, and different seals can have different attributes.andP;  The hole is notgiven any attributes, and the appearance of the edges of the hole depends onthe attributes of the face to which the hole belongs.andM;* Attribute data structureandM;Attribute data in RSP are basically separate from geometric data.andP;  A fewattribute data, however, are closely related to geometry, and are called&quot;geometry-dependent attribute data.andP;  All other attribute data are called&quot;geometry-independent attribute data&quot; (Figure 6).andP;  Before the renderingprocedure can be used, both geometry-dependent and geometry-independentattribute data must be linked to geometry data.andM;Geometry-dependent attribute dataandM;Careful attention must be paid to the assignment of geometry-dependentattribute data, because they are allowed to be linked only to pertinentgeometric data.andP;  Specifically, smooth-shading attribute data can be linkedonly to triangles.andP;  They consist of normal vectors corresponding to the threevertices of each triangle.andP;  Mapping attribute data consist of a mappingorigin, a mapping direction, an actual length along each mapping direction,and a mapping offset.andP;  The geometric primitives to be mapped are basicallyrestricted to rectangles, but it is possible to map image data to a triangle,for example, as long as the user specifies a virtual rectangular mappingcanvas including the mapping origin, mapping direction, and so on.andM;Geometry-independent attribute dataandM;Geometry-independent attribute data are divided into two types: &quot;attributedomain definition data&quot; and &quot;rendering attribute data.&quot;andP;  The role ofattribute domain definition data is to define an &quot;attribute domain,&quot; whichrepresents a region with the same rendering attributes to be assigned as aface attribute.andP;  One of the unique features of RSP originates in theattribute domain structure.andP;  The concept of the attribute domain is discussedin more detail in the section on attribute mapping.andP;  An attribute domain iscoupled via an &quot;attribute index&quot; with rendering attribute data.andP;  Renderingattribute data consist of color, optic, and bump attribute data.andP;  Usuallythey are referenced by a pointer corresponding to an attribute domain.andP;  Colorattribute data represent either a RGB color value or a pointer to a colorimage.andP;  Optical attribute data represent a set of optical coefficients to beused in shading.andP;  Examples of optic data are ambient, diffusive, reflective,and refractive coefficients.andP;  Bump attribute data represent a pointer eitherto a functional bump generator or to a bump image.andP;  A functional bumpgenerator generates a two-dimensional wavy bump pattern.andP;  Both a wavy bumppattern and a bump image are used to perturb surface normal vectors, andperturbed normals are then used in shading calculation.andM;* Rendering condition data structureandM;RSP has four rendering conditions, which are classified as the camera, light,environment, and special conditions of each rendering method.andM;Camera data are defined by the viewing parameters familiar to users ofGDDM/graPHIGS (6) [16].andP;  Therefore, a user can easily combine RSP andgraPHIGS environments on a workstation.andP;  RSP, however, employs a normalizedprojection into a logical workstation space called the &quot;normalized projectioncoordinates&quot; (NPC).andP;  The NPC of RSP are defined as a cubic space from zero toone along each axis.andP;  RPS maintains a camera data list, and one of thecameras is selected for the rendering process.andM;RSP supports three types of light source: a point light source, a spot lightsource, and a light source parallel to the image.andP;  RSP maintains a light datalist, and the lights in this list can be turned on or off.andP;  Each light hasseveral parameters, such as light color, position, direction, spotlightangle, and so on.andM;Environmental information consists of the ambient light term, backgroundinformation, the fog-effect ratio, sky-effect parameters, and a global shadowcalculation switch.andM;The special conditions of each rendering method involve parameters such asthe maximum ray reflection number of the ray-tracing method and theanti-aliasing level of the scan-line and ray-tracing methods.andM;Attribute mappingandM;Attribute mapping [17, 18] is a generalization of texture mapping.andP;  Whiletexture mapping maps attribute values directly, attribute mapping maps&quot;indices&quot; that correspond to a bundle of various rendering attributesincluding colors, bumps, optics, and shading models.andP;  These indices arecalled &quot;attribute indices,&quot; and each is defined for a closed region called an&quot;attribute domain&quot; within a rectangular mapping canvas.andP;  Rendering attributeswithin an attribute domain are assumed to be coherent.andP;  The core conceptunderlying attribute mapping is the attribute domain definition function(ADDF), which defines attribute domains and the associated attribute indices.andO;By virtue of the ADDF, the integration of image analysis and image synthesisis easily attained, which in turn makes it possible to produce very realisticimages.andM;* Attribute index and bundle tableandM;On the basis of the available shading models implemented in RSP, onceparameters associated with a shading model are determined, we can determinethe intensity of an object at an arbitrary point.andP;  The attribute valuesnecessary for attribute mapping are simply a set of these parameters in whatwe call a &quot;bundle.&quot;andP;  Let us conventionally divide attribute values into threecategories: 1) color attributes, 2) bump attributes, and 3) optic attributes.andO;Color and bump attributes are independent of any shading model, but opticattributes are not.andP;  Color, bump, and optic attributes together are referredto as &quot;rendering attributes.&quot;andP;  Each parameter of a rendering attribute isspecified in one of three wyas: a unique, fixed value (Type 1), a functionalvalue (Type 2), or a value looked up in a two-dimensional table (Type 3).andM;The value is independent of the position in the first method, but not in theother two methods.andP;  The last method is usually employed in texture mapping.andO;When we access a rendering attribute, it is necessary to specify a &quot;Type&quot;parameter, as defined above, and the associated pointers.andP;  These data arekept in a table called an &quot;attribute bundle table.&quot;andP;  To be more specific, thecontents of an attribute bundle table are a specification type (Type 1, 2, or3) and three pointers to rendering attributes: a pointer to the colorattribute, a pointer to the bump attribute, and a pointer to the opticattribute.andP;  The attribute bundle table itself can be accessed by using anindex called an &quot;attribute index.&quot;andP;  Texture mapping maps attribute valuesdirectly.andP;  In contrast, attribute mapping maps attribute indices, which inturn are replaced by a specification type and pointers to renderingattributes.andM;* Attribute domainandM;Compound objects typically seen in minerals and rocks have differentattributes intermixed, and distinct coherent regions are distributed over thesurface of the object.andP;  An example of an artificial compound object is onewith metallic seals pasted onto a package that is not metallic by itself.andP;  Anexample of a natural object of this kind is a granite that naturally containsdifferent minerals such as quartz, mice, and feldspar, each of which hasdifferent rendering attributes.andP;  These compound objects are very difficult torepresent realistically.andP;  To solve such difficulties, we introduce what wecall &quot;attribute domains.&quot;andP;  By using attribute domains, compound objects canbe simulated very realistically.andP;  Another purpose of defining attributedomains is to reduce the amount of memory required, taking advantage of areacoherence.andM;As shown in Figure 7, there is a one-to-one correspondence between a surfaceand a rendering attribute in ordinary texture mapping.andP;  In contrast, if wedefine attribute domains between a surface and a rendering attribute, therelation between a surface and the rendering attributes in general becomesone-to-many.andM;With each &quot;attribute domain,&quot; we associate a function called an&quot;attribute-domain definition function&quot; (ADDF).andP;  An ADDF is defined eitherfunctionally or by assigning a black-and-white image called a &quot;triggerpattern.&quot;andP;  Examples of functionally defined ADDFs include a tiledattribute-domain generation function.andP;  A trigger pattern is a rectangularpixel pattern whose content is used as a pointer to an attribute bundletable.andP;  In other words, the contents are used as attribute indices.andM;* Rendering pipeline in RSPandM;Figure 8 shows a so-called &quot;rendering pipeline&quot; or &quot;mapping pipeline.&quot;andP;  Thismapping pipeline includes attribute mapping and other functions, startingwith a process for obtaining an object's position and ending with a processfor obtaining the values of its rendering attributes.andM;Process 1andM;Starting with a screen coordinate value[(S.sub.X, S.sub.y)], this processobtains a modeling coordinate value corresponding to a point on the object ofconcern.andP;  It generally depends on the rendering method used.andP;  For example, inray-tracing we can work in the world coordinate (WC) system directly.andP;  Inother words, it is simply necessary to convert data from world coordinates(WCs) to modeling coordinates (MCs).andP;  The scan-line method usually beginswith screen coordinates (SCs) because their shading calculation often dependson the number of scan lines in the screen.andP;  In these methods, SCs are firstconverted to view coordinates (VCs), then to WCs, and finally to MCs.andP;  Theconversion among multiple coordinate systems can be expressed in ahomogeneous four-by-four matrix.andP;  The output of this process is a point whosevalue is expressed in MCs.andM;Process 2andM;This process depends on the geometry of the object and the definition of amapping function from 3D to 2D geometry.andP;  Even if the geometry of the objectdoes not change, an almost infinite variety of definitions of mappingfunctions may exist.andP;  For instance, let P be a point on a parametricallydefined bivariate bicubic patch, P = (s, t).andP;  A simple mapping function fromP to 2D coordinates (u, v) is established by settings s [right arrow] u, tandlsqb;left arrow] v.andP;  Another mapping function is obtained by first convertingkthe value of P into (x, y, z) according to the bicubic patch definition andthen setting y [right arrow] y, z [right arrow] v, which is equivalent toprojecting the point P to the plane X = C (constant).andP;  The polar coordinatesystem or cylindrical coordinate system can also be used for defining amapping function.andM;Process 3andM;This process converts (u, v) in a 2D real space obtained in Process 2 into(u', v') in a rectangular normalized UV-space.andP;  Mapping parameters such asmapping direction, mapping scale factor, and wraparound control flag areincluded here.andP;  The flexibility of the mapping process is greatly enhanced bya suitable choice or parameters.andM;Process 4andM;The kernel of attribute mapping lies in this process.andP;  Here the values (u',v'), together with the trigger pattern, if any, are given to an ADDF definedon a surface of an object, and an attribute index is produced as output.andM;Process 5andM;In this process, the attribute bundle table is accessed by an attribute indexobtained in the previous process.andP;  By using the contents of the table entrycorresponding to the attribute index, each rendering attribute is obtained.andO;A typical example of an attribute bundle table is shown in Figure 9.andM;Image synthesis toolandM;* Near-real-time displayandM;BSP treeandM;A simple way to display an object is to sort a group of polygons by using therelationship between the view and the normal of a polygon.andP;  However, it itstill computationally expensive, because a slight change in view makes itnecessary to sort all the polygons again.andP;  Since many more applications needview changes than need world-model changes, we decided to use a binary spacepartitioning (BSP) tree, which was proposed by Fuchs et al.andP;  andlsqb;6andrsqb;.andM;A BSP tree is a structure in which processed polygon data are stored.andO;Traversing the BSP tree with a given eye location performs hidden-surfaceremoval in near real time.andP;  The procedure for generating a BPS tree can besummarized as follows:andM;1.andP;  Pick an arbitrary polygon from the polygon list, and assign it as theroot polygon.andM;2.andP;  Process the rest of the polygons to make a front polygon list and a backpolygon list.andP;  If all the vertices of a polygon list and a back polygon list.andO;If all the vertices of a polygon are in front of the root polygon above, thepolygon is added to the front polygon list.andP;  If all the vertices of thepolygon are behind the root polygon, the polygon is added to the back polygonlist.andP;  Otherwise, the polygon is divided into two polygons by the plane onwhich the root polygon is located.andP;  Then the front part of the polygon isadded to the front polygon list, and the back part of the polygon is added tothe back polygon list.andM;3.andP;  Repeat this process recursively for the front polygon list and the backpolygon list until no more polygons are left.andM;Traversing the BSP tree gives the display order of the polygons.andP;  At eachnode of the BSP tree, the dot product of the given viewing vector and thenormal of the partitioning polygon are calculated.andP;  If the dot product isnegative, the eye is in front of the polygon, and the polygons behind thenode polygon are traversed before those in front of it.andP;  If the dot productis positive, the polygons in front of the node polygon are processed first.andO;If the node is a leaf of the BSP tree, the polygon is drawn and then theprocess goes back to traverse the rest of the BSP tree.andP;  This process iscontinued until all the polygons are drawn.andP;  Details of the algorithm for theBSP tree can be found in [6].andM;BSP tree for interactive useandM;One of the most suitable applications of the BSP tree is for interactiveediting of 3D objects.andP;  Here, interactive editing means the editing of boththe shape and the attributes of the 3D objects.andP;  Editing the shape, that is,changing the topology and geometry of the 3D objects, can be done through awire-frame picture.andP;  But editing the attributes of the object is difficult todo in the environment of a wire-frame picture.andP;  Of course, it is possible toedit the attribute by picking an appropriate edge of the object's face andthen entering the appropriate values from a keyboard.andP;  However, this is nolonger interactive.andP;  In an interactive environment, changes in the objects'attributes are reflected in the picture displayed.andP;  When the color ischanged, the color of the shaded image should be changed in real time.andO;Editing the individual color of polygons is a typical application.andM;To take advantage of the interactive capability, the system provides fourstages in the rendering, as shown in Figure 10.andM;First, a user must generate the BSP trees for the objects to be displayed.andO;The user picks an arbitrary node of the body, and then the systemautomatically makes a BSP tree for the polygon data under the body node.andM;After generating the BSP trees, the user must prepare to set severalattributes.andP;  At this stage, appropriate attributes are associated with theBSP tree generated in the previous stage.andP;  The user chooses arbitrary camera,light, environment, and glogal attributes, and can change these attributesindependently of one another.andM;To increase the flexibility with which 3D objects can be editedinteractively, we provide the following interface associated with a polygon'sattributes, which affects the appearance of faces, seals, and edges when theyare displayed.andP;  The color lookup table architecture is assumed in the system.andO;We decided to calculate a set of colors according to the attributes set bythe user, and load the colors to the color lookup table before the displaystage, so that the advantages of the BSP tree and the lookup tablearchitecture are fully utilized.andP;  The dot product of the viewing vector andthe face normal gives the intensity of luminescence.andP;  This value is convertedto an appropriate color table index, depending on the number of color lookuptable entries to which the color is assigned.andM;Thus the system is designed to give the user an opportunity to assign anarbitrary number of color lookup table entries to arbitrary face or sealattributes.andP;  If the user would like to see a subtle change in the color dueto the lighting, a large portion of the color lookup table should be assignedto the color.andP;  If the user does not care much about it, a few lookup tableentries are enough for the purpose.andP;  The above color lookup allocation can bedone through a system's function call.andP;  The user can specify which part ofthe lookup table, the starting entry or the number of the entries, is usedfor a particular face, seal, or edge attribute.andM;After setting up the attribute, the user specifies the designated workstationin the display stage.andP;  The user associates the BSP tree with the workstationwhere a picture of the object represented by the BSP tree is supposed to bedisplayed, and can associate several BSP trees with the workstation if hewants to display more than one object simultaneously.andM;Finally, when the user does not need to display the object of the BSP treeany more, the tree should be deleted to save memory space.andM;* Shading display with shadowandM;Our shaded display with shadow is processed by the Bouknight scan-linealgorithm [1, 2] with the shadow volume algorithm [3, 8].andP;  Basically, theBouknight approach consists of a y-bucket sort on the edges.andP;  The first stepis to create an edge table for all nonhorizontal edges of all polygons.andP;  Eachedge is stored in the table according to its smaller y-coordinate.andP;  Next, theactive edge list is created from the edges that intersect the currentscan-line.andP;  For each scan-line, an x-coordinate sort is run on the activeedge list, which is based on scan-line coherence.andP;  The scan-line depth bufferof active polygons shows the visible one.andM;The addition of shadows vastly complicates the image synthesis process,though it contributes considerably to the realism of a scene and increasesthe perception of depth.andP;  In 1977, F. Crow presented a technique for shadowcasting that was based on shadow volumes [3].andP;  A shadow volume is defined bythe shadow polygon given by planes defined by 1) contour edges and 2) lightsource position.andP;  The contour edges are those edges owned by bothfront-facing polygons and back-facing polygons for each light source.andP;  Theendpoints of the edges from the light source positions are the bounds of thefield of view.andP;  The shadow polygons are added to the ordinary geometricaldata, and do not influence visibility.andP;  However, the depth order of shadowsurfaces and visible surfaces determines the shadowing.andP;  If a visible pointlies within the shadow volume, the point is in shadow.andP;  The shadow-volumemethod allows concave polygons with holes and any number of light sourcesanywhere in 3D space in the scan-line process.andP;  This unconstrainedenvironment is the most efficient feature in other shadow algorithms based ona scan-line method or z-buzzer methods [1, 2, 5, 7].andM;The most efficient feature of our scan-line method is its shadow-polygon datareduction techniques [19].andP;  A shadow-volume algorithm is expensive for imagesynthesis in a complex environment, because it generates a lot of shadowpolygons.andP;  In order to relax the restriction, we have proposed shadow-polygonreduction techniques.andP;  These consist of the use of a coplanar surface (seal)data structure, determination of shadowing polygons by using six-spacesubdivision at a point light source, and techniques for extraction of contouredges.andP;  Use of these techniques makes the shadow-volume algorithm effectivein a complex environment.andM;In order to overcome this aliasing problem, we apply color-blendingtechniques at each scan-line process in the scan-line method.andP;  The color ateach pixel is approximated by the product of the area sums of visiblepolygons.andP;  In order to calculate the precise area of visible polygon at eachpixel, we applied a subscan-line division technique, which divides ascan-line into N subscan-lines:andM;andlsqb;Mathematical Expression Omitted]  (1)andM;Here, [Color.sub.pixel] is the color of a pixel and [L.sub.i] is the lengthof the face on the subscan-line; [C.sub.i] is the color of the face on thesubscan-line, and N is the number of subscan-lines in a scan-line.andM;* High-quality image displayandM;A ray-tracing method gives RSP the function of high-quality image display.andO;It enables transparency, translucency, refraction, reflection, and shadowingto be used as standard functions.andM;In ray-tracing methods, a ray is traced from the eye through each pixel intothe polygonal data environment.andP;  At each polygon struck by the ray, areflected and/or a refracted ray can be generated.andP;  The rays are tracedrecursively to establish what polygons they intersect, and an intersectiontree is constructed for each pixel.andP;  The final pixel intensity is determinedby traversing the tree and computing the intensity contribution of each nodeaccording to the shading model.andM;There is usually a trade-off between high-quality image display and highperformance.andP;  Whitten [9] shows that 75 percent of the total time is spend oncalculating intersections between rays and objects for simple scenes.andP;  Toreduce this burden, we employ a &quot;voxel&quot;-based method [11] withuser-controllable parameters such as the number of voxels along eachcoordinate axis and the voxel size (Figure 11).andP;  A voxel is an orthogonalcuboidal cell, which can be thought of as a 3D extension of a raster grid,with pixels becoming voxels.andP;  The voxel data structure is constructed beforethe intersections between rays and objects are calculated.andP;  Each cell hasinformation on which polygons are involved in the cell.andP;  The 2DDDA(three-dimensional digital differential analyzer [11]), which is like a 3Dline generator, is a basic tool for traversing voxel data structures.andP;  It isapplied in the direction of the ray, and continues pursuing the ray in thesame direction until some object is intersected or until it leaves the voxeldomain.andP;  The calculation of motions from one cell to another is achieved byincremental logic, without any multiplication or division.andM;A salient feature of our ray-tracing method is that it incorporates attributemapping, using a full set of attribute data assigned to each face.andP;  Attributemapping coupled with ray-tracing has the capability of producing extremelyhigh-quality pictures.andP;  Supersampling coupled with ray-tracing also enhancesthe image quality.andP;  The user can specify the degree of supersampling withparameters provided by rendering condition data.andM;ApplicationsandM;In this section, we describe some applications of RSP.andM;Visual simulation has become popular in architectural CAD.andP;  It is veryimportant to understand the potential appearance of new buildings, or theview, lightness, and shadows of the interior rooms.andP;  Figure 12 shows asimulation of a landscape by the list-priority method.andP;  The user can rotatethe view, pick a visible polygon, and change the attributes on the screeninteractively.andP;  Figures 13 and 14 show the visual effect created by changingfrom carpet to polished tile patterns on the floor.andP;  They are respectivelyrendered by the scan-line method and the ray-tracing method.andP;  Figure 15 showsan example of image composition functions.andP;  It combines a computer-generatedimage and a photographed picture.andP;  The photographed foreground picture isextracted by image segmentation by thresholds, and overlaid on thecomputer-generated picture.andP;  Figure 16 shows an example of attribute mapping.andO;Attribute mapping is used at the transoms near the ceiling.andP;  Each transomconsists of a polygon on which transparency and color image information ismapped.andM;The spatial shape of molecular orbital functions plays an important role inallowing researchers to understand the nature of chemical reactions, as thefrontier orbital theory [20, 21] and Woodward-Hoffmann theorem [22, 23] haveshown.andP;  If polyhedral approximation is done in molecular orbital functions,the user can rotate, zoom, shift, and overlay equivalued surfaces.andP;  Theoverlay of molecular orbital functions of two molecules is useful forrecognizing reaction sites.andP;  Figure 17 shows an equivalued surface of theelectron density of [C.sub.2.H.sub.5OH].andP;  The electron density values are 0.1and 0.125 andlsqb;bohr.sup.-3andrsqb;.andM;Three-dimensional visualization has become important in helping physicians tounderstand the complex anatomy of the human body.andP;  If the triangulation of aconstant-density surface by 3D computer tomography is achieved, the resultingmodels can easily be displayed with RSP.andP;  Figure 18 shows some results ofcomputer tomography, with the soft-tissue surfaces displayed in transparentform.andM;The polyhedral data of Figures 17 and 18 are generated by the tetrahedralgrid method [24, 25].andP;  Figures 13, 14, 15, and 16 were rendered with aresolution of 800 by 800 pixels.andP;  Figures 13 and 15 are generated by twosubscan-lines, and Figure 16 by one subscan-line.andP;  The former is moreanti-aliased than the latter.andM;ConclusionsandM;We have described data visualization techniques for use with ageneral-purpose renderer.andP;  The polygonal model approach was proposed for easyand economical implementation of flexible interactive manipulation, real-timeanimation display, and high-quality image display.andP;  When the number ofpolygons becomes large, there may be a memory problem in an applicationprogram.andP;  But we believe that in this case the problem can be processedcompletely in a large virtual-memory environment.andP;  In particular, theenhancement of program addressability [26] will overcome the problem.andM;In order to satisfy the requirements of all applications, we provide threerendering methods.andP;  The user can select the most suitable of them for theimage generation process.andP;  This allows stepwise refinement of the imagequality.andP;  Texture mapping is a powerful tool for realistic image synthesis incomputer graphics.andP;  As a generalization of texture mapping, we have proposed&quot;attribute mapping.&quot;andP;  By virtue of ADDF, it can generate more realisticimages and run more efficiently than ordinary texture mapping for surfaceswith complex textures.andM;Currently, we are continuing to improve RSP, and are developing aninteractive graphics environment.andP;  A user-friendly interactive graphicsenvironment will help novice users and nonprogrammers to generate pictureseasily.andP;  We also aim to develop higher-quality rendering methods, which willbe able to support mutual interreflection of light, color bleeding, penumbra,and realistic texture generation.andM;Akio Doi CIM System Development, IBM Yamato Laboratory, IBM Japan Ltd.,andO;Shimotsuruma 1623-14, Yamato-shi, Japan.andP;  Mr. Doi received his B.S.andP;  and M.S.andO;degrees in civil engineering from Kobe University in 1980 and 1982.andP;  Hejoined the Tokyo Scientific Center in 1982.andP;  In 1986, with Dr. Akio Koide, hedeveloped a scientific visualization tool using tetrahedral elements, and hasbeen improving it.andP;  Mr. Doi has contributed to the development of theRendering Subroutine Package, in particular a scan-line method with shadowpolygon generation algorithms.andP;  His research interests include computergraphics, scientific visualization, and application programming interfaces.andO;He is a member of the IEEE Computer Society and the Computer GraphicsSociety.andM;Masaki Aono Tokyo Scientific Center/Tokyo Research Laboratory, IBM JapanLtd., 5-19 Sanban-cho, Chiyoda-ku, Tokyo 102, Japan.andP;  Mr. Aono received hisB.S.andP;  and M.S.andP;  degrees in information science from the University of Tokyoin 1981 and 1984.andP;  He published a paper entitled &quot;Botanical Tree ImageGeneration&quot; in the IEEE Computer Graphics and Applications journal with Prof.andO;Kunii of the University of Tokyo in 1984.andP;  Since joining the Tokyo ResearchLaboratory in 1984, Mr. Aono has worked on computer graphics projects.andP;  Hedeveloped a new texture mapping called &quot;attribute mapping&quot; and hascontributed to the development of the Rendering Subroutine Package.andP;  Hisresearch interests include computer graphics, computational geometry, andphysically and biologically based modeling.andP;  Mr. Aono is a member of the IEEEComputer Society and the ACM.andM;Naoki Urano Tokyo Scientific Center/Tokyo Research Laboratory, IBM JapanLtd., 5-19 Sanban-cho, Chiyoda-ku, Tokyo 102, Japan.andP;  Mr. Urano received hisB.S.andP;  and M.S.andP;  degrees in computer science from Rensselaer PolytechnicInstitute in 1981 and 1984.andP;  Since joining the Tokyo Research Laboratory in1984, he has worked on computer graphics projects.andP;  He developed a rule-basedanimation system called ROMA in 1986, and has contributed to the developmentof the Rendering Subroutine Package.andP;  Mr. Urano's interests include 3Dinteractive graphics, geometric modeling, and computer graphicsstandardization.andP;  He is a member of the IEEE Computer Society and the ACM.andM;Kazutoshi Sugimoto Tokyo Scientific Center/Tokyo Research Laboratory, IBMJapan Ltd., 5-19 Sanban-cho, Chiyoda-ku, Tokyo 102, Japan.andP;  Mr. Sugimoto is amanager of Applied Graphics at the Tokyo Research Laboratory.andP;  He receivedhis B.S.andP;  and M.S.andP;  degrees in applied physics from Waseda University in 1976and 1978, joining the Tokyo Scientific Center in 1978.andP;  From 1979 to 1982, heparticipated in a partnership program on a data processing system for landuse, in which he developed a regional information system which has beeninstalled by local and national governments.andP;  In 1984, as a CIP of IBM Japan,Mr. Sugimoto developed a raster-to-vector conversion software (GIFTS) and aPC version of GIFTS (MicroGIFTS) that became one of the main functions of theIBM PC CAD in 1989.andP;  His research interests include computer graphics,computer vision, image processing, and multimedia applications.andP;  He is amember of the ACM.andM;ReferencesandM;andlsqb;1andrsqb; W. J. Bouknight and K. Kelly, &quot;An Algorithm for Producing Half-ToneComputer Graphics Presentation with Shadows and Movable Light Sources,&quot; AFIPSConf.andP;  Proc.andP;  36, 1-10 (1970).andM;andlsqb;2andrsqb; W. J. Bouknight, &quot;A Procedure for Generation of Three-DimensionalHalf-Toned Computer Graphics Presentations,&quot; Commun.andP;  ACM 13, No.andP;  9, 527-536(1970).andM;andlsqb;3andrsqb; F. C. Crow, &quot;Shadow Algorithm for Computer Graphics,&quot; ACM Proc.andP;  SIGGRAPH11, No.andP;  2, 242-248 (1977).andM;andlsqb;4andrsqb; P. Atherton, K. Weiler, and D. Greenberg, &quot;Polygon Shadow Generation,&quot;ACM Proc.andP;  SIGGRAPH 12, No.andP;  3, 275-281 (1978).andM;andlsqb;5andrsqb; L. Williams, &quot;Casting Curved Shadows on Curved Surfaces,&quot; ACM Proc.andO;SIGGRAPH 12, No.andP;  3, 270-274 (1978).andM;andlsqb;6andrsqb; H. Fuchs, G. D. Abram, and E. D. Grant, &quot;Near Real-Time Shaded Display onRigid Objects&quot; ACM Proc.andP;  SIGGRAPH 17, 65-72 (1983).andM;andlsqb;7andrsqb; L. S. Brotman and N. I. Badler, &quot;Generating Soft Shadows with a DepthBuffer Algorithm,&quot; IEEE Computer Graph.andP;  andamp; Appl.andP;  4, 5-12 (1984).andM;andlsqb;8andrsqb; P. Bergeron, &quot;A General Version of Crow's Shadow Volumes,&quot; IEEE ComputerGraph andamp; Appl.andP;  6, 17-28 (1986).andM;andlsqb;9andrsqb; T. Whitted, &quot;An Improved Illumination Model for Shaded Display,&quot; Commun.andO;ACM 23, 270-274 (1980).andM;andlsqb;10andrsqb; A. S. Glassner, &quot;Space Improved Subdivision for Fast Ray Tracing,&quot; IEEEComputer Graph.andP;  andamp; Appl.andP;  4, 15-22 (1984).andM;andlsqb;11andrsqb; A. Fujimoto, T. Tanaka, and K. Iwata, &quot;ARTS: Accelerated Ray-TracingSystem, IEEE Computer Graph.andP;  andamp; Appl.andP;  6, 16-26 (1986).andM;andlsqb;12andrsqb; P. Sabella, &quot;A Rendering Algorithm for Visualizing 3D Scalar Fields,&quot;ACM Proc.andP;  SIGGRAPH 22, No.andP;  4, 51-58 (1988).andM;andlsqb;13andrsqb; C. Upson and M. Keeler, &quot;V-BUFFER: Visible Volume Rendering,&quot; ACM Proc.andO;SIGGRAPH 22, No.andP;  4, 59-64 (1988).andM;andlsqb;14andrsqb; R. A. Drebin, L. Carpenter, and P. Hanrahan, &quot;Volume Rendering,&quot; ACMProc.andP;  SIGGRAPH 22, No.andP;  4, 65-74 (1988).andM;andlsqb;15andrsqb; M. F. Cohen, S. E. Chen, J. R. Wallace, and D. P. Greenberg, &quot;AProgressive Refinement Approach to Fast Radiosity Image Generation,&quot; ACMProc.andP;  SIGGRAPH 22, No.andP;  75-84 (1988).andM;andlsqb;16andrsqb; Understanding graPHIGS, Order No.andP;  SC33-8102, 1989; available throughIBM branch offices.andM;andlsqb;17andrsqb; M. Aono and T. L. Kunii, &quot;Attribute Mapping,&quot; Research ReportTR-87/1010, IBM Tokyo Research Laboratory, 1986.andM;andlsqb;18andrsqb; M. Aono, &quot;Methodology of Attribute Mapping and Its Applications,&quot; JIPSProc.andP;  Graph.andP;  andamp; CAD, pp.andP;  31-38 (1988).andM;andlsqb;19andrsqb; A. Doi et al., &quot;Some Techniques for F. Crow's Volume Algorithm,&quot; IPSJProc.andP;  38th Annual Convention (1989).andM;andlsqb;20andrsqb; K. Fukui, &quot;An MO-Theoretical Illumination for the Principle ofStereoselection,&quot; Bull.andP;  Chem.andP;  Soc.andP;  Jpn.andP;  39, 498-503 (1966).andM;andlsqb;21andrsqb; K. Fukui, &quot;Recognition of Stereochemical Paths by Orbital Interaction,&quot;Acc.andP;  Chem.andP;  Res.andP;  4, 57-64 (1971).andM;andlsqb;22andrsqb; R. B. Woodward and R. Hoffmann, &quot;Stereochemistry of ElectrocyclicReaction,&quot; J. Amer.andP;  Chem.andP;  Soc.andP;  87, 395-397 (1965).andM;andlsqb;23andrsqb; R. B. Woodward and R. Hoffmann, &quot;Selection Rules for SigmatrophicReaction,&quot; J. Amer.andP;  Chem.andP;  Soc.andP;  87, 2511-2513 (1965).andM;andlsqb;24andrsqb; A. Koide, A. Doi, and K. Kajioka, &quot;Polyhedral Approximation Approach toMolecular Orbital Graphics,&quot; J. Molec.andP;  Graph.andP;  4, 149-156 (1986).andM;andlsqb;25andrsqb; A. Doi and A. Koide, &quot;An Efficient Method of Triangulating Equi-ValuedSurfaces by Using Tetrahedral Cells,&quot; J. IEICE Trans.andP;  e-74, 214-224 (1991).andM;andlsqb;26andrsqb; B. R. Aken, Jr., &quot;Large Systems and Enterprise Systems Architecture,&quot;IBm Syst.andP;  J. 28, No.andP;  1, 4-14 (1989).andM;(1) CADAM is trademark of CADAM, Inc.andM;(2) CATIA is a trademark of Dassault Systems Corporation.andM;(3) CAEDS is a registered trademark of International Business MachinesCorporation.andM;(4) MVS/SP and MVS/XA are trademarks of International Business MachinesCorporation.andM;(5) AIX is a registered trademark of International Business MachinesCorporation.andM;(6) GDDM and graPHIGS are trademarks of International Business MachinesCorporation.andO;</TEXT></DOC>