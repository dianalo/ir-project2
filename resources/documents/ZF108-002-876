<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-002-876  </DOCNO><DOCID>08 002 876.andM;</DOCID><JOURNAL>AI Expert  Jan 1990 v5 n1 p48(8)* Full Text COPYRIGHT Miller Freeman Publications 1990.andM;</JOURNAL><TITLE>An introduction to model-based reasoning.andO;</TITLE><AUTHOR>Fulton, Steven L.; Pepe, Charles O.andM;</AUTHOR><SUMMARY>Rule-based expert systems are inadequate for such complexapplications as critical-system diagnostics because thesensor-based information they receive may not be consistent andbecause the sensors themselves may fail.andP;  The rules used also maynot cover all possible failures.andP;  Model-based expert systems offeran alternative that simulates the structure and function of themachine being diagnosed.andP;  A special function in a model-basedshell simulates a failed component.andP;  Other modules insert andpropagate specific commands for monitoring and diagnosis.andP;  Themodel-based system can diagnose sensor failure as well ascritical-system failure and is not threatened by modification ofthe machine.andP;  NASA is investigating model-based expert systems fordiagnosing faults in space vehicles.andM;</SUMMARY><DESCRIPT>Topic:     DiagnosticsExpert SystemsModeling of Computer SystemsKnowledge-Based SystemsProcess ControlRule-Based Systems.andO;Feature:   illustrationprogramgraph.andO;Caption:   Model-based reasoning system. (program)Full adder. (graph)Full-adder knowledge base. (program)andM;</DESCRIPT><TEXT>an introduction to MODEL-BASED REASONINGandM;Thousands of electrical and mechanical operations require accuratecoordination to launch a space shuttle mission.andP;  The brevity of the launchwindow allows little time for troubleshooting when an anomaly is detected ina critical system during countdown.andP;  Consequently, for the last six yearsNASA has been researching intelligent ground-support systems at the KennedySpace Center in Florida that can diagnose their own failures and takeappropriate corrective action.andP;  Rule-based expert systems have not beenwidely incorporated because they can't provide comprehensive diagnosticcoverage when confronted with an abundance of sometimes errant sensor data.andO;This article will present some of the problems making rule-based expertsystems ill-suited to these diagnostic tasks and will present the model-basedapproach under development.andM;THE PROBLEM WITH RULESandM;Now that their novelty is wearing off, it's apparent that rule-based expertsystems were never particularly suited to industrial-monitoring applications.andO;Before you accuse us of AI blasphemy, let's examine several of the moreblatant shortfalls within the domain of fault diagnosis.andP;  In our situation,we diagnose faults within the shuttle environmental-control system, but thedifficulties we encounter apply equally well to general manufacturingenvironments.andM;A typical rule-based industrial expert system must interact with a mass ofsensor information, which may or may not be holistically consistent.andP;  In theevent of an industrial machinery failure, the expert system uses the rules inthe knowledge base to form an association between the set of sensor data anda fault.andP;  This method is commonly called an associational diagnosis due tothe mapping performed between faults and system states.andM;But before performing this mapping, the question &quot;Is the sensor datacorrect?&quot; must be answered.andP;  Sensors can and do fail, triggering alarms thatindicate malfunction when the system is actually nominal.andP;  Sensorverification is the first of many hurdles to jump when generating anindustrial expert system.andP;  A conventional verification method creates rulesexploiting sensor dependencies to verify that each sensor has a valueconsistent with other &quot;related&quot; sensors.andP;  According to current estimates, upto three-quarters of industrial expert-system rules do nothing more thanverify sensor accuracy.andM;When we detect a broken sensor, great difficulty arises if we continuediagnosing other failures, because typical rule-based systems do not degradegently when sensors fail (because the mapping is dependent on a complete andaccurate set of sensor data).andP;  Multiple sensor failure greatly compromisesthe reliability of the generated diagnosis.andM;However, most human experts can make an educated guess in light of partialdata, even going so far as recognizing when they lack the informationnecessary to make an intelligent decision.andP;  Generating rules to compensatefor even a subset of the possible partial data situations is an onerous taskthat catastrophically increases the required number of rules.andP;  It is highlyimprobable such an effort will ever provide complete scenario coverage, whichis essential in dangerous situations such as loading liquid oxygen into theshuttle's external fuel tank.andM;Let's assume the sensor verification issue has been properly cared for so wecan take a closer look at the completeness of the rules performing the faultdiagnosis.andP;  Where do these rules come from and how sure are we that theycover all possible failures?andP;  An expert must predict how objects might failand how the sensors would react to those failures.andP;  As the number of objectsin the system increases, it becomes very difficult for the expert to predictaccurately what state each sensor will be in for each possible failure.andM;A much simpler method is to generate the faults and observe the effect theyhave on the sensors.andP;  Even in this situation, the task of generating andtesting for faults cannot cover all possible scenarios.andP;  In some cases, suchas a nuclear reactor, it is impossible to generate every fault safely merelyto record sensor data.andP;  Not only will the generated rules encompass only asubset of all possible faults, but they probably will not include some of themost obvious ones.andP;  (The obvious has a way of becoming obscure whenpredicting how an object can fail.)andM;But suppose by some stroke of luck a complete table is generated listing allpossible faults and the observed sensor states.andP;  Suppose rules are written toverify sensor data and to completely compensate for errant sensor data.andP;  Thissystem would become obsolete quickly in the real world due to system designchanges; one new sensor in a critical location could require reworking mostof the existing rules.andP;  In a dynamic environment, the rule-based system mustconstantly struggle to stay abreast of modifications and changes in machineconfiguration.andM;THE MODEL-BASED APPROACHandM;What's the solution?andP;  Does AI have any role in diagnosing critical systems?andO;NASA grappled with these issues before examining a method termed model-basedreasoning, or model-based expert systems.andP;  These systems differ fromrule-based systems in that they contain a model simulating the structure andfunction of the machinery under diagnosis.andP;  Instead of reasoning only fromobservable values, these systems reason from first principles: they know themachinery's internal processes and can determine which state the machine isin to generate the observed values, rather than remembering a &quot;canned&quot;association between sensor values and system state.andM;As a machine operates and sends the model-based system its sensor data, asimulation generates predicted sensor values.andP;  The observed sensor values arecompared with the predicted simulation values, setting off an alarm wheneverthe actual value does not lie within the predicted value's tolerance.andP;  Analarm forces a diagnosis and could generate control commands to prevent thesystem from entering a dangerous state.andM;When an alarm is generated, we assume only one component has failed, which iscalled the &quot;single point of failure&quot; assumption.andP;  This assumption may not beintuitive, but as we look at time in increasingly minute segments, we canalways show that no two failures are truly simultaneous.andM;In the code for the simplified model-based shell, shown in Listing 1, afunction called fail-object manually simulates a failed component.andP;  In thehardware, a failed component will be detected through a reading from ahardware interface module, the electrical device that converts a sensorreading to machine-understandable form.andP;  An error is generated in our systemby altering the real-world sensor values, causing a discrepancy between thesimulation values and the observed sensor values.andM;For example, to simulate a blown fuse, we might turn all electrical sensorsthat measure something receiving power through that fuse.andP;  In diagnosing thisfailure, the model-based system will reason about what could go wrong withthe simulated model's structure to yield the same functional results as theobserved (real-world) sensor values.andP;  In this manner, we separate thestructural portion of a system from its function; our system represents eachindividual system component with all its connections and transfer functionsdescribing correlations between the connections.andM;Some systems use only a mathematical model, rather than a component one, topredict system function.andP;  A mathematical model could be constructed to modelthe function of a grandfather clock, taking into account the oscillatorlength, gear size, and so on.andP;  A numeric model could predict the position ofthe hands after a specific time interval and, with more complexity, mighteven give a clue as to why the clock was too fast or slow.andM;In contrast, a component model would contain a functional description of eachclock component and its interactions with other components.andP;  As the clockticked, each component would alter itself, then propagate its final positionto its neighbors, allowing them to alter their positions.andP;  In this manner theindividual processes involved in running the clock, rather than merely afunctional description of the overall activity, can be examined.andM;KNOWLEDGE REPRESENTATIONandM;Let's examine a model-based shell.andP;  The one described here diagnoses logiccircuits using a simplified knowledge-representation scheme.andP;  The knowledgebase is a collection of frames, and each frame has a name and a set ofslot-value pairs.andP;  The knowledge base is broken into a generic class leveland an instance level.andP;  The frames in the class level represent a kind ofobject or component.andP;  An and-gate frame would look like:andM;(deframe AND-GATE (ako logic-gate) (inputs (in1 in2) (outputs (out1))(output-function (and in1 in2)))andM;This frame shows that an and-gate is a-kind-of logic-gate; it has two inputscalled in1 and in2, one output called out1, and its transfer or outputfunction is the logical and of its two inputs.andP;  The frame does not representany particular and-gate, but a general description for all the and-gates inthe knowledge base.andP;  The deframe macro builds the frame structure as aproperty list of the object under the property frame.andP;  An example of aninstance level frame corresponding to the and-gate frame could be:andM;(deframe AND-GATE-1 (aio and-gate) (inputs (in1 command-1) (in2 not-gate-1))(outputs (out1 or-gate-1)))andM;This frame represents a particular and-gate in the schematic.andP;  The aio slotdescribes what type of object this component is an-instance-of (aio).andP;  Theinputs and outputs slots show the structure or connectivity of the knowledgebase.andP;  The inputs of and-gate-1 come from command-1 and not-gate-1 and theoutput goes to or-gate-1.andP;  Note that we have restricted objects in thisknowledge base to have only one output.andP;  As the knowledge base is loaded, thefunctionality (or output-function slot) of the object will be inherited fromits aio object and become part of the structure of the instance level frame.andO;The separation of the structure and function allows for a moreobject-oriented approach and easier knowledge-base generation.andP;  At run timeeach instance level frame will essentially model a particular component'sbehavior.andM;Along with the components, sensors and commands must be represented.andP;  (Bycommand we mean a signal representing something such as &quot;turn the pump on&quot; or&quot;open a valve.&quot;)  The directional flow of information in the system is fromthe commands through the components to sensors.andP;  A frame representing acommand contains no inputs or output function slots: its only function is tosend its value to its connected components.andP;  A sensor has no outputs; itsvalue is the value of its one input.andM;FULL-ADDER EXAMPLEandM;We have chosen a full adder to demonstrate our model-based shell's monitoringand diagnosing capabilities.andP;  Figure 1 shows 13 logic-gate components, threeinput commands and five measurements.andP;  Two pseudoobjects, xor-gate-1 andxor-gate-2, are also shown.andP;  These do not represent actual components in theschematic, but components grouped together because of their functionality.andO;This grouping occurs because an xor-gate can be functionally replaced withand, not, and or gates, as shown in the dashed boxes.andP;  This componentgrouping allows diagnosing at different levels.andM;The components in the full-adder knowledge base (shown in Listing 2)represent what we call the model.andP;  The real world in this case is thehardware of a full adder wired as in our schematic.andP;  The essence of ourmodel-based expert-system approach is to generate a model that acts as closeto the real world as possible, except when a measurement or component in thereal world fails.andP;  When the real world begins to act differently from themodel, we detect the discrepancy and diagnose the change using the model.andO;The diagnoser tries to determine which component could have failed,explaining how the real world is currently operating.andP;  Table 1 shows thelogic table for this system in nominal operation.andM;MONITORINGandM;A model-based approach not only requires a description of a system in thestatic sense; it also requires a simulation of a dynamic system.andP;  Acomponent's output value will change when at least one of the componentsconnected to its inputs changes.andP;  We term the flow of changing output values&quot;constraint propagation.&quot;andP;  The propagation starts with the issuing of acommand; the function insert-command is called with the command name and itsnew value.andP;  The value cell of the command is set to the new value and thefunction propagate is called recursively on all the objects the currentobject is connected to.andP;  The propagation stops at the sensors because noobjects are downstream of a sensor.andM;All the inputs are initially set to nil.andP;  If we were to issue the command(insert-command 'command-1 t), command-1 would be set to true and propagateto and-gate-1.andP;  Before the new value of command-1 gets to and-gate-1, the in1input is nil because it was connected to command-1.andP;  Input in2 is truebecause it is connected to output of not-gate-1, the logical not of command-2currently nil.andP;  The new value of command-1 changes the in1 input ofand-gate-1 to be true.andP;  Now both inputs are true turning its output to betrue.andP;  The new value of and-gate-1 is then propagated to meas-4and-or-gate-1.andP;  meas-4 gets a new value but doesn't propagate anywhere.andP;  Thenew output value of and-gate-1 changes the in1 input of or-gate-1 to be trueand or-gate-1 reevaluates its output to be true.andM;The propagation continues through all the objects or-gate-1's output isconnected to and through all possible downstream objects andsensors ofcommand-1.andP;  As a result of issuing command-1 to be true, the sensors meas-1,meas-2, and meas-4 are true.andP;  A new set of sensor readings now describes thesystem.andP;  By comparing the sensor readings of the model with the real-worldsensor readings, the constraint propagation algorithm provides a monitoringcapability.andM;DIAGNOSISandM;A natural extension of the monitoring algorithm is the ability to diagnosefailures or component malfunctioning in the real world.andP;  A failed componentor sensor will produce an errant sensor reading in the hardware, and thecomparison of the observed and the model-produced sensor values will generatea discrepancy.andP;  The system then uses that discrepancy (which could be morethan one discrepant sensor) and collects all the objects that arestructurally upstream of one of the discrepant sensor readings.andP;  Since weassume a single point of failure, any discrepant sensor reading can be usedto collect the suspects.andM;The modeling system then checks each of the collected upstream relatives ofthe discrepant sensor by failing that component in the model and propagatingthe change throughout the system.andP;  Failing a discrete component simply meanschanging its output to be the opposite of its current value: t ==andgt; nil or nil==andgt; t.andP;  After the propagation is complete, the real and model worlds arecompared again; if the sensor readings match, the component is considered oneof the final suspects.andM;It is beyond this article's scope to discuss the connection of hardware tothe software.andP;  We simulate the connection by keeping a global list of theobserved sensor values in *real-world*.andP;  We keep the model-generated sensorvalues in *model-world*.andP;  A failed component or sensor in the hardware issimulated by changing the appropriate sensor values in *real-world*.andM;Having set command-1 to be true, if we now fail and-gate-1 by calling(fail-object 'and-gate-1 nil), this will set meas-1, meas-2, and meas-4 to benil in *real-world*; those same sensors are true in *model-world*.andP;  To detectthe discrepancy and perform a diagnosis, call (diagnosis).andP;  The diagnoseruses two levels of hierarchical structure.andP;  If possible, the system will tryto diagnose at the functional-grouping level rather than the component level.andO;The system responds with a listing of the discrepant sensor readings (meas-1meas-2 meas-4) and returns the suspect list, (xor-gate-1).andM;This diagnosis level at the functional grouping is faster and the diagnosismay be sufficient for the user because the xor-gate-1 may be replaceable as aunit.andP;  However, it may be desirable to know what component failed withinxor-gate-1.andP;  This information is acquired by calling (diagnoser 'xor-gate-1)and the system returns the suspect list (not-gate-1 and gate-1).andP;  Not enoughsensors exist for the system to clear not-gate-1 as a suspect.andP;  Hadnot-gate-1 failed, it would have produced the same discrepant sensorreadings.andM;A few extensions might be necessary to build a more robust model-based systemusing these methods.andP;  For example, you might want to allow for analogobjects.andP;  The only difficulty analog objects introduce is choosing a value atwhich the object might have failed.andP;  This problem is not insurmountable; itsimply requires the ability to invert algebraic equations.andP;  Another usefulextension is controlling real-world objects.andP;  With only minor modificationsto the diagnosing algorithm, a system can be built to monitor, diagnose, andcontrol.andP;  More challenging extensions include allowing for feedback andrecovery from failed objects.andM;BENEFITSandM;Rule-based expert systems are cumbersome on the shop floor.andP;  They requireregular modification, maintenance, and attention from an expert-systemexpert.andP;  Within the domain of mechanical-fault diagnosis, the model-basedexpert system can provide a comprehensive and easily maintained alternativeto the rule-based approach.andP;  One specific improvement is the model-basedsystem's ability to handle sensor failure.andM;Model-based reasoning provides the ability to diagnose sensor failure in thesame way as diagnosing the failure of any other system component.andP;  While arule-based system may use three-quarters of its rules to verify sensor data,the model-based system does not require any special sensor verification.andP;  Nordoes the system's designer need to look for sensor dependencies to createverification rules; the model-based system will automatically exploit sensorrelationships since it contains a physical description of componentconnectivity.andM;Since rules are not created (just a list of components and their functions),machine modification no longer poses a threat to diagnostic ability.andP;  Thecomponent knowledge base simply is modified to reflect the changes, a task nomore difficult than altering a set of schematics -- a dramatic contrast tothe rule-based system.andM;Of even greater contrast is the model-based system's ability to detectnonintuitive anomalies.andP;  A traditional expert system relies on expertexperience likely to be deepest concerning common failures; the uncommonfailure is doomed to obscurity and may not be properly diagnosed.andP;  On theother hand, a model-based system can reason and diagnose even the uncommonfailure.andP;  To reason about a machine, it is only logical for an expert systemto have some idea about how it works.andM;MODEL-BASED APPROACHESandM;Our approach has been to sell the idea of model-based reasoning as analternative to rule-based systems.andP;  However, the model-based approach is notthe appropriate choice for all applications: if you can't create a completeand accurate model of your system, stick with rules to perform diagnosis.andO;Since we do not have a complete and accurate model of the human body, itwould be foolish to use a model-based approach to diagnose diseases.andO;Similarly, if the system is constantly changing in radical ways (such aslong-term weather forecasts), it is impossible to generate an accurate modeland thus is a bad candidate for model-based reasoning.andM;In addition, the model-based approach requires sensors in the system underdiagnosis.andP;  If your system precludes the presence of sensors, this approachwill be futile.andP;  Imagine calling an air conditioner repairer and saying theunit is not functioning, but you can only say the room temperature is 95degrees.andP;  A model-based reasoning system, like a human expert, needssufficient information to generate a diagnosis.andM;For our applications, however, we have found that model-based reasoning worksand is the preferred method for performing diagnosis.andP;  It has beenincorporated in an expert system at the Kennedy Space Center to diagnosefaults within the shuttle's liquid oxygen loading system and in a system todiagnose and control an environmental control unit.andP;  Researchers areexamining the optimal structure of the knowledge base and expanding theability to model time-dependent objects.andM;NASA is seeking to generate knowledge bases automatically from CAD drawings.andO;This research could widen expert-system applications: imagine thepossibilities for AI if we could generate expert systems from the schematicsdescribing the machine to be diagnosed.andM;Many hurdles are left to jump, but model-based systems are finding theirniche in the expert-system marketplace.andP;  With time, they may well make expertsystems as common as television.andM;REFERENCESandM;Davis, R., and W. Hamscher.andP;  &quot;Model-based Reasoning: Troubleshooting.&quot;andP;  InShrobe, H.E.andP;  (ed.) Exploring Artificial Intelligence: Survey Talks from theNational Conferences on Artificial Intelligence, San Mateo, Calif.: MorganKaufmann, 1988.andM;Forbus, K.andP;  &quot;Intelligent Computer-Aided Engineering,&quot; AI Magazine, Fall 1988,pp.andP;  23-36.andM;Scarl, E., J. Jamieson, and C. Delaune.andP;  &quot;Diagnosis and Sensor ValidationThrough Knowledge of Structure and Function.&quot;andP;  IEEE Transactions on Systems,Man, and Cybernetics 17(3): 360-368.andO;</TEXT></DOC>