<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF109-582-905  </DOCNO><DOCID>09 582 905.andM;</DOCID><JOURNAL>Hewlett-Packard Journal  Oct 1990 v41 n5 p21(10)* Full Text COPYRIGHT Hewlett Packard 1990.andM;</JOURNAL><TITLE>HP IVI application program interface design. (HP InteractiveVisual Interface)</TITLE><AUTHOR>Munsch, Pamela W.; Otsuka, Warren I.; Thomsen, Gary D.andM;</AUTHOR><SUMMARY>Leveraging features from current user interface and softwaredesigns was one of the primary goals of the HP IVI project.andP;  Thesewere to be blended into the feature set and design of thefunctions of the application program interface (API).andP;  Conceptsfrom graphics packages, window technology, widgets, Xt Intrinsics,and object-oriented design were used.andP;  X, Xt Intrinsics, andwidgets form the basis for API's input handling model.andP;  Variousgraphics packages supply the coordinate system concepts andtechniques in the API functions for drawing graphics objects,windows, and widgets on the display.andP;  Object-oriented architectureis used.andP;  There are three layers to the architecture of the API:the API function layer, the API object layer, and the devicedependent layer.andP;  The internal design of the API is a successfulblend of graphics, windowing, X toolkit, widget, andobject-oriented technologies.andM;</SUMMARY><DESCRIPT>Topic:     Object-Oriented ProgrammingUser InterfaceSoftware EngineeringGraphical User InterfaceProduct Development.andO;Feature:   illustrationchart.andO;Caption:   Software technologies used in HP IVI. (chart)The API input loop. (chart)The API server object event handling loop. (chart)andM;</DESCRIPT><TEXT>HP IVI Application Program Interface DesignandM;ONE OF THE MAIN goals of the HP Interactive Visual Interface (HP IVI) projectwas to leverage features from current user interface and software designtechnologies and blend the best of each into the feature set and design ofthe application program interface (API) functions.andP;  In doing so, the projectteam investigated windowing, graphics, the X toolkit (Xt Intrinsics),widgets, and object-oriented design.andP;  This article discusses the featuresused from each of these technologies, and how these features are incorporatedinto the internal design and implementation of the API functions (see Fig.andO;1).andM;WindowingandM;To hide the complexities of the X Window System [1,2] from HP IVI applicationdevelopers, the API provides a layer of simplifying software over X.andP;  Theonly X features left exposed are those that we thought the applicationdeveloper must have access to, or that cannot be layered over.andP;  Even withthis layer of software, the user still has access to X functions.andP;  Forexample, X provides an event called ConfigureNotify that tells theapplication that a window has been resized, moved, or changed in some way.andO;The API handles resizing the window object when this event occurs but letsthe application decide if all the objects in the window should be resized tomatch the new window's size, or if the objects should maintain their sizesand only the coordinate system of the window should be adjusted.andP;  The userstill has direct access to the X functions if they are needed.andM;The API also ensures that all X events (e.g., a mouse button press andrelease) that occur in a window object are sent to the application.andP;  This isdone through callback techniques based on the Xt callback mechanism.andP;  Thereare also mechanisms and data structures to provide a linkage between X eventdata formats and API data formats.andM;GraphicsandM;Most graphics packages, such as Hewlett-Packard's Starbase graphics package,[3] provide coordinate systems that allow users to write device independentgraphics programs.andP;  Since creating a user interface with the X Window Systemis currently done using pixels, the API project team decided to provide APIfunctions that enable user-interface designers the same type of deviceindependent coordinate system features as offered by Starbase.andM;Graphics packages provide coordinate systems that:andM;* Communicate with a particular device (device coordinates)andM;* Provide display resolution independence (normalized or virtual devicecoordinates)andM;* Allow the user to work in a system that reflects their world (worldcoordinates)andM;* Allow users to move, scale, or rotate images easily without recalculatingthe placement and size of the image (modeling transformations).andM;Device coordinates (DCs) are the coordinates used to write to a device.andP;  Forthe X Window System, device coordinates are defined in pixels.andM;Virtual device or normalized device coordinates (NDCs) provide a means togain independence from the resolution of the display.andP;  This coordinatesystems maps the width and height of a display to the coordinate range from0.0 to 1.0.andP;  Normalized device coordinates define a viewport.andP;  A viewport isa rectangular drawing region on the display surface.andP;  Specifying the viewportin NDCs maintains the ratio between the drawing area and the display sizeregardless of the display resolution.andM;World coordinates provide a user-defined coordinate system.andP;  This systemallows users to create pictures using the most appropriate coordinate systemfor the task.andP;  For example, if the world coordinates represent the physicaldimensions of a factory, using the dimensions from a blueprint of the factoryto create a picture is straightforward.andP;  World coordinates define which areaof the unbounded world coordinate space is visible in the viewport.andP;  Thistype of coordinate system also provides viewport-size independence anddisplay-resolution independence since the world coordinates remain the sameregardless of the physical size or resolution of the display.andM;Modeling transformations allow the user to define a slightly different viewof the world coordinates for each piece of the picture.andP;  Modelingtransformations are geometric transformations such as scaling, rotation, andtranslation (movement).andP;  This feature allows the user to draw an object andthen reuse it in the picture by moving, scaling, and rotating it to fit therequirements of the picture.andM;These three coordinate systems and the modeling transformations are linkedtogether when an object is drawn.andP;  First, the object is transformed by itsmodeling transformations to the desired orientation in the world coordinatesystem.andP;  The world coordinates are scaled and translated to fit into theviewport and converted to normalized device coordinates.andP;  Finally thenormalized device coordinates are converted to device coordinates to draw thepicture in the viewport.andP;  These transformations are shown in Fig.andP;  2.andM;Widgets and Xt IntrinsicsandM;The widgets (pushbuttons, scrollbars, etc.) and the Xt Intrinsics provide thebasis for the API input model and for other API features.andP;  The API projectteam took the input loop from Xt Intrinsics and added processing to handleAPI graphics objects.andP;  Also leveraged from the Xt Intrinsics are the methodsfor getting file descriptor input and timeouts.andP;  An extension of the Xtcallback technique allows users to attach functions to window objects tohandle X events and to API graphic objects, which include geometric figuressuch as circles, arcs, and rectangles, to handle mouse button events.andM;To keep the number of API functions low, API parameter handling is patternedafter Xt Intrinsic Arglists.andP;  The API Arglists are arrays of attribute andvalue pairs.andP;  This feature frees the application from having fixed parameterlists that force it to make many calls.andP;  The application also doesn't have topass unnecessary parameters.andP;  Parameters that it doesn't pass areautomatically defaulted.andP;  One deviation from the Xt Intrinsic Arglist is thatthe API uses a null-terminated list instead of a counted list.andP;  The API alsoextends the attribute default concept so that the application can change thedefaults of different classes of objects at run time.andP;  API Arglists aredescribed in the article on page 11.andM;Object-Oriented DesignandM;HP IVI is an object-oriented system.andP;  Object-oriented design andobject-oriented programming are being increasingly used at HP for softwareproduct development.andP;  [4,5]  The goals of object-oriented methods are veryappealing because they encourage such practices as code reuse and functionalcohesion of software components (objects).andP;  Also, once a stable and reliablelibrary of objects is available, software development and maintenance costsshould be reduced.andP;  In the API a special utility was used to create anobject-oriented environment from C language programs.andP;  The box on page 29describes some basic object-oriented concepts and an overview of the APIobject-oriented environment.andP;  The special utility used for creating theobject-oriented environment is described later in this article.andM;Input HandlingandM;The input handling model for the API is based on X, Xt Intrinsics, andwidgets.andP;  The Xt Intrinsics provide a way to call application functions whencertain events occur.andP;  These functions are called callbacks and are attachedto widgets.andP;  The Xt Intrinsics provide input handling capabilities for Xevents, time-outs, and file descriptor input through the XtMainLoop function.andO;This function consists of an infinite loop calling XtNextEvent()to get thenext event and XtDispatchEvent() to send the event to the appropriateprocessing function (see Fig.andP;  3).andP;  Because the API provides several specialinput features the project team implemented its own version of XtMainLoop.andM;The basic API input loop consists of an HP-UX select() call to see if inputexists on either the user's file descriptors or the API server object's filedescriptors and a test to see what events came in (see Fig.andP;  4).andP;  If input ispending on the file descriptor for the X server a message is sent to the APIserver object to process all X events queued.andP;  If input is pending on auser's file descriptor the user's callback function is invoked.andM;The server object still does the XtNextEvent() and XtDispatchEvent() loopingbut it has additional code to handle conversion of X callback information toAPI format, callbacks on graphic objects and window objects, Expose andConfigureNotify events on window objects, global callbacks, and eventgrabbing (see Fig.andP;  5).andM;Callback HandlingandM;Callbacks are implemented as objects in the API.andP;  These objects contain apointer to the user-written function to be called when an X event occurs, apointer to callback-specific data, and the specific reason that will causethe callback to invoke the user function (see Fig.andP;  6).andP;  The file descriptorthat is checked during input processing is an example of callback-specificdata.andP;  The reason for the invocation of the callback is an integer value thatindicates the type of input event such as a button press.andP;  These callbackobjects are put in a list called a callback list and are attached to theobject requiring them.andP;  For the Xt Intrinsics, the callbacks are attached tospecific-reason resources instead of one central callback list.andP;  The APImethod of handling callback eliminates having one attribute per callback foreach object type and eliminates having to add and delete attributes whenreasons change.andP;  Time-outs and file descriptor callbacks are attached to theAPI system object, which stores global attributes and resources.andP;  X eventcallbacks are registered on the window objects.andM;The API creates an identifier (Ztld) for each object that an applicationcreates.andP;  However, the data returned to callbacks from a widget consists of awidget identifier and widget-specific data, which is unusable to APIapplications.andP;  This problem is solved by minifunctions that are registeredwith the widgets.andP;  These minifunctions are interfaces that convertwidget-specific data into something that can be understood and used by theAPI.andP;  When a minifunction is attached to a widget, the object identifier Ztldis also attached to the widget.andP;  This scheme allows widgets to be treatedlike other API objects when widget input is received.andM;Callbacks on GraphicsandM;Graphic objects include shapes such as arcs, rectangles, and circles.andO;Because graphic objects can be manipulated the same as windows and widgets inthe HP IVI environment, we decided to have button press and button releaseevents associated with them.andP;  Therefore, graphic objects need callbackfunctions.andP;  For example, an octagon-shaped graphic object representing a stopsign may require a callback object with a method for stopping some operation.andO;Callbacks on graphic objects are handled differently from widgets.andP;  Since thegraphic objects are not widgets, the Xt Intrinsics cannot be relied on tocall API functions when an event occurs on a graphic object.andP;  All widget andgraphic objects have a corresponding extent object.andP;  The extent objectconsists of two point objects that define a rectangular region.andP;  Whenassociated with an object, the extent defines the smallest rectangle thatencloses an object (see Fig.andP;  7).andP;  When the minifunction for window eventsdetects a button press or button release, it converts the x,y coordinateposition of the sprite to a point object.andP;  Since the window minifunction iscalled, this indicates that the button event did not occur over a widget(remember the widget minifunction converts widget data to API usable data).andO;The button event results in a call to a function to find the object that isunder the point.andP;  The function will search the hierarchy for an object thathas the point in its extent.andP;  If a graphic object is found, the object listis searched to see if there is a corresponding callback function and if so,the event is dispatched to the function.andM;Global CallbacksandM;A requirement of the API was to detect a function key press regardless of thelocation of the sprite in the window.andP;  This was a problem if the sprite wasover a widget when a function key was pressed because widgets grab any inputover them.andP;  The project team extended the callback process so that the windowobject could also receive the event even if it was over a widget.andP;  This typeof callback is referred to as a global callback.andM;Global callbacks are implemented by providing an additional check during theinput processing in the server object (see Fig.andP;  5).andP;  After the event isdispatched to the appropriate object, a check is made to see if globalcallbacks are enabled.andP;  If so, the event is dispatched again to the windowobject and any global callbacks attached to the window that match the eventare called.andP;  For events that were originally over widgets, the x,ycoordinates of the event are recalculated to be relative to the API windowobject before dispatching.andP;  Recalculation of widget points is done becausethe API understands points relative to the window object coordinate systemand not to the widget coordinate system.andM;Event GrabbingandM;For customers making their own user-interface builders and also for HPIVIBuild, a feature was needed to direct events only to the window.andP;  Forexample, the normal behavior for a widget pushbutton object is to flash whenit is selected.andP;  However, in the builder, selecting the pushbutton may be thestart of a move operation on it.andP;  To suppress normal widget behavior and letthe application determine the meaning of the event, a button press event overa widget has to be directed only to the window object.andP;  The event has to begrabbed.andP;  To solve this problem, input handling at the server object levelwas modified so that if event grabbing is enabled, the event is only sent tothe window object for processing.andM;Window Expose and ResizeandM;When Expose and ConfigureNotify events occur on API window or graphicsobjects, special functions are called in the server object to handle theseevents.andP;  Since graphic objects are not in individual X windows as the widgetsare (see Fig.andP;  8), the window object has to redraw the graphic objects whenan Expose event occurs and resize its children when a ConfigureNotify eventoccurs.andM;For an Expose event, the window object removes all Expose events for thiswindow from the queue and keeps two lists of corresponding extent objects.andO;Remember that an extent object consists of two point objects that define arectangular region.andP;  One list contains the extents of each Expose event indevice coordinates.andP;  This list is used in the server object to create X cliprectangles when graphics objects in the exposed region are redrawn.andP;  Thesecond list contains extents of each expose event in normalized devicecoordinates.andP;  After constructing these two lists, the window object goesthrough a redraw pass of the objects in the window.andP;  When the graphicsobjects are told to display themselves, they check the previous normalizeddevice coordinate clip list to see if they are in the exposed areas.andP;  If theyare, they send a message to the server object to do the X drawing commands.andO;This scheme ensures that only those objects that are actually exposed getredrawn by the server object and it significantly improves performance ifexposed objects are only a small portion of the window.andM;For ConfigureNotify events, the window object sets the new window placementand size values.andP;  Then during the next redraw of the window, the objects areredrawn to fit within the new window size.andM;Coordinate SystemsandM;The coordinate system concepts and techniques found in various graphicspackages are incorporated into the API functions for drawing graphicsobjects, windows, and widgets on the display.andP;  The user can define theviewing area in world coordinates (e.g., inches, feet, etc.) and the APIfunctions transform these coordinates to a window in the X coordinate systempixels.andM;A viewport is a rectangular portion of the display onto which window objectsdefined in world coordinates are mapped.andP;  Viewports are typically defined ina device independent coordinate system called normalized device coordinates,or NDCs.andP;  In X a viewport is represented by an X window, which is defined indevice coordinates (DCs).andP;  The API allows users to define the position andsize of a window object (viewport) with NDC coordinates.andP;  This allows awindow to be defined as occupying a certain portion of the total display areaindependent of display resolution.andP;  Mapping a window object described in NDCsto the device coordinates of a display is straightforward.andP;  When anapplication initiates drawing to a specific X server, the display resolutionof the server is queried.andP;  The NDC values describing the viewport aremultiplied by this display resolution to get pixel values.andP;  Since NDCs usethe lower-left corner of the display as the origin and X uses the upper-leftcorner as the origin, the y values of the viewport must be subtracted fromthe height of the display for compatibility with the X coordinate system.andO;Since this calculation is done at run time, the application does not need toknow the type of display the application is using.andM;Consider a window that occupies the NDC region from (0.0,0.0) to (0.5,0.5) ona display that is 1024 pixels wide and 768 pixels high (see Fig.andP;  9a).andP;  Whenconverted to DCs as explained above, the window occupies the region of thedisplay at pixel locations (0,767) to (511,384) (see Fig 9b).andM;The transformation equations for converting from NDCs to DCs are:andM;[P.sub.xDC] = [P.sub.xNDC] X (width of display in DCs/1 NDC) (1)andM;[P.sub.yDC] = [P.sub.yNDC] X (height of display in DCs/1 NDC).andP;  (2)andM;To take into consideration the upper-left origin of the X Window System:andM;[P'.sub.yDC] = height of display in DCs - [P.sub.yDC.] (3)andM;Substituting the values from Fig.andP;  9a into equations 1 and 3 and compensatingfor the starting pixel yields:andM;[P.sub.1xDC] = 0.0 X 1024/1 = 0 [P'.sub.yDC] = 768 - (0.5 X 768/1) = 384[P.sub.2xDC] = (0.5 X 1024/1) - 1 = 511 [P'.sub.2yDC] = 768 - (0.0 X 768/1) -1 = 767.andM;These coordinate values are shown in Fig.andP;  9b.andM;To define what is drawn within the window object, the user defines whatportion of the world coordinate (WC) space is viewable in that area.andP;  Thisviewable area can be changed at run time to perform operations such aspanning or zooming.andP;  To draw to the X window representing the user's windowobject, the API must convert all values in WCs into the device coordinates ofthe display.andP;  WCs are transformed to pixels in a two-step process.andP;  The firststep transforms the WCs to NDCs and the second step transforms the NDCs toDCs.andM;Every window object contains a viewport-to-window transformation matrix(VTM).andP;  This matrix describes how to scale and translate the viewable WCregion to fit within the window.andP;  A scale factor (SF) is calculated to scalethe WC width and height to the width and height of the viewport.andP;  This scalefactor for the x coordinate is:andM;[SF.sub.x] = width of the window in NDCs / width of the viewable WC region inWCsandM;and for the y coordinate isandM;[SF.sub.y] = height of the window in NDCs / height of the viewable WC regionin WCs.andM;For example, in Fig.andP;  10a the viewable area of the world coordinate window isdefined to occupy a viewport in the upper-right quadrant of a display.andP;  Thescale factors for mapping the WC region to NDCs in this example are:andM;[SF.sub.x] = (1 - 0.5)/(110 - 10) = 0.005 NDCs/WCandM;and for the y coordinateandM;[SF.sub.y] = (1 - 0.5)/(85 - 10) = 0.0067 NDCs/WCandM;To transform the pushbutton coordinates shown in Fig.andP;  10a from WCs to NDCs:andM;[P.sub.1x] = 10 X [SF.sub.x] = 0.05 NDCs [P.sub.2x] = 60 X [SF.sub.x] = 0.3NDCsandM;[P.sub.1y] = 10 X [SF.sub.y] = 0.067 NDCs [P.sub.2y] = 47.5 X SFy = 0.318NDCs.andM;Fig.andP;  10b shows the pushbutton scaled to NDC coordinates.andM;The NDC system maps the coordinate (0.0,0.0) to the lower-left corner of awindow.andP;  Therefore, if the viewable WC region does not map the coordinate(0.0,0.0) to the lower-left corner of the window, a translation factor isadded to the NDC coordinates.andP;  The translation factors are computed as:andM;For the pushbutton example the translation factors are:andM;[T.sub.x] = - 0.005 X 10 = - 0.05 NDCs [T.sub.y] = - 0.0067 X 10 = - 0.067NDCs.andM;Adding the translation factor to the NDC points [P.sub.1] and [P.sub.2]results in:andM;[P.sub.1x] = 0.05 - 0.05 = 0 NDCs [P.sub.2x] = 0.3 - 0.05 = 0.25 NDCsandM;[P.sub.1y] = 0.067 - 0.067 = 0 NDCs [P.sub.2y] = 0.318 - 0.067 = 0.25 NDCs.andM;Fig.andP;  10c shows the results of the translation.andM;Like most graphics packages, the API follows the convention of defining theorigin in the lower-left corner of the drawing area.andP;  However, because the XWindow System defines the origin to be the upper-left corner, an additionaltranslation factor (or flip factor) must be added in the y direction to movethe origin from the lower-left to the upper-left corner.andM;The NDC height for the window in which the pushbutton in Fig.andP;  10 resides is0.5 NDCs.andP;  Compensating for the flip factor (F) results in:andM;[P'.sub.1y] = F - [P.sub.2y] = 0.5 - 0.25 = 0.25 NDCs [P'.sub.2y] = F -[P.sub.1y] = 0.5 - 0.0 = 0.5 NDCsandM;andandM;[P'.sub.1x] = 0.0 [P'.sub.2x] = 0.25.andM;Fig.andP;  10d shows the result of applying the flip factor.andM;The scale factors, the translation factors, and the flip factor areincorporated into the viewport-to-window transformation matrix VTM.andO;Combining all the transformation factors in one matrix and performing thetransformation operations looks like:andM;[Mathematical Expression Omitted]andM;Fig.andP;  10e shows the final transformation of the pushbutton NDCs to X windowdevice coordinates.andP;  The coordinate points shown in Fig.andP;  10e are derived bysubstituting the values from Fig.andP;  10d into transformation equations 1 and 2and compensating for the starting pixel.andM;[P.sub.1xDC] = 0.0 X 1024/1 = 0 [P.sub.1yDC] = 0.25 X 768/1 = 192[P.sub.2xDC] = (0.25 X 1024/1) - 1 = 255 [P.sub.2yDC] = (0.5 X 768/1) - 1 =383.andM;Modeling CoordinatesandM;The API provides modeling transformations that allow any object within theuser interface hierarchy to be transformed by scaling (enlarging orshrinking), rotation, and translation.andP;  This lets the user draw a symbol thatcan be reused by providing only the data that differentiates its position andsize from another instance of the symbol.andP;  The API concatenates modelingtransformations so that an object is affected by the transformations on itsancestors.andP;  This allows an entire subhierarchy of objects to be transformedby one operation on a common ancestor instead of requiring transformations onevery object in the subhierarchy.andP;  These transformations are used when anobject is being drawn.andP;  The modeling transformation values are converted toWCs by multiplying the transformation on an object to its WC attributes.andP;  Acurrent transformation matrix (CTM) is maintained during a drawing pass onthe objects.andP;  Each object multiplies its transformation matrix with the CTMcontaining the transformations of its ancestors.andP;  In the API, the CTM isinitialized to be the VTM.andP;  Doing this reduces the number of matrixmultiplications and improves the performance of the drawing operation.andM;Adjustments and ScalingandM;Besides allowing the application developer to work in a display resolutionindependent manner when creating the windows for an application, the worldcoordinate system allows a user to resize the window interactively and theobjects to be redrawn without the intervention of the application.andP;  Changingthe size of the window changes the NDC definition of the window.andP;  This changecauses the scaling factors in the VTM to be recalculated at the next displaypass.andP;  The objects are either enlarged or shrunk to fit within the new windowsize.andP;  When resizing a window, the user may change its aspect ratio.andP;  Thatis, the physical width-to-height ratio of the object may be different fromthe WC width-to-height ratio.andP;  When this happens, objects begin to lookdistorted.andP;  For instance, a circle begins to look like an oval.andP;  This may bean appropriate action for some applications, but for others, especially thosewhere the objects on the display are meant to represent something in thephysical world, the application developer wants the objects to maintain theirwidth-to-height ratio.andP;  In graphics packages, these two modes of operationare referred to as anisotropic and isotropic scaling, respectively.andP;  The APIwindow object provides the attribute ZtADJUST which the application can setto ensure that the aspect ratio is maintained.andP;  If this attribute is set andthe window is resized, the WC height or width mapping to the window isadjusted to maintain the original aspect ratio.andP;  This process results inmodifying the scale factors stored in the VTM.andP;  This also results in moreviewable WC space in the window in either the x or the y direction.andM;Applying the various coordinate systems to windows and widgets has workedsuccessfully.andP;  Specifying their position and size in NDC or WC units allowsthe user to define them in the same manner as graphic objects.andP;  It alsoallows the application to be independent of the display and window size evenas the user interactively resizes the window.andM;Scaling and moving widgets works the same as for graphics objects.andP;  However,as the widgets scale smaller and larger, the font that they use does notscale because it is a bit-mapped font.andP;  The widget scales larger and leavesmore space between the edge of the text and the edge of the widget or itscales smaller and closes in on the text, eventually clipping it (see Fig.andO;11).andP;  A few possible solutions to this problem exist.andP;  One solution is forthe X Window System to support scalable fonts.andP;  This will allow the font toscale with the widget.andP;  Another solution is to switch between a set of fontswith different sizes as the object grows and shrinks.andP;  Widgets also cannotrotate from a horizontal base.andP;  In the API, when a widget is rotated, itsdefining point is rotated, and the widget is redrawn in the new position witha horizontal base.andP;  This allows the widgets to be rotated as part of a symboland to move along with any associated graphic objects.andP;  Despite thesedifferences between the operation of the widgets and the graphic and windowobjects, the coordinate system feature of the API still provides a largeproductivity gain for the application developer.andM;Object-Oriented ArchitectureandM;Without using an object-oriented programming language, the API encompassesfeatures provided by an object-oriented language through conventional Clanguage features.andP;  The API's architecture is divided into three layers: theAPI function layer, the API object layer, and the device dependent layer (seeFig.andP;  12).andP;  The API function layer provides the communication interfacebetween a user application and the objects created by the application.andP;  It isa thin layer of code that validates the user's parameters and sends messagesto the objects to perform the tasks requested.andP;  The functions provided inthis layer are described in the article on page 11.andP;  In the API object layer,an object is created and destroyed and all manipulation of an object's dataoccurs.andP;  In the device dependent layer, all the function calls to underlyingsubsystems are made to draw an object to the display.andM;Messaging in the APIandM;The API consists of a number of function calls that provide the communicationpath between an application and the underlying objects manipulated by theapplication.andP;  Most of the API functions require objects as parameters.andP;  It isthrough this interface that an object's specific data and the functions thatmanipulate the data are accessed.andP;  In essence, the API hides from the user asmuch as possible the details of using objects.andM;To provide the interface between an application and its objects, apreprocessor tool called rtc (run time class information) is used to definethe API object messaging facility and class interitance hierarchy based oninformation from a group of description files.andP;  Every API class consists of aclass header file and a class definition file.andP;  The class header file definesthe data storage for each instance of an object of that class.andP;  This fileidentifies the object as a member of a class or classes and provides theconnection to the set of methods that manipulate that object's internal data.andO;The class definition file is a C program module that contains the methodsthat are specific to a particular class.andP;  The class header file must beincluded in the C program module so that the data structure of this objectand the class definition pointer can be accessed.andP;  Once an object's datastructure, class, and specific functions are defined, it needs to bepositioned within the class hierarchy.andP;  The positioning of the class in theclass hierarchy is determined by the nature of the class and the methods tobe inherited.andP;  The simpler a class is, the higher up in the class hierarchyit is positioned.andP;  Conversely, a more complex class is positioned furtherdown in the class hierarchy.andP;  The positioning of a class within the classhierarchy is defined within the library definition file.andP;  This file definesthe methods that are available for messaging to a class and the methods thatcan be inherited by that class.andM;Adding an API ObjectandM;Adding a new class to the API class hierarchy is a four-step process.andP;  Thisprocess is illustrated for the circle class in Fig.andP;  13.andP;  First, the librarydefinition file (graphic.r) is used as the input to the rtc tool.andP;  The rtctool takes the library definition file and produces several files as output.andO;One of these output files (circle.rtc in Fig.andP;  13) is the run-time classinformation file, or .rtc file.andP;  A .rtc file is created for every classdefined in the library definition file.andP;  It contains the class definitionstructure and the method dispatch tables for that specific class.andP;  The .rtcfile is included at the end of the class definition file for that class whenthe class definition file is compiled (step 2).andP;  In the third step the newlibrary definition files (graphic.h and graphic.c) are compiled.andP;  Finally,the pointer to the new class must be added to the file that defines the classhierarchy.andP;  This file is called the glue file (classlibs.c).andP;  In step four,classlibs.c is compiled with the class header file (graphic.h) to produce theobject file classlibs.o.)andP;  When these object files (circle.o, graphic.o, andclasslibs.o) are linked into an application, the addresses to the methodssupported by the various classes are resolved.andM;By using object-oriented technologies, the API is able to create graphicobjects.andP;  One problem users have with software systems such as the X libraryis that graphic primitives are not objects.andP;  The X library provides manygraphic functions that operate on the individual pixels of a graphic displaybut the parameters describing the object are not kept.andP;  For example, if acircle is drawn and the application simply wants to change its color fromblue to red, all the parameters (location, size, line width, etc.) to drawthe circle must be passed to the X library function again.andP;  The API solvesthis problem by providing graphic objects using the rtc tool.andP;  This allowsthe user to describe the parameters of the object once and then make simplemodifications only to the parameters that are changing.andP;  The application isfreed from maintaining all of the data necessary to redraw all of thegraphical objects in the window.andM;ConclusionandM;The HP IVI project was successful in blending graphics, windowing, X toolkit,widget, and object-oriented technologies in the internal design of the API.andO;Because most of these technologies were developed separately, it was notalways clear how to integrate them.andP;  The API solved most of the problemsencountered and as a result of this effort a high-level user interfacetoolkit was created that reduces the complexity of building a sophisticatedgraphical user interface for an application.andM;AcknowledgmentsandM;Besides the three authors, the other members of the API development team wereScott Anderson, Hai-Wen Bienz, Mark Thompson, and Mydung Tran.andM;ReferencesandM;[1] F. E. Hall and J. B. Byers, &quot;X: A Window System Standard for DistributedComputing Environments,&quot; Hewlett-Packard Journal, October 1988, Vol.andP;  39, no.andO;5, pp.andP;  46-50.andM;[2] K. H. Bronstein, D. J. Sweetser, and W. R. Yoder, &quot;System Design forCompatibility of a High-Performance Graphics Library and the X WindowSystem,&quot; Hewlett-Packard Journal, December 1989, Vol.andP;  40, no.andP;  6, pp.andP;  6-12.andM;[3] Ibid, p. 7.andM;[4] J. A. Dysart, &quot;The NewWave Object Management Facility,&quot; Hewlett-PackardJournal, Vol.andP;  40, no.andP;  4, August 1989, pp.andP;  17-23.andM;[5] T. F. Kraemer.andP;  &quot;Product Development Using Object-Oriented SoftwareTechnology,&quot; Hewlett-Packard Journal, Vol.andP;  40, no.andP;  4, August 1989, pp.andO;87-100.andM;Pamela W. MunschandM;Pam Munsch, a software development engineer on the HP IVI project at HP'sindustrial Applications Center, worked as a development engineer on an ICtesting project shortly after she joined HP's Santa Clara Division in 1983.andO;She is now an Randamp;D project manager working on HP IVI.andP;  Pam received her BSdegree in computer science in 1983 from the University of California at SantaBarbara.andP;  She is married, lives in the city of her birth, San Jose,California, and enjoys playing volleyball.andM;Warren I. OtsukaandM;As an Randamp;D software engineer at HP's Industrial Applications Center, WarrenOtsuka was responsible for input handling and widget objects for the HP IVIproject.andP;  After joining HP's Data Systems Division in 1978, he worked onsupport for the HP F/1000 forms management tool and HP F/1000/HP-UX products.andO;Before joining HP, Warren was a project lead for user interface developmentand an engineer on a document project for Docugraphix, Inc., and he providedsystem support for the STAR-100 operating system at Control Data Corporation.andO;He earned a BS degree in computer science from the California StateUniversity at Chico in 1972.andP;  Born in Kona, Hawaii, Warren is married, has adaughter, and lives in Campbell, California.andP;  He enjoys family activities,reading mysteries, and photography.andM;Gary D. ThomsenandM;Software development engineer Gary Thomsen, who joined HP's Data SystemsDivision in 1979, helped design widget classes for the HP IVI project.andO;Before that, as an Randamp;D software engineer, he provided support for the HP 1000Series Forms/1000 product, and as an Randamp;D product design engineer, he designedthe HP 1000 Series A hardware packaging.andP;  Gary earned his BA degree inmathematics from San Jose State University in 1977.andP;  He is married, lives inSan Jose, California, and enjoys softball, biking, and woodworking.andO;</TEXT></DOC>