<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF109-452-475  </DOCNO><DOCID>09 452 475.andM;</DOCID><JOURNAL>Communications of the ACM  Sept 1990 v33 n9 p125(17)* Full Text COPYRIGHT Association for Computing Machinery 1990.andM;</JOURNAL><TITLE>Concurrent object-oriented programming. (includes related articleon multicomputers)</TITLE><AUTHOR>Agha, Gul.andM;</AUTHOR><SUMMARY>Three significant trends in concurrent computing are increased useof interacting processes by individual users; the use ofcost-effective workstation networks as the primary way to shareresources and distribute them for problem solving; andmultiprocessor technology, which delivers supercomputing power ata much lower price.andP;  Software engineering has moved toward dataabstraction to promote program modularity, as shown by theincreased acceptance of object-oriented programming.andP;  Concurrentobject-oriented programming (COOP) provides a software foundationfor concurrent computing on multiprocessors; the foundations andmethodology of COOP are discussed.andP;  COOP includes a range ofstructures that can be used to express patterns of concurrentproblem solving.andP;  The actor model as a framework for concurrentsystems is discussed specifically.andM;</SUMMARY><DESCRIPT>Topic:     Object-Oriented ProgrammingMultiprocessingSoftware DesignModular ProgrammingConcurrent ProgrammingNew TechniqueProgram Development Techniques.andO;Feature:   illustrationchart.andO;Caption:   A transactional structure: each request generates a uniqueresponse. (chart)A simple prime sieve. (chart)A recursive factorial computation. (chart)andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>CONCURRENT OBJECT-ORIENTED PROGRAMMING Three significant trends haveunderscored the central role of concurrency in computing.andP;  First, there isincreased use of interacting processes by individual users, for example,application programs running on X windows.andP;  Second, workstation networks havebecome a cost-effective mechanism for resource sharing and distributedproblem solving.andP;  For example, loosely coupled problems, such as finding allthe factors of large prime numbers, have been solved by utilizing idealcycles on networks of hundreds of workstations.andP;  A loosely coupled problem isone which can be easily partitioned into many smaller subproblems so thatinteractions between the subproblems is quite limited.andP;  Finally,multiprocessor technology has advanced to the point of providingsupercomputing power at a fraction of the traditional cost.andM;At the same time, software engineering considerations such as the need fordata abstraction to promote program modularity underlie the rapid acceptanceof object-oriented programming methodology.andP;  By separating the pecificationof what is done (the abstraction) from how it is done (the implementation),the concept of objects provides modularity necessary for programming in thelarge.andP;  It turns out that concurrency is a natural consequence of the conceptof objects.andP;  In fact Simula, the first object-oriented language, simulated asimple form of concurrency using coroutines on conventional architectures.andO;Current development of concurrent object-oriented programming (COOP) isproviding a solid software foundation for concurrent computing onmultiprocessors.andP;  Future generation computing systems are likely to be basedon the foundations being developed by this emerging software technology.andM;The goal of this article is to discuss the foundations and methodology ofCOOP.andP;  Concurrency refers to the potentially parallel execution of parts of acomputation.andP;  In a concurrent computation, the components of a program may beexecuted sequentially, or they may be executed in parallel.andP;  Concurrencyprovides us with the flexibility to interleave the execution of components ofa program on a single processor, or to distribute it among severalprocessors.andP;  Concurrency abstracts away some of the details in an execution,allowing us to concentrate on conceptual issues without having to beconcerned with a particular order of execution which may result from thequirks of a given system.andM;Objects can be defined as entities which encapsulate data and operations intoa single computational unit.andP;  Object models differ in how the internalbehavior of objects is specified.andP;  Further, models of concurrent computationbased on objects must specify how the objects interact, and different designconcerns have led to different models of communication between objects.andO;Object-oriented programming builds on the concepts of objects by supportingpatterns of reuse and classification, for example, through the use ofinheritance which allows all instances of a particular class to share thesame method.andM;In the following section, we outline some common patterns of concurrentproblem solving.andP;  These patterns can be easily expressed in terms of the richvariety of structures provided by COOP.andP;  In particular, we discuss the actormodel as a framework for concurrent systems (1) and some concepts which areuseful in building actor systems.andP;  We will then describe some other models ofobjects and their relation to the actor model along with novel techniques forsupporting reusability and modularity in concurrent object-orientedprogramming.andP;  The last section briefly outlines some major on-going projectsin COOP.andM;It is important to note that the actor languages give special emphasis todeveloping flexible program structures which simplify reasoning aboutprograms.andP;  By reasoning we do not narrowly restrict ourselves to the problemof program verification--an important program of research whose directpractical utility has yet to be established.andP;  Rather our interest is in theability to understand the properties of software because of clarity in thestructure of the code.andP;  Such an understanding may be gained by reasoningeither informally or formally about programs.andP;  The ease with which we cancarry out such reasoning is aided by two factors: by modularity in code whichis the result of the ability to separate design concerns, and by the abilityto abstract program structures which occur repeatedly.andP;  In particular,because of their flexible structure, actor languages are particularlywell-suited to rapid prototyping applications.andM;Patterns of ConcurrentandM;Problem SolvingandM;Three common patterns of parallelism in problems have been found in practice(For example, see [8, 13]).andP;  First, pipeline concurrency involves theenumeration of potential solutions and the concurrent testing of thesesolutions as they are enumerated.andP;  Second, divide and conquer concurrencyinvolves the concurrent elaboration of different subproblems and the joiningof (some or all) of their solutions in order to obtain a solution to theoverall problem.andP;  In divide and conquer concurrency, there is no interactionbetween the procedures solving the subproblems.andP;  A third pattern can becharacterized as cooperative problem-solving.andP;  Cooperative problem-solvinginvolves a dynamic complex interconnection network.andP;  As each object carriesout its own computational process, it may communicate with other objects, forexample, to share the intermediate results it has computed.andP;  An example ofthis kind of a system is a simulation where the physical objects arerepresented by logical (computational) objects.andM;Consider some canonical examples illustrating different patterns ofparallelism.andP;  A simple example of pipeline concurrency is the prime sieve.andO;To generate all the prime numbers, one could generate all numbers and removemultiples of 2,3,5,7,..., up to the largest prime computed thus far.andP;  As soonas a number is identified as prime, it is added to the sieve and numbers arealso eliminated by testing for divisibility by this prime (see Figure 1).andM;The earlier stages of this particular pipeline are a bottleneck because manymore numbers are divisible by smaller primes.andP;  The linear pipeline can beimproved by changing it to a tree with the numbers sent to differentidentically behaving objects, each testing for divisibility by a given (low)prime, and then merging the results.andP;  This can be achieved by usingdemand-driven evaluation which dynamically creates context objects to filterthe numbers for divisibility of the primes below it.andP;  Specifically, eachnumber can create its own copies of the elements of the sieve as it goesalong.andP;  This scheme provides tree pipelining for testing divisibility.andM;It should be observed that because a large number of unnecessary tests areperformed, the technique of generating all numbers and then filtering isquite inefficient in the first place.andP;  An improved version would avoidgenerating multiples of the low primes, 2,3,5,.. (up to some prime).andP;  Athasdescribes the behavior of an algorithm designed precisely to do this [7].andM;Divide-and-conquer concurrency algorithms can often be expressed asfunctions.andP;  Arguments to a function are evaluated concurrently and theirvalues collected to determine the final result.andP;  Consider the problem ofdetermining the product of a list of numbers [4].andP;  We can represent the listas a tree as in Figure 2.andP;  The problem can be recursively subdivided into theproblem of multiplying two sublists, each of which is concurrently evaluated,and their results are multiplied (see Figure 3).andP;  The product is thenreturned.andP;  The tree product program in Figure 3 looks very much like code inLisp or Scheme except that the evaluation strategy is maximally concurrent.andM;In cooperative problem solving concurrency, intermediate results are storedin objects and shared by passing messages between objects.andP;  Simulationprograms, where a logical object represents a physical object, is oneapplication of this kind of concurrency.andP;  For example, the dynamic evolutionof the paths of a number of bodies under the influence of each others'gravitational fields can be modeled as systems of cooperating objects.andO;Another example of cooperative problem solving is blackboard systems whichallow collaboration between agents through a shared work space.andP;  In anobject-based system, the blackboard and the agents may be represented assystems of objects.andM;The Actor ModelandM;A common semantic approach to modeling objects is to view the behavior ofobjects as functions of incoming communications.andP;  This is the approach takenin the actor model [21].andP;  Actors are self-contained, interactive, independentcomponents of a computing system that communicate by asynchronous messagepassing.andP;  The basic actor primitives are (see Figure 4):andM;create: creating an actor from a behavior description and a set ofparameters, possibly including existing actors;andM;send to: sending a message to an actor; andandM;become: an actor replacing its own behavior by a new behavior.andM;These primitives form a simple but powerful set upon which to build a widerange of higher-level abstractions and concurrent programming paradigms [3].andO;The actor creation primitive is to concurrent programming what the definitionof a lambda abstraction is to sequential programming (For example, see [1]):it extends the dynamic resource creation capability provided by functionabstractions to concurrent computation.andP;  The become primitive gives actors ahistory-sensitive behavior necessary for shared mutable data objects.andP;  Thisis in contrast to a purely functional programming model and generalizes theLisp/Scheme/ML sequential style sharing to concurrent computation.andP;  The sendto primitive is the asynchronous analog of function application.andP;  It is thebasic communication primitive causing a message to be put in an actor'smailbox (message queue).andP;  It should be noted that each actor has a uniquemail address determined at the time of its creation.andP;  This address is used tospecify the recipient (target) of a message.andM;In the actor model, state change is specified using replacement behaviors.andO;Each time an actor processes a communication, it also computes its behaviorin response to the next communication it may process.andP;  The replacementbehavior for a purely functional actor is identical to the original behavior.andO;In other cases, the behavior may change.andP;  The change in the behavior mayrepresent a simple change of state variables, such as change in the balanceof an account, or it may represent changes in the operations (methods) whichare carried out in response to messages.andM;The ability to specify a replacement behavior retains an important advantageover conventional assignment statements: assignments to a variable fix thelevel of granularity at which one must analyze a system.andP;  By contrast, thereplacement mechanism allows one to aggregate changes and avoid unnecessarycontrol flow dependencies within computational units which are defined byreceptionists [2].andP;  Replacement is a serialization mechanism which supports atrivial pipelining of the replacement actions: the aggregation of changesallows an easy determination of when we have finished computing the state ofan actor and are ready to take the next action.andP;  For example, suppose a bankaccount actor accepts a withdrawal request.andP;  In response, as soon as it hascomputed the new balance in the account, it is free to process the nextrequest--even if other actions implied by the withdrawal request are stillbeing carried out.andP;  To put it another way, the concurrent specification ofreplacement behaviors guarantees noninterference of state changes withpotentially numerous threads running through an actor under amultiple-readers, single-writer constraint.andM;Concurrent computations can be visualized in terms of event diagrams (seeFigure 5).andP;  These diagrams were developed to model the behavior of actorsystems.andP;  Each vertical line, called a lifeline, represents all thecommunications received by a given actor.andP;  The receipt of a communicationrepresents one kind of event.andP;  Another kind of event is the creation of a newactor represented by an open are on the top of a lifeline.andP;  Connectionsbetween lifelines represent causal connections between events.andP;  Pendingevents, representing communications which have been sent but not received,may be represented by activation lines whose arrows note the message and thetarget.andM;Control StructuresandM;Concurrent control structures represent particular patterns of messagepassing.andP;  Consider the classic example of a recursive control structure whichillustrates the use of customers in implementing continuations.andP;  The exampleis adapted from [14] which provided the original insight exploited here.andP;  Ina sequential language, a recursive formula is implemented using a stack ofactivations.andP;  There is no mechanism in the sequential structure fordistributing the work of computing a factorial or concurrently processingmore than one request.andM;Our implementation of the factorial actor relies on creating a customer whichwaits for the appropriate communication, in this case from the factorialactor itself.andP;  The factorial actor is free to concurrently process the nextcommunication.andP;  We assume that a communication to a factorial includes a mailaddress to which the value of the factorial is to be sent.andP;  In response to acommunication with a non-zero integer n, the actor with the above behaviorwill do the following:andM;* Create an actor whose behavior will be to multiply n with an integer itreceives and send the reply to the mail address to which the factorial of nwas to be sent.andM;* Send itself the &quot;request&quot; to evaluate the factorial of n-1 and send thevalue to the customer it created.andM;One can intuitively see why the factorial actor behaves correctly, and canuse induction to prove that it does so.andP;  Provided the customer is sent thecorrect value of he factorial of n-1, the customer will correctly evaluatethe factorial of n.andP;  Moreover, the evaluation of one factorial does not haveto be completed before the next request is processed; (i.e., the factorialactor can be a shared resource concurrently evaluating several requests).andO;The behavior of the factorial actor in response to a single initial requestis shown in Figure 6.andM;This particular function is not very complicated, with the consequence thatthe behavior of the customer is also quite simple.andP;  In general, the behaviorof the customer can be arbitrarily complex.andP;  The actor originally receivingthe request delegates most of the processing required by the request to alarge number of actors, each of whom is dynamically created.andP;  Furthermore,the number of such actors created is in direct proportion to the magnitude ofthe computation required.andM;There is nothing inherently concurrent in the recursive algorithm to evaluatea factorial.andP;  Using the algorithm in Figure 6, computation of a singlefactorial would not be any faster if it were done using an actor language asopposed to a sequential language.andP;  All we have done is represent the stackfor recursion as a chain of customers.andP;  However, given a network ofprocessors, an actor-based language could process a large number of requestsmuch faster by simply distributing the actors it creates among theseprocessors.andP;  The factorial actor itself would not be as much of a bottleneckfor such computations.andM;Patterns of communications represented in recursion, iteration, divide andconquer, etc., can be abstracted into linguistic forms which automaticallycoordinate independent computations.andP;  An important service provided byhigh-level actor languages such as Acore [20] is the generation andcoordination of customers which are actors provided in a request message.andP;  Acustomer can be sent a reply message when a request is completed, or acomplaint message if it is not possible to successfully complete the request.andM;History-SensitiveandM;BehaviorandM;Often it is necessary for an actor to change its local state and to respondto more than one kind of message.andP;  For example, a bank account changes itsbehavior in response to processing an incoming deposit or withdrawal message.andO;In order to define these kinds of actors, a form called mutable is providedin the Rosette actor language developed at MCC by Tomlinson and others incollaboration with the author.andP;  The mutable form is used to define agenerator actor which creates actors using a behavioral template.andM;The behavior of a simple bank account may be defined using a mutableexpression (see Figure 7).andP;  The generator actor that results from the mutableexpression is bound to the symbol BankAccount.andP;  The generator allows creationof instances via a create expression.andP;  Following the keyword mutable is asequence of identifiers for the state variables of an instance ofBankAccount.andP;  In this case there is just a single state variable, balance.andO;The methods or communication handlers associated with a BankAccount follow.andO;A method is specified by listing a keyword representing the operation to beexecuted by the method, followed by a table that represents the content ofthe request message (in this case a withdraw-from message must specify anamount), and a body that defines how such messages are to be processed.andP;  Whenused within the body of a mutable generator, the form become is used tospecify the replacement behavior of the instance of an actor created usingthe generator--the generator itself does not change.andM;A new BankAccount may be generated with an initial balance of 1000 by usingthe create operation as follows:andM;(define my-account (create BankAccount 1000))andM;We can make the communication handles (the keywords determining which methodis to be performed) visible by declaring them to be operations.andP;  The behaviorof an operation is to send to its firs argument a message containing itselfand the rest of the arguments it received.andP;  This allows object-orientedmessage-passing style and functional styles to be freely mixed in an actorlanguage.andP;  The two styles serve as duals of each other.andM;Requests may be issued to the new account by using the methods that aredeclared as operations:andM;(deposit-to my-account 100) [right arrow] 'deposited 100andM;(withdraw-from my-account 78) [right arrow] 'withdrew 78andM;Subexpressions are evaluated concurrently.andP;  Thus, the computation of areplacement behavior, done by the become command, is concurrent with thecomputation of a response.andP;  The capability to access the account may bepassed to another actor, dynamically reconfiguring a system; for example:andM;(send-to my-wife my-account)andM;would allow the actor whose mail address is bound to my-wife to access theactor my-account.andM;Join ContinuationsandM;Divide and conquer concurrency can often be naturally expressed by using afunctional form which evaluates its arguments concurrently.andP;  Implementationof such forms requires the specification of a join continuation whichsynchronizes the evaluation of the different arguments.andP;  For example, thetree-product program given in Figure 3 can be expressed in terms of actorprimitives as shown in Figure 8.andM;The form (bar foo) represents an asynchronous message foo sent to bar.andP;  Theform [x1 x2...] represents a data constructor whose elements x1, x2, ...andP;  areconcurrently evaluated.andP;  It should be noted that the two tree products in thedo body are also concurrently evaluated and their values are sent tonew-cust, where new-cust is a history-sensitive actor whose role is to storethe first value it receives and multiply the stored number with the secondnumber it receives in order to produce the final response that is sent to thecustomer which was specified at the time of its first invocation.andP;  The formrlambda defines actors rather than actor behaviors (which are defined bymutable).andP;  In the body of an rlambda, become specifies the replacementbehavior of the actor itself.andP;  Thus rlambda is the actor analogue of lambda;it captures the history-sensitive behavior of an actor using the form become.andO;Note that in join-cont, v1 refers to the first message received by theactor--which could correspond to either the product of the left subtree orthe right subtree.andM;The behavior of tree-product is shown in terms of an event diagram in Figure9.andP;  When the three-product actor receives a list represented as a treecontaining 1tree as its left subtree and rtree as its right subtree, itcreates a customer, called a join continuation, which awaits the computationof the products of each of the two subtrees.andP;  The join continuation thenproceeds to multiply the two numbers and send the result to the originalrequester.andP;  Because multiplication is commutative, we need not be concernedabout matching the responses to the order of the parameters.andP;  If we weredealing with an operator which was not commutative, we would need to tag themessage corresponding to each argument and this tag would be returned withthe response from the corresponding subcomputation.andP;  The replacement behaviorof the join continuation would then depend on the order in whch the resultsof the evaluation of arguments were received.andP;  Because the semantics ofconcurrency requires that the evaluation of the two invocations oftree-product be indeterminate, the behavior of join-cont cannot be expressedfunctionally--despite the fact that the behavior of tree-product itself isfunctional.andM;In Figure 9, we provide the behavior of the history-sensitive joincontinuation explicitly.andP;  The advantage of explicit join continuations isthat they provide considerable flexibility--they can be used to control theevaluation order, to do partial computations, and to do dynamic errorhandling.andP;  For example, if the number 0 is encountered, the join continuationcan immediately return a 0--without waiting for the results of evaluating theother subtree [4].andP;  Furthermore, we may want to flag error conditions such asdata exceptions.andP;  If we require, for example, that all the numbers in thetree be positive we may want to terminate the computation once we encounter anegative number.andP;  In this case, we can invoke an error handler to clean upthe data or take other appropriate action.andP;  Figure 10 specifies the code fora join continuation with such error-handling capability.andM;In general, error handlers distinct from the regular continuation structurescan be passed along.andP;  These error handlers provide non-nonfunctional jumpswhich can appropriately clean-up erroneous conditions that may arise in thecourse of a computation.andP;  Because this separates code with distinct purposes,programming with non-functional jumps supports greater modularity; inparticular, it gives us th e ability to independently specify and reasonabout the normal and abnormal behavior of a program.andM;NondeterminismandM;Although actors take a functional view of an object's internal behavior atany given point in time, actors can represent shared history-sensitiveobjects.andP;  Consider the canonical example of a bank account.andP;  The behavior ofa bank account changes over time as a function of the balance in the account.andO;By contrast, the purely functional programming approach, while mathematicallyelegant, is insufficient to represent structures in the real world ofdistributed computing: what makes a shared account meaningful is that statechange is visible to many users.andP;  The values of functions are, however,returned only to the caller or invoker of that function.andM;The need to implement synchronization between concurrent computationsrequires the ability to define an indeterminate, complete merge of messagessent to an actor.andP;  We call such a merge a fair merge.andP;  A fair merge iscomplete because it merges messages from every sender and may not ignore anysender indefinitely and it is indeterminate because no particular order isspecified for messages sent to the same object by different objects.andP;  Becauseshared history-sensitive objects interleave messages sent by differentobjects, modeling such objects is equivalent to representing a fair merge.andM;Fair mergers are a fundamental concept in modeling concurrent systems; theyallow one to abstract over different possible assumptions about the relativespeeds of processors, the scheduling of processes on processors, and therelative speed of the communication links.andP;  A model which made specificassumptions about such implementation-dependent factors may not besufficiently abstract to be useful in reasoning about different possibleimplementations of a concurrent program (see, however, the discussion aboutcoordinated action in section entitled &quot;Coordination&quot;).andP;  Using a semantics offair merge, one can reason about the eventual behavior of a concurrentprogram; reasoning about eventual properties of a concurrent system isanalogous to reasoning about fixed points in a recursion in sequentialprogramming.andM;The behavior of fair merge cannot be represented by the standard substitutionsemantics grounded in the lambda calculus.andP;  A substitution semantics requiresthat an expression have the same value regardless of the context in which itis invoked--a condition violated by the shared bank account whose behaviorchanges as a function of the balance in the account.andP;  Because the ability toimplement shared resources is so fundamental to a concurrent system, theactor approach is to integrate the ability to create modifiable, sharedstructures into the programming model.andP;  Furthermore, the connections betweenobjects may be dynamically made or broken.andP;  Fair mergers in the actor modelare implicit--they are captured by the guarantee of message delivery whichstates that any message sent to an actor must eventually be received--i.e.,andO;after a finite but arbitrarily long delay.andP;  The guarantee of delivery doesnot specify the order in which messages may be received by an actor.andP;  Inparticular, the sequence of messages from one actor to another need not bepreserved: this allows for the possibility of adaptive routing.andM;It should be observed that the guarantee of message delivery in anasynchronous communication model itself cannot be realized with certainty--itcan only be provided with some level of confidence in a well-engineeredsystem.andP;  For example, in principle, an actor could produce enoughcommunications to exceed the buffering capacity of the communication network.andO;This problem is similar to that of implementing recursion using a stack: arecursion may be prematurely terminated by limitations of stack size.andP;  In asequential system, only bounded stacks are physically realizable but thebounds would vary with every specific implementation.andM;Building Actor SystemsandM;Computation in a typical actor system is performed by the decisions andcommunications of many small modules.andP;  Actor primitives provide a verylow-level description of concurrent systems--much like an assembly language.andO;Higher-level constructs are necessary both for raising the granularity ofdescription and for encapsulating faults.andP;  Such constructs delimitcomputational boundaries by aggregating a collection of events intoorganizational units characterized by patterns of interactions.andP;  Simpleexamples of patterns of interactions include control structures, synchronouscommunication, and transactions.andP;  The following discussion elaborates onthese examples and their use in implementing actor systems.andM;CoordinationandM;A simple example of coordination is that required in function calls whichreturn a value to the (usually implicit) join continuation which is thereturn address for the call.andP;  The creation of join continuations increasesthe available concurrency in a function call.andP;  Thus, function calls are anexample of a very simple two-party interaction involving synchronizationbetween a message and an actor.andM;A more complex example of a two-party interaction is syncrhonouscommunication between two actors; such communication represents an atomicinteraction between two actors.andP;  Because there is no instantaneous action ata distance in a distributed system, synchronous communication can beimplemented only by strongly constraining the implementation.andP;  In particular,its implementation requires a known time bound on the potential communicationdelay between the two actors which can communicate syncrhonously.andM;The syncrhonous communication model is critical to the problem ofcoordination in distributed systems.andP;  Specifically, it allows not onlyinformation to be shared but the meta-knowledge that the information has beenshared: if an actor X communicates information i syncrhonously with an actorY, X shows that Y knows i and Y knows that X knows that Y knows i, etc., andinfinitum.andP;  This stage of knowledge is called common knowledge; commonknowledge is essential for coordination between agents who need to act inconcert (see, for example, [21]).andP;  In the above example, if X will not actuntil X knows that Y will also act, then it can be shown inductively thatneither actor will act unless they have common knowledge.andP;  The notion ofcommon knowledge can be generalized to collections of an arbitrary number ofagents.andP;  Common knowledge may be achieved through mechanisms representingasyncrhonous communication which is guaranteed to be delivered within aspecified bounded time interval.andP;  Note, however, that there is no uniqueglobal clock in a distributed system; thus time delays must be expressed inrelativistic terms (they may be bounded, for example, using a distancemetric).andP;  The problem of coordination raises a number of interestinglinguistic and semantic issues and is an active area of research in theauthor's group.andM;Transactions are another example of n-party interactions.andP;  In the context ofactor systems, communications can be classified as requests or responses.andO;Each request carries a customer to which a (unique) response is to be sent.andO;A transaction is defined as all events intervening in the combined causal andarrival ordering between a given request and a response to it.andP;  An event(processing of a message) precedes another event in the causal order if thesecond event is the result of processing the message corresponding to thefirst event.andP;  The arrival order represents the order in which messages areprocessed by a given actor.andM;Transactions delineate computational boundaries for error recovery or for theallocation of resources.andP;  Transactions have been used to support debuggers inconcurrent computation (see below) and have been proposed as a mechanism fordetermining resource allocation policies at a high level (see the sectionentitled &quot;Resource Management&quot;).andM;Visualizing Actor ProgramsandM;There are two important difficulties in monitoring and debugging concurrentprograms.andP;  First, concurrency implies that program execution isnondeterministic.andP;  Thus any given execution trace of a program is not likelyto be repeated.andP;  Second, in any reasonable-sized concurrent system, the largenumber of objects and interactions between the objects results in enormousdata consisting of the large set of events and their relations.andP;  This isfurther complicated by the fact that since there is no unique or true globalstate in a distributed system, the observations of on-going activity in asystem themselves suffer from nondeterminism due to the observer's frame ofreference.andM;One approach to monitoring computations is to retroactively reconstructrelations between events which have already occurred; this can beaccomplished by constructing event diagrams of the sort described in Figure5.andP;  Each actor records the communications it has received in the order itreceives them and the actions it takes in response to thosecommunications--namely the communications it sends out and the actors itcreates.andP;  The sending and receiving events are linked by looking at therecordings in the actor which was the target (specified recipient) of thecommunication.andM;A problem with the use of event diagrams is that they contain every eventand, in any realistic concurrent system, there are simply too many events.andO;Using event diagrams to try to pinpoint an error can be harder than lookingfor a needle in a haystack.andP;  Mechanisms are necessary to structure events bydelineating computational boundaries.andP;  One such mechanism is based on theconcept of transactions.andP;  For our purposes, a transaction is delimited byevents between a request message and a response message, where &quot;between&quot; isin terms of a partial order defined by the transitive closure of causal andarrival orders on events.andP;  In addition, the transaction must obey thefollowing properties:andM;1.andP;  if a request generates subrequests, the corresponding subtransactionsmust also be within the transaction.andM;2.andP;  no subtransaction is shared with other transactions, (i.e., twoindependent transactions include the same subtransaction).andM;3.andP;  the first two conditions recursively hold for the subtransactions.andM;Transactions can be used to pinpoint errors in much the same way a microscopeis used to pinpoint areas by recursively focusing on smaller regions whichcontain the potential point of interest (see Figure 11).andP;  In case of atransaction which does not meet its specification, one can look at itssubtransactions to determine which of these subtransactions may be causingthe observed error.andP;  In standard usage, the term transaction also implies arequirement of atomicity, (i.e., either all events that are part of atransaction occur or none of them occur).andP;  While the atomicity requirement isuseful for delimiting boundaries for error recovery, it is often too strongfor a general-purpose programming language.andM;A debugging system based on this mechanism has been implemented by Manning atMIT.andP;  The system is called the observatory [19].andP;  When the transactionalstructure is not preserved in a computation, for example because of a sharedsubcomputation, the request reply structure still serves as a granularitycontrol mechanism.andP;  Using the observatory, one can end up potentially weavingback and forth through connected computations looking for the source oferror.andP;  In order to address this kind of difficulty, Yonezawa's group at theUniversity of Tokyo has developed an alternative method for monitoringprograms based on collecting objects into groups (see [24]).andM;Resource ManagementandM;In a concurrent language, a problem is often dynamically partitioned intosubproblems.andP;  An application developer needs to be able to specify theallocation of resources to each dynamically created subproblem.andP;  Becausethousands of subcomputations may be created, such allocation decisions needto be specified at a high level of abstraction.andP;  Sponsors are actors whichconnect to the underlying resource management system and are used to drive orthrottle a computational path.andM;For example, in a graph search problem, examining a node may suggestexamining a number of other neighboring nodes.andP;  This process may be termednode expansion.andP;  All nodes which are candidates for expansion may not beequally promising candidates; thus a sponsor is needed to specify how muchresource to allocate to a node expansion.andP;  Furthermore, an allocationdecision may need to be dynamically modified as a computation proceeds.andP;  Inorder to determine how much resource to give to a node expansion in a graphsearch algorithm, a sponsor may use a given sponsorship algorithm whichmeasures the goodness of a target expansion.andP;  The sponsor may also be afunction of current resources which are available for the computation.andM;A decision about whether to perform a subcomputation is thus specifiedindependently of how the computation itself is to be carried out.andO;Furthermore, a sponsorship algorithm does not need to specify details abouthow to utilize physical resources, such as memory or processing power, anddoes not need to make assumptions about their associated costs.andP;  It simplyprovides very high-level control over the relative rates or extent ofunfolding of particular computational paths.andM;In many computations, it is natural for subcomputations to be shared betweena number of independent computations.andP;  A number of messages may be mergedbefore being processed; for example, a number of requests to a money marketaccount may be merged into a single subcomputation involving the trading of aset of stocks.andP;  In this case, explicit policies must be developed to mergeresources and, conversely, to assess computation costs.andM;Other Models of ObjectsandM;A number of COOP language models unify a declarative view of objects asabstract data types with a procedural view of objects as sequentialprocesses.andP;  In this model, each object is a sequential process which respondsto messages sent to that object.andP;  Every object may execute its actionsconcurrently.andP;  The number of objects which have a pending message to process(i.e., are potentially active) at a given time during the execution of aprogram is called its concurrency index at that time.andP;  In particular, theconcurrency index is limited by the total number of objects in a system at agiven time, although new objects may be created dynamically.andP;  The concurrencyindex may be increased by invoking objects asynchronously--thus activatingother objects.andM;Languages which use a process model of objects include ABCL [24], POOL [5],Concurrent Smalltalk (see [25]) and BETA (see [22]).andP;  Some other languagesrealize a simple variant of the Actor model: the body of an object isexecuted sequentially and assignments may be used within the body butmessages are buffered and may not be received during &quot;intermediate&quot; states ofan object.andP;  Semantically, the behavior of all COOP languages, whether theyuse a process model or otherwise, can be modeled by actors, much as functionscan describe the semantics of procedures in sequential programming.andM;A traditional sequential process model allows arbitrary control structures tobe specified within the body of a given object.andP;  The traditional model alsoencourages sequencing of actions which is potentially unnecessary from thepoint of view of understanding the concurrency inherent in the logic of aprogram.andP;  An advantage of a process model is that it allows the explicitspecification of state change using a familiar one step at a time assignmentto variables; the variables are, of course, encapsulated within a givenobject.andP;  Another advantage is that a programmer can optimize the size of thesequential processes to match the optimal size of processes on a givenconcurrent architecture.andP;  Thus, the process size can be determined by aprogrammer as a function of architectural characteristics such as the costsassociated with process creation, context switching and communication.andM;On the other hand, the sequential process model of objects has at least threedisadvantages.andP;  First, sequential processes which are optimal on onearchitecture may not be so on another with different characteristics.andO;Second, because not all state change is due to the logic of an algorithm, itbecomes harder to reason about the parallelism in a particular algorithm.andO;Finally, because assignments of values to variables are frequently used inthe sequential process model, it complicates programs by discouraging the useof functional components when such components are adequate.andM;An alternative approach to providing efficient execution on concurrentarchitectures is to throttle the concurrency in an inherently concurrentlanguage, using translators which are optimized for a particulararchitecture.andP;  This is an area of active research in actors (as well as inthe concurrent implementation of declarative languages such as functionalprogramming languages and the so-called concurrent logic languages).andM;Inherent ConcurrencyandM;There are some basic language design decisions involved in providing anotation to specify the behavior of objects; these decisions affect what kindof concurrency can be extracted from the behavioral description of an object.andO;In particular, two styles of expression evaluation can be identified:andM;Call/Return Style.andP;  Subexpressions in the code are evaluated (possiblyconcurrently) and their values are substituted before proceeding to theenclosing expression.andM;Customer-Passing Style.andP;  Subexpression's evaluations and the joincontinuations' creation are initiated concurrently.andP;  The object is then freeto accept the next message.andP;  A join continuation takes the results ofsubexpression evaluations and carries out the rest of the computationspecified by the original computational thread provided in the object'sbehavior.andM;The customer-passing style supported by actors is the concurrentgeneralization of continuation-passing style supported in sequentiallanguages such as Scheme.andP;  (2)  In case of sequential systems, the objectmust have completed processing a communication before it can process anothercommunication.andP;  By contrast, in concurrent systems it is possible to processthe next communication as soon as the replacement behavior for an object isknown.andM;Note that the ability to distribute work in systems using call/return style,those using customer-passing style, and those that do or do not sequenceactions within objects, may be identical.andP;  For example, the language Cantordeveloped at Caltech, uses sequential execution of code in the body of anobject.andP;  Cantor has the full power of actor languages; it supports dynamiccreation of objects, asynchronous message passing between objects, and atomicreplacement behaviors.andP;  In case of primitive actor actions, typicallyasynchronous message sends, sequencing actions within an object causesminimal delay; the time required for these actions is fairly small and theresulting activity is concurrent.andP;  However, when arbitrarily complexexpressions are to be evaluated, unnecessary sequential dependencies cancreate significant bottlenecks.andM;Consider the concurrent implementation of the mergesort algorithm.andP;  Assume wehave a linked list of numbers which we want to sort.andP;  Of course, a linkedlist is a (very) sequential data structure; we are using it here forillustrative purposes only.andP;  A linked list can be split in n/2 steps where nis the length of the list, provided that n is known--essentially we have towalk the pointer links to the middle of the list and create a pointer (callit second) to that part of the list.andP;  If the length of the list is not known,it would take an extra n step to determine it.andM;After a list is split, the two sublists can be concurrently sorted usingmergesort, and the results merged by successively comparing an element fromeach of the two lists and picking the smaller one.andP;  The next element from thelist to which the lesser element belongs is then used in the next comparison.andO;Thus, given two sorted lists, merge produces a sorted list containingelements in both lists.andP;  It should be noted that this merge procedure hasnothing to do with the concept of merge in concurrency which represents aninterleaving of all incoming messages discussed earlier.andM;The mergesort algorithm can be expressed as in Figure 12.andM;The form let* represents multiple (possibly recursive) let bindings andfirst-half and second-half return the respective halves of the list and theirlengths.andP;  As recursive calls are made, the list is split until we havesingletons.andP;  Each split requires half the number of operations of theprevious.andP;  As in a sequential mergesort, the total number of operations isO(n log n); however, the concurrency index doubles each time a split is made.andO;Thus the splits can potentially be executed in O(n) time--given a sufficientnumber of processors and assuming constant overhead.andP;  Initially there are n/2merges involving only two elements and these can be carried out concurrently.andO;The final step involves a single merge of two lists of roughly n/2 elements.andO;The merges takes O(n) time since in the final merge one has to walk down thetwo lists doing comparisons.andM;Following Atlas [17], Figure 13 gives the concurrency index (CI) for themergesort algorithm executed on 1000 elements.andP;  To simplify countingexecution steps, we assume all processes are run synchronously--although thealgorithm has no synchronous processing requirement.andP;  Each interval in thex-axis of the diagram represents the processing of a single message by allactors which have a pending message.andP;  Furthermore, message delivery isassumed to take one time step.andP;  These time steps are called sweeps.andP;  Noticethat a difficulty with this algorithm is that it requires roughly nprocessors to sort a list of n numbers.andP;  However, most of these processorswould be idle much of the time (as far the execution of the mergesortalgorithm is concerned).andP;  In practice, the processing corresponding to asweep will be delayed until all the processing in the previous sweep can becompleted.andP;  In other words, the concurrency index curve plotted as a functionof steps needs to be truncated at the maximum number of processors available.andO;Thus, executing the algorithm on a real parallel computer will take at leasta time factor which equalizes the areas under the two concurrency indexcurves (the truncated curve and the curve assuming a sufficiently largenumber of processors).andM;The total time efficiency of mergesort in the presence of a limited number ofprocessors can be improved by the following observation: Because thebeginning element and length of the first half of the list are known, thefirst half of the list is determined even as the first element of the secondhalf is being computed.andP;  (3)  Thus, one can start sorting the first half ofthe list concurrently with computing the first element of the second half ofthe list.andP;  The algorithm in Figure 14 provides a skeleton of how this can bedone.andM;Figure 15 plots the expected ideal behavior of this algorithm (as simulatedby the Rosette system).andP;  It gives the concurrency index as a function of thenumber of sweeps.andP;  Note that the processors are more uniformly busy and themaximum number used is only a small fraction of the number of elements in thelist.andP;  The reason for the more uniform concurrency index is that theconcurrency index builds up much more rapidly as more mergesorts aretriggered.andM;The case of expression in an inherently concurrent language simplifies notingthe data dependencies which are simply expressed as synchronizations implicitin function calls.andP;  On the other hand, it is possible to express the samecode in terms of sequentially executed primitive actor bodies--without anymeaningful loss of speed.andP;  The second case requires that, instead of waitingfor an arbitrarily large number of objects to execute, the dynamic creationof a number of context objects be explicitly specified to carry out thesubcomputations.andP;  In an inherently high-level actor language, this work issimply transferred to a compiler.andM;CommunicationandM;and CoordinationandM;Because there is no instantaneous action at a distance, the interactionsbetween components of a distributed system must be built in terms ofasynchronous communication.andP;  In an asynchronous communication model, a senderis free to take further action after dispatching a given message.andP;  This is incontrast to sequential object-oriented languages such as Smalltalk which usesynchronous communication: in this case, a sender waits for a response beforecontinuing its execution.andP;  Synchronous communication fits naturally with theuse of a single active computational thread which weaves through differentobjects which are invoked and return a value to their caller.andM;In the context of concurrent computing, however, synchronous communicationreduces the number of objects that may be potentially active at any givenpoint in time.andP;  If an asynchronous communication model is used, as in theprimitive Actor model (see section entitled &quot;The Actor Model&quot;), thencustomers representing return addresses must be explicitly supplied.andP;  Forexample, the behavior of an actor x in response to a [+ 3 c] message may beto return 8 to the customer c which has been supplied in the message.andP;  It isoften convenient to assume that the value of a subexpression will beautomatically substituted for the arithmetic subexpression when theexpression is evaluated.andP;  Such a notation abstracts from the explicitsynchronization which must be implemented in terms of asynchronousmessage-passing.andP;  The difference between implicit and explicitsynchronization is similar to the difference between an assembly language anda (sequential) programming language with expressions.andP;  The constructs of theactor model are primitives which can be used to build higher-order concurrentprocedural and data abstractions.andM;ReasoningandM;about ObjectandM;BehaviorandM;Because the state of the components of a system is constantly changing, it isgenerally impossible to predetermine precisely what state a particularcomponent will be in when another component attempts to interact with it.andP;  Inmodels of concurrency based on communicating sequential processes, the effectof a message received at all potential entry points within a process must beconsidered.andP;  In a shared variable model, even more interactions are possibleas different information may be written into each shared variable of aprocess by any other process, creating an exponential number of possibilitiesfor interaction.andP;  Each interaction corresponds to a different indeterminateexecution of the system.andM;Actors encapsulate operations so that they may be externally invoked at onlyat one entry point.andP;  This can be achieved by breaking up a sequential processinto a number of smaller independent objects; in fact, it is sometimespossible to use formal transformation rules to automatically decomposeprocesses into objects with a single entry point as proposed by Shibayama atthe Tokyo Institute of Technology (see [24]).andP;  Intermendiate states of anactor are invisible to the outside, and actors may not be interrupted in suchstates.andP;  Because interactions between intermediate states of two actors neednot be considered, such decomposition promotes modularity; specifically, itcan reduce the complexity of invariant properties to be established in orderto reason about the behavior of a program.andP;  The distinction between actorsand procedures with multiple communication entry points can be appreciated byconsidering their analogy to the difference between procedure calls andunrestricted goto's.andM;The behavior of an actor is atomic, (i.e., internal loops are prohibitedwithin actors).andP;  Thus the interaction problem is transferred to anotherlevel: the number of interactions between independently triggeredcomputations can again be large as an actor interleaves messages triggered bydistinct requests from different senders.andP;  This potential disadvantage ismitigated by two factors: first, actor languages encourage greater use offunctional components which are referentially transparent and easy to reasonabout.andP;  Second, actor languages use a customer-passing style to separate thecontinuation representing an actor's future behavior and the continuation ofa computational thread.andP;  In other models of concurrent objects, multipleentry points are possible when synchronous communication is used.andP;  However,even in some of these models, the target object is invoked at a single entrypoint and provides a response to the caller at the point of the call.andM;A second advantage of COOP is the locality properties in the model.andP;  Anobject may send a message only to those objects it knows about [15].andP;  Theaxioms governing which objects are known to an object are called localitylaws; these laws were developed in the context of the Actor model by Hewittand Baker at MIT.andP;  Locality laws further restrict the number of possibleinteractions between objects which have to be considered in a given system.andO;Locality laws make it possible to model open systems, (i.e., evolving systemswhich are open to interaction with their environment).andP;  Because the outsideenvironment is dynamically changing and may contain unknown elements, itsbehavior cannot be completely predicted.andP;  Therefore an open systems modelmust allow local reasoning about a module in different possible contexts.andP;  Byregulating interactions with other actors, locality laws make such localreasoning feasible.andP;  In particular, because the constituents of thedistributed system will not be known to a single object in the system,(global) broadcasting is not generally a meaningful construct in opensystems.andM;Object-OrieantedandM;ProgrammingandM;Object-oriented programming supports the reusability of code, thus supportingan evolutionary programming methodology, and it provides modularity inprogramming, thus allowing a separation of design concerns.andP;  These powerfulaspects of object-oriented programming can be utilized in concurrentprogramming by providing mechanisms such as inheritance and reflection.andP;  Thissection discusses the basic constructs which can be used to build thesemechanisms and points to some interesting research issues.andM;InheritanceandM;A powerful feature of object-oriented languages is inheritance.andP;  Inheritancewas introduced in Simula primarily as a organizational tool forclassification.andP;  In Simula, objects can be defined as members of a class and,as a consequence, share procedures that are applicable to all members of theclass; note that members of a class may themselves be classes.andP;  Class-basedsharing naturally promotes modularity in the code by putting all the codecommon to a number of objects in one place.andP;  Modifying and debugging programsis simplified by making changes to a class whose behavior in turn is visibleto all its members.andP;  Organization of objects using classificationincorporates objects into a tree-like structure and can provide clarity inknowledge representation--as experience in chemistry (periodic table) andbiology (taxonomy of species) has shown.andM;Inheritance essentially makes the code in one object (a class) visible toanother object (a member).andP;  Code sharing leads to namespace managementissues--the same identifier may be bound to procedures and parameters in anobject and in its class.andP;  Object-oriented languages differ regarding how suchname conflicts are handled.andP;  In Simula, superclass identifiers are renamed;this essentially provides static bindings which are resolved lexically.andO;Simula also provides for a virtual declaration which allows identifiersrepresenting variables (but not those bound to methods) in a superclass to bevisible in a subclass--a case of dynamic scoping.andP;  Virtuals are used tosupport incomplete specifications which are to be added to by the subclasses.andO;While Simula was not designed to support concurrency, one of the designers ofSimula, Kristen Nygaard at the University of Oslo, has developed incollaboration with Ole Madsen at Arhus University and others, the languageBETA which explicitly supports concurrent programming.andP;  Concurrency in BETAis obtained by explicitly specifying alternation or multisequential execution(see the chapters on BETA in [22]).andM;By contrast, Smalltalk takes a more operational view of inheritance.andO;Conflicts in identifiers are resolved dynamically to provide greaterflexibility.andP;  This emphasis led to its use primarily as a programming methodto suport sharing and reusability of code and data, rather than as amechanism for classification.andP;  A good discussion of a number of issuesrelating to inheritance and object-oriented programming can be found in [22].andO;(See, specifically the classification of object-oriented languages developedby Peter Wegner at Brown University.)andP;  Related mechanisms include classlessschemes such as dynamic inheritance and delegation.andM;One proposal, advanced by Jagannathan and the author, is to allow programmersto define different possible inheritance mechanisms in a single linguisticframework [17].andP;  Associated with an object is a local environment whichprovides bindings for the identifiers in that object.andP;  The idea is to providethe ability to reify environments (see the discussion in the followingsection and to explicitly manipulate them as first class objects).andP;  Forexample, two environments may be composed so as to shadow the bindings in oneobject (for example, a class) with the bindings in another object (forexample, an instance).andP;  By using different possible compositions, distinctinheritance mechanisms can be obtained and these mechanisms can coexist inthe same system.andP;  This proposal is an extension of the work of Jagannathan onfirst-class environments [16].andM;The interaction of concurrency and inheritance raises a number of interestingissues.andP;  For example, replacement behaviors in actors are specifiedatomically.andP;  If inheritance is defined in terms of a message-passing protocolbetween one object and another, the task of determining a replacement may benaturally distributed as part of the replacement behavior is determinedlocally and part in a different object.andP;  This is not an issue in a sequentiallanguage like Smalltalk which uses synchronous communication with a singleactive thread: parts of the state of an object are updated throughassignments made by the object and other parts of the state may be assignedby its class.andP;  Another complication which arises in concurrentobject-oriented languages with inheritance mechanisms is the interactionbetween inheritance and synchronization constraints.andP;  This has been a veryactive area of research and a number of solutions have been proposed (forexample, see [23]); we discuss this interaction briefly in the next section.andM;ReflectionandM;In the normal course of execution of a program, a number of objects areimplicit.andP;  In particular, the interpreter or compiler being used to evaluatethe code for an object, the text of the code, the environment in which thebindings of identifiers in an object are evaluated, and the communicationnetwork are all implicit.andP;  As one moves from a higher-level language to itsimplementation language, a number of objects are given concreterepresentations and can be explicitly manipulated at the lower implementationlevel.andP;  for example, the join continuation actor in Figure 8 is implicit inFigure 3.andP;  When the join continuation is made explicit, it can be usefullymodified, as we showed in Figure 10.andM;The dilemma is that if a very low-level language is used, the advantages ofabstraction provided in a high-level notation are lost.andP;  Alternately, theflexibility of a low-level language may be lost in a high-level language.andO;Moreover, although it is possible for a low-level program to have a model ofits own behavior (for example, as in the case of a Universal Turing Machine),this need not always be the case.andP;  A reflective architecture addresses thisproblem by allowing us to program in a high-level language without losing thepossibility of representing and manipulating the objects that are normallyimplicit [18].andP;  Reification operators can be used to represent at the levelof the application, objects which are in the underlying architecture.andP;  Theseobjects can then be manipulated like any other objects at the higherapplication level.andP;  Reflective operators may then be used to install themodified objects into the underlying architecture.andP;  Reflection thus providesa causal connection between the operations performed on this representationand the corresponding objects in the underlying architecture.andM;In the example of a tree product, the program can be expressed in ahigh-level language as a functional product expression.andP;  However, whenneeded, its join continuation can be dynamically reified and a new joincontinuation actor can be installed to perform the necessary synchronization.andM;In a COOP system, the evaluator of an object is called its meta-object.andO;Reflective architectures in COOP's have been used to implement a number ofinteresting applications.andP;  For example, Watanabe and Yonezawa (see [24]) haveused it to separate the logic of an algorithm from its scheduling for thepurposes of a simulation: in order to build a virtual time simulation,messages are time-stamped by the meta-object and sent to the meta-object ofthe target which uses the time-stamp to schedule the processing of a messageor to decide if a rollback is required.andP;  Thus the code for an individualobject need only contain the logic of the simulation, not the mechanisms usedto carry out the simulation; the specification of the mechanisms is separatedinto the meta-objects.andM;One application of reflection in actor-based systems is to address theproblem of synchronization constraints, (i.e., conditions limiting whichcommunications an actor in a given state is able to process).andP;  For example, abounded buffer which is full cannot service requests to enqueue.andP;  In someCOOP languages, synchronous communication is used to enforce synchronizationconstraints; the recipient refuses to accept communications which it is notin a state to process.andP;  This solution, while quite simple, can reduce theamount of concurrency available in a system by requiring suspension of theexecution of actions by a sender until the recipient is ready to accept themessage--even if the sender's future behavior does not depend on whether themessage has been delivered.andM;One approach to increasing concurrency in the synchronous communication modelis to dynamically create a new object which attempts to synchronouslycommunicate with the target.andP;  The original sender is then free to continueits processing.andP;  While theoretically feasible this solution can beinefficient: it may increase the traffic in the communication network as asender repeatedly tries to transmit the message to an unavailable recipient.andM;Another solution, used in actor systems, is to let an object explicitlybuffer incoming communications which it is not ready to process (i.e.,andO;selective insensitivity).andP;  For example, an actor may need to process messagesin the order in which they are sent by a given sender.andP;  However, because ofadaptive routing, the order in which messages arrive may be different fromthe order in which they were sent.andP;  In this case, messages which arrive outof sequence can simply be buffered until their predecessors have arrived.andM;The insensitive actor approach has an important deficiency: it fails toseparate the question of what order a given set of tasks can be executedin--i.e., the synchronization constraints from the question of how thosetasks are to be executed--i.e., the algorithmic structure of actions to betaken.andP;  Such a separation would support local reasoning about feasibleactions.andP;  In the Rosette language, Tomlinson and Singh proposed a reflectivemechanism which reifies a mail queue for an actor and modifies the queue'sbehavior by making it sensitive to enabledness conditions which capture thesynchronization constraints of the actor to which the queue belongs [23].andM;Research EffortsandM;The development of architectures and systems based on the COOP model is anactive area of research around the world.andP;  We briefly describe a few of theseefforts.andP;  This list is by no means complete but gives a flavor for some ofthe work under way.andM;In Europe, several large-scale efforts are under way.andP;  Under the auspices ofESPIRIT, de Bakker, America and others have worked on the definition of aparallel object-oriented language called POOL [5].andP;  In the POOL object model,each object has a body, a local process, which starts as soon as the objectis created and executes in parallel with the bodies of all other objects.andO;Sending and receiving of messages is indicated explicitly within this body insuch a way inside every object everything proceeds sequentially anddeterministically.andP;  In industrial partnership with Philips, the project hasalso designed a language-driven architecture called DOOM (DecentralizedObject-Oriented Machine).andP;  DOOM is a parallel machine consisting of a numberof processors (100 in the present prototype), each with its own privatememory, and connected via a packet-switching network.andP;  Many small and severalmedium-to-large applications have been written in POOL.andP;  Example applicationareas are databases, document retrieval, VLSI simulation, ray tracing, expertsystems, and natural language translation.andM;Another large ESPRIT project, called ITHACA (Integrated Toolkit for HighlyAdvanced Applications), is working to produce an object-oriented applicationdevelopment environment including a concurrent object-oriented language anddatabase, a Software Information Base (which will store a large collection ofclasses), a set of tools for browsing, querying and debugging classes, andtools to support interactive application construction from reusable classes.andO;ITHACA is a 5-year, 100 man-year/year (12 million ECU/year) project led byNixdorf, with Bull, Geneva, and three other European partners.andP;  An academicpartner in the project is a group under the direction of Tsichritzis at theUniversity of Geneva.andM;Japan's Ministry of International Trade and Industry recently announced thatit will support a Cooperating Agents Project based on COOP.andP;  Initial fundinglevel for this seven year project is estimated to be $35 million.andP;  Yonezawaat the University of Tokyo, whose group developed ABCL (an actor-basedconcurrent language), is an academic leader of this effort.andP;  A focus of thisproject is to apply the work on actors to coordination technology.andM;In the United States, where a foundation for COOP was provided by the work ofCarl Hewitt and associates at MIT, a number of smaller groups are developingCOOP systems.andP;  Hewitt's group in particular is focusing on open informationsystems and artificial intelligence applications.andP;  Ken Kahn, Vijay Saraswatand others at Xerox PARC are working on a high-level actor programminglanguage called Janus.andP;  The author's group at the University of Illinois atUrbana-Champaign is currently working on programming abstractions andlanguage models for dependable concurrent computing.andP;  Finally, the UnitedStates has a considerable lead in innovative multicomputer architecturesinspired by language models closely tied to concurrent object-orientedprogramming.andM;(1) The term Actor was introduced by Carl Hewitt at MIT in the early 1970s todescribe the concept of reasoning agents.andP;  It has been refined over the yearsinto a model of concurrency.andP;  It should be noted that our use of the termbears no relation to the language Actor--the latter being a commercialproduct introduced in the late 1980s.andM;(2) It is interesting to note that Scheme itself was inspired by an attemptto understand the concept of actors as it was first proposed [1].andM;(3) This observation was communicated to the author by Chris Tomlinson.andM;ReferencesandM;[1] Abelson, H. and Sussman, G.J.andP;  Structure and Interpretation of ComputerPrograms.andP;  MIT Press, Cambridge, Mass, 1985.andM;[2] Agha, G. Actors: A Model of Concurrent Computation in DistributedSystems.andP;  MIT Press, Cambridge, Mass., 1986.andM;[3] Agha, G. Supporting multiparadigm programming on actor architectures.andP;  InProceedings of Parallel Architectures and Languages Europe (PARLE '89), vol.andO;II: Parallel Languages, LNCS 366.andP;  Springer-Verlag, New York, 1989.andM;[4] Agha, G. and Jagannathan, S. Reflection in concurrent systems: A model ofconcurrent continuations.andP;  Tech.andP;  Rep., Dept.andP;  of Computer Science.andP;  Univ.andO;of Illinois at Urbana Champaign, 1990.andP;  To be published.andM;[5] America, P. Issues in the design of a parallel object-oriented language.andO;Formal Aspects Computing, 1, 4 (1989), 366-411.andM;[6] Annot, J.K.andP;  and den Haan, P.A.M.andP;  POOL and DOOM: The object-orientedapproach.andP;  In Parallel Computers: Object-Oriented, Functional, Logic, P.C.andO;Treleaven, Ed.andP;  Wiley, 1990, pp.andP;  47-79.andM;[7] Athas, W. Fine grain concurrent computations.andP;  Ph.D.andP;  dissertation,Computer Science Dept., California Institute of Technology, 1987.andP;  Alsopublished as Tech.andP;  Rep.andP;  5242:TR:87.andM;[8] Athas, W. and Boden, N. Cantor: An Actor Programming System forScientific Computing.andP;  In Proceedings of the NSF Workshop on Object-BasedConcurrent Programming, G. Agha, P. Wegner, and A. Yonezawa, Eds.andP;  ACM, N.Y.,andO;April 1989.andP;  pp.andP;  66-68.andP;  Special Issue of SIGPLAN Notices.andM;[9] Athas, W. and Seitz, C. Multicomputers: message-passing concurrentcomputers.andP;  IEEE Comput.andP;  9, 23 (August 1988).andM;[10] Dally, W. A VLSI Architecture for Concurrent Data Structures.andP;  KluwerAcademic Press, 1986.andM;[11] Dally, W. The J-Machine: System Support for Actors.andP;  In Towards OpenInformation Systems Science, C. Hewitt and G. Agha, Eds.andP;  M.I.T.andP;  Press,Cambridge, Mass., to be published.andM;[12] Dally, W. and Wills, D. Universal mechanisms for concurrency.andP;  InProceedings of Parallel Architectures and Languages Europe (PARLE '89).andP;  VolII: Parallel Languages.andP;  Springer-Verlag, New York, 1989.andP;  LNCS 366.andP;  pp.andO;19-33.andM;[13] Fox, G., Johnson, M., Lyzenga, G., Otto, S., Salmon, J., and Walker, D.andO;Solving Problems on Concurrent Processors.andP;  Vol I, General Techniques andRegular Problems.andP;  Prentice Hall, Englewood Cliffs, New Jersey, 1988.andM;[14] Hewitt, C. Viewing control structures as patterns of passing messages.andO;J. Artif.andP;  Intell.andP;  8, 3 (June 1977), 323-364.andM;[15] Hewitt, C. and Baker, H. Laws for communicating parallel processes.andP;  In1977 IFIP Congress Proceedings, IFIP (August 1977) pp.andP;  987-992.andM;[16] Jagannathan, S. A Programming Language Supporting First-Class, ParallelEnvironments.andP;  Tech.andP;  Rep.andP;  LCS-TR 434, Massachusetts Institute ofTechnology, December 1988.andM;[17] Jagannathan.andP;  S. and Agha, G. Inheritance through Reflection.andP;  Tech.andO;Rep., Dept.andP;  of Computer Science, Unive.andP;  of Illinois at Urbana Champaign,1990.andP;  To be published.andM;[18] Maes, P. Computational Reflection.andP;  Ph.D.andP;  dissertation, VrijeUniversity, Brussels, Belgium, 1987.andP;  Tech.andP;  Rep.andP;  87-2.andM;[19] Manning, C. Traveler: the actor observatory.andP;  In Proceedings of EuropeanConference on Object-Oriented Programming.andP;  Springer Verlag, New York,January 1987.andP;  Also appears in Lecture Notes in Computer Science, vol.andP;  276.andM;[20] Manning, C. Introduction to programming actors in acore.andP;  In TowardsOpen Information Systems Science.andP;  C. Hewitt and G. Agha, Ed., MIT Press,Cambridge, Mass, to be published.andM;[21] Moses, Y. Knowledge in a distributed environment.andP;  Tech.andP;  Rep.andO;STAN-CS-86-1120, Computer Science Dept., Stanford University, 1986.andM;[22] Shriver, B. and Wegner, P., Eds.andP;  Research Directions in Object OrientedProgramming.andP;  MIT Press, Cambridge, Mass., 1987.andM;[23] Tomlinson, C. and Singh, V. Inheritance and Synchronization with EnabledSets.andP;  In Proceedings of OOPSLA-89, (1989).andP;  To be published.andP;  ACM, New York.andM;[24] Yonezawa, A., Ed.andP;  ABCL: An Object-Oriented Concurrent System.andP;  MITPress, Cambridge, Mass., 1990.andM;[25] Yonezawa, A. and Tokoro, M., Eds.andP;  Object-Oriented ConcurrentProgramming.andP;  MIT Press, Cambridge, Mass., 1987.andM;MulticomputersandM;Several kinds of concurrent computer architectures have been proposed.andP;  Thesearchitectures may be broadly divided into synchronous computers, sharedmemory computers, and multicomputers (also called message-passing concurrentcomputers).andP;  Synchronous computers, such as the Connection Machine, aresuitable for data-parallel computation.andP;  These computers are quitespecial-purpose and rather restrictive in their model of concurrency.andP;  We areprimarily interested in general-purpose computing--for this purpose,computers which support control parallelism are of greater interest.andM;Shared memory computers have multiple processors and provide a global sharedmemory.andP;  For efficiency reasons, each processor also has a local cache, whichin turn creates the problem of maintaining cache coherence.andP;  The sharedmemory computers that have been built typically consist of 16 to 32processors.andP;  Because large numbers of processors create increased contentionfor access to the global memory, this kind of architecture is not scalable[10].andM;Multicomputers use a large number of small programmable computers (processorswith their own memory) which are connected by a message-passing network.andO;Multicomputers have evolved out of work done by Charles Seitz and his groupat Caltech [9] and have been used to support actor languages [7].andP;  Thenetwork in multicomputers supports the actor mail abstraction; memory isdistributed and information is localized on each computer.andP;  Load balancingand maintaining locality of communication simplified by using small objectswhich can be created and destroyed dynamically, qualities which arecharacteristic of actor systems.andM;Configurations of multicomputers with only 64 computers exhibit performancecomparable to conventional supercomputers.andP;  It should be noted that machinesbased on the transputer are also multicomputers, but these computers use amodel of computation based on communicating sequential processes rather thanthe actor model.andM;Multicomputers may be divided into two classes: medium-grained multicomputersand fine-grained multicomputers.andP;  Two generations of medium-grainedmulticomputers have been built.andP;  A typical first-generation machine (alsocalled the cube or the hypercube because of its communication networktopology) consisted of 64 nodes and delivered 64 MIPS.andP;  Its communicationlatency was in the order of milliseconds.andP;  The typical second-generationmedium-grained multicomputer has 256 nodes, can carry out about 2.5K MIPS andhas a message latency in the order of tens of microseconds.andP;  The developmentof these machines continues.andP;  Third-generation machines are expected to bebuilt over the next five years and increase the overall computational powerby two orders of magnitude and reduce message latency to fractions of amicrosecond [9].andM;However, the frontiers of multicomputer research are occupied by work onfine-grained multicomputers.andP;  These computers realize an idealized actormachine with fine-grain concurrent structure inherent in the functional formof an actor's behavior; in turn the Actor model is well-suited to programmingthem (for example, see [10]).andP;  Two projects building experimentalfine-grained multicomputers are the J-Machine project by William Dally'sgroup at M.I.T.andP;  [11] and the Mosaic project by Charles Seitz's group atCaltech.andP;  The experimental prototype of the Mosaic system will consist of16,384 nodes and is expected to deliver 200,000 MIPS [9].andM;Obviously, Actor languages can be implemented on a number of computerarchitectures such as sequential processors, shared memory machines, and SIMDarchitectures.andP;  However, multicomputers are particularly interesting becauseof their scalability characteristics.andP;  It should also be observed that actorscan be directly supported on multicomputers whereas implementing otherprogramming paradigms on such computers may require their implementation interms of some simple variant of the actor execution model (For example, see[12]).andO;</TEXT></DOC>