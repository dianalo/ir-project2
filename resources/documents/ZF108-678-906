<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-678-906  </DOCNO><DOCID>08 678 906.andM;</DOCID><JOURNAL>AI Expert  July 1990 v5 n7 p52(8)* Full Text COPYRIGHT Miller Freeman Publications 1990.andM;</JOURNAL><TITLE>Turing, Searle, andamp; thought. (includes related articles on Chineseroom complexity and epiphenomena) (John Searle rejects the Turingtest to define intelligence)</TITLE><AUTHOR>Bourbaki, Nick.andM;</AUTHOR><SUMMARY>John Searle's argument against using the Turing test as adefinition of intelligence is examined.andP;  The Turing test replacesone contestant, who is not required to be truthful, with amachine.andP;  If the results of the test are unchanged by themachine's presence, the machine is said to be capable of thought.andO;Searle's opinions have stirred controversy in the artificialintelligence (AI) community.andP;  They will continue to raise debate,but Searle's work is obviously useful to science.andM;</SUMMARY><DESCRIPT>Topic:     Turing MachinesIntelligent DevicesArtificial Intelligence.andM;</DESCRIPT><TEXT>John Searle rejects the Turing test to define intelligence and so standsaccused of everything from bigotry to mysticism.andM;What does he think, and why arc his critics so hostile?andM;In the Jan. 1990 issue of Scientific American(1) and an earlier, moreextensive article,(2) john Searle of the University ofandM;California at Berkeley presented an argument against using the Turing test asa definition of intelligence.andP;  His papers have attracted much criticism fromthe Al community; some have accused Searle of  sins ranging from mysticism tobigotry.andP;  Since both Searle and his critics are engaged in a debate ratherthan a discussion, the issues involved in defining intelligence seem to begetting less clear.andP;  In a debate, neither party has any genuine interest inthe opinions of the other, but each party's tendency to distort the views ofopponents is generally confusing to interested parties.andP;  This problem isfurther complicated because scientists and philosophers have differentcultures and modes of working and communicating; it's no wonder that debatingscientists and philosophers can hardly make each other out.andP;  The purpose ofthis article is to present, in as fair a manner as possible, the views ofSearle and some of his critics.andM;Before discussing those views, let's remind ourselves about Alan Turing'stest.andP;  In a paper written in 1950,  Turing proposed an operational definitionof intelligence chosen to be equally applicable to humans and machines.andP;  Thetest was described as a generalization of a parlor game Turing called the&quot;imitation game.&quot; The basic idea of this game is that an interrogatorattempts to determine the sex of one or more contestants by asking questionsand receiving answers in writing.andP;  The goal of at least one contestantanswering these questions is to cause the interrogator to make the wrongdetermination.andP;  No information is available to the interrogator other thanthe written answers, and at least one of the contestants answering questionsis not obligated to tell the truth.andM;The Turing test, in its original form, is to replace one contestant who isn'trequired to be truthful with a machine.andP;  If the results of the game areunaffected by the machine's presence, by Turing's definition this machine issaid to be capable of thought.andP;  In other words, a machine that isindistinguishable from a human being solely on the basis of &quot;written&quot;interaction is considered to be capable of thought, where written interactionincludes teletypes, questions transmitted via a third (human) party,typewritten questions and answers, and so on.andM;In his paper, Turing motivates this definition by noting that such writteninteractions are generally considered sufficient for assessing theintelligence (or lack of intelligence) of a person.andP;  He discusses some of theimplications of various computability results on this sort of definition.andP;  Inparticular, his discussion shows how the definition could be correct,provided you are willing to accept that the essential nature of intelligenceis adequately captured by a formal system.andP;  Turing also briefly considers afew objections to this definition, involving a range of topics from romanticlove to extrasensory perception.andP;  While his treatment of these objections isnot inflammatory, his attempts to critique the definition seem to be fairlyweak.andM;For such a seminal work in a technical field, Turing's paper is unusuallyinformal, but I expect that Turing thought it &quot;obvious&quot; that such adefinition of intelligence was correct and saw no reason to be more formal.andO;However, while Turing's definition is an obvious choice, raisingwell-considered objections is quite possible.andM;Searle's argument is subtle in a way seems to confuse intelligent readers.andO;To illustrate this subtlety, I want to propose a problem similar to Turing'sand Searle's but that is less important, or at least less emotional.andP;  Theproblem is to find a definition of gender that can apply equally to humansand machines.andP;  (To imagine this problem  properly, try thinking of Robbie theRobot instead of an IBM mainframe.) We'll find that no satisfactoryoperational definition of gender exists for reasons that are plausible toscientists and that is similar to Searle's argument against the Turing testas a valid definition of intelligence.andM;One approach is to specify a test involving only physical appearance thatwould work for humans (which apparently isn't even the view of theInternational Olympic Committee).andP;  Such a test probably would fail formachines.andM;A second approach is to define gender in terms of observed behavior-gestures,mannerisms, clothing, and sexual interactions, for example.andP;  Imagining amachine that could act like a male or a female is easy; however, in an era ofchanging sex roles and surgical techniques, this definition doesn't seem todistinguish true human males from true human females.andM;A third approach is to define gender in terms of both observed behavior andpotential observed behavior.andP;  Here we can include giving birth or thepotential to give birth.andP;  (Clearly some sort of definition of children andbirth that was equally applicable to humans and machines and that wasoperational would be needed, but that doesn't seem insurmountable.) However,women who have never and could never give birth do exist.andP;  For example,defective organs or defective genetic material can prevent conception orbirth.andP;  Trying to repair a definition based on potential observed behavior isdifficult, because an arbitrary number of reasons exist why a true femalecould never give birth, and it seems impossible to list or even characterizeall of them.andM;Many people consider the concept of gender inseparable from its biologicalorigin and nature; it is not merely the fact that physical structures are acertain way but that they came to be that way without surgery and are due tocertain chromosomal features.andP;  Any definition of gender that applies equallywell to humans and machines would not satisfy such a person.andM;So in short, it seems to me that any operational definition of gender isimpossible.andP;  The difficulty is that the concept of gender involves not simplyoperational or behavioral characteristics, but also structural and functionalcharacteristics.andP;  A structural characteristic depends on the way a mechanismis put together; a functional characteristic, on the other hand, depends onthe purpose and mechanism of operation of a particular structure orcombination of structures.andM;Someone concerned with the biological aspects of gender may intellectuallyappreciate an implementation-independent definition of gender and use itoccasionally or to learn about the true nature of gender, but to such aperson this definition would be of something related to, but other than,gender.andP;  Searle holds this view with regard to human reasoning.andM;SEARLE'S ARGUMENTandM;To describe Searie's point of view, it will be expedient to introduce theidea of intentionality: &quot;Intentionality is the characteristic ofconsciousness whereby that consciousness is aware of or directed toward anobject.&quot; If you're thinking about what you had for lunch, trying to rememberwhere your car is parked, or when your spouse's birthday is, you are beingintentional.andP;  If you bark your shin on a coffee table in the middle of thenight, you don't start being intentional until you begin to wonder why youpersist in keeping the table in the path to the kitchen.andM;Searle has also stated that intentionality is &quot;that property of the mind(brain) by which it is able to represent other things.&quot;(4) Here, the word&quot;represent&quot; doesn't have quite the same meaning that computer scientists use.andO;A &quot;representation&quot; is a mental state with a propositional content thatdetermines its conditions of satisfaction and a propositional mode thatdetermines the direction of fit&quot; of its propositional content.andP;  The directionof fit determines the means of failure of the conditions of satisfaction ofthe propositional content.andP;  If the mental state is a belief of some state ofaffairs, the direction of fit is that the state of affairs must match thosespecified by the propositional content of the belief-the direction of fit ismind-toworld.andP;  For example, if I believe it is raining, my belief is true ifit is indeed raining an not if water is failing from the sky (which canhappen even if it isn't raining).andP;  ere, the propositional mode tells us thatthe belief is false when it is not raining.andP;  The wish that it were raining isalso a representation, which isn't satisfied when it is raining but when thebeliever sincerely wishes it would rain and it is not raining.andP;  The directionof fit is world-to-mind.andM;One important application of the concept of intentionality is to distinguishthought from mechanical action, so Searle's use of it in his argument is notsurprising.andP;  Some attempts have been made to characterize intentionality interms of properties, but it appears that these attempts are not generallyregarded as successful (a cynic might say that the attempts are seen asfailures precisely because they allow intentionality to occur in machines).andO;In Searle's argument the concept is treated as a primitive one.andM;Searle's &quot;Chinese room&quot; argument is aimed against the principle of &quot;strongAl,&quot; which is that an appropriately programmed computer thinks, rather thansimulates thought.andP;  This principle is equivalent to accepting the Turing testas a definition of thought, always provided a computer can actually pass thetest (see the accompanying sidebar on this page).andM;Searle's argument is really quite simple.andP;  Imagine someone who understandsonly English sitting in a room with a set of rules that tells how to respondto questions written in Chinese in such a way as to pass the Turing test.andP;  InSearle's view, the person in the room does not &quot;understand&quot; Chinese, and sothe Turing test is not testing for comprehension or thought in any realisticsense.andP;  (Some argue that it is the room or entire system that understandsChinese.andP;  This objection is easily rebutted because you could modify theargument so that the person memorized the rules or had the rules surgicallyor chemically implanted in their brain.) In other words, any test for thoughtthat can be passed by systems behaving in purely formal ways can be reducedto something like the Chinese room and therefore is an inadequate test.andP;  ForSearle, the central point of the argument is that the person answering theChinese questions is not engaged in intentional behavior with respect tothese questions and so can't be said to be &quot;thinking about&quot; the answers.andP;  Asa result, the test is not valid.andM;REAL CONTINGENCIESandM;Searle goes on to contend that intentional behavior must be in response toreal contingencies, not formal simulations of reality.andP;  If so, it wouldfollow that the capacity for intentional behavior is the result of what mightbe called phylogenic contingencies and would be found only in products ofreal evolution.andP;  In short, Searle contends that just like other biologicalactivities such as digestion and photosynthesis, thought is intrinsicallydependent on the biochemistry of its origin.andP;  just as a formal simulation ofdigestion is not really digesting, a formal simulation of thought is notreally thinking.andP;  And to tie this argument to the gender thought experiment,a formal simulation of gender is not gender because it lacks biologicalstructural and functional characteristics.andM;Searle doesn't hold that all machines are incapable of thought, because hethinks humans are precisely such machines; in other words, Searle holds thathumans are a certain kind of  digital computer&quot; capable of thought.(5) Healso doesn't contend that artificial machines can't think; he claims that asufficiently precise copy of a human, no matter how fabricated, would think.andO;Finally, Searle expresses no opposition to the attempt to create a machinethat passes the Turing test or to the idea that the understanding of such amachine could provide insight into the nature of human thought.andP;  He alsobelieves that animals have intentionality.andP;  In other words, Searle is nottaking refuge in the sort of vague, antiscientific mysticism that contendssomething inherently beyond understanding about thought and the mind exists.andM;Now let's return to the question of intentionality and how Searle uses it.andO;According to Searle, intentionality and other mental states are &quot;caused by&quot;and &quot;realized in&quot; the structure of the brain.andP;  To illustrate this concept,Searle uses an analogy with liquid properties of water.andP;  No individual watermolecule can be said to be wet, but the wetness of water is caused by themotions and other properties of those molecules as they interact, and wetnessis realized in the structure of the material that is the collection of watermolecules.andP;  That is, wetness is caused by the behavior of water molecules,and wetness is realized in the water-wetness isn't something added to thecollection of molecules, and it is not an epiphenomenon (see sidebar thispage).andM;A key point of Searle's analysis is that the causation of wetness bymolecular behavior is possible because the concept of wetness is anabstraction or a property of the gross, statistical behavior of a large groupof molecules; whereas the only direct physical causality ismolecule-to-molecule, there is a level-shift causality of the macropropertiesby the microproperties.andM;Intentionality is caused by and realized in the structure of the brain, butcan it be caused by and realized in other structures? Searle appears to thinkthis is possible in principle.andP;  A related question is whether &quot;the same&quot;intentionality can be caused by and realized in different structures.andP;  Isthere some set of properties (I include as properties the structuralconnections and relationships among elements) such that two different sets ofphysical media or instrumentality have those properties, and all statescaused by and realized in one medium are also caused by and realized in theother, at least at the level of abstraction we are interested in? Forexample, both water and mercury are liquids, but water molecules are notmercury atoms.andP;  In fact, scientists can construct novel molecules whose grossstructure is liquid.andP;  Furthermore, if such different media exist, is itreasonable to conclude that this set of properties, rather than the media,represents an abstract description of the origins of intentionality?andM;RELATIONSHIP PROBLEMandM;This reminds me: understanding the relationship between software, hardware,and the behavior that software causes hardware to exhibit is a problem.andO;Every programming language has a clear mapping between programs and theirmeanings where the meaning can be expressed, for example, as the behavior offunctions over specified domains.andP;  For example, Scheme has denotationalsemantics that can be used to assign the meaning of any Scheme program.andO;Compilers and interpreters take programs and map them into instructions anddata structures that exhibit the behavior specified by the program.andP;  There isalso a meaning function from behavior as exhibited by a computer running aprogram to the same semantic domain, as is used to assign meanings toprograms.andP;  A compiler is correct when the meaning of every program is thesame as the meaning of the running compiled program.andM;Computer hardware is designed to have well-defined and suitable behavior toimplement the semantics of various programming languages.andP;  A largeprogram-any program for that matter-is a structure that specifies a set ofproperties and relationships that, when the program is executed, cause a setof program states to exist and that are realized in the structure of therunning program.andP;  As the program runs the structure changes, where thechanges are determined by the properties of the program.andP;  The implementationof the program on any particular computer is possible because the computerprovides a medium that can be made to exhibit the properties the programspecifies.andM;The property of a state being caused by and realized in a physical medium isa means, according to Searle, to solve the mind-body or mind-brain problem.andO;That problem is, approximately, about the relation between mental events andphysical action.andP;  For example, how does my intending to raise my arm cause myarm to raise? If mental events are not physical, how can they cause physicalevents? And if mental events are really just physical events, what is amental event, anyway?andM;To Searle this dilemma is neatly solved because mental events are caused byand realized in physical (biological) structures.andP;  The only apparentdiscrepancy between the model of mental events and computational events isthat today's computers are not nondeterministic in ways that the brain mightbe.andM;SEMANTICSandM;The nature of the semantics (or meaning) of a computer program isinteresting.andP;  Searle maintains that a program can contain no semanticsbecause it is formal and subject to many interpretations.(1) On the otherhand, he maintains that a person can  impose intentionality on (his)utterances by intentionally conferring on them certain conditions ofsatisfaction which are the conditions of satisfaction of certainpsychological states.&quot;(3)andM;Programs written in programming languages have &quot;certain conditions ofsatisfaction&quot; (semantics) intentionally conferred on them by reference to thesemantic rules of the language, which are always written down, often inprecise language.andM;One of Searle's arguments is: &quot;What, in fact, are the differences betweenanimal brains and computer systems that enable the Chinese room argument towork against computers but not against brains? The most obvious difference isthat the processes that define something as a computer-computationalprocesses-are completely independent of any reference to a specific type ofhardware implementation.&quot;(1) Of course, wetness, as we saw, is alsoindependent of any reference to a specific type of molecule, so perhapswetness is a poor analogy to use to explain the nature of intentionality.andM;COGENT ARGUMENTSandM;Most of the critics of Searle's argument fall to respond directly to hispoints.andP;  This fact is not all that surprising since most are scientists andSearle's argument is philosophical, but it also means that doing apoint-by-point critique of the argument is unlikely to be very useful.andP;  Inthis section, I'll discuss the main points culled from their responses.andO;Since the sources of these counterarguments range from published articles toelectronic mailing lists to informal conversations, I'll make no attempt atattribution, except to say that none of these ideas originated from me.andM;The most commonly raised objection is that intentionality, at least asdefined by Searle, should not be considered necessary for thought.andP;  The ideais that intentionality is associated with the thought of biological entities,but requiring it to be part of all thought has the effect of arbitrarilyrestricting the use of the term.andP;  It is common practice in science to allow aconcept to be applied to a new phenomenon, even one that is essentiallydifferent, provided it is not operationally different.andP;  For example, adiabetic's insulin may be produced by an artificial means, but few peoplewould regard it as being other than real insulin.andP;  Thus the fact  that  thethought of a  human-made machine is not intentional  may raise a warningflag, but it does not mean that it isn't thought.andM;Another objection is that restricting intentionality only to biologicalsystems is arbitrary and suspect.andP;  (It isn't obvious to me that Searle makesthis restriction, at least when you look at the body of Searle's work on thetopic in the last 10 years.andP;  It is more likely that he is simply pointing outthat for now the biological origin of thought is necessary.) While thecapacity for intentional behavior certainly does arise from evolutionaryprocesses, it needn't do so exclusively.andP;  Searle's argument for thisexclusivity is based on his thought experiment using the Chinese room, butyou could argue that this experiment is seriously, and perhaps fatally,flawed.andM;For example, suppose someone suggests a thought experiment involving a papercup containing all the electrons in the u we might well balk until weunderstood how a paper cup was to be made without electrons.andP;  By the sametoken, a set of rules that could pass the Turing test in Chinese would behuge and tremendously complex, and if the rules were exercised manually by asingle person, it is extremely doubtful that he or she would ever live longenough to answer a question or even a &quot;fraction&quot; of a question.andM;The idea is that any system complex and elaborate enough to pass the Turingtest must surely have a structure and behavior of a richness to rival that ofa human brain, and anyone considering a brain in terms of the sequentialbehavior of individual neurons might easily be unable to perceiveintentionality, just as we need more information to understand wetness thanwe can gather from a single water molecule.andP;  Because the intelligence of aTuring-smart machine may be very different from our own, we had best waituntil we can realistically study it before we conclude anything about itspossession of such subtle properties.andM;Others object that intentionality is not a primitive concept but is simply acombination of subjective state and context.andP;  In other words, if, unknown tothem, you remove someone's brain and stick it in a machine that creates aperfect simulation of the outside world, is their  thought still intentional?andO;If so, how is it any different if any other machine is in their place in thesimulation, and if not, doesn't that just show that intentionality isentirely subjective? To the extent that intentionality is a function ofcontext, we may propose different requirements on the Turing test, but wecan't dispose of it.andP;  To the extent that intentionality is subjective, wemust examine these states in any machine as we would in any person, and this,too, is just an alteration of the Turing test.andP;  In either case an operationaldefinition of thinking can still exist.andM;The next objection is an obvious refinement of Turing's discussion of histest; in this view, intentionality is totally irrelevant.andP;  A theory of mindand thought need not concern itself overly with notions such as understandingand meaning, as these concepts are too vague and coarse to be basic.andP;  just aschemists had to abandon concepts such as phlogiston, scientists studyingthought must recognize that intentionality is at best a vague intuition andnot a fundamental concept.andP;  The tradition in science is that all fundamentalconcepts must have an operational or at least testable and observabledefinition, and so it must be in Al.andM;Computer programming illustrates the efficacy of this principle.andP;  When a bugis discovered in a program, the source of the bug must be found.andP;  Theprogrammer has a model of the program that is a set of properties,constraints, relations, and so on, often timevarying.andP;  This model is similarto a philosophical theory-it's derived from studying the program in varioustheoretical lights but generally with minimal direct observation of theprogram while running.andP;  This model is most often used to guide the search forthe error by pointing out possible sources and also by eliminating largeportions of the program from consideration.andP;  Every programmer soon learnsthat some bugs cannot be fixed unless parts of that model that they areabsolutely certain about are abandoned.andP;  So it is with science andphilosophy: if a philosophical theory or belief is contrary to observedfacts, it must be abandoned, and sometimes such a theory or belief must beabandoned even to begin scientific progress.andM;This objection arises at least partly after reflection of the question &quot;Howdo we know intentionality exists?&quot; As Searle himself notes, &quot;We can't makesense of ...andP;  behavior otherwise.&quot;(9) Searle apparently believes that not allof the properties of neurobiological matter are captured by currentcomputational systems, but he never clarifies exactly which mental phenomenonconvinces him of this.andM;SILLY ARGUMENTSandM;One silly objection that I've seen contends that Searle's argument revealshis bigotry.andP;  Even though Searle concludes that some essential quality ofthought is missing from the &quot;mental&quot; activity of a computer, I think itpremature to assume he will stand in the way should his great-granddaughterdecide to marry a robot.andM;I have also seen responses claiming Searle is a mystic, and these claims Itreat more seriously-not because I think they have more merit, but becausesuch accusations are less likely to be regarded as frivolous.andP;  A dangerexists that scientists may internalize the philosophical bases of theirdiscipline so thoroughly that they mistake their point of view as &quot;truth&quot; andconclude that anyone with a different perspective is a mystic.andP;  I'm notsuggesting that you should take seriously the views of every crank with aperpetual-motion theory in hand-illustrated tracts, but it is possible totake exception to conventional views without being nuts.andM;I don't agree with Searle, but he has some good questions: what is thedifference between thinking and simulating thought, what would causeintentionality in a computer system, is intentionality inextricably linkedwith biological systems, are the aims of AI too quixotic? I am convinced thatthe essential  properties of intelligence are, in fact, purely formal andthere can be a suitable purely operational definition of intelligence.andP;  I amalso convinced that this question is not closed and I may be wrong.andM;Many people I know find Searle's skepticism a refreshing alternative to thenonsense and hubris of the Al &quot;boosters&quot; who have loudly predicted aTuring-smart machine five years in the future for the past 30 years andpointed at some trivial, trick program they had their graduate students writeas evidence they are really on the right track.andP;  If Searle is somewhatmotivated in his critique by a desire to burst their self-inflated bubble,good for him.andM;Others say Searle is just whistling in the dark, uneasy about the prospect ofa world in which the human monopoly on intelligence is broken.andP;  Perhapsthat's true, but what difference does it make? I think that his argumentsstand on their own, and whatever moves him to seek truth is less importantthan what he finds.andM;One of the problematic things about Searle's argument is that it has becomecaricatured by the Chinese room.andP;  (Searle himself contributed to thiscaricature by focusing strongly on it in his Scientific American article.)andO;This particular caricature is easy to ridicule and rebut, but the realargument is much more compelling and supported by many years of strongphilosophical work.andM;I don't believe that we'll be able to produce Turing-smart artifacts withinthe foreseeable future or that computers and programming languages as we knowthem are the best vehicles for creating such machines.andP;  I'm sure of thisbecause I'm familiar with languages, computers, and techniques available toAl researchers or under development-not because Searle has cooked up atrivial, trick, three-line proof.andM;In spite of the failure of Searle's arguments to change my mind, his work isobviously useful to science.andP;  Like all good philosophy, it can serve to helpkeep science honest, if scientists will let it.andM;REFERENCESandM;1.andP;  Searle, J. R. &quot;Is the Brain's Mind a Computer Program!&quot; ScientificAmerican 262(l), jan. 1990, pp.andP;  26-3 1.andM;2.andP;  Searle, J.R.andP;  Minds, Brains, and Programs.&quot; The Behavioral and BrainSciences 3, 1980, pp.andP;  417-457.andM;3.andP;  Turing, A., &quot;Computing Machinery and Intelli(236), Oct. 1950, pp.andO;433-460.andM;4.andP;  Searle, J.R.andP;  Intentionality: An Essay in the Philosophy of Mind.andO;Cambridge, UK: Cambridge University Press, 1983.andM;Nick Bourbaki, an Al EXPERT columnist and consultant to Lucid inc., is aselftaught computer scientist.andP;  He wrote this article while vacationing atthe Salish Lodge in Snoqualmie, Wash.andM;Chinese Room ComplexityandM;Conceivably, a Turing smart machine would be about one million times morepowerful, both in size and speed, than today's fast workstations.andP;  Forexample, suppose a 10 MIPS machine with 500 MBs of disk storage would needabout five minutes to answer one deep question.andP;  Searle recommends usingbaskets of Chinese symbols as the medium for manipulation, so let's assumethat two bytes is sufficient to hold a Chinese character and each physicalsymbol should be about two inches on a side.andP;  The &quot;table&quot; that the man in theChinese room will need is about 500 miles on a side (about the area ofTexas), and if the man can do one rule (as Searle defines them) per second(which is fast considering the need to increase to 700 miles to execute onerule) the man would need about 100,000 millenia to answer one question.andO;Using everyone alive on earth would take about 10 days, assuming five billionpeople can be coordinated.andM;EpiphenomenaandM;An epiphenomenon is an attending or secondary phenomenon that appears inconnection with another but does not or cannot have a causal effect on theprimary phenomenon.andP;  Because consciousness is clearly something weexperience, it could be regarded as a phenomenon, but there might be no sensein which a mental event can cause a physical one (within the brain or nervoussystem).andP;  To people who hold this view, consciousness is an epiphenomenon ofbrain or nervous-system activity.andM;An epiphenomenon must be distinguished from a description or interpretation.andO;An observer could conclude that another individual has consciousness becausethe second individual acts in a way that can be described or interpreted onlyas &quot;conscious.&quot; However, because I experience consciousness directly, I'mfairly certain it is a phenomenon, and my conclusion that other people areconscious is a combination of my observation of their behavior-includingreports of their own experiences-and the knowledge of my own consciousness.andO;To Searle, a third condition may exist that is the biochemical nature ofother brains and nervous systems.andM;An interesting side observation based on this argument is that much humanbehavior is precisely of this nature.andP;  For example, most people perform longdivision by following rules, where the only intentional aspect is-knowingthat the rules will provide the answer to a question about how many times onenumber &quot;goes into&quot; another.andM;When we start to think about how much human activity is rule-derived in wayssimilar to long division, it is clear that a lot of that activity isnonintentional.andP;  One interesting question might be what fraction of activityhas to be intentional for a person to be judged &quot;thinking.&quot; Perhaps&quot;potentially intentional&quot; is sufficient.andO;</TEXT></DOC>