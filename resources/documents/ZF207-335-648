<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-335-648  </DOCNO><DOCID>07 335 648.andM;</DOCID><JOURNAL>UNIX Review  June 1989 v7 n6 p68(9)* Full Text COPYRIGHT Review Publications Co. 1989.andM;</JOURNAL><TITLE>Tools on a new level. (Software BackPlane, an integratedproject-support environment)</TITLE><AUTHOR>Paseman, W.andM;</AUTHOR><SUMMARY>Anew species of software is being developed that provides anentire environment for application programming.andP;  AthertonTechnology has introduced one such product called SoftwareBackPlane, which supports an environment for tool integration.andO;The program's approach is based on the object-oriented 'desktop'metaphor, which has its roots in the Macintosh's SmallTalk.andP;  Usersdefine a type for each object they want to create at both theuser-interface and database levels.andP;  Every object type is definedin terms of messages, methods and instance variables.andP;  Objectsshare behavior through a type hierarchy, which allows users tobuild types by factoring out common messages and instancevariables.andP;  The integrated-environment approach to softwaredevelopment appears to be the best answer to this task so far.andM;</SUMMARY><DESCRIPT>Company:   Atherton Technology Inc. (products).andO;Product:   Software BackPlane (Program development software) (productspecifications).andO;Topic:     Program Development ToolsIntegrated SoftwareObject-Oriented Data Bases.andO;Feature:   illustrationtablechart.andO;Caption:   Models of the desktop metaphor. (table)The BackPlane type hierarchy. (table)Command and function flowcharts. (chart)andM;</DESCRIPT><TEXT>TOOLS ON A NEW LEVELandM;It is no secret that software development projects are often plagued withproblems.andP;  Market opportunities are missed because of inaccurate schedulingand cost overruns.andP;  Final products often do not comply with initialrequirements, and product quality is perceived as low.andM;There is no shortage of explanations for this situation: theedit-compile-link-debug loop is too slow; the code isn't documented; codeisn't reused; the wrong implementation language is used; requirements areincorrectly defined; requirements are correctly defined but ignored; productsare tested incorrectly, or not tested at all; incorrect methodologies areused; no methodology is used at all--and so the list goes on.andP;  The currentwisdom dictates that users employ software tools to address each of the aboveissues.andP;  And such tools can, in fact, at least partially solve users'development problems.andM;The various software tools available, however, often do not work together.andO;As a result, when users assemble a collection of tools, they must integratethem themselves.andP;  Unfortunately, since each tools uses a data formatdifferent from, and in many cases incompatible with that of others, userscan't query the assemblage as a whole.andP;  For example, users can't ask: &quot;Whatrequirement has the code not yet met?&quot;andP;  No single tools contains both therequirement tool's data representation and the code development tool's datarepresenttion.andP;  Worse yet, it could be necessary to enter the same data intotwo separate tools--which means doing twice as much work.andP;  For example, usersmight have to keep a list of bug fixes for release 4.03.01 in each modulethey have fixed and in the final product release notes as well.andP;  Furthercomplications arise if the duplicated data becomes inconsistent, to thedevelopment manager's chargrin and the customer's fury.andP;  Clearly, managing aconsistent, useful (that is, queryable) view of all development data acrossthe customer's life-cycle is a daunting tasj.andM;Enter now a new species of software: the environment.andP;  What does anenvironment do?andP;  Like an operating system, it provides the basic &quot;glue&quot; thatholds tools together.andP;  While several experimental environment developmentefforts are currently under way in the US and Europe, Atherton Technology hasintroduced an environment based on a product called Software BackPlane.andP;  Thisarticle describes how this environment supports tool integration.andP;  First,let's look at earlier tool integration approaches.andM;The Toolset Approach.andP;  The majority of commercial software development isdone using programs (tools) that communicate directly with the host operatingsystemn.andP;  UNIX was one of the first operating systems to provide mechanismsthat helped tools work together.andP;  Users have an interface to these mechanismsvia a command interpreter language, which models tools as primitivefunctions.andP;  Function arguments are text strings, environment variables, and ageneric opon file called stdin.andP;  Function results are returned via twogeneric open files called stdout and stderr.andP;  The following two commandsillustrate this approach: 1s -1 dirandgt; foo grep andless;foo &quot;fred&quot;andM;When Is is invoked, it is passed two strings, -1 and dir, and one open file,foo (which is bound to stdout).andP;  By convention, Is uses these strings asinput parameters and writes its result to stdout.andP;  When grep is invoked, itis passed the string fred and one open file, foo (which is bound to stdin).andO;By convention, grep uses the string and stdin as input, and writes its resultto stdout (which in this case defaults to the console).andM;Tools can be combined through functional composition.andP;  For example, thestring: 1s - 1 dir : grep fred connects the stdout of Is to the stdin of grepusing the UNIX pipe symbol.andP;  In this way, intermediate files like foo are nolonger needed.andP;  In addition, piped tools run concurrently.andM;UNIX's shell language and pipes provide users and other tools with a uniformmethod of invoking, controlling, and combining multiple tools.andP;  The shell andpipes, then, constitute UNIX's control integration mechanism.andM;However, UNIX must do more to make tools work together.andP;  The data produced byIS must be understood by grep.andP;  UNIX accomplishes this via a convention thatrequires the data passed through pipes to be in the form of byte streams (asopposed to lists or arrays).andP;  Byte streams are UNIX's data integrationmechanism.andP;  Data is passed by value from one tool to another.andM;UNIX's tool integration mechanims encourage users to write small tools in amodular fashion so that they can be easily connected.andP;  As a result, UNIX issaid to use a toolset approach to tool integration.andM;Language-Centered Approach.andP;  The conceptual model furnished by the C languageis strongly supported by UNIX services, which is turn is (usually) stronglysupported by the underlying hardware.andP;  However, some languages provide aconceptual model that is only weakly supported by the operating system, oreven by the underlying hardware.andP;  Examples include Interlisp and Small-talkrunning on standard commercial machines.andP;  As a result, developers ofenvironments for these languages generally replace the existing operatingsystem with a virtual machine model that strongly supports the language'scentral paradigm--for example, a list model for Lisp and an object model forSmalltalk.andM;This approach allows both the language and its enclosing environment(operating system) to operate off the same virtual machine.andP;  Sharing a vitualmachine allows both programming-level procedures and operating-system-leveltools to be invoked and controlled by the same set of mechanisms.andP;  The nativelanguage's means of combination (functional application in Lisp and messagepassing in Smalltalk) is used to combine tools and programs in the same way.andO;Language-centered environments have a seamless appearance, given this sharingof control integration mechanisms between tools and programs.andP;  The virtualmachines tend t be single-threaded, which eliminates contention for sharedresources.andP;  The single-threaded approach also tends to make language-centeredenvironments single-user.andM;List- and object-based data models can be recursively &quot;composed&quot; (forexample, &quot;List A consists of lists B, C, and D&quot; or &quot;Object A referencesobjects B, C, and D&quot;).andP;  These data models are therefore conceptually strongerthan array or byte-stream models, which have no composition capability.andP;  As aresult, language-centered approaches have a stronger data-integrationmechanism than do tool-centered approaches.andM;Architecture.andP;  The Atherton Software BackPlane approach is based on theobject-oriented &quot;desktop&quot; metaphor, invented at Xerox PARC and popularized bythe Apple Macintosh.andP;  (The desktop metaphor, in turn, has its roots inSmalltalk.)andP;  Software BackPlane's architecture, shown in Figure 1, reflectsthis.andP;  At both the user-interface and database levels, users define a typefor every object they wish to create.andP;  Each object type is defined in termsof:andM;* messages it receives (procedure interfaces that can be called);andM;* methods that process the messages (procedure bodies);andM;* instance variables it has (persistent, externally visible variables).andM;Software BackPlane allows objects to share behavior through a type hierarchy,shown in Figure 2, which allows users to structure types by factoring outcommon messages and instance variables.andM;A type makes use of three alternative method-implementation approaches: itmay pass messages directly to the type above it in the type hierarchy (itssupertype); it may implement the method itself; or it may do some localprocessing and have its supertype do some more.andP;  Having these threealternatives provides the implementor with considerable flexibility inextending the type hierarchy.andM;Figures 3 and 4 summarize traditional method invocation and type refinementmechanisms.andM;The Atherton environment provides procedural interfaces to the datarepository.andP;  As a result, objects are medium-grained, not fine-grained likeSmalltalk (which has a language interface) or coarse-grained like operatingsystems (which have a process interface).andP;  However, Software Backplane'sobject model supports both access control and dynamic binding.andM;At the command-interpreter level, how does the object-oriented approach mapto a tool integration model in a standard operating system environment?andP;  Mosttools take a primary argument of a given type.andP;  For editors, it is the nameof the file to be edited, which is of type text; for C compilers, it is thename of the file to be compiled, which is of type c.andP;  We view these tool datafiles as objects, and their file types as object types, in the type hierarchy(see Figure 2).andP;  For example, text files are mapped to type text, and c filesare mapped to type c (which is a subtype of the text type).andM;Software BackPlane views a tool as a package of functionality that takesinput objects, performs a computation, and produces output objects, possiblymodifying the input.andP;  (Even interactive applications fit into this kind offunctional definition, since actions such as select simply define the inputarguments for a particular computation.)andP;  As such, tools are modeled asmethods on types.andP;  For example, grep is a method on type text and all itssubtypes; grep is invoked via a grep message.andP;  Interactive tools becomemethods for open messages (as on the Macintosh).andP;  For instance, vi or emacsbecomes the default method for the open message on text and all its subtypes,and opening of directories invokes a special directory system traversal tool.andM;This approach allows the introduction of generic messages, which includeNew/Free, Open/Close, and Checkout/Checkin.andP;  Generic messages help reducecomplexity by allowing users to invoke similar tools using identical syntax.andM;Instance variables are used to support data integration.andP;  They model thesub-file data that one encounters in a file.andP;  For example, in a C file,instance variables include the syntactic objects of the C language.andP;  Forstructured analysis/structured design (SA/SD) data-flow files, instancevariables include data flows, data stores, and process bubbles.andP;  Using thisapproach allows the Atherton environment to integrate disparate applicationdata dictionaries into one integrated schema, since both file and sub-filedata from all the tools can be put into the same type hierarchy.andM;The relationship between the desktop user model, its screen appearance, andAtherton's object-oriented implementation is summarized in Figure 5.andM;As shown above, the Software BackPlane approach provides basic support forsoftware development and tool integration.andP;  But what additional benefit canthis approach bring?andM;Catalog Support.andP;  The environment controls a large number of tools.andP;  Beforeusers (or other tools) can use any tool, they have to find it, know what itdoes, and know how to use it.andM;The commands man, help, and their equivalents are useful for describing whata tool does and how it can be used by humans.andP;  However, this informationneeds to be formatted so that programs can also find, understand, and use it.andO;Such an arrangement allows help tools to interface to the catalog and letsclients describe what they want to do, not just name the tool they want touse.andP;  The help tools then use the description to select candidate tools forusers.andM;Since the type hierarchy is the central data dictionary for the environment,it plays the role of a catalog in our approach.andP;  It provides a naturalcategorization of tools, their arguments, and their result types.andP;  It ismachine-readable, can be accessed associatively, and acts as a resource forboth users and programs.andM;Control Integration.andP;  An environment should be able to invoke a toolautomatically, as well as provide a mechanism by which users can invoke thetool.andP;  The environment should provide a mechanism for abstracting commonpatterns of usage and combining tools into larger tools.andP;  UNIX shell scriptsare an example of this capability.andP;  Scripts allow command sequences at theshell level to be captured in a file and re-executed at a later time.andP;  TheMacintosh is an example of a system which lacks this capability, and whichsuffers as a result.andM;Tools should be able to exchange data.andP;  Before they can do so, a controlprotocol must be developed to let the environment read data from a tool'sdatabase and write it back.andP;  This protocol must work for incrementalinterchanges of short duration, such as those required for inter-tool &quot;cut&quot;and &quot;paste&quot;, and for a large batch transactions, such as feeding data to abatch translator.andM;Finally, the environment must control a tool's file references so that it canprovide transparent (potentially inter-node or inter-architecture) fileaccess and support access control.andM;Software BackPlane supports these needs by providing a smooth and consistenttool invocation mechanism for both tools and users.andP;  Tools can define manualdata transfer protocols (select, cut, and paste) by defining the appropriatemethods on their argument's types.andP;  Knowing the internal target types towhich paste will transfer allows the environment to perform the appropriatetype conversions.andP;  Redundant data can also be automatically tracked by theenvironment.andP;  The Atherton environment builds upon this capability to notifyusers when two &quot;corresponding&quot; data items are no longer in sync.andP;  (AlthoughSoftware BackPlane supports data interchange protocols and automatic update,these cannot be enforced; it is not possible to paste into a tool, forexample, that provides no interactive or batch write interface.)andM;Finally, the Atherton environment is equipped with a command language as wellas a bitmap interface to support scripts, and tool file references arecontrolled via the native operating system's access control capability.andM;Work-flow Control.andP;  Typically, environment administrators want an environmentto control the way that tools are applied and data is shared.andP;  Access controlis an example of this.andP;  However, there is a broader requirement for awork-flow control model, which must respect and enforce organizationalboundaries that are already in place.andP;  As part of this, it is critical forcomputer advocates to recognize the following two facts:andM;* Most of the work flow in most organizations is not computerized (files aremanila folders that sit in steel-cased file cabinets);andM;* Computers must interface smoothly with existing organizational structuresif they are to be accepted.andM;This often means that computers do not completely automate a task, butinstead provide &quot;sign off&quot; points for human controllers.andP;  Machines may alsoneed to support the creation and management of paper files that will continueto reside in a file cabinet, and it should not be assumed that informationwill be kept solely in electronic form.andM;Software BackPlane helps tools support this model by allowing local policiesto be implemented as message refinements and &quot;triggers&quot;.andP;  These triggers mayrequire user input or a password in order to proceed with a particularaction.andP;  In addition, the environment provides several models for concurrentaccess to shared data by several tools, ranging from file locks to shorttransactions to long transactions.andM;Data Integration.andP;  The term data integration refers to the ability of onetool to take the output of another.andP;  It works best when tools recognize acommon interchange format, and when that format has an associated genericdata model, such as an Entity Relationship, Object, or List model.andP;  Theformat's external representation should also support operational capabilitiessuch as insert, delete, and retrieve.andM;This last point is especially important for the incremental updating ofparallel databases.andP;  Suppose an SA/SD tool has a representation of aprocedure (called p1) deleted from its database of 64,000 procedures.andO;Suppose it wishes to communicate that information to the applications incharge of the &quot;code&quot; portion of the database.andP;  It is better to transmit amessage such as &quot;Version 2 of the SA/SD database is the same as Version 1except that p1 is deleted&quot; than to re-transmit the 63,999 procedures thatremain unchanged.andP;  Note that incremental updating requires that theenvironmental support versioning.andP;  Note also that logical information, notphysical delta information, ougght to be transmitted (such as &quot;procedure p1changed&quot; rather than &quot;lines 7, 10 and 23 changed&quot;).andP;  Finally, note that thetransfer protocols often optimize the transmission of large batches of data.andO;Data compression and encoding techniques are examples of such optimizations.andO;These same optimizations are usually not economical for transmitting smallbatches of data.andP;  It is desirable that the data protocol be optimizable forboth the large data transfers that occur during batch translation and thesmall data transfers that occur during cut and paste operations.andM;Unfortunately, in the real world no two SA/SD interfaces or intermediateformats are alike.andP;  This adversely affects environment performance andintegration complexity.andP;  For such situations, there are generally twosolutions.andP;  The first is to write a translator for every pair of tools in theenvironment.andP;  If there are m tools in the environment, this approach resultsin (m(m-1)) translators.andP;  The second approach is to develop an intermediateformat and to write a translator to and from that format for each tool.andP;  Ifthere are m tools in the environment, this results in 2m translators.andM;Software BackPlane takes the second approach.andP;  Standardization efforts arealso currently under way to support this second approach.andP;  They include theIRDS and EDIF proposals.andP;  Neither of these standards is all-encompassing.andO;Each deals only with data interchange for a portion of the softwarelife-cyle.andP;  As a result, tool-integration environments must support multiplestandards.andP;  (Practical acceptance of these standards depends primarily onbusiness--not technical--issues.andP;  Tool vendors will support them only whencustomers demand them.)andM;Since the hierarchy provides that types share instance variables as well asmessages and methods, data dictionary standards can be integrated directlyinto it.andP;  All types that obey the standard can be viewed as common subtypes.andO;For example, if SA/SD company 1 and SA/SD company 2 provide a common datamodel for data-flow diagrams, then their dataflow_diagram implementations canbe viewed as subtypes of the data-flow_diagram type.andM;User Model Integration.andP;  It is tempting to decree that the user interface beconsistent at all levels, and that the text fields of an SA/SD process&quot;property sheet&quot; be filled out using the editing commands used in the users'favorite text editor.andP;  Unfortunately, achieving that degree of consensusamong existing tool vendors is not possible.andP;  In addition, asking EDT, emacs,or vi users to change their editing habits does not promote user acceptance.andO;As a result, we must strike a balance between two conflicting goals,commonality and habit preservation.andM;To achieve this balance, Software BackPlane requires commonality in the userinterface (for example, all applications are invoked in a common way), butprovides for habit preservation inside each application (it does not requireemacs users to use vi keystrokes).andP;  It also supports an easy interface toboth interactive and batch applications.andM;The Incremental Approach.andP;  In practical terms, it is important thatintegrators be able to integrate existing tools incrementally.andP;  This meansthat no one should be required to rewrite tools in order to reap the benefitsof integration.andP;  Instead, for a little work integrators should get a littleintegration benefit, and for a lot of work they should get a lot of benefit.andO;This is a strong restriction.andP;  Since existing tools run on commercialoperating systems such as VMS and UNIX, the integration approach must workwith the host operating system, not replace it.andP;  At one end of the spectrum,the integration should be totally non-invasive--that is, it should requireabsolutely no source or application database changes--and performable,dynamically, at runtime.andP;  At the other end, the environment must providesupport complete enough so that the tool can be ported to multiple platformsif desired.andM;The Atherton environments does allow a user to integrate a toolincrementally.andP;  Types are dynamically definable, so the user can define a newtype on site without recompiling or relinking the environment.andP;  The firststep is to register the tool with the environment, which allows theenvironment to invoke it.andP;  At that point, the user can, for example, register&quot;authorization&quot; functions so that tool invocation is controlled.andP;  The nextstep is to register the tool's arguments with the environment, thus enablingit to intercept the tool's file references.andP;  At that point the environmentcan version the tool's data.andM;The third step is to register a method that can read and interpret a tool'sdata file in batch mode.andP;  This enables the environment to establish&quot;correspondence&quot; between different data files.andP;  Registering a method to writeinto a tool's data file in batch mode enables the environment to keepredundant copies of data in sync.andM;Registering a method that can read and interpret a tool's data fileinteractively supports the cut operation.andP;  Registering a method that caninteractively write into a tool's data file supports the paste capability.andM;Complete integration is accomplished when users use the data repository forfull data management, eliminating redundant storage and providing fullportability.andM;The dramatic increase in the size and complexity of software projects hasresulted in a widening gap between software developers' needs and thecapabilities offered by individual software tools and present-day operatingsystems.andP;  Major aspects of the software development process which are notadequately supported include:andM;* tool integration;andM;* work-flow control and configuration management;andM;* multithreaded access to shared project information.andM;The integrated-environment approach to software development is the mostpromising solution to date.andP;  Furthermore, object-oriented database technologyprovides an optimal engineering solution to the tool-integration anddata-management requirements of such environments.andO;</TEXT></DOC>