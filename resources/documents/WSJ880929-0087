<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO> WSJ880929-0087 </DOCNO><HL> Higher Tech: Computer Researchers Find 'Neural Networks' Help Mimic the Brain --- The Systems, a Building Block For Artificial Intelligence, May Analyze Loans, Radar --- Dwarfed by a Sharp Cockroach </HL><AUTHOR> David Stipp (WSJ Staff) </AUTHOR><SO> </SO><CO> T TXT BTEC </CO><IN> EDP ELE FIN BNK IND ARO </IN><G> DEF </G><DATELINE> BOSTON  </DATELINE><TEXT>   In a one-room company he incorporated here last month, Michael Kuperstein is planning to take on mighty American Telephone andamp; Telegraph Co. -- in ping-pong.    He is developing a robot driven by a so-called neural network, a computer system modeled roughly after the brain's web of neurons. Mr. Kuperstein feels neural networks will revolutionize computing. To make his point, he wants to match his machine next year against a ping-pong-playing robot recently built by ATandamp;T's Bell Laboratories.    Mr. Kuperstein maintains ATandamp;T's system, like all conventional robots, moves the hard way: by processing huge amounts of data to calculate distances and angles. He says humans move more fluidly without such calculations and, if his project works, his robot will, too.    His player, he says, will employ a neural network analogous to memory maps that infants form in their brains as they learn hand-eye coordination. By way of example, Mr. Kuperstein turns to a prototype of his robot and holds out a small wooden cylinder. Spotting it through two video cameras, the robot reaches out and grabs the cylinder with a mechanical claw.    Neural networks, a class of mathematical models that roughly mimic brain-like computing, are emerging as one of this decade's most important technology advances. Two years ago, they were little more than research projects in a few dozen laboratories. Now, well over 100 companies are working on them, ranging from ATandamp;T itself to companies like Mr. Kuperstein's, which he calls Neurogen. A multitude of prototypes based on the networks already are being tested, including systems to interpret radar signals, to determine credit ratings, to diagnose diseases, to compose music and to solve assembly-line glitches. As is usually the case in the computer industry, a major competition is shaping up between the U.S. and Japan in this new high-technology arena.    &quot;The same kind of excitement that surrounded artificial intelligence some years ago seems to be around neural networks today,&quot; says Arno Penzias, Bell Laboratories' vice president of research. &quot;Some of it is hype. But neural networks are moving faster from concepts to serious applications than artificial intelligence did.&quot;    Unlike conventional computer systems, which can process precisely defined information at blinding speed, neural networks are good at analyzing &quot;fuzzy&quot; data, such as spoken words or fingerprints. And, in a sense, they can learn by example. These abilities promise to advance research on artificial intelligence, which is attempting to replicate human faculties with computers.    The networks can be implemented with programs that run on desktop computers. About a dozen small companies have sold more than 10,000 neural-network modeling programs during the past year, says Tom Schwartz, a neural-network consultant in Mountain View, Calif. Some are priced at less than $100. That has enabled an army of researchers to develop prototype applications almost overnight.    Clearly, many proposed uses of neural networks will require computing speed available only from specialized neural-network hardware. Such devices are cousins of new parallel processors, which employ numerous small computers working in concert. Indeed, neural networks may foster a multibillion-dollar market for new kinds of chips and computers. At least, that is the hope of giants pursuing the technology, such as ATandamp;T, International Business Machines Corp. and Japan's Ministry of International Trade and Industry.    Defense applications are emerging fastest, says Edward Rosenfeld, who publishes &quot;Intelligence,&quot; a neural-network newsletter, in New York. They include radar systems that might distinguish an airliner from a fighter and &quot;smart&quot; missiles that visually zero in on targets before exploding. A recent Department of Defense study recommended that the U.S. spend $400 million over the next eight years to develop neural networks for defense.    Business applications will probably come first, though. Next month, Textron Inc.'s Avco Financial Services unit will begin limited field testing of a neural network for analyzing loan applications. BancTec Inc., in Dallas, plans next year to introduce a neural network to read handwritten numbers on checks, now a human chore. At least a dozen other companies, including Morgan Stanley Group Inc. and American Express Co., are pursuing neural-network applications.    &quot;We're seeing an exponential increase in interest in neural networks,&quot; says Peter J. Carroll, a partner at Oliver, Wyman andamp; Co. The consulting firm, based in New York, is developing systems for financial services with Nestor Inc., a maker of networks in Providence, R.I.    Neural networks excel, among other things, at pattern matching, the process of associating, say, heart-monitor data with specific cardiac problems. Many business problems can be formulated in terms of pattern matching, and thus are targets for neural-network programmers.    Nestor and Oliver Wyman use this approach in a system for assessing mortgage applications. It detects whether patterns of data drawn from an applicant's credit history match similar patterns that loan officers have judged to be good risks. Adaptive Decision Systems Inc., a start-up neural-network company in Andover, Mass., offers an analogous system for rating consumer loans. Other neural-network researchers hope to predict stock prices by associating recent market trends with historical patterns.    Neural networks tackle pattern-matching problems by digesting often incomplete, highly variable data. A neural network, for example, might identify a faulty motor from its sound. In contrast, a conventional computer system isn't so flexible, and often sputters when something as simple as a slightly misspelled command violates its internal rules.    Traditional &quot;rule-based&quot; computer systems can be programmed to associate symptoms with diseases and perform other tasks that involve pattern-matching. In fact, &quot;expert&quot; systems, which mimic human decision making in narrow areas of expertise, do just that. But expert systems stumble on many problems involving fuzzy data, since they require too many rules covering too many variations.    Neural networks, which don't use rules, quickly match unfamiliar patterns with the best approximations of them in their memories, much as humans might identify a mutt as mostly German shepherd. They are cracking many stubborn fuzzy-data problems, such as the recognition of human speech by machines.    Neural networks are programmed in ways that resemble human learning by experience. Under one method used to prepare a system to rate loans, thousands of examples of past loan applications and the outcome of the loans are first run through the neural network. The system automatically builds patterns in its electronic memory that enable it to predict the outcome of future applications.    Still, the networks' associative powers can be thrown off by the wrong kind of examples or by too much &quot;training.&quot; Murray Smith, who founded Adaptive Systems, says that, in tests, a prototype of his loan-rating neural network often approved loans to applicants with low salaries and rejected people with higher ones.    The problem was that people with low salaries who get loans typically are very good credit risks in certain regards. The data from a loan company he used to train his system contained several of these examples. Thus, &quot;in a sense, the system learned that very low income stood for good things,&quot; he says. The network has since been modified.    Despite such difficulties neural networks have performed even better than human mortgage officers, says Oliver Wyman's Mr. Carroll. He explains that when the network is made to incorporate the decisions of many experts in the mortgage business, it makes associations based on their collective wisdom. The network's decisions then tend to be better than any single human's. Moreover, a system's performance can be continually updated based on new examples. &quot;That is translatable into real bucks,&quot; he boasts.    In the 1960s, precursors of today's networks were also stirring excitement in computer circles. But by 1970, they lost favor as researchers focused on conventional computers. Studying brain-like ones became a kind of underground movement in science.    During the past decade, however, researchers advanced the mathematical theory underlying neural networks and developed new technology to make the systems. That paved the way for applications.    A number of scientific luminaries, including Nobel laureate physicist Leon Cooper and computer chip pioneer Carver Mead, have jumped on the neural-network bandwagon. A professional group devoted to the technology was formed last year and now has more than 2,500 members. &quot;It is the fastest-growing scientific society on earth,&quot; contends Stephen Grossberg, a Boston University researcher and the society's first president.    Now neural networks are taking a leading role in research on artificial intelligence, the computer industry's holy grail. &quot;Conventional artificial intelligence {research} has achieved marginal success,&quot; says Bart Kosko, a University of Southern California neural-network expert. &quot;But it hasn't solved a single one of the age-old problems about the mind.&quot;    Neural networks, on the other hand, invite arresting -- but sometimes misleading -- comparisons with human thinking. Besides employing memories that are crude likenesses of the brain's mesh of neurons, they &quot;degrade gracefully.&quot; If a few of a system's neurons go bad, it can still match previously learned patterns, just as aging brains can as neurons die.    But neural networks don't really learn the way humans do. The training process is automatic only after problems are put in a form the network can understand -- a tricky process. The networks are also impractical for replicating many of the brain's abilities -- such as adding numbers -- that conventional computers handle easily. Indeed, neural networks will probably be combined with conventional expert systems for many applications.    Moreover, the networks are far less complex than the brain. The computing power of today's neural networks is dwarfed by that of a cockroach, according to the recent Defense Department study on the technology. And, as the study notes, there is no guarantee that neural networks can be expanded to tackle big problems, such as interpreting massive amounts of data from radar and other devices during a battle.    Still, the neural network represents a remarkable conceptual leap in the computer world. It is a critical building block in artificial intelligence, much as the neurons in humans are the vehicle for brain function. The network has allowed researchers to create the first convincing likeness of the brain in areas such as memory and vision.    As the realization about the complexity of the brain's own neural networks has sunk in, researchers in artificial intelligence have, of late, become more cautious about what they promise. Their analogies now often involve the brains of insects instead of humans. For example, researchers estimate that a battlefield surveillance system would require the computing power equal to that of a bee -- several orders of magnitude beyond that of existing neural-network computers.    Says neural-network researcher James A. Anderson of Brown University, &quot;It's as if the truth about the brain were to the west, and at last we're heading vaguely northwest.&quot; </TEXT></DOC>