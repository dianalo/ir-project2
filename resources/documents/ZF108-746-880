<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-746-880  </DOCNO><DOCID>08 746 880.andM;</DOCID><JOURNAL>UNIX Review  August 1990 v8 n8 p38(10)* Full Text COPYRIGHT Miller Freeman Publications 1990.andM;</JOURNAL><TITLE>Tools for creating visions. (scientific visualization)</TITLE><AUTHOR>Upson, Craig.andM;</AUTHOR><SUMMARY>Scientific visualization is growing in popularity, helpingscientists and engineers view and analyze objects they arestudying.andP;  New visualization software analyzes the features ofobjects and performs geometric mapping and 3D rendering beforedisplaying an image.andP;  The first generation of visualizationenvironments, although limited in some aspects, promises toimprove the productivity of researchers by allowing rapidprototyping.andP;  Problems include difficulties with bidirectionaldata communications between modules.andP;  Larger, more complete andaccurate simulations of mechanical and natural processes will bepossible in the future.andM;</SUMMARY><DESCRIPT>Topic:     VisualizationResearch and DevelopmentData CommunicationsProduct DevelopmentSoftware DesignEngineering.andO;Feature:   illustrationchart.andO;Caption:   The numerical simulation process. (chart)Flow of control in the visualization cycle. (chart)andM;</DESCRIPT><TEXT>Scientific visualization is a technique of growing Popularity amongscientists and engineers, as it helps them better perceive and analyze theirobjects of study.andP;  The technique is still relatively new, and needs to becultivated and enhanced.andP;  Some progress is being made through the developmentof visualization-software environments.andM;In recent years, researchers in the computational and engineering scienceshave benefited appreciably from the development and use of scientificvisualization-the application of computer-graphics and image-processingtechnologies to the study of natural and mechanical processes.andP;  To study suchprocesses, researchers have conventionally generated exceedingly complexnumerical simulations that produce tremendous volumes of data.andP;  As valuableas they are, these simulations have required super- and near-super-computersto run them.andP;  Previously, data from these simulations was represented incopious compilations of numbers on reams of paper.andP;  This situation haschanged greatly, because of both the availability of more powerful and lessexpensive machines, and the development of scientific visualization, whichaffords dramatically improved interpretation of simulation results throughthe use of graphical displays.andM;Although it is well established, scientific visualization is still a youngpractice.andP;  To further aid researchers in their digestion of numerical data,scientific visualization is being advanced through the development of bettersoftware tools.andP;  In this article we will discuss the basic problem ofvisualization and take a look at several implementations ofvisualization-software environments [1].andM;Each of the environments we will examine uses an innovative, visual userinterface for application generation.andP;  The general process of configuring anapplication entails the building of a directed acyclic graph, where the nodesin the graph represent functional modules and arcs depict data-communicationlines between the modules.andP;  This diagrammatic representation of theapplication resembles a flow chart, borrowing on a long and fairly intuitiveprogramming tradition.andP;  Flow charts were originally used by assembly-languageprogrammers to visualize the flow of control in a program and to addstructure to a language.andP;  This gave them a visual representation-or map-torefer to when lost in an abyss of detail [2].andM;The use of a diagram editor to create applications in visual programmingsoftware is not new, and in fact has a fairly rich tradition associated withit.andP;  We are concerned here with visualization-prototyping systems, which areto be distinguished from systems dedicated primarily to visual programming,visual prototyping, or program visualization.andP;  To minimize the confusionregarding names, we will use the following definitions:andM;* program visualization: the automatic generation of graphs representing anexisting program [3];andM;* Visual programming: the icon-based source-code-generation process, whereicons are fundamental computational elements [4,5];andM;* visual prototyping: interactive user-interface layout and interfacebuilding;andM;* visualization programming: the creation of traditional, monolithicapplications for visualization purposes, in which a graphics library is usedto render images and maintain a display-list database;andM;* visualization prototyping: application prototyping applied tovisualization.andM;The Visualization Process.andP;  In the course of simulating a naturalprocess-such as the northern hemisphere's weather over a period of 48 hours,the fracture of a mechanical part due to a shearing force, or the bonding oftwo molecules in the presence of a catalyst--an engineer must progressthrough several distinct steps.andP;  While in typical problems not every step isencountered, it is instructive to see the entire process involved in anumerical simulation.andM;These steps can be broken into three major categories, characterized by thefunction of the scientist or engineer performing them: the theorist, theexperimentalist, or the computational scientist.andP;  It is only recently thatthis triad of skills has been recognized as the emerging fundamental workingmethod in modem science.andP;  Until about twenty years ago, theorists andexperimentalists were considered the two essential components of scientificmethod; they have now been joined by their computational counterpart.andM;The first steps are taken by the experimentalist.andP;  He or she observes aphysical process to develop a physical model of the phenomena under study.andO;An example of this could be the study of a small-scale weather pattern forthe purpose of understanding the driving mechanism behind severe storms.andP;  Theexperimentalist must correlate numerous sets of data to form a hypothesis.andO;In the case at hand, the researcher collects data on the relative humidity,atmospheric pressure, perturbational temperature, and wind speeds, as well aslocal terrain variations in height and surface roughness.andP;  The correlation ofthis data over several events brings the experimentalist insight into thephysical mechanism.andP;  Our meteorological-analysis example might correlate theappearance of high humidity, temperatures, and pressure gradients withtornadic storms.andM;This physical model, relating the various primitive variables as depicted inFigure 1, then moves on to the theorist, who must derive a set ofmathematical equations from it.andP;  The theorist tries to represent the volumesof data obtained by the experimentalist and in the process createsprogressive iterations of equation sets and parameters.andP;  At this point, thetheorist-assuming that the theorist and the experimentalist are distinctpersons, which is seldom the case-gives the equations back to theexperimentalist, who attempts to obtain new data critical to the verificationof the mathematical formulation.andP;  This give-and-take occurs several timesbefore a suitable model is developed.andM;These mathematical relationships that ultimately result-a set of partialdifferential equations--are not directly solvable numerically and must beapproximated.andP;  Translating these mathematical models into numerical form isthe domain of the computational scientist.andP;  The process entails two distinctapproximations, the first of which involves the derivation of ordinarydifferential equations from the original partial differential equations.andO;Such equations can be solved numerically, given a suitable physical domain.andM;The domain contains three components: a discrete representation in space andtime; initial conditions, defined at each location in the domain for whichthe equations are valid; and boundary conditions that detail how this domaininterrelates with the rest of the world.andP;  The discrete, or computational,domain generally consists of a mesh of nodes in N space with simpleconnectivity-that is, an N-dimensional matrix.andM;Not all problems are simple enough to be approximated by this representation;in such cases either several of these meshes must be connected together, eachwith its own areas of local refinement, or a separate mapping must be madefrom this simple computational space to physical space.andP;  This mapping relatesthe computational index of each node to its true physical coordinates.andP;  Inour weather example, each node in a three-dimensional,computational-space-based matrix would be mapped into a coordinate triplet inphysical space, and several physical variables would be defined at thatlocation.andP;  These variables might include pressure, temperature, threecomponents of velocity, humidity, cloud water, and rain water.andP;  In general,this mapping from computational space to physical space is very complicated,and can require the largest time investment on the part of the scientist.andM;An initial value for each variable at each node is required in order toinitialize the numerical equations.andP;  In addition, as the discrete domain onlyapproximates a small portion of the real world, the differentiation betweenwhat is modeled and what is not plays a critical role in the accuracy of thenumerical simulation.andP;  These boundary conditions remain valid over the entiretime sequence of the simulation.andP;  Together these three components--a discretemesh, initial conditions, and boundary conditions-comprise the simulationscenario.andM;In the second part of the approximation, a solution is initiated and iteratedover time, with each current solution used as an initial guess for the nextinstant's solution.andP;  The outcome of the simulation is then collected foranalysis.andP;  One possible result of this analysis step is that the solution maybe discovered to have been inaccurate, at which point a new mesh is createdor the old one is refined in the critical regions.andP;  Numerical instabilitiesin the method could also be revealed, in which case the numericalapproximation is reformulated; this could be as simple as reducing thetime-step or as complicated as changing the method.andM;A third possible negative outcome is the determination that although theunderlying equations have been simulated faithfully, the solution does notmimic the phenomena under study.andP;  At this point the theorist andexperimentalist are again brought into the picture to reexamine the validityof the underlying mathematical and physical models.andM;Of course, analysis could lead to a confirmation of the entire process-thatthe simulation results indeed do reflect what we observe in nature.andP;  Thescientist can then study the results in more detail to get a betterunderstanding of the system in general.andP;  This is accomplished by means ofnumerous parameter studies to determine the sensitivity of the system toperturbations.andM;In general, none of these outcomes is likely-usually, there is too much datato understand much of anything from the simulation.andP;  A normal time-varying,three-dimensional simulation can generate so much data that the scientistbecomes completely swamped.andP;  This is where visualization techniques can beapplied to great advantage.andM;The Analysis Step: The Visualization Cycle.andP;  The process of analyzing theresults of a large simulation can be broken into several phases.andP;  In eachphase the scientist attempts to reduce or transform the underlying data intoa more relevant set, or applies visual-representation techniques.andM;The first step in this process is feature analysis or extraction (see Figure2).andP;  The object is to reduce the volume of data to a more comprehensiblesize-extracting a two-dimensional cross-section from a three-dimensionalvolume, for example.andP;  For the weather example cited above, this might meanextracting the atmospheric pressure on the ground surface from the fullythree-dimensional pressure field.andP;  This class of operations also includes thederivation of other physical quantities from the primitive variables (thoseused in the simulation).andP;  For a weather analysis, a scientist might beinterested in analyzing the pressure field and deriving the gradient, whichhas particular implications in the location of severe weather systems.andO;Image-processing operations, re-sampling, and geometric transformations arealso components of this feature-extraction stage.andM;The second step in the analysis process is the transformation of this reducedset of data into geometric primitives.andP;  A given set of data can betransformed into a broad array of geometric primitives.andP;  For instance, athree-dimensional scalar field can be visualized using everything fromzero-dimensional point primitives to one-dimensional linear contours,two-dimensional polygons to three-dimensional volumetric cells.andP;  Eachrepresentation form reveals different aspects of the information contained inthe dataset.andP;  The scientist typically moves from one form to the next orcompares several different representations to extract the meaningfulinformation.andP;  In addition, each primitive type has a concomitant set ofsurface or volumetric properties that can be assigned to it, giving itdistinguishing visual characteristics.andP;  These might be assigned either atthis point or during rendering.andM;During the rendering stage the geometric primitives are converted intoimages.andP;  Here attributes such as frame composition, colors, transparency,texture, other surface-material properties, and shading methods aredetermined.andP;  Rendering is the best understood aspect of the entire analysisprocess, and has been researched in great detail over the past two decades.andM;The final step is the actual display of the image and its integration intothe scientist's or engineer's work environment.andP;  This includes output to theworkstation screen as well as incorporation into other documents, orrecording onto videotape or film.andM;Visualization-Prototyping Environments.andP;  The goal of anapplication-prototyping system is to add new functionality into an existingframework quickly.andP;  This framework typically supplies the application's mainevent loop and major user-interface and I/O components.andP;  This approachdiffers from typical graphics- or visualization-programming environments inwhich each new program or utility must supply its own interface, memorymanagement, and main program, while calling library functions to accomplishspecific graphics tasks such as building display lists, setting attributes,or rendering images.andM;The benefits of using a proto-typing environment depend on the volume of newcode that must be generated to develop new functionality-just the opposite ofthe traditional library-based approach.andP;  Somewhere between these two extremeslies the &quot;expandable application&quot; approach typified by Mac-App on theMacintosh [6], in which a main routine and user-interface subroutines aresupplied in a reusable format.andP;  The main difference lies in the fact that adefault (or, rather, mandatory) superstructure is supplied in the prototypingenvironment, while the expandable application provides one that must becustomized.andP;  The large amount of information hiding in prototyping systemscreates a restrictive environment that can result in faster prototyping for alimited problem domain.andM;The basic characteristics of visualization-prototyping systems can besummarized thus:andM;* they consist of an executive function or process that controls theexecution ordering of lower-level computations;andM;* they contain numerous functional modules that perform the real work offeature extraction, geometric mapping, rendering, and image display;andM;* these modules are reusable, and the degree of their reusability isinversely proportional to the richness of their datatyping;andM;* the connection mechanism used to permit data transfer between modules isdriven typically in a visual manner;andM;* their usage modes consist of two steps: configuring an application byconstructing a directed graph, and executing that graph.andM;In the following pages we will compare three visualization-prototypingenvironments that are currently being developed and distributed.andP;  Othersystems have been developed in research environments that have influenced thedevelopment of the environments presented here [7,8].andM;ConMan.andP;  The Connection Manager (ConMan) was in many ways a source ofinspiration for the two other systems we will subsequently discuss [9,10].andO;The main idea behind the ConMan design is the disintegration of monolithicapplications into smaller pieces that can be connected interactively atruntime.andP;  In this manner the end user's application-design space is notlimited by the developer's insight.andP;  This sentiment is reflected in thedesign and implementation of all three environments.andM;Each of the modular components in a ConMan application graph is a separateprocess with its own address space.andP;  Each process synchronizes communicationusing its graphics-input queue, the GL (Graphics Library) queue resident onSilicon Graphics workstations [11].andP;  This input queue contains three types ofinformation: input from the user in the form of mouse and possibly keyboarddata; messages from the system that govern window operations such asredrawing; and interprocess-communication messages signaling that data fromanother module is ready.andM;During the graph-construction process, modules register their input andoutput ports with ConMan.andP;  A text string describes a label for each port.andO;Each module can have several input and output ports as well as severalconnections to each port, allowing &quot;fan-in&quot; of information on a port.andP;  In afan-in situation, several modules may feed a downstream input port.andP;  ConManselects the active port--the one with which the user most recentlyinteracted-as the current upstream output port.andM;The executable graph is data-flow-like in that each edge of the graph isunidirectional.andP;  Since there is no explicit control in the graph, processesfire asynchronously.andP;  The application graph can be described as amonopartite, directed multigraph [12].andP;  It is monopartite in that it containsonly one type of node-a computational module.andP;  Since the data moves in asingle direction on each edge of the graph from node to node, it is adirected graph.andP;  It is a multigraph in that nodes can be connected bymultiple edges.andM;The user can alter the connectivity of the graph at runtime without expressknowledge of any affected module.andP;  The communication mechanism is as follows:as a module executes (due to user input or arriving messages), it writes itsoutput data to disk files in a well-known directory.andP;  It then notifies theexecutive process that the new data is ready for further processing by othermodules if necessary.andP;  ConMan blocks the sending process from writing moredata, traverses the dependency graph, and notifies all processes connecteddirectly downstream that new data is ready to process.andP;  In a laterimplementation, the file-based data storage has been replaced by UNIXsockets.andP;  Each of these communications is made using variable-lengthsynchronous messages.andM;The data types supported by the system were originally limited totransformation matrices (for object, viewpoint, and light-sourcepositioning), geometric lists (for object specifications), colors in the formof red-green-blue triplets, and bitmap images.andP;  Later extensions haveincluded those for text, fonts, and input-event streams.andM;ConMan's connection editor differs substantially from those of the othersystems we will examine in that it uses strictly direct manipulation.andP;  Thegraph produced consists of the individual interaction window of each modulein the application with arc connections attached to port-window pads overlaidon these frames (see Figure 3).andP;  Line connections run between these portwindows.andP;  In this manner the connection diagram is identical to theinteraction windows of the modules plus the arcs.andM;A new renderer module can be added to this network by connecting it to theoutput of the sweep process (a geometric structure) and the output of theviewing transformation (a matrix; see Figure 4).andM;The module suite consists of numerous components such as modelers, renderers,and object editors, targeted at geometric manipulations.andP;  To add a newmodule, an end-user or developer uses a traditional language and links themodule with a ConMan-specific library.andP;  Thus there are two usage levels: onefor the component developer (with C and a text editor) and one for theapplication builder (using ConMan).andM;apE.andP;  The Animation Production Environment (apE) developed at the OhioSupercomputer Center was designed to be used by scientists and engineers overa wide geographical area, with outlying local workstations tying into asupercomputer for simulation results [13,141.andP;  The role of the localworkstation varies from user to user, of course, but it is used primarily asthe control device for the visualization application, with the computationalmodules located on other networked machines.andM;Under apE, modules run as separate processes connected together via one oftwo mechanisms.andP;  Modules running on the machine on which the interface isrunning are connected via standard UNIX pipes.andP;  For those modules running onmachines other than the user's machine, the connection is made using a remoteshell.andP;  The advantages of the latter mechanism are that it is simple toimplement and can be easily ported to new UNIX-based machines.andP;  In a pipelineof processes, the first process creates data and sends it down the pipelineby writing it to standard output.andP;  The next process reads that data andeither deletes it from the stream or allows it to flow through to the nextmodule.andP;  This second module also adds its data to the output stream.andP;  In thismanner the amount of data transmitted can grow rapidly.andM;There are two types of modules in apE: tools and filters.andP;  Tools consistmainly of user-interface components, offering little computationalfunctionality.andP;  Such tools include image-display modules, histogram-creationand -display features, and a method for grouping data structures together foruse by filters.andP;  One special tool is the Build module, also known as thediagram, or connection, editor.andP;  Filters contain no user interface-onlycompute functionality.andP;  Modules in this class include those forinterpolation, scaling, and pseudocolor-mapping.andP;  Such modules read data fromstandard input until a trigger signal is sent, at which point they executeand place data on the output stream.andP;  A subroutine library is used to extractpointers of named data from the input stream.andM;The execution networks created by apE are  (quasi) bipartite, directedmonographs.andP;  Even though there are two classes of modules--tools andfilters-the networks are not strictly bipartite since tools can be connectedto tools and filters to filters (practices that violate the definition ofbipartite).andP;  As in ConMan, in apE data flows in one direction along an edge,creating directed graphs.andP;  Execution networks in apE are almost monographs inthat every module but one has only one input and one output.andP;  Special modulesact as splitters, routing input data into two output streams and bringingoutput streams together.andP;  This permits networks that are more complicatedthan single pipelines (see Figure 5).andM;Build, the connection editor, is used interactively to create the data-flowdiagrams.andP;  Individual processes are drawn as square icons that can be snappedto a gridded palette.andP;  The connections between the processes-which can feeddata in any direction-are represented by pipe-like icons.andP;  The splittersmentioned above are included in this collection of pipes.andP;  The output ofBuild is an executable UNIX script.andM;Datatyping in apE is substantially different from datatyping in the other twosystems under consideration.andP;  The datatypes-known as Flux groups-areuser-extensible.andP;  Simple ASCII representations consisting of keyword/valuepairs establish naming conventions, sizes, primitive types, and otherdescriptive information.andP;  Flux is designed to support an intuitive generaldata hierarchy, making it is easy to add a customized type, as data can beentered in a free-format, order-independent manner.andM;The disadvantage of working in such an unrestricted environment is that theproliferation of data-types becomes difficult to control, diminishing modulesharing and reuse.andP;  No type-checking occurs at connection time, since whilethe data generated by the module directly upstream might not be producingdata of the required type, a module further upstream might be.andP;  Thisflexibility comes at the sacrifice of ease of use; although any module can beconnected to any other module, the user doesn't get a good feel for theoptions available.andM;AVS.andP;  The Application Visualization System (AVS) introduced by StardentComputer is the product of three distinct-and at times competing-prototypingefforts inspired by the disintegration approach of ConMan.andP;  Unlike apE, AVS'soriginal goal was not to distribute the computational modules onto a largenumber of machines and build an interface that could run on non-graphicsworkstations, but rather to exploit fully the user's workstation as arendering and perhaps compute engine [15].andM;AVS modules can either exist as separate processes with independent addressspaces or be linked in the AVS executable.andP;  As separate processes theycommunicate with the execution controller, or flow executive, via sockets.andO;Modules consist of two components: a description routine and a computeroutine.andP;  The description function names and types input and output ports andestablishes parameters, thus determining the calling sequence for the computeroutine.andP;  A default mapping of each parameter to a user-interface widget isalso made in the description routine.andP;  The compute routine performs the mainfunction of the module.andM;AVS modules fall into four categories: input, filter, mapper, and renderer.andO;Input modules have no input ports and typically generate data or read it fromdisk.andP;  Filter modules perform operations closely related to thefeature-extraction functions detailed above.andP;  Mappers convert primary orderived physical data into geometric primitives which are then converted intoimages by the renderer modules.andP;  For historical reasons, image-displaymodules are also categorized as renderers.andM;The graphs generated by the network editor can be characterized asmonopartite, directed multigraphs.andP;  While there are four module categories,the distinction between them is irrelevant from the editor's perspective;thus the diagram is monopartite.andP;  It is a multigraph, like ConMan, in thatfan-in and fan-out are supported and, as in the other systems discussed, itis a directed graph.andM;In AVS's diagram editor, shown in Figure 6, modules are represented assimple, box-shaped icons without pictorial form.andP;  Input and output ports arecolored according to type, giving the user a guideline for possibleconnections.andP;  At connect time, a tree-like structure is drawn from theselected port to all permissible ports in the graph with a similar datatype.andO;The user then selects one branch and makes the connection.andM;Unlike apE, AVS has a restricted set of datatypes.andP;  Data falls into one offour categories: colormap, field, geometry, or pixmap.andP;  Color-maps aretransfer functions used for pseudocoloring geometric objects and images, towhich they map a discrete range into red, green, blue, and opacity values.andO;In AVS, the workhorse is the field datatype.andP;  It consists of a generalmultidimensional array or matrix of data.andP;  Mapping data from the logical orcomputational space to a physical space can be accomplished in severalspecific ways, using uniform, rectilinear, and curvilinear mappings.andM;Ports can be typed simply as accepting any flavor of a field or a veryspecific version, such as a floating-point, three-dimensional rectilinearfield.andP;  The more general the type, the greater the module's reusability.andP;  InFigure 7 a uniform, 3D, scalar field (an MRI scan) is represented as apolygonal surface intersected by a planar slice.andP;  Geometric objects arerepresented as geometry edit-list data-types, lists of arbitrary lengthcontaining scene modifications such as object topology, surface types, andlight and object positions.andP;  Finally, pixmaps are images resident in an XWindows server.andM;AVS provides three usage levels.andP;  As with ConMan and apE, new modules areprogrammed using a traditional language such as C or FORTRAN.andP;  Newapplications are prototyped by connecting a graph of processes using anetwork editor.andP;  In addition, AVS contains a traditional applicationinterface.andP;  The network is hidden under this thin layer and the configuredprogram behaves as a traditional button/slider/dial/browser/menu-drivenapplication.andM;These three application-prototyping systems serve the same users:computational scientists and engineers who need visualization tools tocomprehend large numerical simulations.andP;  Each system goes about the problemof delivering this functionality in a unique way, using distinct executionmodels, interfaces, flow of control, and extensibility.andM;The similarities, however, are quite striking.andP;  All use diagram editors toconstruct a visual application network that performs a program-visualizationfunction highlighting the execution process of each module.andP;  All systemsallow new functionality in the form of modules to be created by the user toincrease the utility of the system.andP;  All systems also use a unidirectionaldataflow-communication model, and all developers are aware of the limitationsof this simplified scheme.andM;The harder issues in visualization-and application-prototyping systems areleft to be solved by future enhancements of these systems andsecond-generation systems under development.andP;  Problems associated withbidirectional data communication between modules are simple to address inprinciple, but difficult to implement in an easy-to-use manner.andP;  Invisualization and graphics systems, the on-screen selection of an object orportion of an object has always posed difficult questions with regard to theuser interface.andP;  This is complicated in dataflow-based, disintegratedenvironments where the selected item in the rendered image is not the objectof interest, but rather the data upstream that have given rise to it.andP;  Thismeans that several inverse mappings, one per intervening module, might berequired to derive the data of interest.andP;  In most but not all cases, this canbe accomplished-but to what degree of accuracy?andM;Each of these systems is targeted at the rapid prototyping of applications.andO;This function always entails a compromise between the time it takes, in humanterms, to build an application and the time it takes, in machine time, todeliver a result.andP;  Eventually the user is satisfied with the single imageproduced, and then wants to see several thousand of them.andP;  It is at thispoint that these systems reach their limitations.andP;  The boundary betweenprototyping and production has been crossed, and little inefficiencies inexecution models, data copying, interprocess communication, and memorymanagement now become disabling encumbrances.andM;While the visual-programming-like interface in each of these systems isuseful for prototyping applications, when the required functionality is notpresent in the system the user must make the transition to a traditionalprogramming language to add new modules.andP;  In many cases this prevents usersfrom extending the system.andP;  Future systems will deal with this issue byemploying more visual techniques in the code-development phase, thus blurringthe line between code developer and code user.andP;  If the barrier to programmingis reduced, the system will become extensible to a wider class of users.andM;Finally, all three environments we have examined fail to recognize that theymust fit into a larger context-the user's own working environment.andP;  As statedabove, visualization tools form only a small portion of the tools needed bythe scientists and engineers who use these systems.andP;  The seamless integrationof visualization tools and their output must be made with simulation anddata-acquisition programs, as well as with text editors anddocument-preparation utilities.andM;These limitations aside, this first generation of visualization environmentsshows promise in improving the productivity of computational scientists andengineers, making possible the future development of larger, more complete,and more accurate simulations of natural and mechanical processes.andM;Educated in numerical mathematics at the University of New Mexico, CraigUpson worked for several years at the Lawrence Livermore National Laboratory,where he conducted research on 3D computational fluid dynamics and developedgraphics algorithms.andP;  He then joined Digital Productions in Los Angeles,where he produced animations for TV commercials, science films, and themotion pictures 2010 and The Last Starfighter, among others.andP;  He has sincedeveloped the scientific-vlsualization program for the National Center forSupercomputing Applications at the University of Illinois, and was thearchitect of AVS at Stellar (now Stardent) Computer.andP;  At present, Upson isthe manager of visualization environments at Silicon Graphics Inc.andM;ReferencesandM;[1] For more information on the general development of scientificvisualization, see the pertinent feature articles in Vol.andP;  7, No.3 of UNIXREVIEW.andM;[2] Nan C. Shu, Visual Programming, Van Nostrand Reinhold, New York (1988).andM;[3] Marc H. Brown, Algorithm Animation, MIT Press, Cambridge, MA (1987).andM;[4] Brad Myers, &quot;What are Visual Programming, Programming by Example, andProgram Visualization?&quot;, Proceedings of Graphics Interface (1986).andM;[5] Shi-Kuo Chang (ed.), Principles of Visual Programming Systems, PrenticeHall, Englewood Cliffs, NJ (1990).andM;[6] Kurt J. Schmucker, Object-Oriented Programming for the Macintosh, HaydenBooks, Hackensack, NJ (1986).andM;[7] Tom Nadas and Alain Fournier, &quot;GRAPE: An Environment to Build DisplayProcesses&quot;, Computer Graphics, Vol.andP;  21, No.andP;  4, pp.andP;  75-84 (August 1987).andM;[8] Michael Potmesil and Eric M. Hoffert, &quot;FRAMES: Software Tools forModeling Rendering and Animation of 3D Scenes&quot;, Computer Graphics, Vol.andP;  21,No.andP;  4, pp.andP;  85-93 (August 1987).andM;[9] Paul E. Haeberli, &quot;A Data-Flow Manager for an Interactive ProgrammingEnvironment&quot;, Proceedings of Usenix Summer Conference, Atlanta (1986).andM;[10] Paul E. Haeberli, &quot;ConMan: A Visual Programming Language for InteractiveGraphics&quot;, Computer Graphics, Vol.andP;  22, No.andP;  4, pp.andP;  103111 (August 1988).andM;[11] Silicon Graphics Inc., IRIS User's Guide (1984).andM;[12] Robert E. Filman and Daniel P. Friedman, Coordinated Computing: Toolsand Techniques for Distributed Software, McGraw Hill, New York (1984).andM;[13] D. Scott Dyer, &quot;apE: Providing Visualization Tools for a StatewideSupercomputing Network&quot;, Proceedings of the Fifth International Symposium ofScience and Engineering on Cray Supercomputers, Cray Research Inc. (September1989).andM;[14] Ohio Supercomputer Center,  apE: The Animation Production Environment&quot;,Users Guide (1989).andM;[15] Craig Upson, Thomas Faulhaber, David Kamins, David Laidlaw, DavidSchlegel, Jeff Vroom, Robert Gurwitz, and Andries van Dam, &quot;The ApplicationVisualization System: A Computational Environment for ScientificVisualization&quot;, IEEE Computer Graphics and Applications, Vol.andP;  9, No.andP;  4, pp.andO;30-42 (July 1989).andM;Nota BeneandM;AVS is a trademark of Stardent Computer Inc. apE is a trademark of the OhioSupercomputer Center.andP;  GL is a trademark of Silicon Graphics Inc.andO;</TEXT></DOC>