<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-501-398  </DOCNO><DOCID>07 501 398.andM;</DOCID><JOURNAL>Communications of the ACM  August 1989 v32 n8 p1014(11)* Full Text COPYRIGHT Assn. for Computing Machinery, Inc. 1989.andM;</JOURNAL><TITLE>Technical correspondence.andO;</TITLE><AUTHOR>Xiaofeng Zhou; Gustafson, John L.; Bergmann, Seth; Holt, R.C.;andO;Alexander, James H.; Feng Yang Kuo; Sezgin, Fatin; L'Ecuyer,Pierre; Edgeman, Rick L.; Abrahams, Paul W.; Sand, Francis M.;andO;Park, Steve K.; Miller, Keith W.andM;</AUTHOR><DESCRIPT/><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>Technical CorrespondenceandM;BRIDGING THE GAP BETWEEN AMDAHL'S LAWandM;AND SANDIA LABORATORY'S RESULT Recently, the Sandia National Laboratoriesachieved a 1,000 time speedup on its 1024-processor hypercube system.andP;  Thisresult surprised many people and hence, may help to change the pessimisticview towards massively parallel computing.andP;  The distrust of an achievablelarge speedup from the massively parallel system is raised mainly fromAmdahl's law.andP;  Amdahl's law indicates that the maximum speedup, even on aparallel system with an infinite number of processors, cannot exceed 1/k,where k is the fraction of operations that cannot be executed in parallel.andO;The function and its steep curve give the impression that developingmassively parallel systems may not be a feasible choice because a linearspeedup in terms of number of processors is virtually impossible.andM;However, the results obtained by the Sandia National Laboratories clearlyshow the reality of linear speedup for certain applications.andP;  An argumentraised by the Sandia National Laboratories is: a problem size is not aconstant as used in Amdahl's law; instead, the problem size will increasewhen a more powerful computing resource is given.andP;  For their applications,the researchers at Sandia find that the parallel part of the programs scaleswith the problem size, but the serial part remains constant.andP;  Based on thisapplication model, the researchers at Sandia suggest a new formula: Q = s +pN S = N + (1 - N)s Where, Q is the problem size, s is the serial part of theproblem, p is the parallel part of the problem before scaling, N is thenumber of processors, and S is the speedup.andP;  Contradicting Amdahl's law,equation (2) indicates a linear speedup.andM;The different speedup prediction between Amdahl and Sandia is a result ofdifferent assumptions for the problem size.andP;  Amdahl assumed a fixed sizedproblem to derive his formula, while Sandia, on the other hand, used a scaledsized problem.andP;  Since the predicted speedup is completely different simply bychanging the problem size, it suggests that the problem size should beconsidered to be an independent variable in the speedup function.andP;  Here, wepresent an alternative speedup function that takes the problem size Q as anindependent variable and considers the serial part of the problem to be f(Q),a function of the problem size.andP;  By defining different f(Q), we find thatAmdahl's law is the low-extremum of our speedup function and Sandia's is thehigh-extremum.andM;To derive our speedup function, we define the following notation.andM;Q--Problem size, defined as the number of unit operations of the problem.andM;f(Q)--Serial part of the problem that cannot be executed in parallel; f(Q) isa function of Q,and is decided by the amount of parallelism in the problemand its parallel algorithm.andM;N--The number of processors.andM;c(N)--The average number of processors that do not contribute in computingbecause of communications and communication conflicts.andP;  The communicationcost is usually a function of the number of processors.andM;If the execution time for a problem on a uniprocessor is Q, then the sameproblem, under the best condition, will use f(Q) + (Q - f(Q))/(N - c(N)) timeon a parallel system with N processors which have the same speed as theuniprocessor.andP;  Therefore, the speedup is S = Q / f(Q) + (Q - f(Q))/(N - c(N))S = Q(N - c(N)) / (N - c(N) - 1)f(Q) + QandM;If we assume an ideal parallel system that has no communication cost, i.e.,andO;c(N) = 0, the equation (3b) becomes S = / QN (N - 1)f(Q) + Q (4)andM;Now, let us increase the problem size Q to study the possible speedup one canachieve on a system with N processors.andM;First of all, it sworth noting that f(Q) is not an arbitrary function;instead, it satisfies the condition: constant [is less than or =] O(f(Q)) [isless than or =] Q.andP;  If, for certain types of problems, we can find analgorithm that fixes f(Q) = const., then we have S(Q).sub.Q[right arrow]OC =N (5)andM;That means, under the condition f(Q) is a constant, we can always get alinear speedup for an arbitrary large system simply by increasing the problemsize.andP;  An interesting question is how should a problem size be increased inorder to maintain a linear speedup (or constant system efficiency), i.e.,andO;linear, geometric, or exponential.andP;  Let us use Sandia's assumption, alinearly increased problem size in terms of processor number.andP;  Substitute Q =s + pN into equation (4), assume f(Q) = s as Sandia did, then we have S = s +pN = s + (1 - s)N = N +(1 - N)s (6)andM;This is exactly Sandia's formula that shows the linear speedup can beachieved if f(Q) is a constant and the problem size is linearly increased.andM;However, many computational problems and parallel algorithms cannot fix f(Q)as a constant.andP;  The worst case for a real parallel computation is probablyf(Q) = kQ, where 0 andless;kandless;1 is a coefficient.andP;  For such a case, S(Q).sub.Q[rightarrow]OC = / N (N - 1)k + 1 (7) which is exactly Amdahl's formula.andP;  Equation(7) indicates that no matter how fast one increases the problem size, themaximum speedup will not exceed 1/k.andP;  Equation (7) also shows that Amdahl'slaw is still true for certain kinds of problems even though the problem sizeis increased.andM;From the above discussion, we find that equation (4) is a more generalformula for predicting the possible speedup that can be achieved by amultiprocessor system.andP;  Amdahl's and Sandia's formulas happen to be twoextrema of equation (4).andP;  Furthermore, equation (4) indicates an interestingresearch topic--the scalability of the computational problem, which is notwell studied, but is of fundamental importance for massively parallelcomputing.andM;The feasibility of developing massively parallel computers lies strongly onthe system efficiency, and the goal is to keep it constantly high.andP;  It iscertainly correct to increase the problem size to maintain high systemefficiency as Sandia National Laboratories did because this is what themassively parallel computer is designed for.andP;  However, not everycomputational problem is scalable to get a constant system efficiency; thescalability is based on the problem itself and its parallel algorithm.andO;Equation (4) suggests that we can use f(Q) to find the scalability.andP;  Theabove discussion has shown that there is no way to keep a linear speedup(constant efficiency) if f(Q) = kQ.andP;  On the other hand, a linear problem sizescaling is enough to have constant efficiency if f(Q) is a constant.andP;  Thereare many other possible f(Q) functions between f(Q) = const.andP;  and f(Q) = kQ.andO;For example, if f(Q) = / Q, one can find, by using equation (4), the problemsize must be increased in the rate N.sup.2 in order to get constantefficiency.andM;The concept of scalability, as our multiprocessor systems become larger andlarger, will be more and more important.andP;  We feel that the scalability shouldbe considered as a new criterion to judge parallel algorithms because somealgorithms may have better f(Q) functions than others.andP;  How one finds f(Q)for parallel algorithms is an open research problem.andM;Finally, we would like to point out that c(N) also plays an important role inour speedup function.andP;  To appreciate this, let us assume f(Q) = k (aconstant) and Q goes to infinity.andP;  Substituting these into equation (3b), weget S = N - c(N) (8)andM;Equation (8) shows c(N) must be a constant in order to obtain a near N timespeedup.andP;  In practice, it is quite difficult to keep c(N) as a constant.andO;However, as long as the growth rate of c(N) is under [alpha]N (0andless;[alpha]andless;1),a linear speedup is still possible.andM;Xiaofeng Zhou Dept.andP;  of Electrical Engineering University of FloridaGainesville, FL 32611andM;AUTHOR'S RESPONSEandM;It seems that someone is again trying to help me to &quot;understand Sandia'sresults,&quot; resolving the apparent contradiction between Amdahl's law and ourexperimental observations.andP;  This unneeded assistance seems to be the resultof my unfortunate choice of words in the original letter: &quot;How can this be,when Amdahl's argument would predict otherwise?&quot;andP;  It was a rhetoricalquestion, answered in the paragraphs that followed.andP;  Many readersmisinterpreted the question as a cry for help!andM;Zhou credits E. Barsis 100 percent for the scaled speedup theory.andP;  Thiscredit is partially misdirected.andP;  I have been propounding the scaled speeduptheory for about four years now, predating my collaboration with Ed Barsis atSandia in October of 1987.andP;  Ed's contribution was to suggest that we state itas the formula speedup = s + Np which I accepted and later clarified byputting primes on s and p to distinguish them from the s and p of Amdahl'sformula.andP;  In December 1987, Sandia's large hypercube gave me the experimentalammunition to show the fallacy of fixed-sized speedup models, andCommunications was instrumental in getting the word out rapidly.andP;  I usuallydo not care about such things, but the scaled speedup theory has been toomuch of a tough and personal battle for me to completely relinquish itsauthorship to a recent collaborator.andP;  We usually refer to the model as&quot;Sandia's law&quot; or &quot;Scaled Speedup Model&quot; and avoid putting either of ournames on it.andM;The original Communications note did not use primes to clarify that s and pchange meaning in going from Amdahl's law to Sandia's, although it isexplained in the text of the note.andP;  Zhou does not seem to understand thechange of meaning, however, and frequently confuses total serial effort withserial effort per processor.andM;Zhou's central thesis is that Amdahl's law is the pessimistic extreme, andSandia's law is the optimistic extreme.andP;  This thesis is not true, because itignores memory proximity.andP;  When a fixed-sized problem is spread out over many(distributed memory) processors, the problem fits in a smaller memory spaceper processor.andP;  That usually means access is faster since now the problemfits in cache or registers or does not need mass storage.andP;  Memory access isalmost never &quot;flat&quot; in modern computers, which is another reason one shouldfix problem size per processor instead of total problem size.andP;  It is easy toinvent cases where Amdahl's speedup is much higher than Sandia's.andM;Zhou says (more than once) that the goal is linear speedup.andP;  Maybe that isthe goal of a university professor studying parallelism as an end in itself,but it is not the goal of most computer users.andP;  I think most scientificcomputer users want to run the best simulation they can in a certain amountof time, and would cheerfully accept, say, 1.5 times more power by usingtwice as many processors.andP;  The fallacy of assuming linear speedup is theultimate goal that underlies Amdahl's law and two decades of misguided paperswritten on parallel processor performance evaluation.andP;  I am finding that itis not easy to get computer people to change their mental model of speedupmeasurement, although many have embraced it wholeheartedly.andM;On the positive side, Zhou does a good job of extending the Sandia model andshowing the continuum between scaled and fixed models.andP;  He includes acommunication term c, which is probably the major oversimplification in theSandia model.andP;  However, he assumes c depends only on the problem size and notthe number of processors, which is a dubious assumption.andP;  Zhou's analysis andstyle is very good, but his assumptions are questionable.andP;  John L. GustafsonSandia National Laboratories Albuquerque, NM 87185andM;PASCAL PROGRAMandM;In &quot;The Turing Programming Language&quot; Holt and Cordy (Communications, Dec.andO;1989) criticize the following Pascal program because some lines, such as theone that puts out Hello, end with a semicolon and others do not: programtest(output); begin while true do begin writeIn (&quot;Hello&quot;); writeIn(&quot;Goodbye&quot;) end end.andM;This is not a weakness of Pascal, but of the way students of Pascal arenormally taught to program by PL/I programmers (and others).andP;  Students shouldbe encouraged to write the above program as shown below when first learningPascal: program test(output); begin while true do begin writeIn (&quot;Hello&quot;) ;writeIn (&quot;Goodbye&quot;) end end.andM;Once the student understands that the semicolon is a statement separator, andnot a terminator, he or she can be advised to write as in the first example,to generate less white space.andP;  Seth Bergmann Glassboro State CollegeMathematics and Computer Science Dept.andP;  Glassboro, NJ 08028-1767andM;AUTHOR'S RESPONSEandM;Bergmann suggests that beginners should be encouraged to place Pascal'ssemicolons on separate lines.andP;  this is a terrible idea! Students will refuseto do it, and they are likely to suspect that programming is based on arcanesyntactic trivia.andP;  The solution to the problem of semicolons is to eliminatethem altogether, as is done in the Turing language.andP;  R. C. Holt University ofToronto Computer Systems Research Institute Sanford Fleming Building 10King's College Rd. Rm.andP;  2002 Toronto, ON M5S 1A4andM;USER INTERFACE DESIGN ...andP;  WHOSEandM;PERSPECTIVE?andM;The recent article by Kuo and Karimi (&quot;User Interface Design from a Real-TimePerspective,&quot; Communications, Dec., 1988) is an example of a designmethodology that totally disregards the needs of the end user.andP;  Though themethodology may achieve the laudable goal of automating the user interfacedesign process, it is likely to fall far short of generating a good userinterface by modern standards.andM;First, the user interface of a system should not be considered a by-productof systems analysis.andP;  Consideration of the user should be included in allsteps of the design process.andP;  Thus, a responsible designer will begin toconsider the user's needs even before the construction of a Data Flow Diagramor some similar entity.andM;Second, Kuo and Karimi's AUI (Adaptive User Interface) methodology results ina very weak description of a user interface.andP;  The BNF (Bacus Naur Form)representation of the dialog includes only the barest essentials of thehuman-computer dialog, and a simple-minded translation of this representationinto an actual dialog will yield a suboptimal user interaction.andM;Other than the fact that the use of a BNF representation constrains the typeof interactions permitted (for example, MacPaint is practically impossible torepresent in BNF), the methodology will miss a number of importantconsiderations.andP;  Some of the items a modern interface designer shouldconsider are:andM;* Sequencing the dialog--the sequence of events produced by the AUImethodology are more likely to support the needs of the systems programmerthan the user.andM;* Presentation of understandable dialog--as expressed in the paper by Kuo andKarimi, communication is through the left-hand side terms of the BNF.andO;However, it is simply not acceptable to show any user BNF for any reason!andO;The authors do include construct-like comments to be used to clarify theterms to the user.andP;  However, I question whether the comment mechanism wouldfix this problem.andM;* Layout of the screen--one should design a screen display just as anewspaper editor works to design a newspaper page.andP;  Allowing items to scrollby the user should be something of the past.andP;  This methodology totallydisregards such issues.andM;* Assisting the user with the task--a computer system should not expect theuser to generate any information that the system already has in some form.andO;As in Kuo and Karimi's example, when the system has a list of customers, amenu presentation should be considered rather than a form entry dialog.andP;  Thismethodology would not even consider such an optimization.andM;* Error avoidance--a good system will not require the user to use BNF-likecommands.andP;  It will also assist the user by performing spelling correction,doing type-checking, and creating error recovery routines that assist theuser.andM;All of the items discussed above are within the grasp of present computertechnology and should be an integral part of any methodology for creation ofuser interfaces.andM;Given the current understanding of how to create interfaces that are easy forthe user to operate, it should be considered unprofessional and negligent tobuild a system that does not do everything possible to enhance the userinterface.andP;  As such, I would not consider the methodology proposed by Kuo andKarimi viable unless it were expanded to place more emphasis upon the user'sneeds.andP;  I also believe the ACM (through Communications) should make an effortto ensure that research disregarding the needs of computer-system users isnot promoted as state-of-the-art work.andP;  James H. Alexander 9429 Yale LaneHighlands Ranch, CO 80126andM;AUTHORS' RESPONSEandM;The philosophy of &quot;mapping the task to the user interface model,&quot; adopted asthe basis for writing our paper, has been stated by prominent researcherssuch as Moran and Jagodzinsky.andP;  In particular, we like to point out thatMoran, in his study of mapping the user mental model of the task to userinterface design using command language grammar, proposed a hierarchicaldecomposition of task into subtasks; the descriptions of the user interfaceare divided into four levels: task, semantics, syntax, and the interaction.andO;In another study that examines the psychology, computer science, andcognitive process control for user interface design, Jogodzinsky also statedthat &quot;Moran does not specify how the initial task level model should beelicited from the user, but this is recognized as a problem of systemanalysis and should be amenable to an existing solution such as DeMarco'stechnique of user-drawn data flow diagrams.&quot;andM;The user interface is &quot;not&quot; just a by-product of the system analysis.andP;  It isone of the many products that must be produced at the end of system analysisand logical design.andP;  And indeed, the user interface should be an integralpart of the entire system life cycle.andP;  We have stated that both functionalityand usability are important factors to be considered in user interfacedesign.andP;  However, in our paper, we have also stated that that would focus onthe user interface functionality, and the conceptual analysis and logicaldesign of the user interface.andP;  We have also intentionally avoided discussionsrelated to physical, implementational issues.andP;  This separation of&quot;conceptual&quot; from &quot;physical&quot; is key to understanding our paper.andM;We think that the data flow diagram is perceived by Alexander as a techniqueused as a program structuring tool solely by software engineers and solelyfor programming purposes.andP;  This position, however, is inconsistent with thattaken by DeMarco who has emphasized the derivation of DFDs must be entirelybased upon user needs, using techniques such as interview and on-siteobservations--which are also techniques employed by cognitive psychologiststoday to study the user mental model.andP;  DFDs should describe the user needs,said DeMarco.andP;  A good system analyst is encouraged to take notes of variousfacts and findings, including the user behavioral attributes, as a supplementto the DFD technique.andP;  Our position that system analysts and designers mustalso be cognitive engineers is consistent with that advocated by Card, Moran,and Newell.andM;Alexander also criticizes the use of BNF as the tool for user interfacespecifications.andP;  In this point, he has ignored the strengths associated withthe formal grammars for studying both psychological and linguistic aspects ofthe user interface.andP;  Alexander states that &quot;the BNF representation of thedialog includes only the barest essentials of the human-computer dialog...&quot;andO;But it is the same &quot;bare essentials&quot; as those proposed by Moran in his CLG(Computer Language Grammar).andP;  It also has great potential for studyinginterface usability as was proposed by Reisner.andP;  The GOMS model and theKeystroke Level model may be applied to study the usability issues as well.andM;Alexander states that our approach can yield a &quot;sub-optimal&quot; userinteraction.andP;  We guess that he refers to the issues such as screen layout,choice of vocabularies, use of synonyms, task switching, etc.andP;  We have notaddressed those issues in our paper because of the paper length limitationand, more importantly, because they are strongly related to the tools chosenfor implementation.andP;  The BNF representation does, however, provide a basicskeleton for further refinement.andP;  A User Interface Management System (UIMS)based on the BNF representations should be used for this purpose.andP;  Forexample, the screen layout can be improved by human factor specialist and/orartists to ensure its usability.andM;Is it true that BNF is inappropriate for a MacPaint-like environment.andO;Imagine this implementation strategy.andP;  The objects at the higher levels ofthe BNF are displayed as icons, i.e., the menu of choices become the menu oficons, which can then be manipulated by the device such as a mouse.andP;  The BNF,therefore, can be used to specify at least a part of the logical structure oficons in MacPaint-like interfaces.andP;  This strategy, again, is dependent on thetools chosen for implementation.andM;We are not claiming that the formal grammar is a panacea to solve allproblems in the user interface.andP;  The formal grammar is suitable forspecifying user interface based on the &quot;conversational metaphor,&quot; a term usedby Norman to describe the traditional user interface.andP;  The use of the formalgrammar for the other metaphor, &quot;direct manipulation,&quot; is still yet to beresearched Norman also points out that the strengths of the conversationalmetaphor and direction manipulation depend on the task and the user.andM;We feel that Alexander dislikes our paper because it does not addressusability issues to his satisfaction.andP;  Although it is never our intent, asstated in our paper, to address the issue, we would still like to answerparticular issues raised in his letter:andM;1.andP;  Sequencing the dialog: Alexander says that &quot;The AUI methodology are morelikely to support the needs of the systems programmers than the user.&quot;andP;  Wehope that our arguments presented earlier show that the AUI methodology isnot entirely useless fo assessing user interface usability.andP;  Our position isthat it is very difficult to assess this issue until some empirical evidenceis provided.andP;  Furthermore, the grouping strategies in the AUI methodology,such as object and functional grouping, actually can be interpreted as a wayto satisfy a cognitive factor called &quot;Chunking.&quot;andM;2.andP;  Presentation of understandable dialog: BNF describes the basic interfaceconstruct to be employed in user interface implementation.andP;  BNF descriptionsof the user interface, however, are hidden from the user.andP;  This is similar tousing BNF for describing the grammar for a programming language, say Pascal.andO;A programmer will not write programs in BNF.andP;  However, understanding thegrammar can help the programmer write a clean, working Pascal program.andP;  TheBNF in the AUI methodology describes a coherent construct of the userinterface.andP;  From the usability point of view, it is superior to buildinginterfaces that consist of fragmented, inconsistent pieces.andP;  We are notclaiming everybody should learn BNF in order to use a computer system; a goodUIMs can hide this technical detail from the user.andP;  Moreover, it is easier toteach users such a coherent model than a fragmented one.andM;3.andP;  Layout of the screen: Scrolling is indeed out of style today.andP;  To saythat it should be totally discarded is, however, ignorant.andP;  Take for examplethe following application: the missile firing system to be used by thePresident of the United States.andP;  The President will probably do this one forhis/her entire life; he or she will not want to feel pressured to do this.andP;  Afew questions, many of which have implications of national security, must beanswered.andP;  The pacing must be smooth.andP;  A scrolling question/answer dialogwill be superior in this application.andP;  Our point is that the usability of adialog style really depends on the task and the user, i.e., the nature andpacing of the task and the behavioral attributes (preference, experience) ofthe user.andM;4.andP;  Assisting the user with the task: Again, it depends on the user and thetask; and the BNF is only a blue-print to be used with a UIMs for furtherusability refinement.andP;  An experienced user may want to type in everythingbecause he or she is knowledgeable and efficient to do the job.andP;  It is truethe heuristics in the AUI methodology do not consider Alexander's suggestion.andO;It is also true that the AUI methodology does not include all possibleheuristics for improving interface usability.andP;  To do so, it will probablytake 300 pages to write.andM;5.andP;  Error avoidance: Alexander is right in saying that the system should helpusers in spelling, type-checking, etc.andP;  That is what a context sensitive,intelligent, BNF-based tool should do.andP;  We feel that this is animplementational issue.andM;We are happy that somebody actually read our paper.andP;  We feel, however, muchof Alexander's criticism is unfounded.andP;  We hope we can convince the readersof Communications that our paper will make an important contribution to thefield of software engineering as well as the study of usability for userinterface design.andP;  Feng Yang Kuo Jahangir Karimi University of Colorado atDenver College of Business Administration 1475 Lawrence Street Denver, CO80202-2219andM;ON EFFICIENT AND PORTABLE COMBINEDandM;RANDOM NUMBER GENERATORSandM;In a recent study L'Ecuyer presented an efficient way of combiningMultiplicative Linear Congruential Generators.andP;  I would like to make a fewcomments and corrections on this article.andM;1.andP;  The first part of the proof of lemma 1 is not correct since it is notvalid for n andless; i, because this would imply negative values for W.sub.1.andP;  Thecorrect proof may be obtained by using the fact that (a + b)MOD d = [(a MODd) + (b MOD d)]MOD d.andM;Noting that 0 [is less than or =' W.sub.1 [is less than or =] d - 1, we havefor every integer 0 [is less than or =] n [is less than or =] d - 1 Pr(W = n)= Pr[(W.sub.1 + W.sub.2)MOD d = n] = Pr[((W.sub.1.MOD d + W.sub.2.MOD d)MODd) = n] = [sigma] Pr[(W.sub.2i.MOD d + W.sub.1 - [delta].sub.i.d) = n] wherethe summation is carried out over the range of W.sub.2 and [delta].sub.i = 0if W.sub.2i.MOD d [is less than or =] n, [delta].sub.i = 1 otherwise, Pr(W =n) = [sigma] Pr[(W.sub.2i.MOD d= Y.sub.i) and [W.sub.1 = n + [delta].sub.i.d- Y.sub.i)] = [sigma] Pr(W.sub.2i.MOD d = Y.sub.i)Pr(W.sub.1 = n +[delta].sub.i.d - Y.sub.i) = [sigma] Pr(W.sub.2i.MOD d = Y.sub.i)(1/d) = 1/dsince [sigma] Pr(W.sub.2iMOD d = Y.sub.i) = 1.andM;2.andP;  An amendment is necessary in the argument concerning equation.andP;  Sincea.sup.2 andless; m, one has q = [m/a] [is greater than or =] a implying q [isgreater than or =] a andgt; r.andP;  On the other hand, [s/q] = [(aq + r)/q] for aq [isless than or =] s [is less than or =] aq + - 1.andM;Therefore the inequality should be [s/q]r [is less than or =] [(aq + r)/q]r =ar andless; a.sup.2 andless; m.andM;3.andP;  Concerning equation, if m = aq + r a general expression may be obtainedfor Y = as MOD m in terms of a, q, and r.andP;  To see this, let k.sub.1 = [as/m]= (as - as MOD m)/m and k.sub.2 = [s/q] = (s - s MOD q)/q.andM;Then it is obvious that: Y = as MOD m  (1) = as - k.sub.1.mandM;It may be shown that for a suitable value of h, Y may be written as: Y = a(sMOD q) - rk.sub.2 + h = a(s MOD q) - (m - aq)k.sub.2 + h  (2) = as -k.sub.2.m + handM;The value h may be obtained from the expressions above as: h = (k.sub.2 -k.sub.1)m = [(s -s MOD q)/q - (as - as MOD m)/m]m = [ms - ms MOD mq - aqs +aqs MOD mq]/q = [rs - (aqs + rs)MOD mq + aqs MOD mq]/qandM;Noting that (aqs + rs)MOD mq equals (aqs MOD mq + rs MOD mq)MOD mq, twosituations will arise: h=(rs - rs MOD mq + mq)/q ...andP;  if rs mod mq andgt; m(s MODq)  (3) = (rs - rs MOD mq)/q ...andP;  otherwise, if max(rs) = r(m - 1) andless; mq, thatis, if q andgt; r, rs MOD mq will reduce to rs.andP;  This is the special case studiedby L'Ecuyer, i.E., a.sup.2 andless; m.andP;  Hence, h will take the values 0 or m to keepthe Y positive.andM;4.andP;  L'Ecuyer points out that the period of the generator proposed by Wichmannand Hill is p = 6.95 X 10.sup.12 instead of p andgt; 2.78 X 10.sup.13 as claimedin.andP;  This remark is already made by the aforementioned authors.andP;  The mostcrucial point, however, in using this generator is that it produces some zerovalues due to rounding error depending on the precision of the machine.andM;5.andP;  The limitation imposed by the condition a.sup.2 andless; m may be overcome if a= a.sub.1, a.sub.2, .andP;  .  ., a.sub.n and max[a.sub.1/.sup.2, a.sub./.sup.2, .andO;.  .  , a.sub.n/.sup.2] andless; m.andP;  In this case the MOD operation may be executedin n steps: as MOD m = (.andP;  .  .((a.sub.1.s MOD m)a.sub.2.MOD m).andP;  . andO;.)a.sub.n.MOD  m.andM;For example, the fifth multiplier given in Table I [1, p. may be factorizedas 630360016 = 24112 * 26143.andP;  This multiplier is used in SIMSCRIPT II.5language and implemented in a portable generator.andP;  The followingimplementation is approximately twice faster than the method proposed byMarse and Roberts: KX = IX/89062 IX = 24112 * MOD(IX, 89062) - 20703 * KX KX= IX/82143 IX = 26143 * MOD(IX, 82143) - 19198 * KX IF(IX.LT.0) IX = +2147483647 Fatin Sezgin Ataturk University Erzurum, TurkeyandM;AUTHOR'S RESPONSEandM;1.andP;  The case where n andless; i does not invalidate the proof of Lemma 1.andP;  Even if n- i andless; 0, (n - i)MOD n is always non-negative (note that for n andless; 0, n MOD d isthe smallest non-negative integer n' such that n' = n + kd for some integerk).andP;  The proof is also valid even if the W.sub.i., i [is greater than] 2, cantake negative values, provided that the sum [sigma].sup.[infinity].sub.k=0 isreplaced by say [sigma].sup[infinity].sub.k=-[infinity]..andP;  (Note that thenon-negativity of the W.sub.i.'s was not specified in the statement of Lemma1.)andM;2.andP;  It is true that *s/q* r andless; *(aq + r)/q* r must be replaced by *s/q* r [isless than or =] * (aq + r)/q * r.andM;This is a minor error that affects nothing else in the paper.andP;  Note thata.sub.2 andless; m is not necessary for the given scheme to work.andP;  Just having ar[is less than or =] m also a (less restrictive) sufficient condition(provided all integers from -m to m - 1 are well represented).andP;  SeeandM;3.andP;  The condition a.sub.2 andless; m (or ar [is less than or =]m) is not a hardrestrictive condition.andP;  The fact that the method can be used twice when a canbe written as the product of two factors that obey the condition was alreadymentioned in.andP;  But it then takes about twice the time.andP;  For the same price,we can combine two generators that obey the condition and get much betterproperties.andP;  In fact, even when one of the prime factors of a do not obey thecondition, the generator can still be implemented in a portable way, andthere are different ways to do that, but it will be slower.andM;RANDOM NUMBER GENERATORS AND THEandM;MINIMAL STANDARDandM;The article in the October Communications, &quot;Random Number Generators: GoodOnes are Hard to Find&quot; by Park and Miller is appropriately titled.andP;  Modianos,Scott, and Cornwell highlight a number of deplorable random number generators(RNG) intrinsic to various microcomputer languages and software packages.andO;The problems of a lack of portability, non-randomness, and unacceptably shortcycle sizes cited by Park and Miller can be extended to include lack of(statistical) conformance to the assumed underlying uniform distribution andslowness of random number generation.andM;Though speed of generation is rarely a major consideration in minicomputerand mainframe simulations, the possibility of (multiple) nonuniform streamsof N random numbers should be seriously considered prior to settling on theRNG to be used in any rigorous scientific inquiry.andP;  The validity ofinferences drawn from a simulation study may be in question if the assumptionof uniformity is not within reason satisfied.andP;  It should be noted that theLehmer generator (Park and Miller's minimal standard generator) has beenextensively tested with regard to the uniformity assumption and is deemed toperform satisfactorily.andM;Park and Miller identified naivete as a major problem among (non-specialist)users of RNG.andP;  In statistical simulations naivete can assume a more subtledisguise.andP;  As a specific example, I will cite the use of the Box-Mullertransformation (BMT) of uniform random numbers into standard normaldistributed random numbers.andP;  The mathematical validity of the BMT which usesa two-to-two transformation of uniform random numbers into two standardnormal random numbers is irrefutable and is presented in many elementarymathematical statistics texts such as the classic by Hogg and Craig and alsoin numerous simulation texts such as the ones by Rubinstein and Devroye.andP;  TheBMT uses sine and cosine functions--periodic functions that, when used inconjunction with a linear congruential generator (LCG) such as the Lehmergenerator, produces statistically correlated &quot;random&quot; numbers.andP;  Since mostsimulation applications require statistical independence, those simulationsrequiring normally distributed random numbers should avoid use of the BMT inconjunction with a LCG.andP;  This problem is more extensively discussed in thetext by Bratley, Fox, and Schrage and is well-documented in the statisticalliterature.andM;A recent example of this error in the statistical literature can be found inan article by Westfall where the International Mathematical and StatisticLibraries (IMSL) subroutine GGUBFS was used to produce uniform random numbersthat were subsequently transformed by the BMT into normal &quot;random&quot; numbers.andO;In my mind, any conclusions drawn by Westfall are subject to scrutiny.andM;One simple solution to this dilemma is to avoid the use of the BMTaltogether.andP;  In addition to the BMT, several methods for generatingstandard-normal random variates are presented in [2], [4], and [12].andP;  Inparticular, I favor a rational function approximation to the inverse standardnormal cumulative distribution function; several good ones exist with that ofOdeh and Evans being the most accurate of which I am aware.andM;One further comment I wish to make relates to the issue of cycle size.andP;  TheLehmer generator of Park and Miller has a full-period in excess of twobillion that will not be exhausted prior to completion of most simulationstudies.andP;  However, we are in the age of super-computing and simulationapplications requiring super-computer resources will quickly exhaust thegenerator.andP;  An issue that merits immediate research attention is thedevelopment of a RNG or generating technique with a vastly increased cyclesize that satisfies the criteria of Park and Miller as well as statisticalconformance to a uniform distribution.andP;  Portability of such a generator maynot be a particularly important criteria--at least for a while.andP;  Rick L.andO;Edgeman Computer Information Systems Department College of Business ColoradoState University Fort Collins, CO 80526andM;Although I am not a specialist in random number generation, I must,nonetheless, take issue with the conclusions reached by Park and Miller intheir article &quot;Random Number Generators: Good Ones Are Hard to Find&quot;(Communications, Oct. 1988, 1192-1201).andP;  I do not dispute their points that(a) some common random number generators are very bad, and (b) it takes aspecialist to know if a random number generator is any good or not.andO;Nonetheless, the &quot;minimal standard&quot; that they propose is much slower thanother equally satisfactory generators, at least on some machines.andP;  Moreover,Park and Miller imply that because many published generators areunsatisfactory, all similar ones are unsatisfactory.andP;  That is rather likearguing that because many cats are black, all are.andM;My conclusions are based almost entirely on Knuth's discussion.andP;  Park andMiller acknowledge that Knuth is a leading authority on the subject, but theyseem to ignore some of his most conspicuous recommendations.andP;  For instance,they coyly note in their article (p.andP;  1199) that &quot;today, with oneqnotableexception [18, p. 170], mixed generators are rarely ever recommended byspecialists.&quot;andP;  The reader who does not bother to track this reference may notrealize that the notable exception is none other than Donald Knuth.andP;  Thereference &quot;[18, p. 170]&quot; contains Knuth's answer to the question (quotingKnuth): &quot;What is the result of all this theory?andP;  What is a simple, virtuousgenerator I can use in my programs in order to have a reliable source ofrandom numbers?&quot;andP;  The generator that Knuth recommends is a mixed congruentialgenerator whose modulus is a power of two-precisely the type of generatorthat Park and Miller vigorously lambaste.andM;Park and Miller propose three criteria for a good generator: (1) thegenerator must have a full period, (2) the full period sequence must berandom, and (3) it must be possible to implement the generator efficientlyusing 32-bit arithmetic.andM;I would argue that (1) is not really what we want; a better criterion is thatthe period be sufficiently long.andP;  A generator whose full period is 2.sup.35and whose actual period is 2.sup.33 is clearly superior (all else beingequal) to one whose full period is 2.sup.31., and that achieves that fullperiod.andP;  (Knuth's recommended generator does not have a full period.)andP;  As to(3), it makes sense only if it is taken relatively.andP;  I would restate it as:andM;(3') Using 32-bit arithmetic, it must be possible to implement the generatorwith efficiency comparable to that of any other generator of equalstatistical merit.andM;By (3'), the &quot;minimal standard generator&quot; fails.andP;  It requires two divisionsand a multiplication at minimum.andP;  In its integer version it is likely torequire an additional multiplication unless an operation is available forobtaining both the quotient and remainder of a division at the same time (asit is in machine language).andP;  Knuth offers a number of better alternatives.andM;If we apply Schrage's method (ACM Trans.andP;  Math.andP;  Softw., June 1979, 132-138)as described by Park and Miller to Knuth's mixed congruential generator, wemay be able to avoid some of these multiplications and divisions, dependingon the compiler and our willingness to code a machine-independent algorithmin machine language.andP;  In real arithmetic we can multiply or divide by a powerof two by adding or subtracting an appropriate quantity to the exponent.andP;  Ininteger arithmetic we can multiply or divide by a power of two by shifting,and some compilers will do that for us if given a constant multiplier as apower of two.andM;If we are willing to tolerate overflow on integer operations we can useKnuth's mixed congruential generator as it stands.andP;  In practice this willoften be acceptable, although it admittedly violates the 32-bit arithmeticcriterion.andM;We can use an additive (or subtractive) method such as the one described byKnuth on pages 27 and 171.andP;  It can easily be implemented using 32-bitarithmetic, and it requires no multiplications or divisions.andP;  Although thismethod has not been as thoroughly analyzed theoretically as the congruentialmethod has been, Knuth states: &quot;Besides its speed, [this method] has thelongest period we have seen yet; and it has consistently produced reliableresuts, in extensive tests since its invention in 1958.&quot; Knuth does, however,have some reservations: &quot;The only reason it is difficult to recommend [thissequence] wholeheartedly is that there is still very little theory to provethat it does or does not have reliable randomness properties.&quot;andP;  Since thecongruential method has known statistical defects (adjacent triples fall on asmall number of parallel hyperplanes), Knuth is perhaps being tooconservative here in preferring the devil he knows to the one he does not.andM;Yet another possibility is improving the randomness of a fast but weakgenerator through shuffling, which requires little more than a uniformdistribution of the original (unshuffled) sequence.andP;  Knuth says (p.32): &quot;Onintuitive grounds it appears safe to predict that the sequence obtained byapplying Algorithm M [shuffling] will satisfy virtually anyone's requirementsfor randomness in a computer-generated sequence, because the relationshipbetween nearby terms of the output has been almost entirely obliterated.&quot;andO;Knuth then cites Algorithm B, an improvement on Algorithm M, that transformsa sequence of period 8 into one of period 40 (Sec.andP;  3.2.2, Exercise 3).andO;Perhaps the major disadvantage of shuffling, which relates to a criterionthat Park and Miller do not cite, is that generating independent subsequencesof the random sequence is relatively expensive (or at least there are nopublished recommendations on how to do it cheaply).andP;  L'Ecuyer mentions thisas a drawback of shuffling in the application of random number generators todiscrete-event simulations.andM;As an experiment, I timed three random number generators on a 12 MHz 80286personal computer, using both 32-bit and 16-bit arithmetic.andP;  The results,averaged over 200,000 generations, were:andM;*  Minimum standard, 32 bits ...andP;  196 microsecondsandM;* Shuffle with Knuth's mixed congruential generator, m = 2.sup.32, 32 bits...andP;  61 microsecondsandM;* Subtractive method, 32 bits ...andP;  34 microsecondsandM;* Shuffle with Knuth's mixed congruential generator, m = 2.sup.16, 16 bits...andP;  15 microsecondsandM;* Subtractive method, 16 bits ...andP;  20 microsecondsandM;The 16-bit methods are an order of magnitude faster than the minimum standardmethod.andP;  In applications where 16-bit precision will suffice, the shufflingand subtractive methods are particularly atractive because of their longperiods--far greater than 2.sup.16.andP;  Paul W. Abrahams 214 River RoadDeerfield, MA 01342andM;Three recent papers published by ACM have presented strong arguments for theuse of specific algorithms for random number generator (RNG): one amultiplicative linear congruential (LCG) (Park and Miller), the second(L'Ecuyer) a mixture of LCGs, the third (Haas) a multiple prime method.andP;  Allof the recent papers argue on the grounds of portability as well asperformance.andM;Park and Miller propose a minimal standard RNG against which all othergenerators must be judged.andP;  The minimal standard is defined by the author'sthree criteria:andM;T1: f(z) = ax MOD m is a full-period generating function, i.e.andP;  z.sub.n.+1 =z.sub.n and all integers from 1 to m - 1 are generated before the cyclerepeats.andM;T2: the sequence z.sub.1, z.sub.2., ...andP;  z.sub.m is &quot;random.&quot;andM;T3: f(.) can be efficiently implemented with 32-bit arithmetic.andM;The specific standard RNG is a multiplicative linear congruential generatorwith a = 16807 and m = 2147483647.andP;  The authors state that the multiplicativelinear congruential generator (Lehmar generator) has the advantage ofsimplicity and adequate testing by the computer science community.andM;If the minimal standard is to be adopted widely, it will be necessary toconsider it in relation to a standard.andP;  A standard is not a particulargenerator; rather, it is a basis for testing any reasonable proposal for amethod of generating random numbers.andP;  This comment is made in the hope ofadvancing a step closer towards such a standard.andM;The first criterion seems unnecessarily restrictive, until more experience isavailable with the minimal standard, it is premature to rule out mixed LCGgenerators like the L'Ecuyer or other types such as the Haas portablegenerator.andM;Instead of the Park and Miller criterion T1, we propose the following moregeneral criterion:andM;T1a: if the RNG is a multiplicative linear congruential generator (MLCG), itshould have full period (m - 1); else it should have a period at least aslong as the &quot;equivalent&quot; MLCG, is a sense to be made clear later.andM;The second criterion of the three Park and Miller have suggested is notspecified in detail.andP;  They refer to &quot;more powerful theoretical tests&quot; [4, p.andO;1194].andP;  The Park and Miller standard will have more value if the T2 criterionis clarified.andM;We propose that the second of Park and Millers' criteria be split into threesubcriteria as follows:andM;T2a: the random numbers must be uniformly distributed.andM;T2b: the random numbers must be &quot;disorderly.&quot;andM;T2c: good seeds must be identified.andM;In T2a, uniformity is well understood and can be demonstrated by performingstatistical tests such as Chi-square of Kolmogorov-Smirnov with suitablearrangement of the numbers into finitely many cells prior to testing.andM;In T2b, &quot;disorder&quot; is intuitively appealing, but hard to define rigorously.andO;In its usual meaning, it refers to the distribution of pairs and triplets,but the question may be asked: When stop at triplets?andP;  The minimal standardgenerator has the global property of being constructed from a permutation ofthe integers 1 to m - 1.andP;  What local properties should we demand forgenerators?andM;We propose that the order relationship in sequences of practical lengthshould also be random.andP;  The problem is to decide how long a sequence needs tobe in relation to testability.andP;  Knuth has given an algorithm for thePerutation Test which is suitable for doing T2b tests on portable randomnumber generators.andP;  It is easily implemented in higher-level languages.andO;Powerful theoretical tests such as the Spectral Test are available formultiplicative LCGs like the Park and Miller minimal standard.andM;For &quot;disorderly&quot; we suggest a definition: random number sequences for whichconsecutive k-tuples are equally likely to be arranged in any possiblepermutation order over sufficiently long sequences.andP;  The length of therelevant permutation k, in relation to the length of the entire sequence,requires further discussion.andM;If k = 2 or 3, we have the usual pairs and triples tests.andP;  If a value of k isconsidered which is a large fraction of the total sequence length, it isobviously impossible to have a uniform distribution of such permutationsrepresented in samples.andM;Reasonable values of k may be empirically tested for uniformity.andP;  At somelimit, one would expect the RNG to fail the permutation test.andP;  If this valueis greater than the dimensions of the application space, it sould give noconcern to the user.andM;Finally, we would like to discuss T2c, &quot;good seeds.&quot;andP;  An advantage of the LCGwith prime modulus, m, and full-period multiplier, is: any positive integerup to m - 1 is a valid seed.andP;  Some unpublished work we have just completedshows that, even for the good RNGs, there can be &quot;bad patches.&quot;andM;While the RNG passes the tests for very long sequences, it may fail formoderate sequences.andP;  This is relevant for many users of the RNG who areunlikely to need very long sequences but who are concerned with the qualityof the particular sequence which they employ in their application.andP;  As aresult an additional criterion is required.andP;  Authors recommending particularRNGs should state which seeds the user should use or avoid with that RNG.andO;Unfortunately, the theory for seed selection is lacking in the case of mostRNGs other than MLCGs.andP;  Francis M. Sand James Crawford, Jr.andP;  FarleighDickinson University Teaneck, NJ 07666andM;AUTHORS' RESPONSEandM;We would like to take this opportunity to add a few updates to our recentarticle, &quot;Random number Generators: Good Ones Are Hard to Find,&quot; and thenrespond to the letters by Edgeman, Sand and Crawford, and Abrahams.andP;  Firstthe updates.andP;  (1) There is an important reference that has appeared since ourpaper was first submitted, Stochastic Simulation by Brian Ripley, Wiley,1987.andP;  Ripley's text features a contemporary discussion of random numbergeneration which will be of interest to mathematically sophisticated readersinterested in learning more about this subject.andP;  (2) To keep our article assimple and short as possible, we chose to discuss &quot;...andP;  the class ofgenerators for which the theory is most complete.&quot;andP;  Therefore, we omitted adiscussion of shift-register (Tausworthe) generators.andP;  This was not meant tosuggest that such generators are necessarily inferior to Lehmer generators.andO;However, shift-register generators are less well understood, and portabilityis a potential problem because they are more difficult to implement correctlyand efficiently in some high-level languages.andP;  (3) Recent versions of TurboPascal (versions 4.0 and 5.0) have significantly improved the language.andP;  Forexample a 32-bit integer (longint) type is now available, and by using unitsone can nicely solve the problem of hiding the random number generator seed.andO;The internal Turbo Pascal random number generator has also beenchanged--hopefully for the better.andP;  (4) Several people have written asking usabout random number generation on systems with only 16-bit integer arithmeticand 32-bit real arithmetic.andP;  Our best advice to them is to get a bettersystem.andP;  Failing that, we would recommend the 16-bit generator presented byL'Ecuyer in his article (Communications, Jiune 1988, 742-749, 774).andP;  (5) Wewere remiss in our vague reference to &quot;more powerful theoretical tests.&quot;andP;  Thenature of these tests was implicit in our (frequent) references to thearticle by Fishman and Moore (Siam J. Sci.andP;  Stat.andP;  Comput., Jan. 1986,24-45).andP;  However, we should have made it more clear that we were referringprimarily to the spectral test in spaces of dimension 2 through 6.andM;Now the responses, beginning with Edgeman's letter.andP;  We are in generalagreement with all of Edgeman's points.andP;  Indeed, his letter is an appropriateadjunct to our article.andP;  We would only add, relative to his last point, thatif you need a very large period then consider using the 32-bit compositgenerator recommended by L'Ecuyer in his article.andM;Sand and Crawford, in their letter, seem to have interpreted our T.sub.1(full period), T.sub.2 (random), and T.sub.3 (implementation) tests moreliterally than we intended.andP;  WE introduced these tests as a mechanism fororganizing the article.andP;  For that reason these tests are very specific toLehmer generators.andP;  We agree that if one wants to develop a general (paper)standard applicable to all random number generators then these tests wouldhave to be modified significantly.andP;  However, this is a potentially bottomlesspit into which we would be reluctant to jump.andM;The last period raised by Sand and Crawford--the &quot;bad patches&quot;problem--raises an important and often misunderstood issue.andP;  Pick yourfavorite empirical test, for example, the common frequency test foruniformity, and apply it to, say, 1000 disjoint streams (patches) of randomnumbers produced by your favorite random number generator.andP;  If the test isconducted at, say, a 95 percent level of confidence then you expect to findapproximately 50 (out of 1000) failures.andP;  Indeed, if you were to getsignificantly less (or more) than 50 failures this would be strong evidenceof a defective generator.andP;  So then, are these &quot;patches&quot; bad?andP;  Analogously, ifyou toss a fair coin 10,000 times and observe an occasional long run ofconsecutive heads would you reject these runs as non-random?andP;  The point hereis that &quot;bad patches&quot; may exist.andP;  However, the definition of &quot;bad&quot; isunclear.andM;Abrahams, in his letter, took issue with our conclusions primarily becauseour proposed minimal standard generator is &quot;...andP;  much slower than otherequally satisfactory generators, at least on some machines.&quot;andP;  However, thiscriticism is irrelevant and misleading for the following reasons.andP;  (1) Inreal stochastic simulations the time spent generating U(0, 1) random numbersis virtually always insignificant relative to the time spent doing otherthings.andP;  In the 60s we worried about how to make random number generatorsfast.andP;  Today, we worry about how to make them correct.andP;  (2) There is a20-year-old technique known as simulated division (Payne, Rabung, and Bogyo,Communications, Feb. 1969, 85-86) which can be used to calculate az mod(2.sup.31 - 1) in terms of az mod 2.sup.31 and az div 2.sup.31.andP;  This is thebasis for a common efficient implementation of the minimal standard inassembly language.andP;  If this implementation had been tested by Abrahams we areconfident that its times would have been competitive with the best of thosehe cited.andP;  The point here is that if you need the efficiency provided byusing shifts to calculate quotients and remainders then simulated divisioncan be used to implement the minimal standard generator.andM;The letter from Abrahams reflects an attitute common among non-specialistusers of random number generators--fast is good, faster is better.andO;Reasonable people will always disagree about the best way to generate U(0,1)random numbers.andP;  However, their disagreement should be based on the mostimportant issues, and speed is rarely ever one of these.andP;  Steve K. Park KeithW. Miller College of William and Mary Department of Computer ScienceWilliamsburg, VA 23185</TEXT></DOC>