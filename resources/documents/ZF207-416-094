<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-416-094  </DOCNO><DOCID>07 416 094.andM;</DOCID><JOURNAL>Communications of the ACM  July 1989 v32 n7 p852(9)* Full Text COPYRIGHT Assn. for Computing Machinery, Inc. 1989.andM;</JOURNAL><TITLE>Coding image sequences for interactive retrieval. (SpecialSection) (technical)</TITLE><AUTHOR>Lippman, Andrew; Butera, William.andM;</AUTHOR><SUMMARY>The inclusion of audio and video in computing systems has beenhampered: only analog representations of video information wereavailable; much storage was required; equipment was expensive;video and audio data were not integrated into networked systems;there has not been a well-developed body of knowledge for theapplication of interactive video; and interaction has been limitedby the lack both of technical mechanisms for interacting withdynamic pictorial displays and a formalized language on whichinteraction can be built.andP;  A digital representation of joint audioand video data for playbacks below 1.5M-bps is described.andP;  It isefficient enough for microcomputer applications, allows densestorage of moving pictures on media such as CD-ROM, is amenable toremote access, and incorporates features forming a basis forinteractive systems as well as video distribution of movies.andM;</SUMMARY><DESCRIPT>Topic:     Interactive videoImage processingImage EncodingMultimediaInformation Storage and Retrieval.andO;Feature:   illustrationchart.andO;Caption:   Subband vector coder. (chart)Spectral decomposition of input images. (chart)Pyramid decomposition of a frame pair. (chart)andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>Coding Image Sequences for Interactive Retrieval In recent years, there hasbeen increasing activity in the integration of text, graphics, audio andvideo in personal workstation and distributed computing systems.andP;  The levelof sophistication with which graphics is embedded into systems is high enoughso that modern terminals and workstations bear little resemblance to the&quot;glass teletypes&quot; of only a few years ago; it is fair to say that hig qualitygraphics is a prerequisite for PCs and virtually mandatory for research andmany commercial applications.andP;  However, the inclusion of audio and video hasbeen hampered by several technical and nontechnical factors that include:andM;* Only analogue representations of video information have been readilyavailable.andM;* Excessive storage space is required for video.andM;* Equipment for manipulation of video data is expensive and has only recentlybecome a feasible option.andM;* Video and audio data have not been successfully integrated into networkedsystems.andM;* There has not been as well developed a body of knowledge in the applicationof interactive video.andM;* The repertoire available for interaction has been limited by the lack ofboth the technical mechanisms for interacting with dynamic pictorialdisplays, and a formalized language on which the interaction can be built.andM;In this article, we directly address the first four of these problems anddiscuss the connection between coding and the last two.andP;  We describe adigital representation of joint audio and video data for playback rates below1.5 megabits/second that is efficient enought to be incorporated into PCapplications, allows dense storage of moving pictures on low cost media suchas compact audio disks (CD-ROM), is amenable to remote access of movingvideo, and incorporates a set of features in the representation that forms abasis for the development of interactive systems as well as innovative videodistribution of movies.andM;The video coding used features a number of innovations in moving image codingand is intimately linked to the feature set required for interactiveapplications.andP;  In particular, it is asymmetric, requiring comprehensiveencoding and a correspondingly simpler decoder.andP;  The assumption is that theimages are to be encoded once and viewed many times, in differentcircumstances, i.e., the context of the applications is publishing.andP;  Inaddition, it employs look ahead, a set of techniques where the images areprocessed in multiple passes and the encoding is optimized for the entireimage set.andP;  Unlike videotelephony, where the delay between encoding andremote image presentation must be minimized, we assume that we may processthe entire moving image sequence before any of it need be viewed.andP;  Thus wemay look forward and backward in time and optimize image quality and access;the minimum coding delay is the length of a complete movie.andP;  Finally, asdistinct from most waveform coding approaches designed for extremely lowbandwidth channels, a paramount aspect of the image coding is the necessityfor high quality presentation of moving images.andP;  Again, as distinct fromvideotelephony, where limited bandwidth is the principal constraint and thedesign task may thus be described as presenting the best image possiblethrough a parsimonious channel with minimum delay, in this case, high imagequality is mandatory, and when momentary channel overloads occur (forparticular sequences, for example), techniques such as look ahead andvariable bit rate coding maintain picture quality.andM;The coder is based upon the combination of vector quantization with subbandcoding.andP;  In essence, the image sequence is analyzed by a series of spatialand temporal filters into a set of smaller subbands that are each subsampledand presented to a vector quantizer.andP;  The quantizer encodes each bandexpoiting statistical correlation within blocks of picture elements withineach band and is optimized for the relative amount of energy in each of thebands and differential visual sensitivity to errors in each band.andP;  Inaddition, several statistically based characteristics of the subbands areused to minimize overhead in the quartizer.andP;  Decoding is by a series of tablelook ups and filtering operation and is amenable to large scale integrationand interactive retrieval.andM;CANDIDATE FEATURES OF MOVING IMAGEandM;DIGITAL REPRESENTATIONSandM;There are two broad domains from which we may draw inspiration for the designof a particular moving image representation: broadcast television andapplications of the analog videodisc.andP;  The former has a history dating fromapproximately 1936 and is notably successful; the latter dates from earlywork at N.V.andP;  Philips, Thomson CSF, and Sony and was made widely available in1978.andP;  Many researchers combined the dense storage of the optical videodiscwith computers of varying sophistication and a body of knowledge about thecharacteristics of useful interactive applications has been evolving for thepast 10 years.andP;  A program at MIT's Architecture Machine Group entitled theMovie-Map, for example, presaged the joint use of graphics, multiple diskplayers, and sufficient computing to support a reasonable graphicalinterface, and was developed from 1978 to 1980.andP;  Later work included theMovie-Manual, which extended the previous underlying system through the jointstorage of an image database and a digital descriptive database on the samemedium.andP;  Other workers addressed the use of the disk as a publication mediumfor large scale digital databases, laying the groundwork for many currentapplications of compact audio disks (and CD-ROM) in data publishing.andM;In spite of the utility of the optical disk, it has not been widely acceptedin many compute applications because of the inherent limitations of aread-only analogue system.andP;  The primitive element in the systems is the videoframe, and it cannot be simply scaled, modified or created.andP;  The disk iseffectively a deck with 54,000 images, and like a deck of cards, one mayeither select one or reject it in favor of anoter, or fan through it insequence, but the ability to alter any particular image to sut the immediateneeds of the user is lacking.andP;  The degrees of freedom commonly available in acomputer graphics system are absent, thus limiting the extent to which aneffective simulation of a process under development may be carried out.andP;  Thedisk provides pictorial realism but the cost in flexibility is extreme:descriptive information has been irrevocably lost in the imaging process sothat interactions is restricted to random access replay.andP;  This 3D to 2Dtransformation performed by the camera lens sacrifices information, and theframe contains no history of possible production steps that were used to makeit, such as matt, keys, and camera position.andM;It is worth noting, however, that applications of videodics have madesignificant inroads in the integration of moving pictures with computersimulations in spite of these limitations.andP;  Random access, bi-directionalcontrol of images sequence rate, and reasonably high quality still displaymodes have demonstrated the utility of pictorial and cinematic databases.andP;  Animaginative community of workers are addressing applications ranging fromsimulation to teaching to sales.andP;  In some cases, simple video effects thatcan be done within a workstation such as graphics overlay help broaden therepertoire.andM;The history of applications of the optical videodisc has mde one thingabundantly clear it is difficult to anticipate at the time one prepares thematerial the precise manner in which it will be viewed.andP;  While one can oftenplace constraints on the replay so that a viewers does not jump into a moviein the middle of a word or sentence, or pause it in mid-breath, some programmaterial does not permit the author to compile such a complete list ofpermissible entry and exit points.andP;  An instructional procedure, for example,can be aborted at any time in some systems models but only at its logical endin others; neither model is definitively better in all cases.andP;  Similarly, adance or exercise analysis sequence may well involve stepping through eachframe to avoid the normal effects of gravity and momentum.andP;  In general, it isan undue burden on the author for all access schemes to be specified at thetime of visual material creation, and it is not always possible.andM;We assert that a digital representative of moving pictures requires at leastthe degrees of freedom available in the optical videodisc: random access,high quality still image retrieval, and variable-rate, bi-directionalsequencing.andP;  Lacking these, the only advantage of a digital representationwould be the features gained through coding: compactness and usability innetworks or through local storage media.andP;  In addition, there are two featuresthat are opportunities of a digital representation that directly impact thecoding approach chosen: (1) different encoding for stills and motionsequences; and (2) linking the images to a descriptive database.andM;Joint Still and Moving Image CodingandM;Generally, image compression is predicated on exploiting statisticalcorrelation between nearby spatial samples of a continuous-space scene andthe fact that given a particular viewing situation, the human visual system'sresponse is not identical to that of the camera by which the scene wassampled.andP;  It is well-known and accepted that a given amount of bandwidth ismost effectively used by allocating it in ways attuned to the characteristicsof the human observer.andP;  For moving image sequances, a similar set ofstatistical and psychophysical properties derive from the temporal sampling:humans are not sensitive to simultaneously high spatial and temporalfrequencies.andM;Algorithms that process each image separately, based on statistical andvisual characteristics of that image alone are termed intra-frame coders, andthose that rely on the statistical and visual characteristics of the imagesequence are termed inter-frame coders.andP;  Often in an interframe coder, onecan exploit the fact that each image is viewed for only 1/24 or 1/30 of asecond to present the appearance of high quality images even though eachindividual one is somewhat degraded: the similarity between successive framesis a form of noise cancellation: content that is correlated between images isvisually reinforced, and random perturbations such as noise are visuallycanceled.andP;  Put another way, the appearance of high resolution can be obtainedby a rapid succession of lower resolution still images or by a slowerpresentation of high resolution images.andP;  Moving picture film is an example ofthe latter and normal television is an example of the former.andM;Interactive access to images can require both high quality motion renditionand high quality still reproduction.andP;  It is reasonable to require that asequence played at normal rates look as good as possible and that each framewithin it be able to be examined more closely as a still.andP;  It is alsoreasonable to allow an image to be scaled up or down at full resolution(zoomed), with data being ignored or added as necessary to maintain imagequality.andP;  This makes the problem of coding image sequences for interactiveretrieval an interesting and novel problem.andM;We term the ability to produce images at higher resolution than when viewedin motion resolution refinement.andP;  The implication is that each frame isstored at the resolution with which it will be rendered in motion but thatthere is the capability to augment that rendition with additional dataretrieved from somewhere else on the medium as required for still framedisplay and closeup viewing.andP;  Implicit in this notion is the idea that theaugmentation information be retrieved in an imperceptible interval.andM;Association with a Descriptive DatabaseandM;Two classes of database can be associated with the image: those in which thedata refers directly to the contents of the frame itself, and those in whichthe data is a link to a higher level representation of the process associatedwith the images.andP;  In each case, the data may carry information that is eitherdifficult or impossible to derive on replay.andM;Sound is a prime example of the first class, and it is imperative that amoving picture encoding system contain at least the storage space or channelbandwidth to couple the sound to the picture and render both simultaneously.andO;Sound cannot generally be reconstructed from the image alone.andM;Matte and range information are two other more speculative candidates.andP;  Thefirst provides the information necessary for a system to alter the contentsof a frame without deriving the necessary information directly from the imageitself, as is the case with a chroma-key normally used in video production.andO;Image processing systems occasionally include a separate image plane, calledan alpha-plane in which matte information is directly represented.andP;  Such akey-plane need not necessarily contain the same tone scale quality as animage plane and is amenable to dense compression.andP;  We suggest incorporatingit directly into the coder design.andM;Range information can take the form of another image plane where the distanceof each point in the image from the camera is recorded.andP;  The investigation ofrange cameras that capture such information is an active area of researchboth for image production and machine vision.andP;  Inclusion of range informationpermits a variety of alterations to be performed in the images at the time ofviewing such as changing the apparent point of focus, simulating differentlighting, handling occlusion between objects inserted into the frame andallowing some variation of the point of view of the camera.andM;Look AheadandM;The fundamental notion of look ahead is that a system designed for retrievalof images in a publication system can process the entire input sequencebefore any output need be generated.andP;  The minimum delay in encoding a movie,therefore, is the length of the movie itself.andP;  By using look ahead, we canexploit higher order correlation in the image sequence itself and availourselves of a higher level model of the movie.andM;One generally assumes that proximate frames are more highly correlated thandistant ones and this is exploited in interframe codes.andP;  This is true on amicroscopic scale but a movie may have additional, higher-level correlationsas well.andP;  Typical movies have on the order of 1500 edits but only 150distinct scenes.andP;  Often smaller sequences are intercut to create a montage,and these are clearly cyclical in their similarity.andP;  This can be exploited toadvantage in a vector quantizer, as will be seen later, by reusing thecodetable from similar scenes and thus saving on table update bandwidth.andM;On a smaller scale, one can exploit temporal masking where an abrupt changein scene contents (e.g., an edit) masks the perception of detail both beforeand after the transition itself.andP;  This can be used when the placement of thescene changes is known in advance to allow the coder to delete edge detailinformation both before and after such transitions.andP;  Other data can besubstituted instead.andM;CODER DESIGNandM;The complete image coding system is presented in Figure 1.andP;  For the sake ofdiscussion, it is useful to introduce the notion of a frame group thatcomprises a pair of images.andP;  A frame group is analyzed into a set ofcomponents temporally and in two spatial dimensions by a set of separablequadrature mirror filters.andP;  The output of the lowest spatial and temporalfilter bank is further subdivided into high and low spatial frequencycomponents.andP;  The spectral decomposition is shown in Figure 2.andP;  Thedecomposition is carried out on the luminance portion of the signal;chrominance is coded separately.andM;The result of this is the representation of the input frame group as 13separate subimages, each of which is then coded.andP;  The analysis and subsequentresynthesis is a substantially lossless process as will be explained in thefollowing sections, and is performed to preprocess the image for the coder.andO;The ensemble of 13 subimages is encoded and decoded at one-half the framerate, since each ensemble is used to render two output frames (Figure 3).andM;Note that the chrominance information is represented at a lower spatial andtemporal rate than the luminance information.andP;  There is reasonable evidencethat the human visual system is relatively insensitive to simultaneously highspatial and temporal chrominance information, so this optimization isjustified for normal image viewing.andP;  If a still frame is desired, however,only every other frame will have correct chrominance information.andO;Chrominance information from frame 2n is used for frame 2n + 1.andM;In addition, since the frame group is essentially intra-frame coded, randomaccess and reverse replay is straightforward.andP;  When one frame is decoded, thetemporally adjacent one is also available.andP;  These can be reconstructed ineither order and all the information for either is available within eachframe group.andM;In later coding steps, each subband is compressed by the vector quantizerwith a different error rate, effectively a successively decreasing signal tonoise ratio (SNR).andP;  It has been shown that for a given appearance of qualityin a moving picture, the lowest spatiotemporal frequencies must berepresented at a high SNR, and successively higher frequencies may have alower SNR.andP;  This is accomplished automatically by the quantizer.andM;The subband decomposition may be done recursively on the image set presentedto the system, and higher frequency bands can be readily included.andP;  A movingpicture encoder that is comparable to television quality requires on theorder of 320 X 240 picture elements per frame, although somewhat higherresolution is desirable.andP;  The coder processes images at this resolution butcontains a pre-filter to separate image information in the band between 320elements and 640 across a line, and similarly for vertical detail.andP;  Thisadditional information may be stored separately or transmitted through ahigher bandwidth channel to allow higher quality reconstruction or imageenhancement in still modes.andP;  Current work addresses the additional bandwidthand SNR required for including the higher frequency bands within thebandwidth constraints of the CD-ROM.andM;Subband CodingandM;Subband coding for images has roots in work done in the 1950s by Bedford andon Mixed Highs image compression done by Kretzmer in 1954.andP;  Schreiber andBuckley explored general two channel coding of still pictures where the lowspatial frequency channel was coarsely sampled and finely quantized and thehigh spatial frequency channel was finely sampled and coarsely quantized.andO;More recently, Karlsson and Vetterli have extended this to multiple subbandsusing a decomposition similar to ours, and Adelson et al.andP;  have shown how arecursive subdivision called a pyramid decomposition can be used both forcompression and other useful image processing tasks.andP;  The essence of asubband coder is shown in Figure 4 for a one-dimensional signal.andP;  The signalis presented to a set of analysis filters with responses H.sub.l.(z) andH.sub.h.(z) where the subscript denotes the lowpass or highpass response.andO;After filtering, each signal is then decimated by a factor of two and thenencoded.andP;  The signals are then passed through a channel, decoded, upsampledand then passed through an interpolation filter, or synthesis bank withresponses F.sub.l.(z) and F.sub.h.(z).andM;The problem of bandsplitting and subsampling is illustrated in Figure 5.andO;While one would desire a pair of filters that precisely divide the originalband of the signal in half, this is not possible.andP;  Realizable filters H.sub.land H.sub.h either leave a hole in the spectrum or allow overlap that willresult in aliasing when each halfband is subsampled.andP;  A solution to thisproblem involves using a set of filters that allow aliasing (band overlap) tooccur, but where the aliased components cancel on reconstruction.andM;In particular, it has been shown that by choosing the lowpass filterH.sub.l.(z) to be a linear phase FIR halfband filter of length N - 1 thatmeets certain criteria and selecting the remaining filters according toH.sub.h.(z) = z.sup.-(N-1).H.sub.l.(-z.sup.-1.) F.sub.l.(z) =z.sup.-(N-1).H.sub.l.(Z.sup.-1.) F.sub.h.(z) =z.sup.-(N-1).H.sub.h.(z.sup.-1.) perfect reconstruction is possible iffidelity in each subband is preserved through later coding or communication.andM;The design rules for useful subband filters is an active research topic.andO;Some workers have designed filters where the analysis and synthesis filtersare symmetric, time or space inverses and some work has addressed asymmetricanalysis/synthesis pairs where the synthesis filters require only shifts andaddition to implement.andP;  Useful filters should be limited in both spatialextent and frequency response so that they provide good band separation andare efficient for hardware realization in a coder, and also so that theyintroduce minimal aliasing artifacts when each subband is not perfectlyrepresented.andP;  In addition, a desirable characteristic of the filters is thatthey isolate local image features.andP;  This permits them to present to thesubsequent coder a series of image characteristics rather than arbitrarytransform values.andM;The effect of the subdivision of frame pairs is to divide the input sequenceinto separate subframes that segregate energy related to the following imagefeatures:andM;* Low frequency, broad areas, both stationary and movingandM;* Vertical detail, both stationary movingandM;* Horizontal detail, both stationary and movingandM;* Diagonal detail, both stationary and movingandM;In the coder used here, the low frequency static sub-image is furtherdecomposed into four subframes that contain the mid-band edge detail and onevery low spatial frequency subimage.andP;  If one desired to browse the image set,this low frequency, postage-stamp version of the original may be vieweddirectly.andM;Vector QuantizationandM;A vector quantizer (VQ) operates by forming an N-dimensional vector x.sub.1 =[x.sub.1.x.sub.2....x.sub.N.].sup.T from a block or group of samples of theinput data and quantizing this vector to form a new vector y taken from alimited set of N representative vectors Y = [Y.sub.1., 1 [is less than or =]i [is less than or =] M] (see).andP;  The quantizer achieves compression byreplacing the input block with a channel symbol i and storing the mappingbetween channel symbols and representative vectors at the decoder.andP;  If thereare B = log.sub.2.M bits per vector, there are R = M/N bits per point.andM;The quantization rule is q(x) = y.sub.i., if x E C.sub.1 where C.sub.1 is oneof M cells each containing a representative vector y.sub.i..andP;  The pointy.sub.i is chosen to be the centroid of the cell (Figure 6).andM;Vector quantization is useful if the data to be quantized is statisticallycorrelated but linearly independent.andP;  In this case, the probability densityfunction of the multidimensional space is not generally separable and onecannot independently remove the correlation between the samples.andM;For example, color images have been effective compressed using VQ by formingthe vector from the red, green, and blue separations of the original.andP;  Inthis case, the three-dimensional space formed by the vector x = [r, 8,b].sup.T has strong statistical correlation but clearly each component is notlinearly dependent on the other.andM;The red, blue, and green separation images that comprise the color pictureare evidently related--they clearly look like they are parts of the sameimage.andP;  Thus they are correlated but linearly independent--no primary imageis a linear combination of the same picture elements in the otther two.andP;  Ineach single separation, there may be a seemingly uniform distribution ofintensities, but in the image as a whole, hgih brightness values for oneprimary may occur only when there is simultaneously high brightness foranother.andP;  Thus, their joint probability density function shows correlation,but the individual distributions of each primary is uniform.andP;  The vectorquantizer exploits this by quantizing the three-dimensional space created bythe three primaries taken together.andP;  Regions of this space with high densityare quantized more finely.andM;The key issues in the design of a vector quantizer are the manner in whichthe space is partitioned to form the representative vectors, and the methodof searching the space to select the quantization codeword.andP;  The problem isthat of finding the nearest neighbor in N-dimensional space.andP;  There are anumber of techniques used to do this; a promising one is the use of a k-Dtree to both create the space and to index into it for encoding.andP;  The k-Dtree algorithm successively subdivides along each dimension using a rule thatattempts to minimize the error at each succeeding step in the subdivision.andO;For example, one can divide the N-dimensional space with a hyperplane ofdimension N - 1 so that equal samples of the space lie on either side of thesubdivision and so that the division itself is along the mean of the samples.andO;When this is done, the mean squared error will be minimized.andP;  Generally, thesubdivision process is halted either when some error criterion is met or whenthe number of divisions reaches some maximum determined by the channelcapacity.andP;  Heckbert developed a novel subdivision algorithm where the largestcell is selected for subdivision.andP;  When used for color quantization, thisinsures that the peak error is minimized at the expense of average error.andP;  Inimage coding, this is often useful, since mean squared error is not generallya good measure of picture quality.andM;Encoding is performed by traversing the tree with a succession ofone-dimensional comparisons and occurs in log N time.andP;  The centroids areencoded as a number that is the index of that codeword; decoding involveslooking up the codeword i in a table and replacing it with the vectory.sub.1..sup.4andM;In some applications, a single codetable may be used for all data to beencoded.andP;  For example, in speech, the vector is formed from a set of samplesof the speech signal itself or of its transform.andP;  The statistics of speech donot vary over time, so a training set of several words is used to create thecodetable and it can be used for almost all possible speech sequences.andP;  Thestatistics of images are not stationary, however, so most generally, anadaptive quantizer is used where the codetable is updated periodically whenan error threshold is crossed.andM;The subband coder combined with VQ is a hybrid coder.andP;  Only the highfrequency, or edge information is encoded with the vector quantizer, and itmay be argued that the statistics of edges in images are close to stationary.andO;It is the broad areas and low frequency components of images thatdistinguishes them.andP;  The codetable created for a subband decomposition of theimage sequence therefore need be updated only occasionally.andP;  A less strongstatement is that when the images are taken from a motion picture sequence,succeeding images are very much alike and may therefore use the samequantization table.andP;  In experiments to date, there is negligible SNRdegradation in the decoded image when the same codetable is used for 24images (one second of film time) when that period does not span an edit.andM;In addition, there are several other optimizations that may be made to thequantizer that exploit redundancy between subbands and the psychophysics ofthe viewer.andP;  These are:andM;Rotationally Symmetric Codebooks.andP;  The first optimization is the rotationallysymmetric codebook.andP;  To form this, we exploit the fact that images aregenerally isotropic.andP;   There is no preferred direction for detail in theimages and the subbands corresponding to vertical and horizontal detail arethus similar but rotated 90 degrees from each other.andP;  Therefore, thequantizer uses the same table for each of these subimages and performs therotation on reconstruction.andM;Multi-Scale Quantization.andP;  There is correlation between the successivefrequency bands into which the image has been decomposed that has not beenremoved by the block coding itself.andP;  This correlation has been exploited inimage coding applications by, for example, Wester-ink where a still image waslinearly filtered into 16 subbands each occupying 1/16 of the spectrum of thetotal image, and a vector was formed by taking the same point in each of thesubbands.andP;  This approach exploits correlation between bands but not withinthe image itself; the fact that it achieves any compression is a result ofthe inter-band statistical relationship.andM;With an octave subdivision, this is somewhat harder to do since thesub-images are each of a different size.andP;  We do this as follows:andM;The smallest image is used as the training set for a p X p block quantizer,and a codebook of N.sub.i codewords is formed, each representing a vector ofdimension p.sup.2.andP;  This is the master codetable for the image set.andM;The next higher region in frequency is then quantized using a blocksize of 2pX 2p, also with i codewords.andP;  The raw table for this level thus containsvectors of dimension 4p.sup2..andP;  Each entry in this table is subdivided intofour, p X p sub-vectors, and this sub-vector is replaced by the nearest entryfrom the table used in the lower level.andP;  On reconstruction, a level ofindirection is required, since the numbers obtained from the initial tablelookup are not representative vectors but are addresses of the vectors fromthe table used for the lower level (see Figure 7).andM;This optimization is based on the principle that detail in the imagegenerally results in correlated energy replicated throughout the imagebandwith.andP;  Thus, if there is an edge at a particular point in the image, itwill result in similar components at frequency f and at 2f, 3f,....andM;Look Ahead Table Update.andP;  As mentioned before, the frames immediatelysurrounding an abrupt change in scene content may be rendered at reducedresolution with no apparent loss of quality.andP;  We exploit this by deleting thehigher order spatial spectral components from these frames and use thechannel space thus provided to contain the table update information to beused to decode the succeeding frames.andM;When the image ensemble consists of a simple series of unrelated scenes, thisdeletion is equivalent to prevending the table to the scene in place of thedetail information in the first few frames.andP;  If, however, the scenes arecyclically related, then a set of tables can be stored in the decoder andrecalled by address.andP;  It is reasonable to subdivide the table further andreplace only part of it, forming a megatable that is analogous to adictionary of tables that are assembled into a table for each scene at thetime of decoding.andP;  The creation of these table-sets is an area of currentresearch.andM;INTERSECTION OF CODING WITHandM;APPLICATIONSandM;The essence of any image coding algorithm is in its utility to match therepresentation of the images with the potential applications to which theimages may be put.andP;  The random access nature of the applications mitigates infavor of an interframe coder where each frame is represented independently ofevery other frame.andP;  This precludes predictive coders that assume high degreesof similarity between successive frames and sequenial replay.andP;  In the subbandcoder, frame pairs are processed, allowing some interframe redundancy to beexploited as well as permitting bandwith to be allocated to moving scense inspatiotemporal regions of maximal observer sensitivity.andP;  The decoderautomatically produces a pair  of frames and either may be displayed byselecting appropriate entries from the vector quantization tables.andM;Look ahead coding exploits higher level analysis of the image sequence, withproportionately higher quality rendition, but potentially sacrifices somequality for randomly accessed images: any particular frame may be renderedwith a suboptimal table (until the correct one can be retrieved andsubstituted).andP;  This is a reasonable solution to the problem of jointlydisplaying high quality still information and efficiently representing motionsequences.andM;Asymmetry is inherent in the coding algorithm both by virtue of the fact thatthe search process in the vector quantizer is computationally more intensivethan the table lookup required for decoding and because the tables themselvesare transmitted both before and after scene transitions.andP;  Advance knowledgeof the transition is required for this to ahve effect.andP;  Later evolutions ofthis coding system will locally store a selection of tables so that higherorder correlations between scenes such as might be found in the intercuttingof a normal movie can be exploited.andM;The ability to present a random still image at higher resolution than thesame image would be presented as part of a motion sequence is consideredimportant for workstation applications and can be useful for zooming into astill or moving image.andP;  Most workstation displays operate at higher scanningdensities than television, and an interactive application may well requirethat the net effect of the image presentation is that it appear at lest asclearly as any computer generated text of graphics that the workstation wouldotherwise present.andP;  For this reason, we endorse the subband representation ofthe image so that successively higher resolution (both spatially andtemporally) can be stored nearby on the medium and accessed when a highquality still is desired.andP;  This complicates the encoding process, since theimages must therefore be scanned at higher resolution than might ultimatelybe used and some decision must be made at the time the data is initiallyprepared for storage about which extra bands should be kept and which shouldbe discarded in favor of space for additional length of the moving sequence.andM;Interaction with other databases is also likely to become a prerequisite forimage encoding algorithms as moving image sequences become more common innormal computer applications.andP;  In the encoding system described earlier, itis reasonable and possible to identify an entity within a given scene byadding a pointer to the codeword used at any level in the decomposition.andO;This allows object identification without allocating a separate image planeto contain identification information; it may be efficiently embedded in thecoding itself.andM;The problem of coding image sequences for interactive retrieval is made moreinteresting by the fact that it is difficult to know in advance the uses towhich those images will be put.andP;  Unlike videotelephony, where the image isdefined to be a visual accompaniment to a voice telephone conversation thuslimiting the problem scope, here we cannot make an a priori determination ofthe manner in which the images may be used.andP;  We have thus attempted toprovide the most flexibility in the design of the coder itself without toogreat a sacrifice in image quality.andP;  We can assert that at coding rates ofabout 1 megabit/second, quality equivalnet to home television recordingequipment is reasonable without any severe restrictions on image content orsequence; the key problem is weighing the relative importance of each of themore nebulous interactive features that may or may not be necessary in futureapplications.andM;Finally, one note about the problem of interaction with moving images needsto be made.andP;  The lack of a ready technology for interacting with a movingimage sequence and the lack of a language for describing whatever interactionone can engage in have historically impeded the growth of interactive video.andO;While the work described here makes no direct impact on the second of theseproblems, we have made some progress in defining the degrees of freedom thatsuch a motion-picture interaction language might have.andP;  We have provided thecapability (and indeed optimized for) interaction within the frame.andP;  Theinclusion of the key-plane data and the linkages to a higher level database,while not directly part of the encoding, but assumed in the definition, allowsome flexibility in altering the sequence and contents of a visualinteraction.andP;  We believe that we can make some attempts to include thesefeatures in some tests of systems interfaces to determine both the utility ofthis and some way of defining the manner in which it can be simply used.andO;</TEXT></DOC>