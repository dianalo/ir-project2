<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-276-654  </DOCNO><DOCID>08 276 654.andM;</DOCID><JOURNAL>IBM Systems Journal  March 1990 v29 n1 p4(29)* Full Text COPYRIGHT International Business Machines Corp. 1990.andM;</JOURNAL><TITLE>Experiences with defect prevention. (technical)</TITLE><AUTHOR>Mays, R.G.; Jones, C.L.; Holloway, G.J.; Studinski, D.P.andM;</AUTHOR><SUMMARY>Defect Prevention is the process of improving quality andproductivity by preventing the injection of defects into aproduct.andP;  It consists of four elements integrated into thedevelopment process: (1) causal analysis meetings to identify theroot cause of defects and suggest preventive actions; (2) anaction team to implement the preventive actions; (3) kickoffmeetings to increase awareness of quality issues specific to eachdevelopment stage; and (4) data collection and tracking ofassociated data.andP;  The Defect Prevention Process has beensuccessfully implemented in a variety of organizations within IBM,some for more than six years.andP;  This paper discusses the stepsneeded to implement this process and the results that may beobtained.andP;  Data on quality, process costs, benefits, and practicalexperiences are also presented.andP;  Insights into the nature ofprogramming errors and the application of this process to avariety of working environments are discussed.andP;  (Reprinted bypermission of the publisher.)andM;</SUMMARY><DESCRIPT>Company:   International Business Machines Corp. (management).andO;Ticker:    IBM.andO;Topic:     ProductivityIncreaseMethodsDefectsFault ToleranceErrorsProcess Control.andO;Feature:   illustrationchart.andO;Caption:   Causal analysis meeting. (chart)Action team. (chart)Stage kickoff meeting. (chart)andM;</DESCRIPT><TEXT>Experiences with Defect Prevention Defect Prevention is the process ofimproving quality and productivity by preventing the injection of defectsinto a product.andP;  It consists of four elements integrated into the developmentprocess: (1) causal analysis meetings to identify the root cause of defectsand suggest preventive actionsandgt; (2) an action team to implement thepreventive actionsandgt; (3) kickoff meetings to increase awareness of qualityissues specific to each development stageandgt; and (4) data collection andtracking of associated data.andP;  The Defect Prevention Process has beensuccessfully implemented in a variety of organizations within IBM, some formore than six years.andP;  This paper discusses the steps needed to implement thisprocess and the results that may be obtained.andP;  Data on quality, processcosts, benefits, and practical experiences are also presented.andP;  Insights intothe nature of programming errors and the application of this process to avariety of working environments are discussed.andM;To achieve quality software products, most development processes rely ondefect detection and correction through inspections, walkthroughs, andreviews early in the development cycle, and through extensive testing.andO;However, reliance on detecting defects after they have been injected iscostly.andP;  The detection and correction of defects does not add function to theend product.andP;  Inspections and testing are also limited in effectiveness.andM;A much more effective approach involves preventing defects from beinginjected during development.andP;  Fewer defects during development permits moreresources to be devoted to developing new product function, and higherproduct quality in the field means greater customer satisfaction.andM;Whereas prevention is simple in concept, it was n ot clear at the beginningof our work on the Defect Prevention Process that software defects could beprevented.andP;  However, our experience with this process has shown that not onlyare defects preventable, but significant reductions in errors can be achievedwith a modest investment.andP;  Software defects have identifiable causes, such asan oversight or communications failure, and are preventable through improvedprocesses, methodologies, techniques, and tools.andP;  A dramatic improvement inquality can be achieved through defect prevention and with it a correspondingimprovement in overall productivity and customer satisfaction.andM;The Defect Prevention Process [1,2] uses causal analysis, which is thedetermination of the specific cause or causes of a defect.andP;  Causal analysisis usually described in the quality control literature in terms ofquality-circle activities and usually in the context of a manufacturingoperation.andP;  [3-5]  The causes of manufacturing defects are analyzed usingcause-effect diagrams (also called Ishikawa or &quot;fishbone&quot; diagrams) andPareto charts.andP;  Crosby, [6] for example, describes a case history involvingthe use of causal analysis to prevent defects on a manufacturing line.andM;Causal analysis of software defects is practiced in a number of Japanesecompanies, usually in the context of quality-circle activities.andP;  Hino [7]describes the analysis of 52 software defects by a quality circle over an11-month period, resulting in an estimated 100 defects prevented.andP;  The circlemembers estimated that as many as 90 percent of their software defects couldbe prevented through improved design techniques and other preventivemechanisms.andP;  Similarly, Sugaya [8] reports that circle members are motivatedto look into the root causes of defects and propose action plans to preventthem in the next release.andM;Nakajo, Sasabuchi, and Akiyama [9] describe a joint effort between YokogawaHewlett-Packard (YHP) and Tokyo University that analyzed 523 defects fromthree software projects at YHP.andP;  The defects were analyzed in retail todetermine both the human error causing the defect and the underlying flaws inthe development process that affected the rate of human errors.andP;  The defectsare analyzed in terms of a fault classification scheme, and the human errorswere determined from various documents and through interviews with thedevelopers.andP;  From this information the underlying process flaws associatedwith the errors were identified and a number of improvements to the designprocess were proposed.andM;Within IBM, causal analysis has been used in the Systems Integration Division(formerly the Federal Systems Division) on the Space Shuttle Primary AvionicsSoftware System, the on-board computer software that controls the Shuttle.andO;[10,11]  Defects are analyzed to determine the cause of the error, how toprevent the error, and how to remove similar defects that may exist in thesystem.andP;  The primary focus of the causal analysis has been on escapes fromtest and inspections, and how to improve the effectiveness of both tests andinspections.andM;The primary difference between these approaches to causal analysis andprevention and the Defect Prevention Process described in this paper is theintegration of the defect prevention activities into the development process.andO;With Defect Prevention, causal analysis is done by the development teamduring the development cycle, as each stage of development is completed,rather than by a quality circle at some later time during development.andO;Direct causal analysis by the developer making the error results in a moreaccurate determination of the cause of the defect and more relevantpreventive actions.andP;  In contrast to a quality circle, the preventive actionsare implemented by an action team with specific skills and authority tochange the development process.andP;  In addition, systematic feedback to thedevelopers is provided by stage kickoff meetings and the status of plannedpreventive actions is tracked in a database.andM;The Defect Prevention Process discussed in this paper was initially developedin the IBM Communications Programming Laboratory at Research Triangle Park,North Carolina, where the development of such communications products as theVirtual Telecommunications Access Method (VTAM), the Network Control Program(NCP), and NetView [TM] is done.andP;  To date, Defect Prevention has beenimplemented in more than twenty-five organizations at seven IBM developmentlaboratories, involving system programming, application programming, andmicrocode development.andP;  The process has been adopted as part ofcorporate-level Programming Process Architecture.andP;  [12]  It is also taught intwo internal courses offered by IBM Corporate Technical Education.andP;  Thesecourses have now been presented at practically every major softwaredevelopment laboratory within the company.andM;In this paper, we summarize the Defect Prevention Process and discuss ourexperiences with it, including observed quality improvements, costs andbenefits of the process, and observations on the nature of programming errorsand preventive actions.andP;  As Defect Prevention has been implemented indifferent organizations and in different laboratories, it has been adapted,adjusted, and enhanced.andP;  Several adaptations and enhancements were made atthe Myers Corners Laboratory in Poughkeepsie, [13] for example.andP;  This paperdescribes the Defect Prevention Process in a generalized form.andM;Throughout the paper we use the terms defect and error interchangeably.andP;  Adefect is also referred to in the literature as a program fault, and refersto a flaw or problem within the software.andP;  An error refers to the underlyingcause of the defect.andP;  The term &quot;error&quot; implies a mistake that the developerhas made.andP;  In our experience, the cause of most defects can be traced tohuman error.andM;The Defect Prevention ProcessandM;In the Defect Prevention Process, the various activities of Defect Preventionare integrated into the development process.andP;  Causal analysis meetings andstage kickoff meetings become part of each developer's day-to-day activities,much like inspections and reviews.andM;In this section we describe the application of Defect Prevention in asoftware development organization, involving causal analysis, the actionteam, and stage kickoff meetings.andP;  The application of the process in a testorganization, in information development, and in other areas is described atthe end of the section.andM;Causal analysis meetings.andP;  The software development process is divided into anumber of design, development, and test stages, such as requirements andplanning, product-level design, component-level design, and code and unittest.andP;  [12]  Programmers generally work together in teams to develop aportion of the product release.andP;  At the end of each stage, an inspection,review, or other validation is conducted in which defects are detected.andM;Once the defects from a stage have been corrected, a meeting that we term acausal analysis meeting, usually two hours in length, is held.andP;  The processis illustrated in Figure 1.andP;  The development team members review the defects,determine the root cause of the programmer errors, and propose actions tohelp prevent such errors in the future.andM;For each defect, the following questions are posed:andM;* What is the category of cause of the error--communication, oversight,education, or transcription?andM;* How was the error introduced or caused?andM;* At what stage was the error created or injected?andM;* How can we prevent this error in the future?andP;  How can similar defects bedetected and removed from other parts of the product?andM;The causal analysis meeting is led by a person from product development whohas been trained as a causal analysis leader.andP;  A chalkboard is used that isdivided into columns for the defect number, defect abstract, cause category,cause abstract, process stage where the defect was created, and suggestedpreventive actions.andP;  A paper form is also used to record the informationwritten on the board.andM;The emphasis of the meeting is on gathering preventive suggestions.andP;  Theleader keeps the meeting moving and not bogged down in details about a defector cause, unless these details lead to better suggested actions.andP;  If someinformation is unknown (foe example, the defect's cause), the leader may skipthat column.andP;  The leader may even decide to skip an entire defect if it doesnot appear that any meaningful actions will result.andP;  Of course, some defectswill produce no suggested actions.andM;During the last half-hour of the meeting, the causal analysis leader directsthe team to take a broader view of the defects and of the stage that the teamjust completed.andP;  The following are typical questions that can be asked atthis point:andM;* Is there a trend in the errors that indicates a broader problem?andP;  Are thereadditional suggestions to address such a trend?andM;* What went right during this last development stage?andP;  What saved time?andP;  Cansuggestions be made to help other teams?andM;* What went wrong during the latter stage?andP;  What wasted time?andP;  Can anysuggestions be made to prevent or avoid these problems?andM;* How can we improve our defect-detection methods, tools, communications,education, etc.?andM;Often this discussion portion of the meeting produces the most importantsuggestions.andP;  After the meeting, the causal analysis leader records the datafrom the meeting (suggested actions, defects, and causes) in an actiondatabase for subsequent reporting and tracking.andM;The team leader may call a causal analysis meeting before the developmentstage is over, when enough errors have been collected for a meeting, usuallyaround twenty.andP;  Repeated causal analysis meetings may be held, especiallyduring the test stages.andP;  Such interim causal analysis meetings allowimmediate feedback to the team to help them prevent additional errors, as thestage progresses.andM;The involvement of the developers who originated the errors is critical,because the developer who created the error is the best person to identifyits cause.andP;  Also, both the developer and the other team members receivedirect feedback about the errors made.andP;  This direct feedback has asignificant effect in preventing similar errors by that team in the future.andM;It is also important to have everyone in the team present for causal analysisbecause a synergism of ideas results from the group as a whole.andP;  It istypical that preventive suggestions come from team members other than theperson who made the error.andP;  Some portion of everyone's defects should beanalyzed.andP;  If someone had no defects during a particular stage, that personwill likely be able to contribue significant ideas toward preventing futureerrors.andP;  That developer's ideas naturally have the respect of the other teammembers.andM;The action team.andP;  A critical element of the process is the action team whosepurpose is to ensure that preventive actions are implemented.andP;  The actionteam is illustrated in Figure 2 and consists of people from the area who workpart-time as action team members.andM;The action team typically serves an entire product development organization.andO;Depending on the size of the organization, the team may be smaller or larger.andO;For example, the action team for a small development organization of 20 to 50people might have three or four members, whereas the action team for anorganization of 200 to 250 people might have eight to ten members.andP;  The scopeof the action team should encompass the entire development organization orthat portion of a large organization that shares the same developmentprocess.andP;  For a product development area, a systems test organization, and aninformation development organization, three separate action teams wouldprobably be required.andP;  In a very large product area, several action teamsmight be formed to serve the different second-line development organizations.andO;[13]andM;The action team members each serve in a role on the team.andP;  One member mighthave responsibility for process definition and documentation, another fortool requirements and implementation, another for education.andP;  Othersrepresent design, development, and test.andP;  A manager also serves on the actionteam to handle actions that require communication with other managers in theorganization or negotiations with other organizations.andP;  Each team member isresponsible for ensuring that the actions assigned to him or her areimplemented, either by doing the work directly or by reassigning to itsomeone else in the organization.andM;The action team meets regularly to review the new actions that have beenproposed, to decide which ones are to be implemented and how to implementthem, to assign the new actions, and to discuss the status of actions thatare currently open.andP;  Closed actions are also reviewed to ensure that the workhas been properly completed.andM;An action team for a large product area (150 to 200 persons) may handleseveral hundred actions each year.andP;  An action database and the supportingdata-collection tool are essential to keep tract of the open actions.andP;  Theaction team uses reports from the action database to guide their meetings.andO;Listings of the new actions and open actions are printed our prior to eachmeeting.andP;  Changes in action status, including the new action assignments, areentered after the meeting.andM;Preventive actions fall into several categories:andM;Process improvements, refinements, or documentation are actions that improveexisting processes, define new processes, or improve process documentation.andO;Such actions might modify the design change process, define a new test-errorfix process, or add new items to a common error list or checklist.andM;Tools are actions that develop new tools or enhance existing tools thatsupport the process.andP;  This might include writing a tool to trace save areautilization or adding a new check to the module checker tool.andM;Education actions improve knowledge about product and nonproduct-relatedtechnical areas.andP;  Education might include such things as developing a classin hardware subtleties, organizing a seminar series on the components of theproduct, preparing a technical write-up on a complex aspect of the product,and writing a newsletter article on repetitive errors.andM;Product changes are actions to improve the product so that developing andenhancing it are less error prone.andP;  This might include improvingdocumentation of product macros, implementing a design change to improve aninternal interface, and rewriting an error-prone part of the product.andM;Communications improvements are actions that improve communicationsprocedures within the product organization or with other organizations.andP;  Herewe think of implementing the automated notification of design changes to allinterested parties, appointing a liaison or focal point to handlecommunication with another organization, and holding weekly team technicalmeetings.andM;Many actions requires saving documentation and information for on-line accessby people in the product organization.andP;  These materials are placed inrepositories, that is, on-line files that can be assessed by everyone in thearea.andP;  These materials might include the documentation of the area's process,procedures, and methodologies, product technical writeups and documentation,common error lists, inspection checklists, coding guidelines, performanceguidelines, a checklist for new-hire education, project managementguidelines, and tools documentation.andP;  Usually there is so much informationthat an index is also required.andM;Not all suggested actions are implented.andP;  The action team may decide that anidea is not cost justifiedandgt; it may be deemed impractical or simply a badidea.andP;  A suggestion might fall outside the scope of the team.andP;  Also, anaction may already have been implemented or may duplicate a suggestionalready received.andP;  When an action is rejected, the rationale for rejection isdocumented and the suggester is notified.andP;  However, the suggester may requestthe action team to reconsider a rejected action.andM;The action team is involved in a number of activities in addition to actualimplementation of actions.andP;  Usually a preliminary investigation of the actionmust be done so that all of the relevant aspects of the action areunderstood.andP;  The action team member will typically assign a priority to theaction so that it is clear which actions of those assigned should beaddressed first.andM;Sometimes an action team member does not have the knowledge to implement anaction.andP;  The member then asks an appropriate person in the organization toimplement the action.andP;  A negotiation with the person's manager may berequired to allocate time for implementation.andP;  The action team membercontinues to have responsibility to see that the action is implemented andfollows up with the implementer until the item is closed.andM;The action team is also involved in feedback to the organization.andP;  Productdevelopers must understand that their suggestion are taken seriously and thatthey are implemented.andP;  An action is not considered finished until there issome form of feedback to the product area about its completion.andP;  Feedback oncompleted actions may be done, for example, through newsletter articles,on-line news bulletins, or at area meetings.andP;  In some product areas, informalawards are presented at periodic area meetings to people who have madesignificant contributions to defect prevention, either in terms of effectivesuggestions or implementation of actions.andM;The action team also reports on the status of its activities to management.andO;These reports may include such items as statistics on defect distribution bycause, action distribution by action category, cost of the process in termsof causal analysis meetings, kickoff meetings, action team meetings andaction implementation, and total projected cost of actions left to beimplemented.andP;  This kind of information may also be presented at areameetings.andM;Stage kickoff meetings.andP;  Stage kickoff meetings are used at the beginning ofeach development stage to prepare the development team for the work of thestage.andP;  The place of the stage kickoff meeting as the primary means offeedback for the Defect Prevention Process is shown in Figure 3.andP;  Theinformation presented during the kickoff is updated by the action team asactions are implemented.andM;Kickoff meetings typically take one to two hours and are led by the technicalteam leader, who is sometimes called the chief programmer.andP;  The emphasis inthe meeting is on technical aspects of the development process and onquality.andP;  Information presented during the meeting includes:andM;* A description of the process for this stage, including specific procedures,methodologies, techniques, tools, guidelines, conventions, checklists, etc.andM;* The inputs available for this stageandM;* Examples of outputs that should be producedandM;* Validation methods that will be used (e.g., inspections, reviews)andM;* The common error list, a list of the errors commonly created during thisstage.andM;* The team assignmentsandM;* The schedule that will be followedandM;The process description, procedures, and methodologies for the stage arereviewed.andP;  Portions of the process document may even be read, word for word.andO;This serves to educate the team, if they have never read the process, or tore-educate the team periodically and to point out recent revisions to theprocess.andP;  The process is thus repeatedly reinforced in the team.andM;Because of the constant improvements through causal analysis and the reviewand discussion during kickoffs, the process document is an active document,representing the actual process used by the organization.andM;The inputs to the stage (e.g., the design document) are reviewed so thatconcerns may be raised about their completeness, for example.andP;  Samples ofoutputs of the stage may also be presented so that the team understands thekinds of outputs required for that stage.andP;  For example, the team might reviewwhat the appropriate level of detail is for the design stage.andM;Reviewing the common error list for the stage is important for preventingerrors.andP;  The list contains brief descriptions--sometimes with examples--oferrors that have been identified during causal analysis as chronic andrepeating.andP;  (See Appendix A for a sample common error list.)andP;  A review of thelist serves as a reminder to the developers and reduces the probability ofmaking these errors.andM;Some development projects are not organized into specific teams, for example,when developers work individually on separate parts of the product.andP;  In suchcases, developers whose development schedules reasonably coincide can beformed into ad hoc teams which then conduct stage kickoff meetings,inspections, and causal analysis together.andP;  Other developers, for example,who develop fixes for field errors do not follow distinct development stages,and a stage kickoff meeting is not relevant.andP;  Such developers shouldparticipate in periodic process reviews, occurring perhaps every three orfour months, instead of stage kickoffs to reinforce their knowledge of theprocess, procedures, and common errors, and to learn of recent processrevisions.andM;Additional aspects of the process.andP;  Field errors or Authorized ProgramAnalysis Reports (APARs) are reported continuously and thus do not fit adevelopment stage.andP;  Special APAR causal analysis meetings are held by thedepartment with responsibility for the component where the APAR defectoccurred, as shown in Figure 4.andP;  The causal analysis meetings are heldwhenever tento twenty APARs have been received.andM;During causal analysis, the cause of the APAR may not be accuratelydetermined for a variety of reasons.andP;  Nevertheless, good preventivesuggestions can still be made.andP;  Developers doing APAR causal analysis cansometimes become bogged down in trying to understand the details of aproblem.andP;  Provided the team remembers not to spend excessive time on eachAPAR problem, APAR causal analysis proceeds like other causal analysismeetings.andM;In organizations that have followed the Defect Prevention Process, developersbegin to make miscellaneous suggestions for improvements outside a causalanalysis meeting.andP;  Developers typically suggest new tools or toolenhancements, and these suggestions are handled by the action team along withthe suggestions from causal analysis.andM;The Defect Prevention Process involves everyone in the developmentorganization over time, as shown in Figure 5.andP;  Developers allow the cycle ofstage kickoff (KO) meeting, work, inspection or review, and causal analysis(CA) meeting for each stage of product development.andP;  The action team (AT)meets usually every two weeks to assign the new suggestions and to report tothe rest of the team on the progress of actions being worked on.andM;If the action team can implement its actions quickly, later teams in adevelopment project will benefit from earlier teams' experiences.andP;  Alterdevelopment team in its kickoff meeting will be able to review processimprovements and common errors that earlier teams suggested in their causalanalysis.andP;  Consider Team 3 in Figure 5.andP;  That team can learn information intheir code kickoff that resulted from suggestions from Team 1's code causalanalysis.andM;The key elements of Defect Prevention.andP;  There are four key elements in theDefect Prevention Process: (1) systematic causal analysis, (2) amanagement-supported action team, (3) stage kickoff meetings, and (4) adatabase and tools for data collection and tracking of actions.andP;  A DefectPrevention plan that omits one or more of these elements will likely beineffective.andP;  Several similar processes--release post-mortems, informalcausal analysis, and quality circles--use some of the elements of defectprevention but are not, in our view, as effective in preventing errors as theprocess described in this paper.andM;A release postmortem is an analysis of the development experiences of therelease of a product, usually compiled at the end of the release.andO;Frequently, a general causal analysis is done, answering questions such as&quot;What difficulties did we encounter during the release?andP;  How can we avoidthem in subsequent development projects?andP;  What activities improved ourprocess?andP;  How can we make them permanent?&quot;andP;  There are several differencesbetween postmortems and the Defect Prevention Process.andP;  Postmortems aretypically done after the release has been completed, with the result that anysuggestions for improvement are delayed at least until the next developmentproject.andP;  The causal analysis in a postmortem does not analyze specificdefects but is more general.andP;  Suggestions for improvements that addressspecific types of errors are frequently overlooked.andP;  Recommendations forimprovement are frequently lost in the subsequent activity of the nextproject or in reorganization that may follow the completion of the project.andO;Usually no formal mechanism exists to ensure that recommendations areimplemented.andM;The causal analysis meetings described in this paper are in effectminipostmortems performed by each team at the end of each development stage.andO;They focus on a sampling of specific errors and their causes.andP;  With the useof an action team and a database of suggested actions inthe Defect PreventionProcess, the shortcomings of the postmortem process are overcome.andM;Informal causal analysis is sometimes done by a developer to gain insightinto the causes of errors and to suggest preventive actions.andP;  The results ofthis sort of work can be very beneficial.andP;  However, this approach has severaldifficulties.andP;  Frequently the analysis is done long after the defects havebeen created (typically after all tests have completed) so that improvementsare delayed.andP;  The defec causal analysis is done by someone other than thedevelopers who created the defects, with the result that the analyst mustguess the cause of the defect.andP;  As with postmortems, there is usually noformal mechanism to ensure that the recommendations have been implemented.andO;The developer doing the causal analysis may be shifted to &quot;more productive&quot;work, effectively ending the opportunity to improve the process.andM;A quality circle or quality improvement team [3-5,14] is a group ofdevelopers, usually members of the same department, who meet regularly todiscuss problems and ways of overcoming them.andP;  Quality circles frequentlyundertake to implement improvements in their work practices, tools, andprocess.andP;  As part of their activities a quality circle may do causal analysisand implement the suggestions.andP;  As with postmortems andinformal causalanalysis, any activity that eliminates the underlying causes of errors isbeneficial.andP;  However, quality circles frequently have shortcomings thatinhibit their effectiveness.andM;Quality circles usually do not do causal analysis of specific defects butrather pursue problems that are perceived by the circle to be the mostimportant.andP;  This practice tends to ignore the many defects that are createdregularly, while ultimately leading ironically to the perception that thecircle has run out of things to work on.andP;  A quality circle is frequentlylimited to changing what its members are able to change.andP;  Thus a majorprocess change affecting the entire development organization or a large tooldevelopment project would probably not be undertaken.andP;  The implementation ofimprovements is usually done on the members' own time.andP;  Management &quot;funding&quot;for quality-circle improvement activities is usually inconsistent and mayevaporate over time.andM;Despite these shortcomings, quality circles can be used very effectively tocomplement the Defect Prevention Process.andP;  A quality circle can, for example,take on the task of doing periodic APAR causal analysis.andP;  In addition, theaction team may request a quality circle to implement a specific action, suchas writing a summary of a technical topic.andP;  In any case, quality circlesshould be encouraged wherever they continue to be effective.andM;Defect Prevention in test and other organizations.andP;  Thus far we havedescribed the operation of the Defect Prevention Process for a softwaredevelopment organization.andP;  Defect Prevention has also been effective in testand other organizations.andP;  Each different organization uses differentprocesses and creates different kinds of errors.andP;  Defect Prevention can beapplied to the errors arising from each particular process.andM;The test process usually has three major steps that are taken for each test:test planning, which defines the people, hardware and tool requirements, andthe schedules for the testandgt; test preparation, which develops and documentsthe detaile dtest cases (also called test scenarios)andgt; and test execution,which involves the actual execution of the test cases and correction of theproblems found.andP;  When Defect Prevention is applied to test, the basic fourelements of the process are followed.andP;  The major types of errors that areanalyzed in test are:andM;* Test-planning and test-case errors--for example, required hardware ismissing from the planned hardware configuration, or a test case fails to testan important product functionandM;* Build and test-environment errors--for example, the test product had thewrong level of a module, data sets needed for the test were missing or hadthe wrong nameandM;* Test-execution errors--sometimes called user errors, these are errors madeby the tester in setting up the test or in interpreting the results--forexample, the tester entered the input commands incorrectly or interpreted thepresence of an error message as a problemandM;* Duplicate errors--failure to recognize that a product defect manifesting acertain sympton is really a duplicate of another error that was foundearlier, possibly with different symptoms (duplicate errors are analyzed fromthe perspective of &quot;Could we have recognized this error as a duplicate of theprevious error?&quot; and &quot;What can we do to identify duplicates of this type inthe future?&quot;)andM;* Recreate requests--a request to recreate a program problem because notenough information was collected when the first failure occurred to permitproblem diagnosis (recreate requests are analyzed from the perspective of&quot;What caused our failure to collect the needed information?&quot; and &quot;Whatdiagnostic tools would help collect the required information or permitaccurate first-failure data capture?&quot;)andM;* Test escapes--product defects that a particular test failed to find butwhich were found in a later test or by a customer (test escapes are productdefects but are analyzed from the perspective of &quot;Should the test have caughtthis error?&quot;andgt; &quot;Why was the error not caught?&quot;andgt; and &quot;What can we do to catchthis sort of error in the future?&quot;)andM;Since the test organization analyzes product errors as test escapes, a givenfield error (APAR) can be analyzed multiple times, both from the developer'sperspective (&quot;Why was the error first introduced?&quot;) as well as from the testperspective (&quot;Why did it get through the target test?&quot;).andM;Information developers (programmers who develop product manuals and relateddocumentation) analyze errors in their books.andP;  The errors can be manifestedduring inspections or reviews of various book drafts, testing, or from fielderrors (documentation APARs) and reader comments.andP;  Other errors that occurduring the planning stage or during production of books can also be analyzedand prevented.andM;Software service programmers (those who diagnose customer problems anddevelop fixes for APARs) analyze errors that result in bad APAR fixes.andP;  Aswith product developers, the root cause of the programming error is examined.andO;Other errors from the service perspective include test escapes, thoseoccurring in the fix packaging and in the install process, and those indiagnosing customer problems.andM;Human factors specialists (persons who analyze, test, and improve productusability characteristics) analyze customer user errors, that is,difficulties customers have had using our products.andP;  Frequently theseproblems are caused by usability problems in the product.andP;  The analysisresults in suggestions for product usability improvements that are thenincluded in subsequent product release plans.andM;Product planners (persons who specify new product requirements and formulateproduct development plans) analyze errors and plan changes that have occurredin the requirements and planning process.andP;  These errors include incomplete orerroneous requirements, late requirements, changes in product or marketstrategy, errors in estimating release size, and difficulties in projectmanagement.andP;  The root cause of the error is determined, and actions forimproving the process or anticipating changes earlier are implemented.andM;Our experience with the Defect Prevention Process shows that it is widelyapplicable to different processes and organizations involved in softwaredevelopment.andP;  Moreover, the process is also applicable outside softwaredevelopment, for example, to management practices, hardware design, hardwaredevelopment, and manufacturing.andM;Management's role in Defect Prevention.andP;  Even though the Defect PreventionProcess emphasizes the direct involvement of developers in improving thedevelopment process, management's role is critical too.andP;  We see this role asbeing a fourfold one:andM;* Support and encourage the Defect Prevention activitiesandM;* Allocate the resources needed for the action teamandM;* Authorize the action team to improve the development process as needed toachieve preventionandM;* Monitor the results of the Defect Prevention Process to ensure itscontinued effectivenessandM;A manager serves on the action team and is key to its success.andP;  This teammember provides management focus on such actions as communicating issues toother managers in the organization, negotiating with other managers for theuse of someone's services to implement an action, and negotiating with otherorganizations.andP;  Because the action team is drawn from many different areas ofthe organization, the team members would not be expected to report to theaction team manager.andP;  The team manager may or may not direct the actionteam's activities.andP;  Frequently it is the process representative who chairsthe action team meetings and coordinates the team's activities.andM;We recommend that managers not participate directly in causal analysismeetings because the presence of the developers' manager is sometimes viewedas inhibiting the free discussion of errors.andP;  A similar rationale was citedby Michael Fagan in regard to management use of inspection data.andP;  [15]  Onthe other hand, managers may choose to conduct their own causal analysis toevaluate problem areas in their own work.andM;Benefits and costs of Defect PreventionandM;In this section we describe the benefits of the Defect Prevention Process,including quality and process improvements, and the costs of implementing theprocess.andM;Defect rates during development.andP;  The role of Defect Prevention in reducingdefects introduced during development has been a significant one.andP;  Oneproduct was studied in detail.andP;  Historical data are available for eightreleases of this product prior to the introduction of the Defect PreventionProcess, which was introduced fully during two recent releases.andP;  Defect ratesexperienced during development are compared graphically in Figure 6 and arelisted in Table 1.andP;  All of the numbers represent defects per thousand linesof new and changed source instructions (KLOC) that were discovered ininspections, reviews, and testing in each development stage.andP;  The data forunit test and function verification test and those for product verificationand system verification test have been combined, because some of the earlierreleases did notperform these tests separately.andP;  To date we have seen a 54percent reduction in defects during the development cycle over history.andM;There are significant differences in the way lines of code are counted in theindustry.andP;  For example, does one count macro expansions or comments?andP;  Themethod used with the product being discussed results in line of code countslower than and error rates correspondingly higher than those cited by othersin the industry.andP;  What is important is not the absolute defect rate butrather the relative improvement in the defect rate experienced by thisproduct.andM;The historical data are summarized in Table 1.andP;  The defect rates shown arethe weighted means of the data for the eight releases, and the standarddeviation is a weighted standard deviation.andP;  In the two recent releases,error data for each development team in each stage were collected.andP;  The sizeof each team's code is given.andP;  For some teams, the module-level design (MLD)stage was combined with the code stage (indicated by n/a in the MLD column).andO;The test stage results have been combined to maintain consistency with thehistorical data.andM;Teams A to D represent one release (28KLOC) and teams E to J represent theother (36.3KLOC).andP;  The product verification and system verification tests(PVT/SVT) for the second release have not completed, as of this writing.andP;  Thedifferences between history and Teams A to J for the individual stages andthe overall defect rate were analyzed using the Student t-test.andP;  The overalldifference and the differences for MLD through PVT/SVT are significant (p [isless than] 0.05).andP;  The difference for the component-level design (CLD) stageis not significant because of the large variability in the historical datawhich have a mean of 7.9 and a standard deviation of 8.4.andM;There are clear differences among the various teams, which are due to suchindividual differences in the team members as level of experience andknowledge of the product.andP;  There are also differences in complexity of thefunction being developed.andP;  Team D, for example, had relatively higher defectrates compared with Teams A to C.andP;  Their product function was particularlycomplex, involving complex timing situations in a part of the product thatteam members had little experience with.andP;  In addition, the expert in thatcomponent was not readily available to answer questions.andM;The field defect rate for the first release for Teams A to D can only beprojected at this point.andP;  However, the number of field defects (total validunique APARs) that have occurred since the release was made available tocustomers is tracking at a level that represents a reduction of 60 percentcompared to the field defect rates of the eight prior releases.andM;One might argue that the observed reductions in error rates are due to otherfactors.andP;  For example, a reduction in error rate might be due to a reductionin the effectiveness of defect detection activities, such as inspections,reviews, and testing.andP;  This is not valid in the case of these releases fortwo reasons: (1) The effectiveness of inspections, reviews, and tests asdetermined by such other measures as inspection preparation time, inspectionrates, and test coverage appears to be at least as good as the historicalreleases.andP;  (2) The error reductions persist throughout the release and intothe field.andM;We are confident that the error reductions we have observed are caused byfewer defects injected during development, as a consequence of the practiceof the Defect Prevention Process.andP;  No clear trend toward continued cumulativeerror reductions can be observed in this small sample of team results.andO;Nonetheless, we believe that further reductions in defect rates will beexperienced as the cumulative effects of constant improvements occur overtime.andM;Costs and direct savings to the organization.andP;  The costs of the DefectPrevention Process come from the different activities of the process.andP;  Thefollowing cost figures are typical of a software development organization:andM;* Stage kickoff meetings--1 to 2 hours per team per stage, where a teamcomprises typically 3 to 7 personsandM;* Causal analysis meetings--2 hours per meeting, usually with 1 to 2 meetingsper team per stage.andP;  There is typically 0.5 to 1 hour of data-entry timerequired by the causal analysis leader at the end of the meetingandM;* Action team meetings--require 1 to 2 hours every other weekandM;* Action implementation--usually averages about 24 person hours per action.andO;The average time spent by action team members is approximately 10 percent oftheir time.andM;Two product areas have kept detailed data on the number of hours spent ineach of these activities.andP;  The average costs of each activity, in personhours, for the two products are shown in Figure 7.andP;  The major differencebetween the two products is in the average cost of action implementation,which is about 16 versus 42 person hours per action.andP;  This cost varies fromproduct area to product area, depending on the level of sophistication andmaturity of the area's process.andP;  In the case of Product 2, considerably moreeffort was spent on tools actions than in Product 1, which accounts for thedifference shown.andM;The total cost of the process for both product areas in 1987, includingaction implementation, is given in Table 2.andP;  For both areas, causal analysiswas done on only about a third of the defects.andP;  At these levels of effort, aproduct area of 150 to 200 people can expect to spend less than one personyear per year on Defect Prevention, or about one-half percent of the area'sresources.andM;An analysis of cost savings for a typical product area identified thefollowing factors where savings will be realized:andM;* Less developer effort is required to fix design and code errors found ininspectionsandgt; inspections also take less time when there are fewer errors.andM;* Less developer effort is necessary to investigate test errors, analyzediagnostic materials, code fixes, inspect and unit test fixes, integratefixes, and answer problems.andM;* Less test effort is needed to investigate problems, prepare diagnosticmaterials such as dumps and traces, analyze and write up the problems,recreate the problems as necessary, and rerun the tests after the fix hasbeen applied.andM;* Less time is wasted when a test is blocked because of unresolved productdefects.andM;An estimate was made of the savings from the first two factors only.andO;Assuming a 50 percent reduction in errors throughout the development cycle,taking into account the cost of fixing errors from inspections and duringtests, the total savings in developer time would be at least 2.2 personyears.andP;  Given a cost for all Defect Prevention activities of about 0.85person years per year, this represents a net savings of more than 1.3 personyears per year.andP;  This is the direct savings that a development area wouldreceive from this process.andP;  Savings in tester effort, from the other twofactors, would be additional.andP;  In addition to quantitative qualityimprovements, we have noticed a number of positive secondary effects inorganizations that follow this process.andP;  These effects have included processimpacts, improved team communications and increased quality awareness.andM;Process impacts.andP;  The development process, in the broad sense, covers thedefined steps followed to develop a software product.andP;  These include therequired work products at each step and the specific methodologies,practices, techniques, tools, and guidelines used.andP;  The development processgradually changes over time.andP;  The process for a newly formed organization maystart off fairly simply, but it changes as problem areas are identified andcorrected and as new practices are tried out.andP;  With continued focus onrefining and improving the process, it reaches a degree of maturity.andP;  [16,17]andM;Ordinarily, an organization's processes change very slowly.andP;  Process change,even when recognized as needed, is frequently difficult to accomplish becausethere is no established way to effect a change.andP;  Even the idea that theprocess should change is frequently not recognized or accepted.andP;  Also, theorganization's process may not be documented or the documentation may be outof date and not reflect the organization's actual practices.andP;  The DefectPrevention Process affects the development process in a number of ways andsupplies some of the methodology and structure that has heretofore beenmissing.andM;The process becomes self-correcting.andP;  Wherever current practices lead toproblems or errors, the practices are scrutinized through causal analysis andcorrected through suggested actions.andP;  If the process correction does noteliminate the problem, the process is automatically reviewed in subsequentcausal analysis and further or different corrections are proposed.andP;  Theprocess is constantly fine-tuned.andM;Process change is accelerated.andP;  Process deficiencies are pointed out andcorrections are implemented rapidly by the action team.andP;  Those deficiencieswhich cause the most errors or problems receive the most focus.andP;  The actionteam becomes the focal point in the organization for process change.andM;PRocess documentation becomes up-to-date and it is actively used by theorganization.andP;  The process is repeatedly reviewed in the stage kickoffmeetings.andP;  The level of adherence to the process increases as a result.andP;  Ifthe area's process is undocumented, one of the first actions is for theaction team to document it.andP;  If the process documentation differs frompractice, this fact is brought up and corrected.andP;  Process changes arecontinuously fed back to the developers.andM;At some point during the adoption of the Defect Prevention Process--perhapsafter a year of causal analysis and stage kickoff meetings--developers beginto make miscellaneous suggestions for improvement.andP;  A miscellaneoussuggestion is not related to any specific defect or causal analysis meeting,but it is an idea that a developer has had to improve the way work is done.andO;The presence of miscellaneous suggestions signals a fundamental change in theorganization.andP;  Developers are now taking an active role in improving theprocesses they follow, acting to prevent errors before they occur.andO;Developers come to realize that they can influence their process, theirworking environment, their tools, their educational opportunities, and eventhey way they are managed.andP;  The developers are now empowered by the systemwith the ability to change it.andM;During software development, inspections play a key role in detecting defectsthat have occurred.andP;  However, there is a danger that inspections can berelied on too heavily for defect removal.andP;  The key is the prevention ofdefects in the first place.andM;Because an inspection is held at the end of each development stage,developers may be inclined to think that being careful with their work is nota high priority because the inspection will catch the errors anyway.andO;However, our experience shows that good inspections are typically 60 to 80percent effective.andP;  This leaves the potential for quite a few errors still inthe work product.andP;  Successful teams are concerned with preventing errors andthus tend to do much more self-checking and informal peer review as they gothrough each stage.andM;On the other hand, inspections and tests are still critical to the quality ofthe final product, and we are not suggesting the elimination of these steps.andO;In fact, early detection of defects through inspections drives the causalanalysis process.andM;Improved communications and quality awareness.andP;  A significant effect ofDefect Prevention on the quality of individual development teams is improvedcommunications.andP;  We have found that teams that have historically had goodesprit de corps do more productive and higher quality work.andP;  The causalanalysis meetings confirm this relationship.andP;  Teams that achieve high qualityinvariably attribute this at the causal analysis meeting to&quot;improvedcommunications&quot; or &quot;good communications.&quot;andM;The improved communication occurs mostly among team members.andP;  The DefectPrevention Process encourages such communication.andP;  For example, during thestage kickoff meetings, the most important items tend to be the reviewing ofcommon errors, discussing preventive techniques, and understanding the needfor the entire team to be more conscious of &quot;trivial&quot; mistakes.andP;  During thestage, the developers do not work as individuals but as a team.andP;  Whatevereducation sessions the team needs are sought.andP;  A vm communications network isused to trnsmit messages to the entire team whenever something needs to becommunicated.andP;  The developers continually verify their ideas with other teammembers and ask many questions.andM;These sound like and are very basic work techniques.andP;  However, they need tobe continually reinforced.andP;  The natural tendency for developers is to receivea work assignment and work on that task alone.andP;  Communications must becontinually encouraged.andP;  An adjunct to improved communications is improvedmorale.andP;  We have observed improvements in team morale in several areas thathave adopted Defect Prevention.andM;Another effect of using this methodology is that quality awareness is greatlyincreased.andP;  The Defect Prevention Process requires that the people who createerrors be involved in analyzing their cause.andM;This increased involvement in quality makes a difference.andP;  The result is amuch more active participation by the people in suggesting preventive actionsand ideas.andM;After repeated causal analyses, developers become aware of the type of errorsand their causes.andP;  When someone else's error is described, the developer askswhether similar errors exist in his or her own work.andP;  If a team member hasdifficulty with a particular type of error, other team members offer help inavoiding that error or assistance in reviewing the work.andM;Net benefits of the process.andP;  In addition to process and quality improvementsduring development, other benefits of the Defect Prevention Process include:andM;* Greater effectiveness of inspections and tests because there are fewerdefectsandM;* Shorter test elapsed time.andP;  We have observed that tests of products thathave used Defect Prevention typically complete on or ahead of schedule,sometimes using fewer testers and other resources than planned.andM;* Cumulative improvements in the development process.andP;  The investments that aproduct area makes in improving its development processes are cumulative.andO;The area keeps earning dividends from the preventive actions which wereimplemented in prior years.andM;Our experience shows that the investment required for effective defectprevention is very small, less than a person year per year or about one-halfpercent in a 150 to 200 person organization.andP;  At this level of investment,the organization receives a direct return of at least double and possiblytriple the cost, assuming a reduction in errors equivalent to what we haveseen in other product areas.andP;  At this rate, the average cost of a single APARwould fund the Defect Prevention Process for more than two motnhs.andM;However, the most significant benefit of the process is higher productquality in the field.andP;  Our experience to date shows that the error reductionsseen in development continue in the field at the same level of reduction orbetter.andP;  Here the benefits of the process both to our customers and thecompany are substantial.andP;  Fewer APARS result in fewer customer problems,fewer customer calls, fewer fixes to be developed, certified, tested, anddistributed.andP;  Because the impact of field errors on the customer can besignificant, higher product quality trnslates into higher customersatisfaction.andM;Process detailsandM;In the development of the Defect Prevention Process over the past six years,there have been a number of refinements and enhancements, including adjustingthe resource allocation for Defect Prevention activities and variousconsiderations to begin the process.andM;Resource allocation in the process.andP;  Organizaitons implementing this processfind that they have so many good ideas and opportunities for improvement thatthey cannot implement them all.andP;  Thus management must decide how much peopletime resource to devote to this process.andP;  Clearly, the more resourcesdeveoted to the process, the more defects will be prevented.andP;  Resources aregenerally constrained in the areas of causal analysis and action team effort.andO;The volume of defects available for causal analysis can be large, and it maynot be feasible for the organization to do causal analysis of all thedefects, although this is the ideal.andP;  The action team may find itself after awhile with a substantial backlog of actions still to be completed.andP;  As morecausal analysis is done, more actions are suggested.andP;  Thus the backlog grows.andM;Management can allocate more resources to the process by authorizing morecausal analysis meetings, by adding additional members to the action team,and by permitting a larger percentage of time to be spent by action teammembers (e.g., 50 percent rather than 10 percent).andP;  In addition, managementmay provide additional rsources to the action team on a temporary basis.andM;Conversely management may choose to limit the resources in each area of theprocess to a specific level.andP;  For example, development teams may be requiredto hold only one two-hour causal analysis meeting for each stage.andP;  Werecommend the following minimum level of resource allocation:andM;* A stage kickoff meeting for each development team at each stageandM;* One causal analysis meeting for each development team at each stage toensure coverage of errors from each team and to provide feedback to alldevelopersandM;* An action team of three to six members, depending on the sizeof theorganization--three members for an organization of 30 or fewer persons andsix members for a 120 to 150 person organizationandM;* Action team participation at 10m percent of each member's timeandM;If causal analysis meetings are limitd in this way to one meeting per teamper stage, an appropriate sampling of errors can be examined in a timelymanner.andP;  If a particular type of error is missed by one team, it will likelybe considered by another team at a later time.andP;  The team leader may select anappropriate number of errors--say twenty--for consideration at the meeting.andO;We recommend that the selection or screening of errors be done with care.andO;Select an equal number from each developer so that everyone's errors areanalyzed.andP;  Select the errors so that a truly representative sample ispresented.andP;  Do not omit errors because they seem obvious or trivial.andP;  Mosterrors are trivial in nature, and trivial errors need to be addressed withparticular attention because they are so numerous.andP;  Omit obvious duplicateerrors, because they waste time.andP;  However, make a note of how many duplicatesoccurred when the error is presented in the meeting.andP;  this lets the team knowthe magnitude of the problem.andM;Alternatively, the team leader can separate the errors into groups of relateddefects.andP;  The leader can then select a representative sample of each type oferror.andP;  For example, one team leader reviewed more than one hundred errorsthat had accumulated for the team, sorting them by cause category.andP;  The teamwas then able to do causal analysis on sample errors from each error group intwo meetings, producing 30 suggested actions.andP;  As with random selection,selection by categorization should be done with care to present a trulyrepresentative sampling of errors, including errors from each person on theteam.andP;  If screening of this sort is done, we recommend that a summary of theerror groups also be presented to the team so that they can understand thedistribution of errors.andM;Even though causal analysis is done only on a sample of the errors from astage, the leader should hold the meeting as soon after the errors have beendocumented as possible.andP;  Otherwise the developers have difficulty rememberingthe causes of the errors.andP;  Also, the developers miss timely feedback on thecauses of early errors that can reduce the posibility of repeating the errorslater.andM;Startup considerations.andP;  In order to start this process in an organization,an advocate is needed to sponsor and promote the process until it isestablished.andP;  Ideally there are two advocatres, one a technical person andthe other a manager.andP;  Advocates facilitate the startup through the educationof developers and management about Defect PRevention, about the benefits andcost of the process, and so on.andP;  The initial education addresses anyskepticism about the process within the organization.andP;  Another duty of theadvocate is that of performing or assisting in initial activities, such asaction team selection, setting up kickoff packages, holding initial causalanalysis meetings, and implementing the initial actions.andP;  The advocate alsomaintains focus on the process throughout the startup period (which may be ayear or longer) by reminding people of their responsibilities, seeing thatmeetings are held, and presenting initial results to management.andP;  Theadvocates should be correctly positioned within the organization.andP;  Ideallyboth the technical and management persons performing that function are inrelatively high positions.andP;  The persons should have credibility within theorganization and be able to influence their peers.andM;Management funding.andP;  Another requirement for startup is management commitmentto the process.andP;  The Defect Prevention Process can be done with relativelysmall impact on the resources of the organization, but there is a continuingneed for management's support and funding.andP;  Management must fund theresources of the action team and must authorize the action team to change andimprove the development process.andP;  The acion team must be viewed as adedicated resource that will be protected from resource cuts and schedulepressures.andP;  Frequently the action team members' responsibilities are put intheir performance plans at an agreed upon level of effort.andM;We recommend that the Defect Prevention Process first be started as a pilotproject, such as a portion of the release of a product involving severalteams.andP;  The pilot project allows the participants to become used to theprocess without excessive stress.andP;  Initial adaptation of the process to onearea can be accomplished, and the process can then be gradually expanded toencompass the entire organization.andM;Action team startup.andP;  Selection of action team members is important to thesuccess of the process.andP;  Action team members should be persons in the areawho are motivated, who can get things done, and who are dedicated toimproving the area's processes.andP;  The best action team members are notnecessarily the technical leaders in the area.andP;  A positive attitude and awillingness to work are more important than technical expertise.andP;  The actionteam manager should likewise be motivated and willing to improve thedevelopment process and should be able to represent the team's perspective tomanagement.andM;During the startup period it is important to establish the credibility of theprocess.andP;  This can be accomplished by implementing some of the initialpreventive actions quickly and publicizing them.andP;  Developers need to feelthat their efforts in making suggestions for improvement are being takenseriously and that change to the development process is possible.andM;Initial meetings.andP;  The initial causal analysis and stage kickoff meetingsshould include an introductory section that reviews the Defect PreventionProcess and describes the format of the meeting.andP;  Developers will initiallybe uneasy because the meetings are new.andP;  A review of the meeting content willhelp set them at ease.andP;  At the end of these initial meetings it is also goodto ask for comments from the participants about the meeting and the process.andM;In causal analysis there may be an initial sensitivity and defensivenessbecause developers are being asked to openly discuss their mistakes.andP;  Thus itis important to ensure that the atmosphere of the meeting is monthreatening.andO;The causal analysis leader should keep the meeting light, with the focus onsuggested improvements rather than a developer's error.andP;  Developers who arenew to development frequently do not realize that everyone makes mistakes.andP;  Agood strategy can be to present errors from everyone, beginning with the moreexperienced developers.andM;During the startup period, there is typically a flood of suggestions, withsometimes three or more suggestions for every defect analyzed.andP;  This isusually because there are many suggested improvements that developers havealready considered but that have had no channel for implementation.andP;  As timegoes on, the rate of suggestions slows because ideas that have been offeredpreviously will also apply to defects analyzed later.andP;  Thus an initialtwo-hour causal analysis meeting may cover about seven defects and produce 20suggestions, many of which will be fairly easy to implement.andP;  After perhaps15 causal analysis meetings, a typical meeting will cover 15 to 25 errors andproduce five to seven suggestions.andP;  Often these later suggestions are morecreative actions that may take longer to implement.andM;The nature of programming errorsandM;Over the past six years, we have participated collectively in dozens ofcausal analysis meetings, involving many widely varied software products,including systems software, applications, and microcode.andP;  The study of thespecific causes of errors gives a unique perspective on the nature ofprogramming errors and the types of actions needed to prevent them.andM;Error cause categories.andP;  For many years, software engineers have tried tocategorize errors in order to determine what areas to address to improvequality.andP;  A number of different error taxonomies have been proposed.andP;  [18-22]Error classification schemes may be helpful to identify broad error-proneareas and activities, but they do not address the variety of specific causesfor errors.andM;In our view, error classification schemes obscure the details of the errorand its cause.andP;  As a result, these schemes generally do not lead to thoroughpreventive measures.andP;  It may be misleading to try to identify preventiveactions by considering the percentage of errors caused by the quality ofspecifications, [18] misunderstandings of the design, [20] or data definitionfaults.andP;  [21]  Preventive actions, derived solely from error classifications,will not be specific enough.andP;  The thorough analysis of each error duringcausal analysis provides a much better understanding of specifically why anerror occurred and how to prevent its recurrence.andM;We have found one error classification scheme to be useful.andP;  During causalanalysis, we ask that each error be categorized into one of four basic causecategories.andP;  In addition, we ask for a description of the specific cause ofthe error.andP;  The cause category helps the team identify the specific cause byfocusing the discussion.andP;  It is the specific cause, however, that triggersthe suggestions for prevention.andP;  The four basic cause categories follow.andM;Oversight.andP;  In this category, the developer failed to consider all cases andconditions.andP;  Usually some detail of the problem or process was overlooked.andO;The developer forgot, had difficulty checking thoroughly, or did not haveenough time to be thorough.andP;  To identify the specific cause, we ask &quot;What wasoverlooked?andP;  What was not considered thoroughly?&quot; Examples: Developer failedto consider the end-node case of the message flow.andP;  Developer did not realizethe value of specific variable could exceed a maximum value.andM;Education.andP;  In this category, the developer did not understand some aspect ofthe product or the process.andP;  This category is further divided into educationin base code, education in new function, and other education, depending onwhat was not understood.andP;  To identify the specific cause, we ask &quot;Whatexactly was not understood?&quot; Examples: Developer did not understand wherespecific fields were located in a control block structure (base codeeducation).andP;  Developer did not understand the purpose of a specific new bit(new function education).andP;  Developer did not understand how character fieldsare initialized by the compiler (other education).andM;Communications failure.andP;  Here, the developer did not receive the requiredinformation or the information was incorrect.andP;  To identify the specificcause, we ask &quot;What was not communicated, from whom to whom?&quot;andP;  Examples: Arequirements specification did not list all environments the new function hadto work in.andP;  The design group failed to communicate last-minute changes todevelopment.andM;Transcription error.andP;  In this category, the developer knew what to do andunderstood the item thoroughly but simply made a mistake.andP;  Transcriptionerrors are typically caused by some problem in a procedure--for example,typing or copying a list of items.andP;  To identify the specific cause, we ask&quot;What procedure was being used?&quot;andP;  Examples: The developer transposed lettersin typing.andP;  The developer omitted an item when manually copying a list.andM;An error may have multiple causes and multiple cause categories.andP;  In thesecases, there is usually a chain of causes (z was caused by y, which wascaused by x).andP;  All of the causes can be recorded and considered forpreventive suggestions, although the root cause is usually the most importantto address.andM;A fifth cause category, that a defect may be caused by a flaw in the process,is used by some organizations following Defect Prevention.andP;  There is a debateas to the appropriateness of the process-cause category, because it fails todistinguish the human element of the cause from process flaws that affecthuman performance.andP;  Nakajo et al.andP;  [9] clearly draw this distinction betweenhuman errors and contributory process flaws.andP;  The use of the process-causecategory circumvents consideration of the human contribution to the error andinsulates the developer from taking responsibility for his or her ownmistakes.andP;  In the authors' view, process flaws should be considered afterhuman causes have been identified, ideally when proposing preventive actions.andO;Therefore, the process-cause category should be used with caution.andM;The pinhole effect.andP;  We characterize the variety of specific error causes asthe pinhole effect.andP;  Envision a balloon filled with water, representing thedevelopment process.andP;  Water is leaking from the balloon, not from gapingholes (i.e., from large, obvious groupings of errors), but from thousands ofsmall pinholes.andP;  Thus, product defects result from numerous diverseprogramming errors.andM;We have observed that most error causes are trivial, as for example,misspelling a word or forgetting to reinitialize a variable.andP;  While an errormay have a trivial cause, it may have very severe consequences.andP;  Figure 8shows the distribution of test and field errors for one product, by the stagein which the error was injected.andP;  The bulk of the errors found in the varioustest stages were coding errors.andP;  Upon analysis, these errors were consideredto be simple mistakes that could be avoided through preventive actions andattention to detail.andM;A second observation from these data is that the theory that design errorsexplode into multiple code errors is not true.andP;  A design error is typicallycounted as a single error regardless of the number of lines of code affected.andO;As a project progresses through the various development stages, errors arecreated that are unique to each stage.andP;  That is, as more detail is added tothe design and subsequently to the code, more errors are injected.andM;Process- or product-sensitive errors versus generic errors.andP;  Many errors arespecific to the particular development process and to the maturity of thatprocess.andP;  The term process broadly includes the development stages, tools,procedures, methodologies, and techniques used by the developers.andP;  Forexample, a project whose basic architecture or specifications change whiledevelopment proceeds may be expected to have many errors due to late changesoverlooked or not thoroughly handled.andP;  A product that has significantdependencies on another product that is being developed at the same time willprobably have errors due to failures in communications between the twogroups.andP;  A product area that has a weak education program or an influx of newpeople into the area will probably have a large number of education-typeerrors.andM;In addition, some errors are specific to the product being developed, usuallydue to its architecture or design.andP;  For example, one communications producthas two recurring errors caused by its design and which was dictated by theconstraints of the hardware on which it runs: (1) overwriting registersbecause the linkage and save area conventions were constrained forperformance reasons, and (2) confusion over WXTRN (weak external reference)versus EXTRN because memory constraints required that only selected parts ofthe product be linked at product generation time.andP;  Another product, ahigh-performance operating system, has recurring errors in defining the scopeof registers with USING and DROP due to an unusual program segmenting schemewhich was selected for hardware performance considerations in early versionsof the product.andM;On the other hand, certain errors are truly generic, that is, common to alldevelopers regardless of the process, programming language, or type ofproduct.andP;  Many of these are given in the code common error list in AppendixA.andP;  Other examples include:andM;* Failure to consider all error conditions or error pathsandM;* Failure to consider all possible external factors, configurations, andenvironments under which the program will runandM;* Failure to investigate thoroughly impacts of a changeandM;* Failure to communicate a change or impact to other team membersandM;The nature of preventive actionsandM;Given that programming errors have a large variety of specific causes thatare frequently trivial in nature, it is clear that the key to reducing errorsis attention to detail.andP;  This means attention to the multitude of productdetails that present themselves during development, as well as rigorousadherence to the established development processes.andP;  The potential forprevention is extremely high, particularly in addressing trivial errors.andP;  Inour view, high product quality and high customer satisfaction are attainablefor software development through attention to detail, rigorous processadherence, and development automation, which reduces the amount of tediousdetail work required of programmers.andM;Just as errors tend to be sensitive to an organization's process and theproduct it produces, the types of preventive actions are also typicallyproduct- or organization-specific.andP;  Each organization has a different levelof sophistication or maturity of its processes and tools.andP;  The improvementsfor one organization may be based on its current level of maturity.andP;  Many ofthese improvements may not be relevant to another product area.andM;Figure 9 shows the profile actions for two product areas for the period 1987to 1988, giving the breakdown of actions by type.andP;  Both products had asignificant percentage of actions to enhance their process.andP;  A large numberof these actions involve simple additions to common error lists and otherprocess documentation.andP;  The two products differed in the profile of the othertypes of actions.andP;  Product 1 had fewer tool actions and more product changesand education actions.andP;  Product 2 had more effort spent on improving its setof tools.andP;  This reflects the differences in the specific needs of the twoareas.andM;Thus, we see that it is critical for each product to use causal analysis todetermine what actions will help to improve its processes and tools.andO;Preventive solutions to generic errors, of course, should be shared acrossall development groups, usually in the form of generic tools.andP;  Ourexperience, however, has been that most preventive actions are productspecific.andM;Types of preventive actions.andP;  Different types of preventive actions addressthe different cause categories of oversight, education, communications, andtranscription.andM;Oversights can be prevented by actions that remind the developer or thatautomate the process so that the developer cannot overlook detail.andP;  Exampletechniques include the following:andM;* Checklists and common error listsandM;* Cross-reference and product-logic documentation available on lineandM;* Tools that add automatic checks, such as compilers and post-compile modulecheckersandM;* Templates or skeletons that guide the creation of a work productandM;* Permanent reminders and warnings in product documentationandM;* Reminders in the form of newsletters, memoranda, and reminder notesandM;Some developers also find that holding work sessions with their peers toreview and check one another's work is very helpful in preventing oversights.andO;Often the vocalization of a design approach to a peer identifies holes inone's thinking.andP;  Such work sessions are not considered formal reviews orinspections because the work product has been completed, and the errorsuncovered have not been counted in the error rates.andM;If schedule pressure in the cause of oversights, management should adjusttheir planning rates to allow more time in the schedule to do the workproperly.andP;  The presence of a large number of oversights caused by lack oftime can be used to justify such adjustments by management.andM;Education errors can be prevented by providing the appropriate level ofeducation at the right time, such as the following:andM;* Seminars and classes related to the productandM;* New-hire education checklistandM;* Tutorial articles in the product-area newslettersandM;* Education sessions on the new release functionsandM;Communications failures can be prevented by process changes and the use oftools, such as:andM;* Liaison to receive communications from other areas where the product hasdependencies and to pass on the information to others in the product areaandM;* Use of a conference disk to pass information to interested parties in aproduct areaandM;* Enhanced problem-tracking tool to include automatic notification of changesto affected partiesandM;Transcription errors can frequently be prevented through such tools are thefollowing that automate an error-prone procedure:andM;* Code spelling checkerandM;* Tool that maintain a release's component list and automatically includes itin the design and specification documens and in the build processandM;* Variable-not-declared warning in the compiler to check from names that havebeen mispelledandM;As with oversights, a work session with a team member can frequently helpprevent transcription errors, where an automated procedure is not available.andM;Defect extinction.andP;  The Defect Prevention Process makes it possible toachieve complete extinction of programming defects.andP;  This can be comparedwith the biological phenomenon of extinction, which involves two simplefacts: (1) Offspring are not longer being produced, and (2) all existingmembers of the species have expired.andP;  In the same way, there are two simplerequirements to make programming defects extinct: (1) The cause of the defecthas been removed, so that no new defects are produced, and (2) all existinginstances of that defect have been removed.andP;  Simply preventing future errorsis not enough.andP;  When several defects of a given type are detected, it islikely that additional defects of the same type exist in the product as yetundetected.andP;  To achieve true extinction these existing defects must beidentified and removed.andP;  Thus effective prevention of future defects and thesystematic removal of existing defects are the two goals of defectextinction.andM;We have found that product enhancements and tools are the two most effectiveapproaches in preventing future instances of a defect, and source scanningtoos are the most effective way to discover and remove defects that alreadyexist in a product.andM;In general, tools are the most effective type of preventive action.andP;  Theyhelp identify predictable errors and prevent them automatically.andP;  They canperform an error-prone human task, providing 100 percent accuracy,independently of the programmer's skill.andP;  Tools should be considered if otherattempts to prevent an error have not been sufficiently effective.andP;  The toolmay not actually prevent the error but may enhance our ability to detect theerror or to detect it earlier in the cycle.andP;  For example, a tool may be usedin unit test rather than in systems test.andM;Some specific examples of these approaches to defect extinction are thefollowing:andM;Module checker tools.andP;  These are tools that audit the product source codewith specific checks whenever a module is compiled, producing additionaldiagnostic messeages at the end of the compiler listing.andP;  The checks can bespecific to the product being developed or generic and applicable to allproducts using that language.andP;  The module checker output is generallyrequired at code inspections.andM;Module checker tools have been written for both assembler and high-levellanguages.andP;  The checks are usually derived from errors noted in causalanalysis or from project standards that the area wishes to enforce.andP;  Themodule checker must be able to distinguish instances of new code fromexisting or base lines of code, so that checks can be limted only to newcode.andP;  Otherwise, extraneous diagnostic messages are printed for the basecode and developers may ignore or overlook valid messages from the new code.andO;A module checker can distinguish new code from base code if the product useschange flags on thenew and changed lines of code.andM;The following are examples of module checker checks.andP;  The first threeexamples are instances of product-specific checks, and the remainder aregeneric checks.andM;* A specific keyword must be coded only once on a particular product macro.andM;* % INCLUDES must specify a specific project library.andM;* Register basing must be specified only after initialization of the baseregiterandgt; variables must be referenced only after their register basing isspecified.andM;* Return codes must be tested for successful completion after each module ormacro invocation.andM;* The indentation of the code in IF-THEN-ELSE blocks must be consistent withits nesting level.andP;  This check would detect cases of a missing DO-END groupon a THEN or ELSE leg.andM;Product enhancements.andP;  A product itself may be a cause of errors.andP;  Forexample, a product interface may be error prone, becaue of a design flaw.andP;  Amacro's sequence of parameters may be counterintuitive.andP;  The choice ofvariable names in a control block may be confusing.andP;  The most effectiveapproach to preventing such errors is to correct the product.andM;An example of a product enhancement involved a macro that required theprogrammer to initialize a field after invoking the macro.andP;  If theinitialization were omitted, or if the initialization were done withoutchecking that the macro had succeeded, subsequent processing would fail.andP;  Thepreventive solution involves the following two steps: (1) Move theinitialization of the field into the macro itself by adding a keyword to themacro that specifies the initial field value to be used: and (2) ensure thatthe new keyword is required for new uses of the macro but that existing usesof the macro in the product are not affected.andP;  This was done via the modulechecker.andM;Source scanning tools.andP;  A tool that can scan the entire source code of aproduct is very usevful for discovering and removing existing defects.andP;  Thescans are generallt identified through causal analysis.andP;  Errors that can beidentified through specific syntatic elements in the code are the bestcandidates for scanning.andP;  If the error cannot be identified exactlt throughthe source code, the scanning tool may be ablve to select and subset thepossible instances where th error may have occurred.andP;  Additional analysiswould then be needed to determine whether the error actually was present.andM;Scanning tools have been developed for both assembler and high-levellangauges.andP;  For high-level languages, the ability to treat an entire sourcestatement is usefull, because source statements can span two or more lines oftext.andP;  Frequently a scan requires several search terms connected with BooleanAND, OR, or NOT LOGIC.andP;  It is also useful to have the option to display aspecified number of statements before and aft er the found statement, to bestable to search either by text string or token, and to search independentlyof upper-and lowercase text.andM;Examples of scanning code include:andM;* Incompatible keyword combination on a specific product macro.andM;* Macro or module call but the return code was not checkedandM;* Regiter as the length parameter of an assembler storege-to-storageinstruction.andM;Preventing chronic errors.andP;  Most programming errors are made by developersrepeatedly.andP;  Of these, some errors are noticeably more frequent than therest, perhaps those caused by some general problem in the product of theprocess.andP;  These are the area's chrronic errors.andP;  Usually the chronic errorsbecome evident after only a few causal analysis sessions.andP;  By collecting dataon the frequency of these errors, an ever stronger case can be built 10implement effective preventive actions, and management can make reasoneddecisions on how to allocate resources.andP;  Once preventive acions are put inplace, if the chronic error continues, stronger actions may be justified.andM;As an example of a chronic error, consider the following: Approximately athird of the defecs analyzed in one product area were due to lack ofunderstanding of various aspects of the product or environment.andP;  This factwas used to justify full-time education coordinator for the product area.andO;The coordinator developed a comprehensive education plan and many of thecourses and seminars identified in causal analysis have been made available.andO;In anoter case of chronic error, a product that must do GETMAIN/FREMAIN-typelogic, that is, get storage, use the storage, and then free it, willinvariably have many errors in failing to free the storage on certain paths.andO;Less frequently, the error of freeing the wrong amount of storage will alsooccur.andP;  A tool was developed in one product area to trace storage GETs andFREEs to ensure that the storage is always freed.andP;  Such a tool does notprevent the error and will not be able to catch all instances of failure tofree storage on all paths in the product.andP;  However, it tends to catch a veryhigh percentage of this type of error compared to ordinary testingtechniques.andM;Relative return on investment of actions.andP;  Action teams usually find itnecessary to prioritize their actions so their efforts have the largestreturn to the organization.andP;  One method of prioritization developed is thatof the relative return on investment.andP;  An action's relative return oninvestment begins with an estimate of the action's effectiveness.andP;  Thepercentage effectiveness is a conservative estimate of the percentage ofsimilar errors the action will prevent.andP;  The percentage effectiveness isgenerally assigned by an individual action team member or by consensus of theentire action team.andM;Percentage effectiveness varies for different types of actions.andP;  For example,changes to the development process are generally in the 30 to 70 percenteffectiveness range.andP;  Tool and product changes tend toward 70 to 100 percenteffectiveness, and a newsletter article might be 10 to 30 percent effective.andO;Estimating percentage effectiveness is not intended to be precise, but ratheran approximation to produce a numerical estimate of defects prevented and toproject the return on investment.andM;An action's return on investment (ROI) is the value of preventing a type ofdefect versus the cost of preventing it.andP;  An absolute return on investmentcannot be calculated because the exact number of defects prevented cannot becalculated.andP;  However, an action's relative ROI can be estimated from thenumber of known defects that an action addresses times its estimatedeffectiveness.andP;  For example, a tool enhancement that prevents three knownproduct defects at 70 percent effectiveness and costs two programmer days toimplement has a relative ROI of (3 X 0.7)/2 or 1.05 defects per programmerday.andP;  Adding an item to a common error list that addresses two known defectsat 30 percent effectiveness and which requires 10 minutes (0.02 programmerdays) to implement has a relative ROI of (2 X 0.3)/0.02 or 30 defects perprogrammer day.andP;  Adding the item to the common error list is worth doing,even though it is only 30 percent effective.andM;A basic assumption of this method is that error types that occur in a productin one release, on average are repeated in the next release.andP;  This assumptionis not precise.andP;  The relative ROI is an educated estimate of what today'spreventive action can accomplish for the next release of a product.andM;Concluding remarksandM;Significantly quality and productivity improvements can be attained throughsystematic causal analysis of errors, implementation of preventive actions,and feedback to developers.andP;  The Defect Prevention Process uses the actualerrors that have occurred and corrects their cause, relying on actual defectdata rather than conjecture.andP;  Reductions in defects by more than 50 percenthave been achieved at a cost of about one-half percent of the product area'sresources.andP;  Corresponding productivity improvements are realized through theimprovements in quality.andM;Equally significant are the changes we have observed in the product areasthemselves.andP;  Process change is accelerated and the area's processes becomeself-correcting.andP;  Communications among team members improves and qualityawareness increases.andM;Defect Prevention has been successfully applied to test, informationdevelopment, software service, and human factors, as well as to softwaredesign and development.andP;  We feel that it can be applied generally across allorganizations involved in product development, including hardware design,hardware development, and manufacturing.andM;The investment requirement for the Defect Prevention Progress is very modest.andO;However, the benefit resulting from higher product quality in the field issubstantial, both to a company's customers and to the company itself.andP;  Intoday's technological and competitive climate, we cannot afford to ignoredefect prevention.andP;  The systematic causal analysis of errors and theresultant attention to detail in all aspects of the development processconstitute the most promising approach availabel for achieving high productquality and high customer satisfaction.andM;AcknowledgmentsandM;The authors wish to thank Florence Gans for her considerable assistance incompiling product error statistics and Ben Sun for his assistance withstatistical analysis.andP;  We wish to acknowledge the contribution of Ken deLavigne of the IBM Corporate Technical Education Center, Joanne Wojtusiak ofSkylight Communications, and Jacques Jimenez of Pattern, Inc. in working withthe authors to develop and present the Defect Prevention Process course todeveloperns from a every maor programming center within the company.andP;  We aregrateful to Katsutoshi Shintani for translating and summarizing the Japaneselanguage papers.andP;  We also appreciate the thoughtful comments from Ken deLavigne, Ron Phillips, Florence Gans, and Joanne Wojtusiak in reviewing thispaper.andM;Appendix A: Excerpts from a code commonandM;error listandM;InitializationandM;* Bits, bytes, pointer, or registers are not reset afte processing (occursvery frequently).andM;* Initialize all variable before usageandgt; never assume zeroes.andM;* Initialize all fields of a control blockandgt; do not leave garbage.andM;Data definitionandM;* When defining a counter, make sure its value range is sufficientandgt;anticipate possible future size changes.andM;* Control block or variable declare not properly aligned.andM;* Variable name misunderstood or confused with another variable name.andM;* Do not assume control block bit meanings.andM;InterfacesandM;* Consider all permutations of parameter values.andM;* Parameters passed in wrong order.andM;* Omitted double parentheses for a pointer in a macro call.andM;Program LogicandM;* Moved code (copied code) is very error proneandgt; deleted code is also veryerror proneandgt; check all paths, instructions, and variable names (occurs veryfrequently).andM;* Reset bits in the wrong place in the code.andM;* Loop logic errors: Initialize all flags and counters before entering loop.andO;Consider all flags on each iteration.andP;  Consider three loop cases: first pass,last pass, and middle iterations.andP;  Increment counters and update pointers oneach iteration.andM;Programming language/compilerandM;* DO WHILE is used instead of DO UNTIL.andM;* OR is used instead of AND ina complex IF statement.andM;* Tested OFF instead of ON.andM;* X'10 should have been X'0A'.andM;* Indented statements as a DO group but omitted the DO-END.andM;AssemblerandM;* Register clobbered (occurs very frequently).andM;* No addressbility established.andM;* Assembler half-word usageandgt; make sure data will always fit in two bytes andthat high-order bytes are cleared.andM;Cited referencesandM;[1.] C. L. Jones, &quot;A Process-integrated Approach to Defect Prevention,&quot; IBMSystems Journal 24, No.andP;  2, 150-167 (1985).andM;[2.] R. T. Phillips, &quot;An approach to Software Causal Analysis and DefectExtinction,&quot; IEEE Globecom '86 1, No.andP;  12, 412-416 (December 1986).andM;[3.] A. V. Feigenbaum, Total Quality Control, McGraw-Hill Book Co., Inc., NewYork (1983).andM;[4.] K. Ishikawa, What Is Total Quality Control?andP;  The Japanese Way,translated by D. J. Lu, Prentice-Hall, Inc., Englewood Cliffs, New JErsey(1985).andM;[5.] J. M. Juran and F. M. Gryna, Jr., Quality Planning and Analysix,McGraw-Hill Book Co., Inc., New York (1980).andM;[6.] P. B. Crosby, Quality Is Free, McGraw-Hill Book Co., Inc., New York(1979).andM;[7.] K. Hino, &quot;Analysis and Prevention of Software Errors as a QC Activity,&quot;Engineers (Japanese), 6-10 (Janaury 1985).andM;[8.] H. Sugaya, &quot;Analysis of the Causes of Software Bugs,&quot; Nikkei Computer(Japanese), 167-176 (August 19, 1985).andM;[9.] T. Nakajo, K. Sasabuchi, and T. Akiyama, &quot;A Structured Approach toSoftware Defect Analysis,&quot; Hewlet-Packard Journal 40, No.andP;  2,50-56 (April1989).andM;[10.] B. G. Kolkhorst and A. J. Macina, &quot;Developing Error-Free Software,&quot;IEEE Aerospace Electronic Systems Magazine 3, No.andP;  11, 25-31 (November 1988).andM;[11.] A. Spector and D. Gifford, &quot;The Space Shuttle Primary Computer System,&quot;Communications of the ACM 27, No.andP;  9, 874-900 (1984).andM;[12.] R. A. Radice, N. K. Roth, A. C. O'Hara, Jr., and W. A. Ciarfella, &quot;AProgramming Process Architecture,&quot; IBM Systems Journal 24, No.andP;  2, 79-90(1985).andM;[13.] J. L. Gale, J. R. Tirso, and C. A. Burchfield, &quot;Implementing the DefectPrevention Process in the MVS Interactive Programming Organization,&quot; IBMSystems Jounal 29, No.andP;  1, 33-43 (1990, this issue).andM;[14.] B. K. Lee, &quot;Implementing a Quality Circle Programme for ComputerProfessionals,&quot; Computer System Science and Engineering 1, No.andP;  1, 65-67(1985).andM;[15.] M. E. Fagan, &quot;Design and Code Inspections to Reduce Errors in ProgramDevelopment,&quot; IBM Systems Journal 15, No.andP;  3, 182-211 (1976).andM;[16.] R. A. Radice, J. T. Harding, P. E. Munnis, and R. W. Phillips, &quot;AProgramming Process Study,&quot; IBM Systems Journal 24, No.andP;  2, 91-101 (1985).andM;[17.] W. S. Humphrey, &quot;Characterizing the Software Process: A MaturityFramework,&quot; IEEE Software 5, No.andP;  2,73-79 (March 1988).andM;[18.] A. Endres, &quot;An Analysis of Errors and Thier Causes in System Programs,&quot;IEEE Transactions on Software Engineering SE-1, No.andP;  2, 140-149 (June 1975).andM;[19.] B. W. Boehm, R. K. McClean, and D. B. Urfrig, &quot;Some Experiences withAutomated Aids to the Design of Large-scale Reliable Software,&quot; IEEETransactions on software Engineering SE-1, No.andP;  1, 125-133 (1975).andM;[20.] D. M. Weiss, c Evaluating Software Development by Error Analysis: TheData from the Architecture Research Facility,&quot; Journal of systems andSoftware 1, No.andP;  1, 57-70 (1979).andM;[21.] T. J. Ostrand and E. J. Weyuker, &quot;Collecting and Categorizing SoftwareError Data in an Industrial Environment,&quot; Journal of Systems and Software 4,No 4, 289-300 (1984).andM;[22.] J. S. Collofello and L. B. Balcom, &quot;A Proposed Causative Software ErrorClassification Scheme,&quot; AFIPS Conference Proceedings: 1985 National ComputerConference 54, 537-545 (1985).andM;Robert G. Mays  IBM Communications Systems, P.O. Box 12195, Research TrianglePark, North Carolina 277709.andP;  Mr. Mays is an advisory programmer in theProductivity Support Programs Department, Communications ProgrammingLaboratory.andP;  He joined IBM in 1981 and is currently working on projectsrelated to software process technology and development, including softwaredesign methodology, development methods for enhancing existing code products,and understandability in software development.andP;  His current focus is thedevelopment and promotion of the Defect Prevention Process throughout IBM.andO;Past assignments have included requirements process development and systemplanning for communications management projects.andP;  Mr. Mays received his B.S.andO;degree in chemistry in 1968 from the Massachusetts Institute of Technologyand is a member of the Association ofr Computing Machinery and the IEEEComputer Society.andM;Carole L. Jones  IBM Communication Systems, P.O. Box 12195, Research TrianglePark, North Carolina 27709.andP;  Ms.andP;  jones received her B.S.andP;  in mathematicsfrom Youngstown State University in 1966.andP;  She joined IBM in DOS developmentat Endicott, New York, working in both the development and advanced testingareas.andP;  She transferred to Research Triangle Park (Raleigh) in 1970 and hasheld a variety of technical jobs in design, development, and testing of bothsystems software products and applications products.andP;  In 1980 Ms.andP;  Jonesassumed the responsibility of process coordinator for the NCP products and,in that capacity, she was instrumental in developing and applying theconcepts of the Defect Prevention Process as an integral part of theprogramming development process.andP;  She is currently a senior programmer in theNetwork Management Services area of the Communications Programming Laboratorywith process and quality responsibilities.andM;Gerald J. Holloway  IBM Communications Systems, P.O. Box 12195, ResearchTriangle Park, North Carolina 27709.andP;  Mr. Holloway, known as Lucky Holloway,is an advisory programmer in the Systems Test organization in theCommunication Programming Laboratory.andP;  He received his B.S.andP;  in physics fromthe university of Wisconsin in 1974 and joined IBM in Kingston in the testarea of Virtual Telecommunications Access Method (VTAM).andP;  In 1981 hetransferred to the design area of Network Communications Control Facility(NCCF).andP;  In that capacity he began initial efforts toward optimizing thedesign process and its quality.andP;  In 1983 Mr. Holloway moved to the IBMResearch Triangle Park site and initiated a quality team to pursue defectextinction in NCCF design and development.andP;  Later he worked in networkmanagement support to integrate defect extinction into the entire NetworkManagement product area.andP;  Recently Mr. Holloway accepted a position in theSystems Test organization to integrate the Defect Prevention Processthroughout that organization.andM;Donald P. Studinski  IBM Communications Systems, P.O. box 12195, ResearchTriangly Park, North Carolina 27709.andP;  Mr. Studinski joined IBM CommunicationsProducts Assurance in 1983 and was involved in product assurance for theNetwork Control Program (NCP) and System Support Programs (SSP) products.andP;  In1987 he joined Teleprocessin Access Methods (TPAM) process control.andP;  In thatcapacity, he has implemented and supported the Defect Prevention Processthroughout the TPAM organization.andP;  He is also actively involved in promotingDefect Prevention throughout IBM.andP;  MR. Studinski received his B.S.andP;  incomputer science from Louisiana State University, Baton rouge.andO;</TEXT></DOC>