<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-589-661  </DOCNO><DOCID>07 589 661.andM;</DOCID><JOURNAL>Communications of the ACM  May 1989 v32 n5 p625(4)* Full Text COPYRIGHT Assn. for Computing Machinery, Inc. 1989.andM;</JOURNAL><TITLE>Abstracts from other ACM publications.andM;</TITLE><DESCRIPT/><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>Abstracts from Other ACM PublicationsandM;ACM Transactions on Computer Systems  February 1989andM;Fault Tolerance Under UNIX Anita Borg, Wolfgang Blau, Wolfgang Graetsch,Ferdinand Herrmann,  and Wolfgang Oberle The initial design for adistributed, fault-tolerant version of UNIX based on three-way atomic messagetransmission was presented in an earlier paper.andP;  The implementation effortthen moved from Auragen Systems to Nixdorf Computer where it was completed.andO;This paper describes  the working system, now known as the TARGON/32.andM;The original design left open questions in at least two areas: faulttolerance for server processes and recovery after a crash were briefly andinaccurately sketched; rebackup after recovery was not discussed at all.andP;  Thefundamental design involving three-way message  transmission has remainedunchanged.andP;  However, in addition to important changes  in the implementation,server backup has been redesigned and is now more consistent with that ofnormal user processes.andP;  Recovery and rebackup have been completed in a lesscentralized and thus more efficient manner than previously envisioned.andM;In this paper we review important aspects of the original design and note howthe implementation differs from our original ideas.andP;  We  then focus on thebackup and recovery for server processes and the changes and additions in thedesign and implementation of recovery and rebackup.andM;For Correspondence: Anita Borg, Western Research Lab., Digital EquipmentCorp., 100 Hamilton Ave., Palo Alto, CA 94301; Wolfgang Blau, TandemComputers GmbH., Postfach 560214, Ben-Gurion-Ring 164, 6000 Frankfurt/Main56, West Germany; Wolfgang Graetsch, Ferdinand Herrmann, and Wolfgang Oberle,Nixdorf Computer GmbH., Unterer Frankfurter Weg, 4790 Paderborn, WestGermany.andM;Reliable Scheduling in a TMR Database System Frank M. Pittelli and HectorGarcia-MolinaandM;A Triple Modular Redundant (TMR) system achieves high reliability byreplicating data and all processing at three independent nodes.andP;  When TMR isused for database processing all nonfaulty computers must execute the samesequence of transactions, and this is ensured by a collection of processesknown as schedulers.andP;  In this paper we study the implementation of efficientschedulers through analysis of various enhancements such as null trnasactionsand message batching.andP;  The schedulers have been implemented in anexperimental TMR system and the evaluation results are presented here.andM;For Correspondence: F. M. Pittelli, 33 Wilelinor Drive, Edgewater, MD 21037;H. Garcia-Molina, Department of Computer Science, Princeton, NJ 08544.andM;A Tree-based Algorithm for Distributed Mutual Exclusion Kerry RaymondandM;We present an algorithm for distributed mutual exclusion in a computernetwork of N nodes that communicate by messages rather than shared memory.andO;The algorithm uses a spanning tree of the computer network, and the number ofmessage exchanged per critical section depends on the topology of this tree.andO;However, typically the number of  messages exchanged is O(log N) under lightdemand, and reduces to approximately four messages under saturated demand.andM;Each node holds information only about its immediate neighbors in thespanning tree rather than information about all nodes, and failed nodes canrecover necessary information from their neighbors.andP;  The algorithm does notrequire sequence numbers as it operates correctly despite message overtaking.andM;For Correspondence: Department of Computer Science, University of Queensland,St. Lucia, Queensland 4067, Australia.andM;Efficient (Stack) Algorithms of Analysis of Write-Back andandM;Sector Memories James G. Thompson and Alan Jay SmithandM;For the class of replacement algorithms known as stack algorithms, existinganalysis techniques permit the computation of memory miss ratios for allmemory sizes simultaneously in one pass over a memory reference string.andP;  Weextend the class of computations possible by this methodology in two ways.andO;First, we show how to compute the effects of copy-backs in write-back caches.andO;The key observation here it that a given block is clean for all memory sizesless than or equal to C blocks and is dirty for all larger memory sizes.andP;  Ourtechnique permits efficient computations for algorithms or systems usingperiodic write-back and/or block deletion.andP;  The second extension permitsstack analysis simulation for sector (or subblock) caches in which a sector(associated with an address tag) consists of subsectors (or subblocks) thatcan be loaded independently.andP;  The key observation here is that a subsector ispresent only in caches of size C or greater.andP;  Load forward prefetching in asector cache is shown to be a stack algorithm and its easily simulated usingour technique.andP;  Running times for our methods are only slightly higher thanfor a simulation of a single memory size using nonstack techniques.andM;For Correspondence: Lt.andP;  Col.andP;  J. G. Thompson, Joint Data Systems SupportCenter (JDSSC/C310), The Pentagon, Washington, DC 20301-7010; A. J. Smith,University of California, Dept.andP;  of Electrical Engineering and ComputerSciences, Berkeley, CA 94720.andM;ACM Transactions on Office Information Systems  October 1988andM;gIBIS: A Hypertext Tool for Exploratory Policy Discussion Jeff Conklin andMichael L. BegemanandM;This paper describes an application-specific hypertext system designed tofacilitate the capture of early deliberations.andP;  It implements a specificmethod, called Issue Based Information Systems (IBIS),  which has beendeveloped for use on large, complex design problems.andP;  The hypertext systemdescribed here, gIBIS (for graphical IBIS), makes use of color and ahigh-speed relational database server to facilitate building and browsingtyped IBIS networks.andP;  Further, gIBIS is designed to support the collaborativeconstruction of these networks by any number of cooperating team membersspread across a local area network.andP;  Early experiments suggest that the IBISmethod is still incomplete, but there is a good match between the tool andmethod even in this experimental version.andM;For Correspondence: MCC, Software Technology Program, 3500 West BalconesCenter Drive, Austin, TX 78759-6509.andP;  ARPA: conklin@-MCC.COM begeman@MCC.COM.andM;Object Lens: A &quot;Spreadsheet&quot; for Cooperative Work Kum-Yew Lai, Thomas W.andO;Malone, and Keh-Chiang YuandM;Object Lens allows unsophisticated computer users to create their owncooperative work applications using a set of simple, but powerful, buildingblocks.andP;  By defining and modifying templates for various semistructuredobjects, users can represent information about people, tasks, products,messages, and many other kinds of information in a form that can be processedintelligently by both people and their computers.andP;  By collecting theseobjects in customizable folders, users can create their own displays whichsummarize selected information from the objects in table or tree formats.andO;Finally, by creating semiautonomous agents, users can specify rules forautomatically processing this information in different ways at differenttimes.andM;The combination of these primitives provides a single consistent interfacethat integrates facilities for object-oriented databases, hypertext,electronic messaging, and rule-based intelligent agents.andP;  To illustrate thepower of this combined approach, we described several simple  examples ofapplications (such as task tracking, intelligent message routing, anddatabase retrieval) that we have developed in this framework.andM;For Correspondence: K.-Y.andP;  Lai, 10-174 Block 129, Bukit Merah View, Singapore0315, Republic of Singapore; T. W. Malone and K.-C.andP;  Yu, Sloan School ofManagement (E53-333), Massachusetts Institute of Technology, Cambridge, MA02139.andM;Work Group Structures and Computer Support; A Field Experiment J. D. Evelandand T. K. BiksonandM;It is frequently suggested that work groups that have computer technology tosupport activities such as text editing, data manipulation, and communicationdevelop systematically different structures and  working processes fromgroups that rely on more conventional technologies such as memos, phonecalls, and meetings.andP;  However, cross-sectional or retrospective researchdesigns do not allow this hypothesis to be tested with much power.andP;  Thisfield experiment created two task forces, each composed equally of recentlyretired employees and employees still at work but eligible to retire.andP;  Theywere given the identical tasks of preparing reports for their company onretirement planning issues, but they were randomly assigned to differenttechnology conditions.andP;  One group had full conventional office support; theother had, in addition, networked microcomputers with electronic mail androutine office software.andP;  Structured interviews were conducted four timesduring the year-long project; in addition, electronic mail activity waslogged in the on-line group.andP;  Although both groups produced effectivereports, the two differed significantly in the kind of work they produced,the group structures that emerged, and evaluations of their own performance.andO;Although the standard group was largely dominated by the employees throughthe extensive reliance on informal meetings, the electronic technology usedby the other tasks force allowed the retirees to exercise primary leverage.andO;We conclude that use of computer support for cooperative work results in bothquantitative and qualitative changes but that effective participation in suchelectronically supported groups requires significant investments of time andenergy on the part of its members to master the technology and a relativelyhigh level of assistance during the learning process.andM;For Correspondence: The Rand Corporation, 1700 Main St., Santa Monica, CA90406.andM;Diversity in the Use of Electronic Mail:  A Preliminary Inquiry Wendy E.andO;MackayandM;This paper describes a series of interviews that examine the ways thatprofessional office workers use electronic mail to manage their  daily work.andO;The purpose is to generate hypotheses for future research.andP;  A number ofimplications for the design of flexible mail systems are discussed.andM;Two principal claims are made.andP;  First, the use of electronic mail isstrikingly diverse, although not infinitely so.andP;  Individuals vary both inobjective measures of mail use and in preferred strategies for managing workelectronically.andP;  Feelings of control are similarly diverse and are related tothe size of the user's inbox, numbers of folders, and subscriptions todistribution lists.andP;  This diversity implies that one's own experiences withelectronic mail are unlikely to provide sufficient understanding of other'suses of mail.andP;  Mail designers should thus seek flexible primitives thatcapture the important dimensions of use and provide flexibility for a widerange of users.andM;The second claim is that electronic mail is more than just a communicationsystem.andP;  Users archive messages for subject retrieval, prioritize messages tosequence work activities, and delegate tasks via mail.andP;  A taxonomy of workmanagement is proposed in which mail is used for information management, timemanagement, and task management activities.andP;  Directions for future researchare suggested.andM;For Correspondence: Massachusetts Institute of Technology, Project Athena,Amherst St., Cambridge, MA 02139.andM;Guided Tours and Tabletops: Tools for Communicating inandM;a Hypertext Environment Randall H. TriggandM;The author of a complex hypertext document is often faced with the problem ofconveying the document's meaning to future readers through a shared computerenvironment.andP;  Two tools implemented in the NoteCards hypertext environment,guided tours and tabletops, allow authors to employ annotation, graphiclayout, and ordered presentation when communicating to readers.andP;  This paperdescribes these tools and gives examples of their use.andP;  Issues of remotepointing arising from an application in legal argumentation are discussed aswell as early work on the use of these tools to support sharing of hypertextstrategies among NoteCards users.andM;For Correspondence: Xerox Palo Alto Research Center, 3333 Coyote Hill Road,Palo Alto, CA 94304.andM;ACM Transactions on DatabasesandM;On the Translation of Releational Queries into Iterative Programs JohannChristoph Freytag and Natham GoodmanandM;This paper investigates the problem of translating set-oriented queryspecifications into iterative programs.andP;  The translation uses techniques offunctional programming and program transformation.andM;We present two algorithms that generate iterative programs from algebra-basedquery specifications.andP;  The first algorithm translates query specificationsinto recursive programs.andP;  Those are simplified by sets of transformationrules before the algorithm generates the final iterative form.andP;  The secondalgorithm uses a two-level translation that generates iterative programsfaster than the first algorithm.andP;  On the first level a small set oftransformation rules performs structural simplification before the functionalcombination on the second level yields the final iterative form.andM;For Correspondence: J. C. Freytag, European Computer-Industry ResearchCentre, D-8000 Munich, West Germany; N. Goodman, Kendall Square Research,Cambridge, MA 02139.andM;On Estimating the Cardinality of the Projection ofandM;a Database Relation Rafiul Ahad, K. V. Bapa Rao, and Dennis McLeodandM;We present an analytical formula for estimating the cardinality of theprojection on certain attributes of a subset of a relation in a relationaldatabase.andP;  This formula takes into account a priori knowledge of thesemantics of the real-world objects and relationships that the database isintended to represent.andP;  Experimental testing of the formula shows that it hasan acceptably low percentage error, and that its worst-case error is smallerthan the best-known formula.andP;  Furthermore, the formula presented here has theadvantage that it does not require a scan of the relation.andM;For Correspondence: R. Ahad, College of Business and Management, Universityof Maryland, College Park, MD 20742; K. V. Bapa Rao and D. McLeod, ComputerScience Department, Henry Salvatori Computer Science Center, University ofSouthern California, Los Angeles, CA 90089-0782.andM;Variable-Depth Trie Index Optimization:andM;Theory and Experimental Results R. Ramesh, A. J. G. Babu, and J. PeterKincaidandM;We develop an efficient approach to Trie index optimization.andP;  A Trie is adata structure used to index a file having a set of attributes as recordidentifiers.andP;  In the proposed methodology, a file is horizontally partitionedinto subsets of records using a Trie index whose depth of indexing is allowedto vary.andP;  The retrieval of a record from the file proceeds by &quot;steppingthrough&quot; the index to identify a subset of records in the file in which abinary search is performed.andP;  This paper develops a taxonomy of optimizationproblems underlying variable-depth Trie index construction.andP;  All theseproblems are solvable in polynomial time, and their characteristics arestudied.andP;  Exact algorithms and heuristics for their solution are presented.andO;The algorithms are employed in CRES--an expert system for editing writtennarrative material, developed for the Department of the Navy.andP;  CRES usesseveral large-to-very-large dictionary files for which Trie indexes areconstructed using these algorithms.andP;  Computational experience with CRES showsthat search and retrieval using variable-depth Trie indexes can be as much assix times faster than pure binary search.andP;  The space requirements of theTries are reasonable.andP;  The results show that the variable-depth Triesconstructed according to the proposed algorithms are viable and efficient forindexing large-to-very-large files by attributes in practical applications.andM;For Correspondence: R. Ramesh, School of Management, State Unviersity of NewYork at Buffalo, Buffalo, NY 14260; A. J. G. Babu, Department of Industrialand Management Systems Engineering, University of South Florida, Tampa, FL33602; J. P. Kincaid, Army Research Institute, Department of the Army, NavalTraining Center, Orlando, FL 32813.andM;Data Replicas in Distributed Information Services H. M. GladneyandM;In an information distribution network in which records are repeatedly read,it is cost-effective to keep read-only copies in work locations.andP;  This paperpresents a method of updating replicas that need not be immediatelysynchronized with the source data or with each other.andP;  The method allows anarbitrary mapping from source records to replica records.andP;  It is fail-safe,maximizes workstation autonomy, and is well suited to a network with slow,unreliable, and/or expensive communications links.andM;The algorithm is a manipulation of queries, which are represented as shortencodings.andP;  When a response is generated, we record which portion of thesource database was used.andP;  Later, when the source data are updated, thisinformation is used to identify obsolete replicas.andP;  For each workstation, theidentify of obsolete replicas is saved until a workstation process asks forthis information.andP;  This workstation process deletes each obsolete replica,and replaces it by an up-to-date version either promptly or the next time theapplication asks for this particular item.andP;  Throughout, queries are groupedso that the impact of each source update transaction takes effect atomicallyat each workstation.andM;Optimizations of the basic algorithm and outlined.andP;  These overlap changedissemination with user service, allow the mechanism to be hidden within thedata delivery subsystem, and permit very large networks.andM;For Correspondence; IBM Almaden Research Center, San Jose, CA 95120.andM;Further Results on the Security of Partitioned DynamicandM;Statistical Databases Mary McLeishandM;Partitioning is a highly secure approach to protecting statistical databases.andO;When updates are introduced, security dependents on putting restrictions onthe sizes of partition sets which may be queried.andP;  To overcome this problem,attempts have been made to add &quot;dummy&quot; records.andP;   Recent work has shown thatthis leads to high information loss.andM;This paper reconsiders the restrictions on the size of partitioning setsrequired to achieve a high level of security.andP;  Updates of two records at atime were studied earlier, and security was found to hold if the sizes of thepartition sets were kept even.andP;  In this paper an extended model is presented,allowing very general updates to be performed.andP;  The security problem isthoroughly studied, giving if and only if conditions.andP;   The earlier result isshown to be part of a corollary to the main theorem of this paper.andO;Alternatives to adding dummy records are presented and the practicalimplications of the theory for the database manager  are discussed.andM;For Correspondence: Departments of Computing Science/Statistics, Universityof Guelph, Guelph, Ontario N1G 2W1, Canada.andM;AGM: A Dataflow Database Machine Lubomir Bic and Robert L. HartmannandM;In recent years, a number of database machines consisting of large numbers ofparallel processing elements have been proposed.andP;  Unfortunately, there aretwo main limitations in database processing that prevent a high degree ofparallelism; these are the available I/O bandwidth of the underlying storagedevices and the concurrency control mechanisms necessary to guarantee dataintegrity.andP;  The main problem with conventional approaches is the lack of acomputational model capable of utilizing the potential of any significantnumber of processing elements and storage devices and, at the same time,preserving the integrity of the database.andM;This paper presents a database model and its associated architecture, whichis based on the principles of data-driven computation.andP;  According to thismodel, the database is represented as a network in which  each node isconceptually an independent, asynchronous processing  element, capable ofcommunicating with other nodes by exchanging messages along the network arcs.andO;To answer a query, one or more such messages, called tokens, are created andinjected into the network.andP;  These  then propagate asynchronously through thenetwork in search of results satisfying the given query.andM;The asynchronous nature of processing permits the model to be mapped onto acomputer architecture consisting of large numbers of independent disk unitsand processing elements.andP;  This increases both the available I/O bandwidth aswell as the processing potential of the machine.andP;  At the same time, newconcurrency control and error recovery mechanisms are necessary to cope withthe resulting parallelism.andM;For Correspondence: Department of Information and Computer Science,University of California, Irvine, CA 92664.andM;ACM Transactions on Mathematical SoftwareandM;Sparse Matrix Test Problems Iain S. Duff, Roger G. Grimes, and John G. LewisandM;We describe the Harwell-Boeing Sparse matrix collection, a set of standardtest matrices for sparse matrix problems.andP;  Our test set comprises problems inlinear systems, least squares, and eigenvalue calculations from a widevariety of scientific and engineering disciplines.andP;  The problems range fromsmall matrices, used as counter-examples to hypotheses in sparse matrixresearch, to large test cases arising in large-scale computation.andP;  We offerthe collection to other researchers as a standard benchmark for comparativestudies of algorithms.andP;  The procedures for obtaining and using the testcollection are discussed.andP;  We also describe the guidelines for contributingfurther test problems to the collection.andM;For Correspondence: I. S. Duff, Computer Science and Systems Division,Harwell Laboratory, Oxfordshire OX11 0RA, UK; R. G. Grimes and J. G. Lewis,Engineering and Scientific Services Division, Boeing Computer Services, P.O.andO;Box 24346, Seattle, WA 98124-0346.andM;A Block 6(4) Runge-Kutta Formula for Nonstiff Initial ValueandM;Problems J. R. CashandM;A new selection is made for an efficient two-step block Runge-Kutta formulaor order 6.andP;  The new formula is developed using some of the efficiencycriteria recently investigated by Shampine, and as a result, a block formulawith much improved performance is obtained.andP;  An important property of thisnew formula is that there is a &quot;natural&quot; interpolating polynomial available.andO;This can be used to compute approximate solution values at off-step pointswithout the need to compute any additional function evaluations.andP;  The qualityof this interpolant is examined, and it is shown to have certain desirableproperties.andP;  The performance of the new block Runge-Kutta formula isevaluated using the DETEST test set and is shown to be more efficient thancertain other standard Runge-Kutta formulas for this particular test set.andM;For Correspondence: Department of Mathematics, Imperial College, SouthKensington, London SW7 2BZ, England.andM;ALGORITHM 670andM;A Runge-Kutta-Nystrom Code R. W. Brankin, I. Gladwell, J. R. Dormand P. J.andO;Prince, and W. L. SewardandM;A robust, reliable, and efficient code implementing recently developedRunge-Kutta-Nystrom (RKN) formulas is described.andP;  Two embedded formula pairsare provided.andP;  The lower order pair allows interpolation.andP;  The structure ofthe code is based on a modular approach to the design  of software for thenumerical solution of ordinary differential equations.andM;For Correspondence: R. W. Brankin, Numerical Algorithms Group Ltd., WilkinsonHouse, Jordan Hill Road, Oxford OX2 8DR, England; J. R. Dormand, Departmentof Mathematics, Teesside Polytechnic, Middlesbrough, Cleveland TS1 3BA,England; I. Gladwell, Department of Mathematics, Southern MethodistUniversity, Dallas, TX 75275; P. J. Prince, Department of Computer Science,Teesside Polytechnic, Middlesbrough, Cleveland TS1 3BA, England; W. L.andO;Seward, Department of Computer Science, University of Waterloo, Waterloo,Ontario N21, 3G1, Canada.andM;Performance Evaluation of Programs for Certain Bessel Functions W. J. Cadyand L. StoltzandM;This paper presents methods for performance evaluation of the K Besselfunctions.andP;  Accuracy estimates are based on comparisons involving themultiplication theorem.andP;  Some ideas for checking robustness are also given.andO;The techniques used here are easily extended to the Y Bessel functions and,with a little more effort, to the I and J functions.andP;  Details on a specificimplementation for testing the K Bessel functions are included.andM;For Correspondence: Mathematics and Computer Science Division, ArgonneNational Laboratory, Argonne, IL 60439-4801.andM;Numerical Experience with Sequential Quadratic ProgrammingandM;Algorithms for Equality Constrained Nonlinear Programming David F. Shanno andKang Hoh PhuaandM;Computational experience is given for a sequential quadratic programmingalgorithm when Lagrange multiplier estimates.andP;  Hesian approximations, andmerit functions are varied to test for computational efficiency.andP;  Indicationsof areas for further research are given.andM;For Correspondence: D. F. Shanno, RUTCOR, Hill Center, Busch Campus, NewBrunswick, NJ 08903; K. H. Phua, Department of Information Systems andComputer Science, National University of Singapore, Kent Ridge, Singapore0511, Republic of Singapore.andM;An Improved Primal Simplex Variant forandM;Pure Processing Networks Michael D. Chang, Chou-Hong J. Chen, and MichaelEngquistandM;In processing networks, ordinary network constraints are supplemented byproportional flow restrictions on arcs entering or leaving some nodes.andP;  Thispaper describes a new primal partitioning algorithm for solving pureprocessing networks using a working basis for variable dimension.andP;  In testingagainst MPSX/370 on a class of randomly generated problems, a FORTRANimplementation of this algorithm was found to be an order-of-magnitudefaster.andP;  Besides indicating the use of our  methods in stand-alone fashion,the computational results also demonstrate the desirability of using thesemethods are a high-level module in a mathematical programming system.andM;ACM Transactions on Graphics  January 1989andM;The Circle-Brush Algorithm K. C. Posch and and W. D. FellnerandM;Brushing commonly refers to the drawing of curves with various line widths inbit-mapped graphics systems.andP;  IT is best done with circles of suitablediameter so that a constant line width, independent of the curve's slope, isobtained.andP;  Allowing all possible integer diameters corresponding to allpossible integer line widths results in every second width having an oddvalue.andP;  Thus, the underlying circle algorithm must be able to handle bothinteger and half-integer radii.andP;  Our circle-brush algorithm handles bothsituations and produces a &quot;best approximation&quot;: All grid points producedsimultaneously minimize (1) the residual, (2) the Euclidean distance to thecircle, and (3) the displacement along the grid line from the intersectionwith the circle.andP;  Our circle-brush algorithm was developed in carefulconsideration of its implementation in VLSI.andM;For correspondence:  Institutes for Information Processing, Graz Universityof technology and Austrian Computer Society, Schie[beta]stattgasse 4a, A-8010Graz, Austria.andM;Intersection Algorithms for Lines and Circles A. E. Middleditch, T. W. Stacyand S. B. TorandM;This paper presents a unified representation scheme for the implicitequations of points, lines, and circles.andP;  An associated set of geometricalgorithms operates successfully on degenerate and nearly degenerategeometry, and when necessary produces degenerate geometric results.andO;Computation errors are interpreted geometrically in order to establishpreconditions for reliable results and requirements on the resolution ofcomputer arithmetic.andP;  The algorithms thus provide a basis for the wide rangeof geometric constructions required by computer-aided drafting and designsystems.andM;For correspondence: A. E. Middleditch, Computer-Aided Engineering Group,Physics Department, Brunel University, Uxbridge UB8 3PH, U.K.; T. W. Stacey,School of Engineering and Science, Polytechnic of Central London, 115 NewCavendish Street, London W1M 8JS, U.K.; and S. B. Tor, Hewlett Packard Asia,Ltd., 1150 Depot Road, Singapore 0401.andM;For Correspondence:  M. D. Chang and C.-H.andP;  J. Chen, School of BusinessAdministration, Gonzaga University, Spokane, WA99258; M. Engquist, ClevelandConsulting Associates, 3415 Greystone Drive, suite 204, Austin, TX 78731.andM;ALGORITHM 671andM;FARB-E-2D: Fill Area with Bicubics on Rectangles--AandM;Contour Plot Program Albrecht PreusserandM;An algorithm plotting contour lines for discrete values z.sub.ij given at thenodes of rectangular mesh is described.andP;  A bicubic Hermite  polynomial f(x,y)is determined for every rectangle of the mesh, interpolating the Z.sub.ij andthe derivative Z.sub.x, Z.sub.y, and Z.sub.xy.andP;  The derivatives areoptionally computed by the algorithm.andP;  The contours found are normally smoothcurves.andP;  They consist of polygons approximating intersections with thebicubics.andP;  It is possible to fill the areas between them with certain colorsor patterns.andP;  This is done with a piecewise technique rectangle by rectangle.andO;The method for finding the points of the polygons is shortly reviewed, andsome numerical problems are pointed out.andP;  The algorithm has a flexible,easy-to-use interface and is easily installed with all plotting systems,provided that a fill-area command is available.andP;  A GKS interface may be used.andM;For Correspondence: Fritz-Haber-Institut, Faradayweg 4-6, D-1000 Berlin 33,West Germany.andM;A Parallel B-Spline Surface Fitting Algorithm Fuhua Cheng and ArdeshirGoshtasbyandM;A parallel fitting algorithm using uniform bicubic B-spline surfaces ispresented.andP;  This algorithm is based on the observation that a tensor productspline surface fitting problem can be split into two spline curve fittingproblems, and each of these problems can be carried out in parallel by cyclicreduction.andP;  Using this approach, the control points of a uniform bicubicB-spline surface that interpolates a grid on m X n points can be found inO(log m + log n) time on m processors.andP;  Furthermore, since smaller systems ofequations are solved in the algorithm, the accumulated error resulting fromthis approach is smaller than that of the traditional algorithms.andM;For Correspondence: Department of Computer Science, University of Kentucky,Lexington, KY 40506-0027.andM;Active Zones in CSF for Accelerating Boundary Evaluation,andM;Redundancy Elimination, Interference Detection, andandM;Shading Algorithms Jaroslaw R. Rossignac and Herbert B. VoelckerandM;Solids defined by Boolean combinations of solid primitives may be representedin constructive solid geometry (CSG) as binary trees.andP;  Most CSG-basedalgorithms (e.g., for boundary evaluation, graphic shading, interferencedetection) do various forms of set-membership classification by traversingthe tree associated the solid.andP;  These algorithms usually generateintermediate results that do not contribute to the final result, and hencemay be regarded as redundant and a source of inefficiency.andP;  To reduce suchinefficiencies, we associate with each primitive A in a tree S an active zoneZ that represents the region of space where changes to A affect the solidrepresented by S, and we use a representation of Z instead of S forset-membership classification.andP;  In the paper  we develop a mathematicaltheory of active zones, prove that they correspond to the intersection ofcertain nodes of the original trees, and show how they lead to efficient newalgorithms for boundary evaluation, for detecting and eliminating redundantnodes in CSG trees, for interference (null-set) detection, and for graphicshading.andM;For Correspondence: J. R. Rossignac, IBM Research Division, Yorktown Heights,NY 10598; and H. B. Voelcker, Cornell University, Ithaca, NY 14853.andO;</TEXT></DOC>