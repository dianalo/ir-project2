<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO> ZF32-200-155 </DOCNO><DOCID>10 535 125</DOCID><JOURNAL>Datamation  March 15 1991 v37 n6 p62(4)* Full Text COPYRIGHT Cahners Publishing Co. 1991.andM;</JOURNAL><TITLE>Miles to go. (future of computing)</TITLE><AUTHOR>Moad, Jeff.andM;</AUTHOR><SUMMARY>Technological innovations in computing will occur more often andaffect greater numbers of people and organizations in the 1990sthan they have in the past.andP;  Advances in semiconductor, packagingand optical technologies will allow manufacturers to put greaterpower and memory capacity in ever-shrinking spaces.andP;  Newnetwork-management tools will emerge.andP;  I/O technology will change:users will be able to use voice and visual input, while computerswill be able to display full-motion holographs.andP;  Softwareproductivity will improve dramatically as tools move beyond theobject-oriented paradigm.andP;  Executives from Apple, IBM, XeroxCorp's Palo Alto Research Center (PARC) and the Media Laboratoryat the Massachusetts Institute of Technology all give their viewson future computing trends.andM;</SUMMARY><DESCRIPT>Topic:     Future of ComputingForecastingFuture Technologies.andO;Feature:   illustrationphotograph.andM;</DESCRIPT><TEXT>Forty years of commercial computing have certainly spawned many technologicaladvancements, but contrary to what some believe, the industry is by no meansmature in a technological sense.andP;  In fact, what will be coming up in the nextdecade and beyond may be even more exciting than what preceded it.andP;  If that'snot completely certain, what is is that the technological innovations willcome at a faster pace than ever before and will affect larger numbers ofpeople and organizations.andM;The more intriguing breakthroughs top researchers and scientists are workingon include: Continuing rapid advances in base-level semiconductor, packagingand optical technologies, which will enable vendors to pack ever morecomputing power and storage capacity into ever less space.andM;New tools to help IS  professionals understand and manage computer networksthat have grown so large they have begun to behave almost independently oftheir human creators.andM;New ways for users and computers to communicate: for users voice and visualinput; for computers, more expressive ways of displaying information,including full-motion holographic images.andM;New languages and advanced compiler techniques that will allow softwaredevelopers to dramatically increase their productivity by moving well beyondthe object-oriented paradigm.andM;&quot;The whole juggernaut of enabling technologies is going to go steaming aheadat the same incredible rates that we've seen for the last 15 to 20 years,&quot;predicts John Armstrong, IBM's vice president for science and technology.andO;The engine that has driven this revolution over the last 20 years or so isnot going to run out of gas.andP;  &quot;andM;Fueling innovation into the next generation-as it has for the last 40years-will be continuing improvements in base-level technologies.andO;Semiconductor vendors will continue to provide improvements inminiaturization, packing more and more circuits onto a chip.andP;  That means morecomputing power and memory on ever smaller platforms, opening up thepossibility even of small, hand-held devices with the power to drive newtypes of interfaces using MIPS-hungry voice-.andP;  and handwriting recognitiontechnologies.andM;Continuing advances in miniaturization also means ever falling prices forcomputing power.andP;  As semiconductor fabrication and packing techniques improveand permit in excess of a million circuits on a chip, IBM's Armstrongpredicts, a dollar will buy between eight and 30 times more computing powerover the next 10 years.andP;  That trend will make it economical to usesemiconductor-based technologies in new ways, such as in color, flat-paneland field-effect displays, which will replace tube displays.andP;  Such displayswill provide brighter graphics and-perhaps just as significant-will cut downon dangerous emissions, according to John Wise, chief technical officer atUnisys Corp. in Blue Bell, Pennsylvania.andM;From Head To DiskandM;Improvements in component miniaturization and reliability also will lead tobreakthroughs in storage technologies.andM;There's still a couple of orders of magnitude improvement left inconventional disk drive technologies, as we reduce head-to-disk flyingheights and introduce things like perpendicular recording,&quot; predicts Bob O.andO;Evans, a partner at Technology Strategies andamp; Alliances in Menlo Park, Calif.,andO;and one of the creators of the breakthrough IBM 360 series mainframes in the1960s.andM;Evans and others also see newer storage approaches, such as opticaltechnologies, maturing to the point that they'll increase storage capacitiesand economies.andP;  Vendors already are combining optical technologies with moreproven magnetic-recording techniques to yield multigigabyte, rewritablestorage devices.andM;Beyond that, researchers at the Microelectronics and Computer TechnologyCorp. in Austin are experimenting with optical holographic technologies,which they say have the potential to revolutionize data storage.andP;  MCC'sso-called Bobcat project has produced a second-generation prototype of arewritable storage device that features high capacities and data transferrates of up to 1.2 gigabytes per second.andP;  MCC senior vice president BarryWhalen says the Bobcat device will be ideal for storing multimedia data suchas video images.andM;In the end, scientists predict, ever smaller and cheaper compute power andstorage will mean one thing.andP;  As IBM's Armstrong puts it:  All data will beon line.andP;  Everybody will be a user.andP;  Everybody will be connected.&quot;andM;A World On LineandM;Of course, that prospect raises new challenges-and new opportunities fortechnology breakthroughs.andP;  When everyone is on line, for example, how do youdeal with the massive burden that will be placed on network resources? How doyou manage networks that connect hundreds or thousands of different types ofdevices or even predict their behavior? Scientists like Armstrong believethat as high-speed fiber optic cable becomes pervasive, linking homes,offices and local-area networks around the world, the need for increasedphysical bandwidth will be satisfied.andP;  And projects like the U.S.andO;government's new High-Performance Computing Initiative's 1-gigabit networkproject will lead to innovative new ways to use that increased bandwidth.andM;But that still leaves open the question of understanding and managing themassive new data networks.andP;  &quot;Up until now, we've concentrated on the easypart-creating standard ways of getting bits from here to there,&quot; saysUnisys's Wise.andP;  &quot;Now comes the hard part-determining what those bits are,what we want them to do and how to provide security and management to globalnetworks.&quot;andM;At Xerox Corp.'s Palo Alto Research Center (PARC), scientists predict that ascomputer networks continue to grow larger users will need completely newtools and techniques for understanding and managing them.andP;  Xerox researchfellow Bernardo Huberman is leading a group that is developing such tools.andO;Without them, he says, networks, as they grow, may become increasinglychaotic, virtually taking on a mind of their own.andM;As the network gets very large, it becomes more and more like some kind ofspecies that is coexisting with us,&quot; says Huberman.andP;  In attempting to managesuch networks, it makes little sense to look at the performance of eachindividual node, he continues.andP;  What's needed is a much higher levelunderstanding of how the network is behaving as a whole.andM;PARC's research to date has focused on looking at large network somethinglike economic system PARC researchers, in project called Spawn and Strand,have found they can at least make network performance less chaotic byenforcing a system of rewards for systems and applications that perform well.andO;For example, an application that makes the right decisions about whichservers to call would be rewarded by being given more resources, such as morememory.andP;  Inefficient applications/ would be give fewer resources.andP;  We are nowtrying to model some of the properties we've observed and build network andapplication management tools,&quot; says Huberman.andM;Beyond those tools, Huberman predicts, will be breakthroughs in programminglanguages and techniques that will add intelligence to net work applicationsso they can automatically sort through the vast amount of data surgingthrough huge networks and present only what is pertinent to the user.andP;  Westill don't have a good language for programming networks and distributedcomputation,&quot; says Huberman.andM;PARC alumnus and current Apple Computer Inc. fellow Alan Kay predicts that anew form of programming, which he calls  &quot;agent-oriented&quot; programming, willone day emerge to help applications sift through the mass of data availableon large networks.andP;  A more intelligent alternative to object-orientedprogramming, Kay says, agent-oriented programming will be based on artificialintelligence languages such as Inference Corp.'s ART, As such, the approachwill make use of AI techniques like inferencing, which will giveself-defining agents in a system the ability to learn what types ofinformation a user or application would be interested in seeing.andP;  The abilityfor software to understand the needs of the user will introduce a newrelationship between systems and people, and it will make possible new typesof interfaces, says Kay.andP;  The icon-based interfaces we developed in the '70swere oriented toward being able to easily teach people about the system.andP;  Thenew interfaces will be based on teaching the system about what the userneeds.andP;  &quot;andM;Kay and others also predict that users in the near future will be given new,more expressive ways to tell computers exactly what they want.andP;  Researchersat the Massachusetts Institute of Technology's Media Laboratory, for example,are currently hard at work on enabling computers to understand not only humanspeech but also visual images.andM;Voice and visual interfaces will bring two areas of significant change tocomputing,&quot; predicts Nicholas Negroponte, the Media Lab's director.andP;  &quot;First,people will be able to deal with computers in passing, without having to sitdown and overtly type on a keyboard or move a mouse.andP;  In that way, our use ofcomputers can be more concurrent with other things we do.andP;  And, secondly,particularly with visual recognition, we can use what I call 'subcarriers ofinformation.' For example, the system will be able to see our facialexpressions and read information from that.&quot;andM;Scientists like Kay and Negroponte predict that computer recognition ofcontinuous human speech will be a reality by the middle of the 1990s.andO;Recognition of visual images is a tougher problem, but well within reach,says Negroponte.andM;At the same time, Negroponte says, scientists are making surprisingly rapidprogress toward creating revolutionary new ways for computers to presentinformation to people.andP;  The Media Lab, for example, recently demonstrated thefirst computer-generated moving holographic image.andP;  The 16,000-processorConnection Machine supercomputer is capable of creating incrediblyhigh-resolution images and projecting them at 30 frames per second.andP;  Usingit, MIT researchers created a 1inch holographic cube that responded tochanges in real time.andP;  &quot;We're still not quite to the level of Star Wars,&quot;says Negroponte, &quot;but in another 10 years, we could be.andP;  &quot;andM;An Emphasis On ProductivityandM;While some scientists work on improving communication between computers andtheir users, others are attacking what undoubtedly continues to be the mostsignificant bottleneck in the IT industry: the gap between the speed withwhich engineers can develop new hardware and the time it takes programmers towrite software for it.andP;  &quot;There's still about a 10-year gap between hardwareand software, and so far we haven't done much to close that,&quot; says PeterWeinstein, a research director at ATandamp;T Bell Laboratories in Murray Hill, NJ.andM;A Broad View of LanguagesandM;But that doesn't mean software scientists aren't trying.andP;  At IBM's AlmadenResearch Center in San Jose, for example, researchers led by IBM Fellow JohnBackus continue work on FL, a new language that Backus says could bring a10-fold improvement in the efficiency and productivity of software developersand maintainers.andP;  FL, which stands for Function Level, represents nearly 20years of work by Backus to create a style of programming that would allowdevelopers to stop what he calls the repetitive &quot;word jockeying&quot; forced onthem by lower level languages like COBOL and take a very broad view ofprograms and data.andM;Backus says his group recently began proving some of his theories using thefirst FL optimizing compiler.andP;  &quot;We believe we're beginning to prove out theviability of this technology,&quot; he says.andM;Taking a very different approach to the same problem are researchers at MCC.andO;According to Whalen, the consortium next month will kick off what it callsits &quot;cooperative programming&quot; project, an effort to provide productdevelopers with a method for linking hardware and software development fromthe initial design phase all the way through implementation.andP;  The projectwill leverage a number technologies, including an object-oriented databasealready developed at MCC; special groupware to keep hardware and softwaredevelopment in lockstep; and object-oriented extensions to the VHDL hardwaredescription language, which will be used for simulation.andM;&quot;In the past, we have always developed the hardware first and then thesoftware, which became the acing item,&quot; says Whalen.andP;  Very often, the lack ofsoftware ha  led to the failure of technologies,  or it's taken years forthem to catch on.andP;  But product cycles are getting shorter,  and we just don'thave time to wait for the software any more.andO;</TEXT></DOC>