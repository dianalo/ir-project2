<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-276-672  </DOCNO><DOCID>08 276 672.andM;</DOCID><JOURNAL>IBM Systems Journal  March 1990 v29 n1 p141(24)* Full Text COPYRIGHT International Business Machines Corp. 1990.andM;</JOURNAL><TITLE>REASON: an intelligent user assistant for interactiveenvironments.andO;</TITLE><AUTHOR>Prager, J.M.; Lamberti, D.M.; Gardner, D.L.; Balzac, S.R.andM;</AUTHOR><SUMMARY>The provision of intelligent user assistance has been an ongoingproblem in designing computer interfaces.andP;  Interactive computingenvironments must support expert as well as novice users whenproviding advice for error correction and answers to questionsdirected to a system.andP;  To address these issues, we haveinvestigated the application of fairly well-understood artificialintelligence techniques in novel ways to provide intelligent help.andO;This paper describes the design methodology used to build REASON(Real-time Explanation And SuggestiON), an intelligentuser-assistant prototype for a windowed, multitasking environment.andO;REASON's central component is an inference engine that solvesproblems arising from a user's activity.andP;  When the user makes oneof several different kinds of errors, the inference engine offersdynamically generated suggestions about what the user might haveintended.andP;  The user can also query REASON using natural language.andO;In addition to providing suggestions of corrected input or answersto questions, REASON can provide two complementary types ofexplanations of these responses, derived from the inferences thatled to them.andP;  (Reprinted by permission of the publisher.)andM;</SUMMARY><DESCRIPT>Product:   REASON (Computer system) (product development).andO;Topic:     Expert SystemsSystem DevelopmentReal-Time SystemsIntelligent DevicesSystem Design.andO;Feature:   illustrationchart.andO;Caption:   Model of REASON user-assistant design. (chart)REASON problem solver. (chart)Explanation process. (chart)andM;</DESCRIPT><TEXT>REASON: An intelligent user assistant for interactive environments Theprovision of intelligent user assistance has been an ongoing problem indesigning computer interfaces.andP;  Interactive computing environments mustsupport expert as well as novice users when providing advice for errorcorrection and answers to questions directed to a system.andP;  To address theseissues, we have investigated the application of fairly well-understoodartificial intelligence techniques in novel ways to provide intelligent help.andO;This paper describes the design methodology used to build REASON (Real-timeExplanation And SuggestiON), an intelligent user-assistant prototype for awindowed, multitasking environment.andP;  REASON's central component is aninference engine that solves problems arising from a user's activity.andP;  Whenthe user makes one of several different kinds of errors, the inference engineoffers dynamically generated suggestions about what the user might haveintended.andP;  The user can also query REASON using natural language.andP;  Inaddition to providing suggestions of corrected input or answers to questions,REASON can provide two complementary types of explanations of theseresponses, derived from the inferences that led to them.andM;Much of the recent work in designing help systems for computer users has beeninfluenced by the difficulties that people have in learning how to interactwith computers.andP;  [1-4]  However, one of the most common, yet arguably leastsuccessful, computer applications is on-line user assistance.andM;In studying new user interface technology, there is a considerable base ofwork in the areas of contextual assistance, user modeling, planning andproblem solving, and natural-language processing.andP;  Much research work hasbeen undertaken investigating the role that each plays in providing on-lineassistance for computer users.andP;  The focus of most research projects onadvisory systems has been on depth of investigation of a particularcomponent, rather than integrating multiple components to address the problemof user assitance.andP;  [5-8]  These projects fall primarily into two categories:(1) projects that have been the source of exciting speculation as opposed touseful technology, and (2) projects that have been tightly bound toreal-world tasks or the laboratory, and thus rarely press forward thefundamental issues that comprise the central goals of artificial intelligence(AI).andP;  Furthermore, the effectiveness of most systems development in researchenvironments has not been studied empirically beyond prototyping functions todemonstrate research propositions.andP;  For the most part, no feedback onperformance has been acquired from users.andP;  This situation contributes to thefact that there are essentially no commercially available systems thatintegrate these features.andM;Contex-dependent help is a popular issue in the current literature.andP;  Contextdependency usually refers to a discourse-based assistance that is tailored toa user's plans for best accomplishing goals.andP;  Inferencing strategies are usedto identify such plans and generate advice at the appropriate level ofdetail.andP;  For a more extensive discussion of context dependency refer toReferences 9 and 10.andP;  Prototype systems (e.g., the TOPS-20 operating system[11]) have been developed that incorporate contextual help, using planrecognition based on AI methods.andP;  [8,12,13]  Information about the currentstate of the interaction can be represented by a plan or plan hypothesis thatmay be only partially developed and instantiated.andP;  For example, a systemknown as the system architect's apprentice (SARA) employs a technique wherebyhelp is integrated into the grammar and then processed by a combined parsergenerator and an integral help generator.andP;  [14]  The integral help generatorhas a concise representation of the user interface available to it, makingcontextual help easier to generate.andP;  This technique provides for consistencyand accuracy of syntactic assistance at a lower level and more in-depthinformation at a higher level.andM;Despite the attention given to context-dependent assistance, it is not easyto see how the various techniques offered can solve the problems associatedwith reliably determining users' plans.andP;  This is partly because it isdifficult to identify and map plan-driven behavior to context-dependentadvice, and partly because most models of question-answering are moreinclined towards database interrogation than requests for help orexplanation.andP;  [9]  Also, much of the recent work on contextual assistanceidentifies the importance of plans but fails to include in knowledge basesexplicit discourse information needed to satisfy pedagogical goals.andM;Similarly, the development of predictive user models has been seen ascritical for advisory systems.andP;  [15]  Quinn and Russell [16] point out thatthe value of an intelligent interface is extremely limited if it is not basedon a strong model of the user.andP;  To a large extent, the work on user modelinghas presumed that users are homogeneous in relevant ways.andP;  Although it istrue that, for the majority of users, a system built on such a principle isbetter than it would have been without homogeneity assumptions, it is nottrue that such a system is likely to be the best that could be produced.andM;Despite this emphasis, some researchers have attempted to individualize usermodels.andP;  In an interactive help facility for Scribe, [17] which is a documentformatter, Rich [18] has incorporated a user model based on patterns of usercommands.andP;  In Scribe, the appropriate level of a question response is afunction of the level of the question itself and the level of knowledge ofthe user who asked the question.andP;  In presenting the correct level ofexplanation, the system maintains a dictionary that contains an entry foreach of the things that can occur in a set of condition-action rulesdescribing knowledge about Scribe.andP;  Associated with each entry is informationthat describes when it may be appropriate to mention the associated conceptsin an explanation.andP;  In answering a specific question, the system locates therule(s) that apply and compares what it knows about the concepts in therule(s) to what it knows about the user, based on patterns of commands issuedby the user during a period of time.andM;Scribe exemplifies a technique for user modeling that is based on inferring auser's skill level and specific problems and errors from actions andresponses.andP;  This technique reflects a desire to place most of the burden ofconstructing the model on the system and thus raises concerns regarding thereliability of user classifications.andM;The feasibility of a more natural approach to user-computer interaction isusually shown by building and demonstrating a prototype system whose aim isto minimize the training required to interact effectively and efficientlywith a computer.andP;  To most persons, this means supplying a system that allowsthe use of the words and syntax of a language used in common discourse, suchas standard English.andP;  [19-22]  Most natural-language systems exist aslarge-scale prototypes that can recognize and interpret fairly extensivevocabularies and sentence structures.andP;  [23-26]  Unfortunately, very few ofthse prototype systems have been evaluated by actually measuring userperformance through extended system usage.andP;  Most of the commerciallyavailable systems have not been on the market long enought to have beenthoroughly evaluated.andP;  Thus, it is nearly impossible to make empiricallyreliable conclusions for or against any particular commercially availablenatural-language technology.andM;In each of the aforementioned areas of research, the emphasis has been ondeveloping state-of-the-art techniques to implement theoretical propositionsregarding the type and amount of assistance users need when attempting toperform an action on the computer.andP;  Numerous programming methodologies,including AI techniques, have been applied to solving the problem of&quot;intelligent help.&quot;andP;  Most of the focus has been on perfecting the varioustechniques to a level of depth that advances scientific inquiry.andP;  Althoughthese aims have been well-appreciated and justified, little if any technologycurrently exists that effectively integrates these well-documented techniquesinto a modular system that addresses the needs of a spectrum of users rangingfrom the computer novice to experienced programmers.andP;  The opportunity for thepractical implementation of these concepts and techniques to providecontextual user assistance currently exists and needs to be addressed.andM;In general, and especially in the AI realm, there has been a slow butpervasive recognition of the fact that the scientific advancement ofprogramming techniques has overshadowed a realistic assessment of the needfor enhanced performance and usability in computer systems.andP;  This reckoningleads to the realization that in the past much of the research work ondesigning intelligent help systems has focused on solving AI problems to theexclusion of practical concerns about implementing systems in a robustmanner.andM;Our work should be viewed as an extension of prior work that has been done oncontextual user assistance, using natural language as a means ofuser-computer discourse.andP;  The purpose of our work is to enhance thehelpfulness of a computer system to users through the integration andapplication of several well-understood AI techniques in solving real problemsstemming from the usage of commercial systems.andP;  An eminent outcome of thiseffort is the design of intelligent command lines that lend themselves to apractical implementation for commercial systems.andP;  It is our intention toensure that this design be fully conforming to the IBM Systems ApplicationArchitecture (SAA) and Common User Access (CUA) standards.andP;  [27]  Thesestandards govern software interfaces, protocols, and conventions for humaninteraction with applications and system services, communication mechanismsthat interconnect SAA systems, and interfaces for program development.andP;  [28]andM;A primary distinction between our work and that of past researchers is thatwe are focusing on breadth of system function.andP;  Specifically, we concentrateon an interactive computing environment in which there often is not only morethan one way to explain something, but also more than one way to dosomething.andP;  We take a user's goal-centered approach to problem solving.andO;Therefore, deducing the user's goals is intrinsic to our system.andP;  In thisapproach, the context of interaction is a determining factor in thegeneration process that produces the form and content of the system'ssuggestion(s) and explanation(s).andP;  Our suggestions are dynamically generatedand automatically supplemented by complementary forms of explanation based ona model of the user.andP;  Our objective is to maximize the flexibility of theuser's interaction with the help function through mixed interaction modes andto tailor advice to the specifics of error conditions.andP;  This objective leadsto a second aspect of the work that focuses on natural language as an inputmedium.andP;  In a truly interactive computing environment, user assistance basedon a human-advisor discourse model needs to be addressed, and naturallanguage is a clear choice.andM;The theme of this paper is fourfold: to review the theoretical basis, designorganization, functional components, and development process of the REASON(Real-time Explanation And SuggestION) system.andP;  We first highlight some ofthe critical issues involved in identifying areas in which users needintelligent help when using an interactive system.andP;  We describe the basis forthe approach we chose to implement our intelligent help system.andP;  An overviewdiscusses the conceptual design model as implemented in REASON.andP;  This sectionpresents a functional description of the components of the REASON system andgives a description of the operation of the working components, highlightingthe implementation choices for our technology.andP;  We concentrate on the designmethodology for building an intelligent user assistant for a command-orientedsystem, such as an operating system.andP;  The operations of system components areexplained using a detailed example of a typical user interaction with anoperating system.andP;  We conclude by summarizing the approach to online userassitance that we have chosen and present our plans for future enhancements.andM;Critical issues in addressing user errors andandM;queriesandM;In providing user assistance, there are essentially two domains for whichcomputer users need support: errors in command usage and requests for helpinformation.andP;  A conflict arises between creating an environment simple enoughfor a novice (i.e., a user with limited knowledge of computers in general orwithin a particular domain) and yet sophisticated enough to accommodate anexpert.andP;  There is a wide continuum of skills between those of a novice, whoknows only the rudiments of a system, and those of an expert, who has masteryover it.andP;  The novice is constantly learning about the purpose of specificfunctions and their interrelationships with other functions and is usuallyfaced with the burden of what to learn and how to locate the necessaryinformation needed to accomplish a task.andM;One approach to addressing this problem has been to provide on-line tutorialsor training manuals.andP;  [29]  This approach is beneficial in allowing users tofocus on their task activity and in providing specific reinforcement fortasks that are accomplished.andP;  Yet it is precisely this hand-holding mode ofoperation that often makes users unwilling to spend any length of timelearning about a system on its own terms.andP;  When consulting on-line tutors, auser, in effect, ceases working.andP;  Consequently, there is a conflict betweenlearning and working that encourages novice users to find ways of by-passingtraining in order to proceed with work, using trial-and-error methodologies.andO;[10.]  Of equal importance is the fact that obtrusive tutorial systems causeexpert users to become frustrated by the lack of freedom to accomplish taskswithout being saddled with unnecessary details of system functions andexplanations.andM;This paper presents a solution to these difficulties through the use ofintelligent on-line user assistance that mitigates thelearning-versus-working conflict by monitoring user activity to identifyerrors and provide advice for error correction that can be selectively viewedat the discretion of users.andP;  A natural-language mode of asking the system forhelp directly can also be of benefit.andP;  This user-assistance approach can helpto better integrate the time and effort spent on learning with actual systemusage.andP;  [30]  This type of design can also help to counteract the sharpseparation between learning and working that often reduces the motivation touse verbose training and help materials.andM;Commands can be erroneous for any number of reasons, and sometimes more thanone form of error is present at a time.andP;  In an effort to identify categoriesof errors, we surveyed users for the most common and serious types of errorsthey make in using operating systems.andP;  Based on our findings, we constructeda taxonomy of error types.andP;  The taxonomy breaks possible errors into fourcategories:andM;* Errors in execution occur when the user knows the correct command to issuebut does not carry it out correctly (e.g., a typographical error).andM;* Errors in remembering are situations in which the user has forgotten all orpart of the syntax of a command.andM;* Errors in understanding occur when the user does not fully understand themeaning of a command and so uses it in an invalid way.andM;* Errors in preparation occur when commands are issued that look goodsuperficially, but are invalid in the current environment (e.g., negativetransference of commands across operating system).andP;  This last situationincludes errors that occur when the user has failed to make the necessarypreparations so that a command will execute successfully.andM;Clearly, the first two kinds of errors do not really require an AI treatment.andO;Typographical errors can be handled by a spelling checker (e.g., InterLispDWIM [31]).andP;  Syntax help can be provided by improved on-line help or aninput-completing parser.andP;  However, we feel that such components are generallynot widely available as parts of operating systems.andP;  Thus it is necessary tooffer assistance in these kinds of situations, along with the quitesophisticated help we are providing for understanding and preparation errors.andM;Our design also focuses on the subject of user queries to an operatingsystem, which provides an appealing domain for the application ofnatural-launguage conceps.andP;  Given that the goal of our work is to develop aninteractive environment that is both efficient and easily, learned, apromising way to achieve this objective is to use natural language as analternative to command input.andM;In designing a natural-language system, attention should be given to ways inwhich a user queries a system.andP;  There is rarely a direct correspondencebetween a precise statement or question representing a user's goal and asequence of commands required to satisfy it.andP;  It is more likey that theuser's query is vague, highlightling a poorly-defined goal, and it can beanswered in multiple ways or by using a number of different sequences ofcommands.andP;  Thus there is some difficulty in validly mapping user queries tosystem answers.andP;  We have categorized user questions into several types in anattempt to reduce the complexity of the mapping problem.andP;  Based onobservation of a sample of users ranging in skill level from novice toexpert, we have created the following categories:andM;* Procedural specification.andP;  How do I perform a certain action?andM;* Function specification.andP;  What does a command do?andM;* Goal or subgoal satisfaction.andP;  How can a goal be accomplished?andP;  How can aspecific subgoal be accomplished within the context of a higher-level goal?andM;* Analysis of a process.andP;  What is the easiest way to accomplish goal?andM;To address the distinction between questions types, we have constructed thefollowing modified taxonomy of systems responses as presented in Reference13:andM;*Introduce new information.andP;  Present commands and actions that are new to auser.andM;* Remind.andP;  Present information about commands that the usr may haveforgotten.andM;* Clarify alternatives.andP;  Present information about the relationships (e.g.,andO;preconditions and postconditions) between commands to which the user has beenexposed, and show alternative commands to achieve a task.andM;* Elicudate goal hierarchies.andP;  Present hierarchical information regarding therelationships between goals and subgoals.andM;These types of responses differ in their format and level of details as wellas in their emphasis and the amount of related information included.andO;Clarifying and elucidating require a careful mixture of reminding andintroducing new information.andP;  However, much of the knowledge needed to regarduser plans in terms of current goals is incomplete.andP;  It is also not possibleto predict with certainty what a user's goal might be.andP;  Hence, the responsesmust be provided as effectively as possible by system infenrencing strategieswithin the constraints of incomplete knowledge.andM;From a system design perspective, emphasis must be placed on the interfencingused to attempt to identify a user's goal and the application of theappropriate knowledge to satisfy the context-dependent assistance provided toa user, on the basis of that goal.andP;  Similarly the choice of the bestpresentation format for the information must be decided upon.andP;  Our solutionto these problems is a goal-centered approace to user assistance, which wenow describe.andM;Motivation for goal-centered user assistanceandM;Rarely do on-line help systems marketed today take the context of a user'sinteraction with the computer into account when presenting canned helpinformation.andP;  [32]  Furthermore, in most systems that presentation format ofhelp information does not parallel a user's view of the task.andP;  Userassistance, in the form of suggestions and explanations of suggestions,should be presented in a format that coincides with a user's approach toaccomplishing a goal.andP;  Similarly, help messages are often pooly understood byusers.andP;  It is not sufficient to provide suggestions alone for accomplishing agoal.andP;  Rather, the system needs to make explicit its reasoning as to why thesuggestions are offered and how suggestions can be implemented.andM;What a user needs to know about a system at any given time depends mostlyupon the user's plans and goals.andP;  Even the most rudimentary advisor must takea user's goals into account, otherwise there is no guarantee that the advicegiven will be appropriate.andP;  Advice is appropriate only to the extent that ithelps a user to derive and debug a plan of action for achieving his or heraims.andP;  The simplest way of responding to user queries is to anticipate thequeries and store information to answer them as canned text.andP;  The simplestsort of canned explanations are error messages.andP;  However, providingpredefined canned text as the basis of help information for all user queriesfails to really satisfy learning needs in accomplishing a goal.andP;  Also, thesytem has no conceptual model of what it is saying.andP;  An advice-giving systemneeds to be able to reason about the current state of the interaction andgive explanations at different levels of abstraction.andP;  This, in turn, impliesthe ability to present the necessary information in a scheme that supportsthe user's view of a plan for goal achievement.andP;  In addition to a meaningfulpresentation format, help messages need to be able to be explained at severallevels of detail.andP;  Explanations must tell a user how to interpret suggestionsgiven as options, as well as how to implement those suggestions.andM;An objective of our work is to use one explanation paradigm to integratedynamically generated explanations that parallel a user's view of a task witha precise explication of the system's reasoning for why a suggestion isoffered.andP;  To achieve this objective, we propose a goal-centered approach toadvice-giving.andP;  In this design, suggestions and justifications of thesystem's actions are given as a direct function of a user's needs within acurrent context and treated as discourse between a user and the computer.andO;Suggestions are provided, based on an analysis of the match between the rulesin the knowledge base and the user goals that the sytem sees as comprising auser model.andM;It is important to note that determining user goals is the focus ofdiscourse-based systems that have been prototype in the past.[12,33] However, our design can be differentiated by the assumption that the outputof goal determination is taken as an input into an inferencing component andmatched against knowledge to generate useful responses that are directlyrelevant to the context of the situation.andM;REASON design and implementationandM;Design considerations.andP;  REASON is an intelligent user-assistant prototype fora command-oriented system, such as the operating system OS/2[TM].andP;  [34]  Thepurpose of REASON is to monitor user actions in order to (1) identify usererrors and provide for correcting such errors, and (2) allow a user to askfor help directly through a natural-language front end.andP;  The operation ofREASON is based on a user-centered systems design approach in which theidentification of user goals or intentions is critical for accurateresponses.andP;  Using this design, REASON operates in a mixed initiative mode,reacting to conditions in the environment as well as to explicit requestsfrom users.andM;User interaction with an operating system provides an appealing domain forstudy and application of the AI techniques employed by REASON.andP;  Basically,all of the problems of language processing and reasoning (i.e., requirementsfor REASON to understand language, hypothesize user goals, access knowledgeabout goals, and form responses) are present in some fashion.andP;  The domain iscomplex enough to provide substantial subproblems, but not so unbounded thata useful working system must posess an extraordinary repertoire ofknowledge.[12]andM;As discussed earlier, we see the major contribution of REASON to be not somuch from a state-of-the-art solution to one or more very narrow fields ofendeavor, but rather to be in the combination of advances from several fieldsover recent years into an effective, robust, working system.andP;  Consequently,REASON's performance in any one area is likely to be less than what might befound in any leading-edge laboratory, but we believe that the very provisionof multiple features suitably integrated can lead to a working system that isable to solve real-world problems in real time.andP;  We, therefore, findourselves frequently invoking an &quot;80-20 rule&quot; (or other variants of the lawof diminishing returns).andP;  If a component can provide a large precentage ofthe function of the state-of-the-art at a small percentage of the cost(memory, speed), we will happily settle for that.andM;Although we have not performed any quantitative measurements of thoseproperties, we can usually tell when we are at the knee in thedevelopment-effort curve.andM;This philosophy was very important with respect to our goal of building aworking system.andP;  We did not want to spend excessive effort in any one area,at the expense of the breadth of the system.andP;  Building REASON has caused usto get involved in the areas of problem solving, knowledge representation,natural-language understanding, planning, plan recognition, explanation, andtext generation, each one of which is a substantial subfield of AI.andP;  We feelthat limiting the effort in each area was the only way to build a completesystem.andP;  However, we structured REASON in such a way that most componentscould be replaced by more advanced versions in the future.andM;We anticipate that the ways in which the REASON system will be used willgenerate new problems that can drive future research efforts in the areas ofAI, intelligent user assistance, and interface design.andP;  For example, analysisof the structure of questions asked by users varying in skill level mightlead to modifications in the interface supporting natural-language input,leading to a more formalized, constrained natural-language dialog as analternative form of input.andP;  Overall, we are enthusiastic a bout the potentialvalue of the design methods chosen to build REASON.andP;  We outline here some ofthe critical issues and decisions that have been guideposts in our designefforts.andM;Generalization of the REASON system.andP;  We have been developing REASON as anintelligent help system for OS/2.andP;  We do not believe that the concept of anintelligent help system is limited to OS/2 or to operating systems generally.andO;Any environment in which the user issues commands via a command line shouldbe amenable to incorporating the REASON technology--for example, texteditors.andP;  Consequently, we have been seeking to develop REASON as far as ispossible in a domain-independent manner.andM;REASON as a rule-based system.andP;  REASON was conceived as a mechanism to solvetwo seemingly independent problems: (1) to respond to direct questions fromthe user about how to use the system, and (2) to intercede when it is noticedthat the user is committing, or is about to commit, an error.andP;  Bothsituations require a problem-solving capability, although in the latter casean extra component is necessary to set up the problem to be solved.andP;  Bothsituations generally require the same body of knowledge about the subjectdomain.andP;  Thus, at the outset, it seemed to us that a single program could bebuilt to achieve both of our major goals.andM;It seemed natural that this program would be a general-purpose problem solvercombined with a knowledge base describing the domain in which it was tooperate.andP;  Making the domain knowledge separate from the inferencing mechanismwould allow easier porting to other domains, as well as easier debugging ofthe REASON system itself.andM;Inference mechanismandM;For an inferencing mechanism, we faced a choice of using backward-chaining orforward-chaining or a combination of both.andP;  The problems to be solved wouldgenerally be of the kind of determining a route (set of steps) to take thesytem from one state (the user's current state) to another state (the user'sgoal state).andP;  We felt that in addition to being largely goal-driven, therewould be many cases for which we would want to find all solutions or at leasta large subset of all solutions.andP;  Consequently, we decided on a depth-first,backward-chaining inferencing strategy much like the control strategy used byProlog.andP;  We also saw that the REASON would require a great deal ofpattern-matching for which the Prolog unification mechanism would work well,which was another reason we decided to use Prolog.andP;  We built our ownmeta-nterpreter in Prolog, because, although we wanted to take advantage ofProlog's search strategy as a control mechanism, we wanted some control overthe search strategy, as well as the pattern-matching, ourselves.andM;Natural languageandM;We wanted an natural-language front end to REASON, but we did not want toundergo an extensive research project in this area.andP;  As previously mentioned,we performed some preliminary studies with potential users to determine thekinds of questions they would ask an intelligent help system.andP;  While thetotality of questions was spread over a large range--from short to long,simple to complex--the majority were of the &quot;How do I...&quot; or &quot;What does...do&quot;variety.andP;  Based on the 80-20 rule, we judged that a fairly simple grammarcould be constructed to represent the majority of these questions.[35]  Wecorrespondingly decided to use a Definite Clause Grammar (DCG),[36] becauseit was easy to write a DCG that parsed most of these questions.andP;  Thisdecision fitted in very well with the choice of programming language, becauseDCGs are very easily implemented in Prolog.andM;The components of REASONandM;We now present an overview of the conceptual model upon which REASON isbased.andP;  This model, showing the functional components of REASON, is presentedin Figure 1.andP;  It is seen that REASON consists of two major components: (1)the REASON operator interface (ROI, which we pronounce &quot;roy&quot;), and (2) theREASON back end (RBE, which we pronounce &quot;ruby&quot;).andP;  These components handlethe user-interaction and inferencing processes, respectively, and as suchrequire a relatively low bandwidth for communication between one another.andO;The logical separation of the user interface from the inference engine, asdepicted in Figure 1, is maintained in the phsical implementation.andP;  ROI andRBE can be implemented either as separate processes in a multitaskingoperating system, such as OS/2, or on different physical machines on a localarea network (LAN).andM;REASON operator interface.andP;  ROI handles REASON's communications with theuser.andP;  This largely entails capturing the user's input and transmitting it toRBE and capturing RBE's response to displaying that to the user.andP;  It itspresent form, REASON requires the existence of an operating system shell,because it must gain access to the commands that the user types in and to thereturn codes issued by the operating system.andP;  Under OS/2 Standard Edition1.1, ROI is implemented as a Presentation Manager application.andP;  [34]  Itshould be noted that REASON itself currently monitors only the user's inputin the system's command line.andP;  The users, however, can review REASON'Sresponse (suggestions and explanations) by direct manipulation.andP;  Later inthis paper there are several examples of ROI in execution, presenting windowsof text containing REASON'S suggestions and explanations.andM;In designing REASON, a primary aim has been to minimize the intrusiveness ofthe system on the user.andP;  Usually the user does not want to surrender controlof the interaction with the computer and does not work efficiently andeffectively with an intelligent agent that is continually interruping to giveadvice.andP;  In an effort to address these concerns, REASON sits as a guardianmonitoring the user's interaction, thereby allowing it to play as unobtrusivea role as possible.andP;  If an error is made or question is asked in acommand-line environment, the user is given a visual cue (e.g., an iconappears), indicating that REASON is ready to give a response that can beviewed if so desired.andP;  In communicating this advice to the user, ROI does nottake control over the user's interaction with the computer.andP;  Rather, itallows the user to have the option of viewing suggestions and explanations atthe desired level of depth, depending upon the expertise of the user.andP;  REASONneither automatically corrects the command for the user on the command linenor executes it.andP;  Once the suggestions are reviewed, the user has controlover their execution.andM;REASON back end.andP;  REASON back end (RBE) is the component of REASON thatactually solves the user's problems.andP;  It does this by an inferencing processand as such can be thought of as being the AI component of REASON.andP;  RBE hasaccess to a description of the user's current environment, and ROI passes thecommands and questions that the user issues to RBE.andP;  RBE responds to allquestions and to those commands tha are in error.andP;  Its response is usually inthe form of one or more suggestions, each suggestion being accompanied by anexplanation.andP;  A suggestion may be anything from do nothign to a series ofseveral actions to be carried out.andP;  These responses are passed back to ROIfor display to the user.andM;RBE consists of a compiled Arity/Prolog[R] application, as well as anexternal file containing its rule/frame bases.andP;  Most of the domain-dependentknowledge for an implementation of REASON is located in this file, but thosefunctions that are inextricably linked with the syntax of the commands in thedomain are part of the compiled module.andP;  This means that changing domaingenerally entails recompiling the REASON system.andP;  This would be a drawback ifREASON were thought of as a general-purpose, expert system shell like ESE.andO;[37]  For the reason that most users are not going to be porting REASONbetween domains, this lack of flexibility is not regarded as serious.andP;  Workis being done to extend the number of built-in functions that can be used todescribe a domain, so as to minimize the domain-dependent code.andM;RBE functional componentsandM;The main components of RBE are the parser, the inference engine, and theknowledge bases.andP;  This section contains descriptions of these components.andO;However, we introduce the subject with a discussion of the methods ofknowledge representation used in REASON.andM;Goal expressions.andP;  The domain knowledge is represented in the form of frames,within which are locations or slots where information is necessarilyrepresented with a finer granularity.andP;  The format used here is what we callgoal expression and is used throughout REASON.andP;  For example, the output ofthe natural-language parser is a case frame, which is transformed into a goalexpression.andM;A goal expression consists of a predicate name--representing an action--andarguments--representing the objects and attributes involved in the action.andO;The objects are represented (depending on the level of detail requied) eitherby atoms or by five-part lists that we call object descriptors.andP;  Thecomponents of object descriptors are: (1) the object's generic nameandgt; (2) itsgiven name or labelandgt; (3) its adjectival descriptorandgt; (4) an all/one/none flagandgt;and (5) possible containing object.andP;  The last field is used to talk aboutfiles in directories as well as other instances of containment.andP;  For example,the goal expression representing erase all files abc.* in directory def wuldbeandM;erase ([file, abc.*, _, all, [directory, def, _, one, _]])andM;It can be seen that goal expressions are syntactically Prolog predicates,although they are never evaluated directly by the base Prolog system.andP;  We usethe square brackets for lists, and the Prolog notation for identifiers.andP;  Inthis notation, identifiers beginning with a lower case letter are atoms,those beginning with a capital letter or the underline character arevariables.andP;  The underline character used by itself is the anonymous variable.andO;Variables are initially unbound, that is, not matched to any atom orstructure.andP;  When bound, all variables within a goal expression or one of ourframes (described later in this paper) are bound to the same value.andP;  Eachinstance of an anonymous variable can bind to (or match) any value.andP;  Beingunnamed, however, it can not be referred to.andP;  Therefore, this essentiallyrepresents a &quot;don't care&quot; condition.andM;Goal expressions may be mapped to a subset of Sowa's [38] Conceptual Graphsrepresentation.andP;  We have considered using Conceptual Graphs directly, buthave so far found the reduced expressive power of goal expressions to besufficient to meet our needs.andM;Conditions.andP;  A special variant of the goal expression is known as thecondition, which is a predicate with name condition.andP;  Condition represents asystem stat by means of an assertion that an attribute of a certain aspect ofthe system has a certain value.andP;  Specifically, the first argument is theproperty name, the second its value, the rest determine the aspect of thesystem being described.andP;  For example, consider the following condition:andM;condition (exists_file, t, c:, \dirl\dir2, myfile.txt)andM;This condition assets that the file c:\dirl1\dir2\myfile.txt exists (where tstands for true).andP;  These conditions are not asserted into the Prolog clausespace but are processed by our own meta-interpreter.andP;  Mentioning the truthvalue directly allows us to asserts:andM;condition (exists_file, f, c:, \dir1\dir2, myfile.txt)andM;which would be difficult to do if we relied simply on the Prolognegotion-by-failure.andP;  In addition, these conditions can take values otherthan true and false.andP;  Consider the following example:andM;condition (screen_mode, mono)andM;This condition says that the current screen mode is MONO, where other valuesinclude CO40 and C080.andM;We have defined conditions so that if the name and the third argument andbeyond of two conditions are equal, the second arguments (or values of theconditions) are equal.andP;  This effectively makes our conditions into functions.andO;This has great value because it helps us determine what prior knowledge isinvalidated when new knowledge is gained.andP;  For example, if we have thefollowing condition,andM;condition (exists_directory, t, dir1)andM;then the assertion of the following conditionandM;condition (exists_directory, t, dir2)andM;will not affect it, because directories can coexist.andP;  However, consider thefollowing condition:andM;condition (exists_directory, f, dir1)andM;This condition causes the former assertion to be cancelled, because adirectory cannot simultaneously exist and not exist, It should be noted thatthe values t and f are not special to REASON.andP;  If they were uniformlysubstituted by red and blue, say, the program would work the same way.andM;Knowledge bases.andP;  REASON maintains its domain-specific information in fourdifferent collections or knowledge bases.andP;  These knowledge bases resemblerule bases, even though not all of the information is strictly in theantecedent-consequent from that is typical of an expert system's rule bases.andO;The knowledge bases represent knowledge of the commands and actions availableto the user, certain relationships between goals and states, and ready-madesolutions to anticipated goals.andP;  This formation is in the form of frames,which--in combination with REASON's generic rules described later--formactual rules.andP;  These frames employ goal expressions heavily.andM;Command frames.andP;  The reason command knowledge base consists of objects calledcommand frames that represent the commands the user can issue in the currentoperating domain.andP;  Command frames have the following slots:andM;* A list containing command name, its class, and two differentrepresentations of the argument listandM;* The parse routine, which is the name of the routine used to parse theargumentsandM;* The intents of the command, namely, the possible user goals that thiscommand accomplishes, represented as a list of goal expressionsandM;* The preconditions of the command, namely, those conditions that must betrue before the command can be executed: Two slots, denoted by the labelsmust and pre, contain these conditions.andP;  These slots contain lists ofdisjunctions of conditions.andP;  The difference between the must and pre slots isthat if a command is tried whose pre conditions fail, REASON tries to createa state in which they succeed, whereas if the must conditions fail, REASONdoes not pursue this line of reasoning.andM;* The postconditions of the command, namely, those conditions that becomenewly true after the command is executed: This slot is a list of conditions.andM;* The tells of the command, namely, the information that running the commandprovides: This slot is a list of goal expressions.andM;* A property list for miscellaneous information, such as whether the commandtakes wild cards or is part of the operating system kernel.andM;For example, the command frame for the erase command in shown in Figure 2.andM;As described later, command frames such as this are used in conjunction withthe REASON generic rules to determine corrections of the user's input.andP;  Oneof these generic rules makes an incorrect command valid by constructing oneor more commands to be issued in advance to create a state in which theformer command's preconditions hold.andP;  This can give rise to undersirableconsequences if the allocation of preconditions to the must and pre slots arenot carefully considered.andP;  In the case of the erase command, putting thecondition that the named file must exist as a must rather than a precondition prevents REASON from suggesting tht the user create a file and thenerase it, when trying to erase a nonexistent file.andM;Action frames.andP;  The REASON action knowledge base consists of objects calledaction frames, which represent the noncommand actions that the user canissue.andP;  Typical actions might be those of inserting or removing diskettes onpressing certain key combinations, etc.andP;  Actions are syntactically verysimilar to commands, except tht they have no associated parse routines orproperty lists.andM;For example, the action frame for inserting a diskette might look as shown inFigure 3.andP;  Note the two intents are used to cover the possibility that theuser might refer to the object being inserted as either a diskette or floppydisk.andM;Consequence frames.andP;  Consequences frames are essentially if-then rules usedto interrelate goal and states.andP;  The primary use of these objects is in caseswhere what the user wants to do is a subject or side-effect of a more majoroperation.andP;  For example, viewing a file can be accomplished by editing it,but tht is not the primary purpose of the editor, so view is not among theintents of an editor, though edit is.andP;  A consequence frame (shown in Figure4) is used to state that viewing is a possible consequence of editing.andM;Goal frames.andP;  Goal frames are used to tell REASON the algorithm for breakingcertain goals into subgoals.andP;  The purpose is to relieve REASON of having towork out from first principles well-known techniques.andP;  A goal frame has thefollowing components:andM;* The goalandM;* What to do if some or any of the parameters are unbound (i.e., the defaultslot)andM;* Conditions or othr relations to test (i.e., the process slot)andM;* The subgoals which, if achieved, guarantee the goal will be satisfiedandM;For example, if the system has been given the goal of formatting a diskette,it must determine the drive, if unspecified, and then have the user insertthe diskette before running the format command.andP;  This is achieved by means ofthe goal frame shown in Figure 5.andM;Currently the frames must be coded by hand, but an aid to automate theprocess is being built.andP;  All the frames are maintained in an external filethat REASON reads in at run time.andP;  Consequently, users are free to customizethe file as they see fit.andP;  For example, they can add command frames todescribe new applications they may import or goal frames to describe newprocedures.andM;Natural-language parserandM;The REASON parser is based on a modified Definite Clause Grammar, [39] withbuilt-in spelling corrector and semantic role analyzer.andP;  The analysis iscase-based, [40] thereby producing a case frame that is later converted to agoal expression.andP;  The lexicon (vocabulary) is maintained in an external file,along with the semantic/syntactic role relations, thus allowing them to beupdated at run time without recompilation.andP;  At one time, the parser containeda built-in morphological parserandgt; however, we found that because almost allquestions issued by users in our studies were in the present tense, it wasmore efficient to include plural forms of nouns and third-person, singularforms of verbs in the lexicon.andM;The verbs in the lexicon are tagged with one or more different labels thatare used both in the selection of the grammar rule and in the construction ofthe case frame.andP;  For example, the set of labels used includes vi(intransitive verb, such as quit) and v_recipient_np (verb taking arecipient, then a noun phrase, such as send).andM;As an example, the case frame that would be generated from the question &quot;Howcan I send a file to the printer&quot; is shown in Figure 6.andM;The components of a case frame are the verb and its various cases.andP;  Forexample, the subject (subj) of the verb send is in this case the word I,which is an example of an actor and plays the role of agent.andP;  For thisquestion and others like it, the parser generates two nested case framesandgt; theouter one is called a question frame.andM;When the parser succeeds in generating a case frame, it invokes a function wecall the case-frame filter to produce a goal expression and an associatedflag called the question type.andP;  For the previous example, the generated goalexpression is:andM;send ([file,_,_,_,_,], [printer,_,_,_,_]}.andM;with the associated question type of how.andM;Inference mechanism.andP;  REASON employs a depth-first, backward-chaininginference mechanism to solve problems.andP;  This mechanism employs a set of whatwe call generic rules, processed by a second-level interpreter.andP;  These rulesspecify different ways that REASON solves the current problem as follows: agiven rule may completely solve the problemandgt; it may solve part of it andgenerate one or more subgoals for the restandgt; or it may simply redefine theproblem.andP;  Solving the problem is defined to mean either taking an incorrectcommand and converting it to a sequence of commands that do what theincorrect command is guessed to be attempting to do, or taking a goal andgenerating a sequence of commands which will achieve the goal.andP;  This sequenceof commands becomes what is presentd to the user as a suggestion.andM;A suggestion often consists merely of a single command, and occasionally itis empty if REASON determines the user is already in the desired goal state.andO;Sometimes the suggestion contains actions, such as inserting a diskette, butfor brevity in this section we assume all of the components of a suggestionare commands.andM;Overall strategy.andP;  Input to REASON back end (RBE) is either an incorrectcommand issued by he user or a question or command in English.andP;  RBE tests theinput according to the following criteria in turn.andP;  It it meets success inany one test it deals with the input appropriately.andP;  This might result inmultiple solutions, but RBE does not proceed with any further tests in thelist.andP;  The input is tested for being:andM;* A correct commandandM;* A command that is correct so far but incompleteandM;* An English question or commandandM;* An incorrect commandandM;* A goal expressionandM;* An English question or command with spelling errorsandM;If the input is an incorrect command, RBE tries to find possible ways tocorrect the input before teminating.andP;  This often results in severalsuggestions.andM;RBE accepts goal-expression inputs directly, primarily as a debugging tool.andO;They are processed by the same mechanism that handles incorrect commands.andO;The value of exposing this interface to the user must be evaluated in futuretesting of the REASON system.andM;When REASON seeks to interpret the input as an English question, it passesthe input to our natural-language parser.andP;  If a parse is generated, theresulting case frame is processed by a case-fame filter, which produces agoal expression along with a flag indicating what kind of question was asked(i.e., what, how, etc.).andP;  This goal expression is then processed by RBE.andM;If the input is parsed as English with spelling errors, a goal expressionrepresenting the input (correctly spelled) is generated, along with adescription of the corrections made.andP;  These corrections are viewable, alongwith other information about the parse process under the REASON operatorinterface (ROI).andM;Generic rules.andP;  Generic rules may be thought of as transformations that takea command or a goal and produce a set of subgoals.andP;  Secondary outputs of theapplication of a rule are commands to be recommended to the user, along withan explanation fragment and a set of rules to be tried further.andP;  The processcomes to an end when a rule generates no subgoals.andP;  The totality of commandsis collected and presented as a suggestion, and the explanation fragments arecollected and converted into coherent English text.andM;The REASON generic rules include the following:andM;* Correct the spelling of the commandandM;* Correct the spelling of the argumentsandM;* Correct the argumentandM;* Complete the commandandM;* Change the command to one with similar meaningandM;* Select a command to satisfy the given command's preconditionsandM;* Select a command whose intention matchs the given goalandM;* Transform the given goal into a more general oneandM;* Break a goal into subgoalsandM;Domain dependence of generic rules.andP;  The rulest that pertain to the syntax ofcommands are not usually domain independent.andP;  They do in fact represent thebulk of the domain-dependent component of REASON that is not yet able to beextracted into an external file.andP;  Consequently, on changing domains, thispart of REASON is recompiled.andM;To REASON, actions have a designated, predefined syntax.andP;  If the new domainconsists entirely of actions, REASON is not recompiled, becausecommand-oriented generic rules are not applicable.andP;  To demonstrate this, weimplemented a &quot;monkey-and-bananas&quot; problem entirely as action frames and goalframes.andP;  The monkey-and-bananas problem places a monkey and a crate atopposite corners of a room.andP;  From the center of the ceiling hang somebananas.andM;To be successful, the monkey must move the crate under the bananas and thenclinb on the crate to reach the bananas.andP;  This problem is often used as abenchmark for comparing the performance of inference engines.andP;  We have usedit to demonstrate that REASON is capable of solving such problems.andP;  We wereable to merge the new knowledge bases with those we had to describe theoperating system, and REASON could solve problems from either domain withoutbeing recompiled.andP;  Monkey-and-banana problems were posed to REASON by meansof the goal-expression input mechanism, described earlier.andM;RBE operationandM;REASON solves problems by the repeated application of the process describedin this section and depicted in Figure 7.andP;  This figure shows how one of thegeneric rules named in the input is selected, merged with a frame, andapplied to the current problem to produce a new problem and a new set ofrules to try, along with the suggestions and explanations produced to thispoint.andP;  The process takes as primary input what we call the current problemand a set of rule names.andP;  The current problem may be a command to be issued,a condition to be satisfied, or a goal to be solved.andP;  The rule names listthose rules that either the starting conditions or the previous applicationof this procedure have determined are appropriate for the current problem.andO;The secondary input to the process is the generic rule base, which is thecollection of frames for the current domain and a desription of the currentenvironment.andM;The problem solver takes each rule named in its input, in turn, and tries touse it to solve the current problem.andP;  It does this by selecting anappropriate frame with which it unifies to form a specific rule.andP;  The problemsolver then applies this specific rule to the current problem.andP;  If theapplication succeeds, it generates the following: a new problem, a new set ofrule names (dictated by the rule that succeeded), a suggestion fragment, andan explanation franment.andP;  The process terminates when no new problem isgenerated.andP;  In this case, the chain of suggestion and explanation fragmentsis processed and sent to ROI to be presented to the used.andM;More than one suggestion can be produced if either of the followingsituations occurs during the inference process:andM;* More than one rule name is listed in the input.andM;* A given rule inifies with more than one frame.andM;Whenever a sequence of rules ends, the suggestion and explanation isgenerated and the inference engine backtracks to the prior choice point, inorder to try the next alternative.andM;In such domains as medical diagnosis, for which expert systems have beenbuilt, it is often advantageous to be able to deal in varying degrees ofabstraction, particularly when it comes to giving explanations.andP;  [41] Depending on the nature of the domain and the domain expert's knowledge ofit, abstract knowledge may or may not be available to the expert system.andO;That is, it may not be possible to enumerate all the possible domainprinciples.andP;  Here, by contrast, because of the artificial and generallysystematic natue of the problem domain, we can in a relatively simple waystart with astraction (out generic rules) and get to specifics in astraightforward manner.andM;Example.andP;  This problem-solving process can be illustrated by means of anexample.andP;  In this example, we see how one of REASON's responses to a user'sfailed attempt to issue a cd mydir command might be to issue a md mydircommand first.andM;Suppose the user issues the command cd mydir (change to directory mydir),where directory mydir does not exist.andP;  The input to the process (the currentproblem) is the command cd mydir, along with a set of rule names thatincludes the rule comm_prem (command premature).andP;  This rule states, ineffect, that when you wish to issue a command C1 and cannot do so because itspreconditions P are not met, find a command C2 whose postconditions includeP, solve for C2, then issue command C1.andP;  This rule is generic because C1, C2,and P are unbound.andM;Unification of the rule is tried with all command frames in turn.andP;  At somepoint the md command (make directory) is attempted.andP;  In this case, theunified rule becomes the following: when you wish to issue a command C1, andcannot because its precondition--i.e., directory D exists--is not met, solvefor command md D, then issue C1.andP;  This rule applies to the input cd mydir, inso doing binding D to mydir.andP;  The new problem to be solved becomes theviability of the command md mydir.andM;When the unifed rule is applied to the input, it is in effect constructingthe highly specific rule: when you wish to issue a command cd mydir, andcannot because its precondition--directory mydir exists--is not met, solvefor command md mydir, then issue cd mydir.andP;  It is this rule, in a transformedstate, that is used to construct the explanation of this step.andM;It should be noted that this fully specified rule represents a small chunk ofspecific domain knowledge and corresponds to the level of granularity of arule in a typical expert system.andP;  It is by the regular nature of theartificial environment in which REASON operates that we are spared having todeduce all of the thousands (potentially) of similar rules.andP;  Instead, we dealwith a few dozen command frames and about a dozen generic rules.andM;The application of the comm_prem rule was just described.andP;  It was mentionedthat this was one of several rule names passed as input to theproblem-solving process.andP;  All named rules are tried, and any others thatsucceed have generated alternative suggestions.andP;  For example, if there hadexisted a directory mydirl, say, then the args_misspelled rule would havesucceeded.andM;Explanation paradigm paralleling user taskandM;activityandM;REASON offers suggestions when the user issues an incorrect command, as wellas when the user asks the system directly for help using natural-languagequeries.andP;  Explanations of suggestions are necessary to aid the user inunderstanding the system's reasoning strategies for why commands areerroneous and how to recover from the errors.andM;As noted earlier, historically, most explanation facilities for help systemshave been merely static traces of system rules or canned text that resemblesan online manual.andP;  A primary problem with using static traces as explanationsis that the system can state what it does or did to arrive at a suggestion,but it cannot state why the system recommends a particular suggestion.andP;  Thesetypes of explanation do not take into account the context in which the errorwas made or that in which the question was asked.andP;  Also, the presentationformat of help information usually does not parallel the user's view of thetask.andP;  Suggestions and explanations must be presented in a format thatcoincides with the user's approach to accomplishing a goal.andP;  It might bementioned that help messages are often poorly understood.andP;  It is notsufficient to provide a single suggestion for accomplishing a goal, butrather the system needs to make explicit its reasonig as to why thesuggestion is offered and how a suggestion can be implemented.andM;In studying new user interface technology, intelligent help appears to be away of providing context-dependent advice that can operate as a partner withthe user by offering advice based on user intentions or goals.andP;  What the userneeds to know about a system at any given time depends mostly upon thoseplans and goals.andP;  Providing predefined canned text as the basis of helpinfomation for all user queries fails to satisfy such needs in accomplishinga goal.andP;  An advice-giving program must be able to reason about the currentstate of the interaction.andP;  [9]  This in turn implies the ability to presentthe necessary information in a scheme tat supports the user's view of theplan for goal achievement.andP;  In other words, the explanations should betailored to the specifics of the situation at hand.andP;  In addition to ameaningful presentation format, advice must be explained at several levels ofdetail.andP;  Explanations must tell the user how to interpret suggestions givenas options, as well as how to implement these suggestions.andM;To accomplish these objectives, REASON implicitly interprets the user'sstatements and then adapst the advice accordingly.andP;  We have chosen toimplement one explanation paradigm that can be used to integrate dynamicallygenerated explanations that parallel the user's view of a tsk providinginformation on why a particular set of suggestions are recommended, as wellas how to perform the steps required to achieve a goal.andM;The basic idea is to extablish an explation paradigm, based on stated orinferred goals of the user.andP;  Its components are generated dynamically throughsystem inferencing and are presented using two complementary formats that arederived from a solution-tree trace converted into connected Englishsentences.andP;  This explanation paradigm parallels the hierarchical nature ofthe user's knowledge about a task, when attempting to achieve a goal usingthe computer system.andP;  The explanation process is depicted in Figure 8.andO;Suggestions and two kinds of explanations are generated when the user asks aquestion or types an incorrect command.andM;Before generating an explanation for the user, the system must firstdetermine what the user wishes to accomplish and how it should be done.andP;  Theaim of the system is to take the user's problem as expressed in terms ofeither an incorrect command or a natural-language question and produce one ormore suggestions.andP;  Each suggestion consists of one or more steps for the usero take to achieve the inferred goal.andP;  In the event that the system finds thatthe user's desired goal state already exists, the suggestion will be to donothing.andP;  In any case, the solution to the problem must take place in such away as to be amenable to explanation.andM;All user queries to the system are represented internally as goalexpressions, whether originating in incorrect commands or natural-languagequestions.andP;  All parts of an explanation are generated dynamically on-the-flyby passing these goal expressions to the problem solver and applying theappropriate inference rules.andP;  In generating explations, for each rulesequence that is applied, a trace is kept of the essential details of eachrule, such as name and appropriate parameters.andP;  By applying suitable texttemplates to this solution tree, an English-like explation of the inferencingprocess is generated.andM;The system offers one or more suggestions.andP;  The explation paradigm includestwo types of explanation of the steps for these suggestions.andP;  The firstfocuses on how the recommended steps fit together to solve the subgoals ofthe problem (i.e., how-it-works).andP;  The second type presents the reason why aparticular suggestion is offered by the system, thereby providing a logicalconnection between each step of the suggestion and the original problem orquestion.andP;  Both types of explanation are used to support a logical mappingfrom the suggestions offered, to the achievement of user goals.andP;  Figure 9shows a response to the question, &quot;How do I install and run program TEST fromdrive A to directory MYDIR on drive C?&quot;andM;As shown in Figure 10, the basic idea of the how-it-works explanation is toshow the procedures or steps that can be implemented to satisfy a set ofsubgoals leading to an overall goal.andP;  This explanation shows how multipesteps in a suggestion fit together to solve all or part of the originalproblem.andP;  The how-it-works explanation is derived from the solution tree in ahierarchical top-down manner.andP;  Each high-level goal is successively brokendown into lower-level subgoals and finally into leaf nodes representingsystem commands or actions that the user must issue in order to achieve hisor her overall goal.andP;  How-it-works is available when the solution processinvolves matching users' goals or subgoals against a predefined goalhierarchy.andM;The explanations for the suggestions to a problem or question are intended toprovide information on errors and why alternative suggestions arerecommended.andP;  A why explanation is always provided for each step in a singleor multistep suggestion.andP;  The why explanation is derived from the solutiontree using a bottom-up trace from each single leaf node in the hierarchicaltree structure to the highest goal (e.g., Install and run program TEST).andP;  Thesequence of rule-firings in the trace is converted into a sequence of Englishsentences that read fluently and explain the logic of the suggestion.andP;  If theuser asks for an explanation of why md mydir is given as part of thesuggestion to install and run program TEST, the help shown in Figure 11 isoffered.andM;This explanation paradigm addresses the stated problem by dynamicallygenerating explanations that take the context of the user-computerinteraction into account.andP;  In addition, the explanation content, whichconsists of a goal-based rationale, parallels the user's view of a task, andcomplementary explanation types (i.e., why and how-it-works) are used toenhance the user's understanding of the information presented.andP;  [30]andM;Summary and conclusionsandM;This paper has concentrated on our attempt to design and implement aprototype for a commercially feasible advisory system that is based on theintegration of AI-based advances from several fields.andP;  It describes ourextensions of previous research on designing advisory systems.andP;  Our aim is toenhance the helpfulness of computers through the use of an intelligentcommand line designed to support a mixed-initiative mode of interaction forcorrecting command errors and responding to natural-language questions.andP;  Onthe basis of our experience in this endeavor, it appears that leverage can beobtained by providing the following:andM;* The integration of several AI techniques to build a robust, commerciallyfeasible intelligent advisory systemandM;* The need for context-sensitive advice, based on a goal-centered approach touser assistanceandM;* The development of taxonomies to enhance an understanding of user errorsand typical requests for help, which can serve as a means to ensure that theadvice provided is compatible with the user's requirementsandM;* The right balance of function to effort required for implementationandM;* Development in a domain-independent manner, with the aim of porting thetechnology across operating system environments as well as task domainsandM;These consideratios have led us to concentrate on the following features ofthe REASON system:andM;* The definition of a goal language as a knowledge-representation medium foruser goals and intermediate subgoalsandM;* A mixed-initiative input mode to accommodate varying levels of userexpertiseandM;* Unobtrusive interactio with the user, allowing for the selective viewing ofsuggestions and explanationsandM;* The development and presentation of an explanation model to integratedynamically generated suggestion explanations that parallel the user's viewof a taskandM;* An emphasis on making the system user extendable with respect to thevarious rule basesandM;Although our experience with the general problem-solving capability of REASONis limited, we are optimistic about the prospects for porting the rule basesand inference mechanism beyond the operating system domain and into otherdomains.andP;  In its current form, REASON is not ready for general use.andO;Nevertheless, it has demonstrated a capability for inferring user goals,processing natural-language queries, and formulating a set of suggestions toachieve desired goal states in a robust manner.andM;Future directionsandM;At present, we are working on several fronts toward giving REASON the abilityto build a more refined model of the user.andP;  Our main objective is to deducethe user's plan by observing command and question patterns, which is the taskof plan recognition.andP;  We also intent to use traces of user errors and thetypes of help previously sought as criteria for inferring user expertise.andP;  Itis our hope that by using individualized user models, based on expertise andprior history, the system will be able to reason more deeply about the user'sactions and plans.andP;  This information will allow REASON both to deduce plansthat might otherwise be missed and to determine which of many equallyplausible plans is most appropriate in a given context.andM;Currently, the REASON knowledge base must be coded by hand.andP;  We are buildingan interactive development aid to ease the developer's task considerably.andO;Not only will it cut down on the possibility of syntax errors in theknowledge base, but also it will be able to show the developer all possiblematches of the rules and frames being entered.andP;  This will help ensure thatthe rules and frames are used as the developer expects.andP;  In addition, thisextension will enable partial precompilation of the knowledge base, whichwill improve REASON's performance.andM;An empirical investigation of REASON with users in varying workingenvironments is also being planned.andP;  We are quite eager to evaluate REASON'sinferencing power across a range of users with differing needs for advicefrom the system.andP;  Included within this evaluation is an assessment of thevalidity and effectiveness of the explanation model incorporated in theREASON design.andP;  This usability testing will also provide us with valuableinformation as to the robustness of our natural-language capabilities,thereby helping us to determine the feasibility of the language restrictionsbuilt into the REASON natural-language parser.andP;  Such an evaluation willindicate whether the natural-language front end is complete enough to be usedas intended.andM;In the longer term, we plan to address whatever deficiencies are found byexperimental use.andP;  We also plan to extend our natural-language parser to beable to differentiate between hypothetical questions and questions referringto the current state of the system.andP;  Similarly we plan to implement multipleexplanation modes characterized by different depths of help and tutorialinformation that is present in on-line documentation, possibly stored ashypertext/hypermedia.andP;  [42]  Finally, we would like to do experimentalresearch to find a way to incorporate REASON into noncommand-driven systems,such as those with direct manipulation interfaces, with the hope ofcontinuing to broaden the scope of potential applications of intelligenthelp.andM;OS/2 is a trademark of International Business Corporation.andM;Arity/Prolog is a registered trademark of the Arity Corporation.andM;Cited referencesandM;[1.] J. L. Alty and M. J. Coombs, &quot;Communicating with University ComputerUsers: A Case Study,&quot; in Computing Skills and the User Interface, M. J.andO;Coombs and J. L. Alty, Editors, Academic Press, London (1981), pp.andP;  7-71.andM;[2.] R. Burton and J. S. Brown, &quot;An Investigation of Computer Coaching forInformal Learning Activities,&quot; in Intelligent Tutoring Systems, D. Sleemanand J. S. Brown, Editors, Academic Press, New York (1982), pp.andP;  79-98.andM;[3.] N. K. Sondheimer and N. Relles, &quot;Human Factors and User Assistance inInteractive Computing Systems: An Introduction,&quot; IEEE Transactions onSystems, Man, and Cybernetics 12, No.andP;  2, 102-107 (March/April 1982).andM;[4.] C. Lewis and D. A. Norman, &quot;Designing for Error,&quot; in User CenteredSystem Design, D. A. Norman and S. W. Draper, Editors, Lawrence ErlbaumAssociates, Hillsdale, NJ (1986), pp.andP;  411-432.andM;[5.] E. Rich, &quot;User Modeling Via Stereotypes,&quot; Cognitive Science 3, 329-354(1979).andM;[6.] J. Faletti, &quot;PANDORA--A Program for Doing Commonsense Planning inComplex Situations,&quot; Proceedings of the National Conference on ArtificialIntelligence (AAAI-82), Carnegie-MEllon University, Pittsburgh, PA (1982),pp.andP;  185-188.andM;[7.] J. F. Kelley, &quot;An Iterative Design Methodology for User-friendlyNatural-language Office Information Applications,&quot; ACM Transactions on OfficeInformation Systems 2, 26-41 (1984).andM;[8.] K. R. McKeown, M. Wish, and K. Matthews, &quot;Tailoring Explanations for theUser,&quot; Proceedings of the Ninth International Joint Conference on ArtificialIntelligence (1985), pp.andP;  794-798.andM;[9.] P. Jackson and P. Lefrere, &quot;On the Application of Rule-based Techniquesto the Design of Advice-giving Systems,&quot; in Developments in Expert Systems,M. J. Coombs, Editor, Academic Press, London (1984), pp.andP;  177-200.andM;[10.] J. M. Carroll and J. McKendree, Interface Design Issues forAdvice-Giving Expert Systems, Research Report RC 11984, IBM Thomas J. WatsonResearch Center, Yorktown Heights, NY (1986).andM;[11.] C. Holg, The Joy of TENEX and TOPS-20 ...andP;  in Two Parts, TechnicalReport ISI/TM 79-15, USC Information Sciences Institute, Marina del Rey, CA(January 1979).andM;[12.] R. Wilensky, Y. Arens, and D. Chin, &quot;Talking to UNIX in English: AnOverview of UC,&quot; Communications of the ACM 27, No.andP;  6 (June 1984), pp.andO;574-593.andM;[13.] U. Wolz and G. E. Kaiser, &quot;A Discourse-based Consultant for InteractiveEnvironments,&quot; IEEE Proceedings of the Fourth Conference on ArtificialIntelligence Applications (March 14-18, 1988), pp.andP;  28-33.andM;[14.] R.S.andP;  Fenchel and G. Estrin, &quot;Self-describing Systems Using IntegralHelp,&quot; IEEE Transactions on Systems, Man, and Cybernetics 12, No.andP;  2, 162-167(March/April 1982).andM;[15.] D. Sleeman and J. S. Brown, Intelligent Tutoring Systems, AcademicPress, New York (1982).andM;[16.] L. Quinn and D. M. Russell, &quot;Intelligent Interfaces: User Models andPlanner,&quot; Proceedings of CHI '86: Human Factors in Computing Systems, Boston,MA (April 13-17, 1986), pp.andP;  314-320.andM;[17.] B. K. Reid, Scribe: A Document Specification Language and Its Compiler,Ph.D.andP;  thesis, Carnegie-Mellon University (1980).andM;[18.] E. Rich, &quot;Users Are Individuals: Individualizing User Models,&quot;International Journal of Man-Machine Studies 18, 199-214 (1983).andM;[19.] L. A. Miller, &quot;Natural Language Programming: Styles, Strategies, andContrasts,&quot; IBM Systems Journal 20, No.andP;  2, 181-215 (1981).andM;[20.] A. W. Bierman, B. W. Ballard, and A. H. Sigmon, &quot;An Experimental Studyof Natural Language Programming,&quot; International Journal of Man-MachineStudies 18, 71-87 (1983).andM;[21.] J. A. Hendler and P. R. Michaelis, &quot;The Effects of Limited Grammar onInteractive Natural Language,&quot; Proceedings of CHI '83: Human Factors inComputing Systems, New York (1983), pp.andP;  190-192.andM;[22.] T. Winograd and C. F. Flores, Understanding Computers and Cognition,Ablex Publishers, Norwood, NJ (1986).andM;[23.] E. F. Codd, &quot;HOW ABOUT RECENTLY?&quot; (English dialog with relationaldatabases using RENDEZVOUS Version 1), in Databases: Improving Usability andResponsiveness, Academic Press, New York (1978), pp.andP;  3-8.andM;[24.] D. Waltz, &quot;An English Language Question Answering System for a largeRelational Database,&quot; Communications of the ACM 21, No.andP;  7, 526-539 (July1978).andM;[25.] M. templeton, &quot;EUFID: A Friendly and Flexible Frontend for DataManagement Systems,&quot; Proceedings of the 1979 National Conference of theAssociation for computational Linguistics (August 1979).andM;[26.] J. J. Robinson, DIAGRAM: A Grammar for Dialogue, AI Center TechnicalNote 205, SRI International, Menlo Park, CA (February 1980).andM;[27.] Systems Application Architecture--Common User Access Panel Design andUser Interaction, SC26-4351-0, IBM Corporation (1987)andgt; available through IBMbranch offices.andM;[28.] E. F. Wheeler and A. G. Ganek, &quot;Introduction to Systems ApplicationArchitecture,&quot; IBM Systems Journal 27, No.andP;  3, 250-263 (1988).andM;[29.] R. Kimball, &quot;A Self-improving Tutor for Symbolic Integration,&quot; inIntelligent Tutoring Systems, D. Sleeman and J. S. Brown, Editors, AcademicPress, New York (1982), pp.andP;  283-307.andM;[30.] A. P. Aaronson and J. M. Carroll, The Answer Is in the Question: AProtocol Study of Intelligent Help, Research Report RC 12034, IBM Thomas J.andO;Watson Research Center, Yorktown Heights, NY (1986).andM;[31.] W. Teitelman and L. Masinter, &quot;The Inter Lisp Programming Environment,&quot;Computer 14, No.andP;  4 (April 1981), pp.andP;  25-34.andM;[32.] R. C. Houghton, &quot;Online Help Systems: A Conspectus,&quot; Communications ofthe ACM 27, No.andP;  2 (February 1984), pp.andP;  126-133.andM;[33.] T. Finin, &quot;Providing Help and Advice in Task Oriented Systems,&quot;Proceedings of the Eighth International Conference on ArtificialIntelligence, Karlsruhe, West Germany (1983), pp.andP;  176-178.andM;[34.] Operating System/2 Standard Edition 1.1, Volume 1, 90X7934, IBMCorporation (1988)andgt; available through IBM branch offices.andM;[35.] M. D. Ringle and R. Halstead-Nussloch, &quot;Shaping User Input: A Strategyfor Natural Language Dialog Design,&quot; to be published in Interacting withComputers (1990).andM;[36.] F. C. Pereira and D. H. Warren, &quot;Definite Clause Grammars for LanguageAnalysis: A Survey of the Formalism and a Comparison with AugmentedTransition Networks,&quot; Artificial Intelligence 13, 231-278 (1980).andM;[37.] Expert System Consultation Environment/VM and Expert System Developmentenvironment/VM, IBM IPS Service Support Center, Irving, TX (1985).andM;[38.] J. F. Sowa, Conceptual Structures: Information Processing in Mind andMachine, Addison-Wesley Publishing Company Reading, MA (1984).andM;[39.] M. McCord, &quot;Natural Language Processing in Prolog,&quot; in KnowledgeSystems and Prolog, A. Walker, Editor, Addison-Wesley Publishing Company,Reading, MA (1987), pp.andP;  316-324.andM;[40.] C. J. Fillmore, &quot;The Case for Case,&quot; in Universals in Language, E. Bachand R. T. Harms, Editors, Holt, Rinehart andamp; Winston, New York (1968).andM;[41.] W. R. Swartout, &quot;Explaining and Justifying Expert Consulting Programs,&quot;Proceedings of the 7th International Joint conference on ArtificialIntelligence (IJCAI), Vancouver, BC (1981), pp.andP;  815-822.andM;[42.] B. R. Gaines and J. N. Vickers, &quot;Design and Considerations forHypermedia Systems,&quot; Microcomputers for Information Management 5, No.andP;  1,1-27 (March, 1988).andM;John M. Prager  IBM Cambridge Scientific Center, 101 Main Street, Cambridge,Massachusetts 02142.andP;  Dr. Prager is a project leader at the IBM CambridgeScientific Center, which he joined in 1979.andP;  He worked initially on officesystems, in particular on the POLITE project.andP;  His research contributionsfrom that effort have earned him an Outstanding Innovation Award and twoInvention Achievement Awards.andP;  His current activities include the developmentof user interfaces for powerful personal workstations, using techniques fromartificial intelligence.andP;  He has published several papers and technicalreports and is a member of the Association for Computing Machinery and theInstitute of Electrical and Electronic Engineers Computer Society.andP;  Dr.andO;Prager received a B.A., a Diploma in Computer Science (with Distinction), andan M.A., all from the University of Cambridge, and a Ph.D.andP;  in computerscience from the University of Massachusetts at Amherst.andM;Donna M. Lamberti  IBM Cambridge Scientific Center, 101 Main Street,Cambridge, Massachusetts 02142.andP;  Dr. Lamberti is a research staff member inthe artificial intelligence (AI) and user interface area.andP;  She received aB.A.andP;  in Experimental Psychology from Vassar College, Poughkeepsie, New Yor,in 1982 and an M.S.andP;  degree in Cognitive Psychology, as well as a Ph.D.andP;  inManagement Information Systems/Decision Sciences from rensselaer PolytechnicInstitute, Troy, New York, in 1987.andP;  Her thesis research was the developmentand empirical evaluation of an intelligent interface for a diagnostic expertsystem.andP;  This work was sponsored by an IBM Fellowship for research ininformation systems.andP;  She joined the Cambridge Scientific Center in 1987.andO;Her current research interests include intelligent interface design fordecision support technology, the design of AI-based advisory systems fororganizations, and the implementation of decision support/knowledge-basedsystems.andM;David L. Gardner  IBM Systems Integration Division, 6300 Diagonal Highway,Boulder, Colorado 80301.andP;  Mr. Gardner was research staff member on the REASONproject.andP;  He received a bachelor's degree in electrical engineering fromBrigham Young University in 1982 and a high technology M.B.A.andP;  degree fromNortheastern University, Boston, Massachusetts, in 1989.andP;  From 1982 to 1986,he was involved in test engineering at the IBM Boca Raton, Florida, facility.andO;From 1986 to 1989, he was a staff member at the IBM Cambridge ScientificCenter.andP;  His interests include personal computers, workstations,computer-human interfaces, artificial intelligence, and the application ofcomputing systems in the high-technology industry.andM;Stephen R. Balzac  IBM Palo Alto Scientific Center, 1530 Page Mill Road, PaloAlto, California 94304.andP;  Mr. Balzac is a research staff member at the PaloAlto Scientific Center.andP;  He first worked for IBM as a co-op at the Thomas J.andO;Watson Research Center.andP;  He received his S.B.andP;  and S.M.andP;  degrees in computerscience from the Massachusetts Institute of Technology, Cambridge,Massachusetts, in 1987.andP;  His thesis work was the development of aninteractive knowledge classification system using a semantic inheritancenetwork.andP;  His current interests include artificial intelligence and knowledgerepresentation.andO;</TEXT></DOC>