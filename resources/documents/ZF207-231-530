<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-231-530  </DOCNO><DOCID>07 231 530.andM;</DOCID><JOURNAL>AI Expert  May 1989 v4 n5 p44(5)* Full Text COPYRIGHT Miller-Freeman 1989.andM;</JOURNAL><TITLE>Understanding Bayesian belief networks. (technical)</TITLE><AUTHOR>Morawski, Paul.andM;</AUTHOR><SUMMARY>Uncertainty is a major concern in expert system research.andP;  The useof Bayesian theory in developing an inference system for reasoningunder uncertainty is discussed.andP;  Inference systems and theirspecialized language and inference rules are examined.andP;  Comparisonis made to inference systems developed using Boolean logic.andO;Models of Bayesian belief networks are analyzed step by step.andP;  Itis concluded that programmers designing expert systems shouldconsider using Bayesian theory.andM;</SUMMARY><DESCRIPT>Topic:     Bayesian TheoryAlgorithmsUncertaintyNetwork ModelsMathematical LogicMathematics of ComputingArtificial IntelligenceComputer LearningBoolean AlgebraExpert SystemsProgram LogicApplications.andO;Feature:   illustrationchart.andO;Caption:   Initial state of network. (chart)State of network after rain alarm. (chart)State of network after rain alarm and phone call. (chart)andM;</DESCRIPT><TEXT>Understanding BAYESIAN BELIEF NETWORKSandM;Inference can be thought of as the process of deriving a conclusionindirectly, given statements that only imply that conclusion.andP;  Possibly themost fundamental issue addressed by AI, inference plays a key role in nearlyall AI systems.andM;All inference systems have two features in common: a specialized language, toexpress statements, and rules of inference, defining how to combinestatements to derive additional statements.andP;  The most familiar form ofinference is based on the two-valued logic of George Boole called Booleanlogic, in which statements are represented by variables that may be eithertrue or false.andP;  Relations between variables are specified using connectivessuch as &quot;and,&quot; &quot;or,&quot; &quot;not,&quot; and &quot;logical implication.&quot;andP;  These connectivesconstitute a language for expressing everyday notions of conjunction,disjunction, negation, and implication.andP;  Of particular interest is logicalimplication, denoted by [right arrow].andP;  If, in some domain, we know that astatement B must be true whenever some other statement A is true, we maywrite A [right arrow] B to represent this knowledge.andP;  If at some future pointwe determine that A is indeed true, we may then infer that B is also true.andM;This rule of inference, called modus ponens, is used pervasively in AI.andO;Consider the statement rain [right arrow] clouds, where the variable rainrepresents the proposition &quot;It is raining&quot; and the variable clouds representsthe proposition &quot;Clouds are present.&quot; This statement captures a generalrelation between rain and clouds, but says nothing about the current state ofthe world.andP;  However, given the additional information that it is raining, wemay infer that clouds are present.andP;  The implication provides only partialinformation about the relation between rain and clouds: although the presenceof rain enables us to infer the presence of clouds, the presence of cloudsdoes not necessarily permit any inference to be made regarding the presenceof rain.andM;The first-order predicate calculus, a generalization of Boolean logic, andmodus ponens provide the language and rule of inference used in anoverwhelming number of AI systems, especially those relying onforward-chaining production rules.andP;  Statements describing the current stateof the world and inferences derived from them are stored in what is termedworking memory, and the implications representing domain knowledge are storedas production or if/then rules.andP;  An inference engine is used to matchpatterns in working memory with patterns in the left-hand side of rules,causing rules to fire and further modify the working memory.andP;  This approachis attractive for several reasons: it provides a language and rule ofinference with which most people are familiar, and the use of productionrules implies that the domain knowledge is being represented in a concise,modular fashion.andM;Although this model has proven tremendously successful, its shortcomings mustbe recognized.andP;  Crisp values such as true and false may not always beavailable to the inference process; sometimes evidence is uncertain.andO;Similarly, the implications themselves may not be crisp; what if rain did notalways imply the presence of clouds?andP;  In addition, the use of productionrules can encourage incomplete specification of domain knowledge--the domainexpert might forget to specify further rules that relate rain and clouds, andlogic provides no simple way to draw tentative conclusions from incompleteinformation.andP;  Furthermore, the modularity inherent in production rules limitstheir utility for managing uncertain information.andM;BAYES' THEOREMandM;An alternative inference technique that provides a framework for reasoningunder uncertainty, termed Bayesian belief networks, is based on probabilitytheory and was developed in its present form by Judea Pearl of the Universityof California (Los Angeles, Calif.).andP;  The origins of this technique can betraced to the inference networks of PROSPECTOR.andM;Understanding Bayesian belief networks requires an understanding of Bayes'theorem, as it provides the underlying inference rule for Bayesian reasoning.andO;In Bayesian reasoning, statements are represented by variables, much like inBoolean logic.andP;  However, these variables may take on many different values,rather than being limited to true and false.andP;  Each possible value for avariable has a probability associated with it reflecting the current amountof belief in that particular value.andP;  For example, a variable representing theactivity of a fire department might have three possible values: fire, idle,or drill.andP;  These values would represent the alternatives: &quot;The firedepartment is at a fire,&quot; &quot;The fire department is idle,&quot; or &quot;The firedepartment is having a drill,&quot; respectively.andM;The values selected for each variable must be mutually exclusive andexhaustive, and the associated beliefs must sum to one.andP;  This means the firedepartment cannot be in a state other than fire, idle, or drill, and it canbe in only one of these states at a time.andP;  For example, the values for thefire department activity variable might be fire (.9), idle (0), and drill(.1), indicating strong belief that the department is at a fire, no beliefthat the department is idle, and a small belief that the department is havinga drill.andP;  Each variable's belief is represented as a column vector: P(firedepartment activity)=andM;Bayesian inference differs from logical inference in that it requires aninitial estimate of each variable's belief values, called the priorprobabilities.andP;  They represent what the variable's belief values should be inthe absence of any external evidence.andP;  The inference process here revisesthese initial estimates as new evidence arrives.andP;  The revised beliefs arereferred to as posterior probabilities and are computed using Bayes'inversion formula: P(x/e) = [alpha][lambda]e(x o P(x)andM;This rule tells us how to compute the revised (posterior) probability ofvariable x given the occurrence of some event e believed to be an indicatorof x.andP;  The likelihood vector [lambda],(x) specifies the strength with whicheach state of variable x is indicated when event e occurs and is defined asfollows:andM;Each conditional probability term in [lambda],(x) specifies the probabilityof event e occurring given that variable x is in state x.andP;  The symbol odenotes term-by-term multiplication of the column vectors, and thenormalizing constant [alpha] is absorbed into the final result so theprobabilities sum to one.andM;The following example illustrates the use of this formula.andP;  Suppose you workin a windowless office and your only way of determining the current weatheris by using a somewhat unreliable rain alarm.andP;  On the average, it rains sixdays out of every 100, so the prior probability of rain is the vector:andM;Now your rain alarm sounds and you wish to determine a revised probability ofrain.andP;  Experience with the alarm tells you that the probability of the alarmsounding when there is rain is .8, but 4% of the time the alarm will soundfalsely.andP;  An appropriate likelihood vector will be: [lambda].sub.alarm.(rain)andM;=We now revise the probability of rain given the alarm as follows:P(rain!alarm) =andM;The value of [alpha] was computed as 1/(.048 + .0376) and was multiplied intothe result so the probabilities would sum to one.andP;  In light of the evidenceprovided by the rain alarm, the probability that it is raining is now 56%.andO;The evidence of rain supplied by an external source such as the rain alarm isreferred to as virtual evidence.andP;  The introduction of such evidence is theprincipal means of communicating information about the current state of theworld of Bayesian belief networks.andM;BAYESIAN BELIEF NETWORKSandM;As its name suggests, a Bayesian belief network is a network consisting ofnodes and links.andP;  Each node in the network represents a probabilisticvariable, as in the previous examples.andP;  Each link in the network represents arelation between the two nodes (variables) it connects; a relation isquantified by a conditional probability matrix associated with the link.andP;  Thenotion of causality between two linked variables exists, so links are drawnwith an arrow pointing toward the affected variable.andP;  The knowledgeengineering process for these networks consists of identifying relevantdomain variables to be represented by nodes and determining the causalrelationships between them.andM;The belief at each node is computed by using Bayes' rule to fuse the beliefsof its parents with diagnostic evidence accumulated by its children.andP;  Thecausal evidence from the parents acts implicitly as the node's priorprobability and is denoted by [pi].andP;  Nodes without parents--top nodes--musthave their prior probabilities specified explicitly by the knowledgeengineer.andP;  The diagnostic evidence from the children acts as the node'slikelihood vector and is denoted by [lambda].andP;  Thus, the belief at each nodeis computed by Belief(x) = [alpha] [lambda](x) o [pi](x).andP;  Evidence iscommunicated along the network's links with a message-passing scheme usingthe conditional probability matrix or its transpose to translate each messageinto terms appropriate for its destination.andP;  The following detailed exampleillustrates the complete process.andM;Suppose it is Saturday and you are working in your windowless office, asusual.andP;  You look forward to going to a baseball game later, but of course thegame may be cancelled if it rains.andP;  You have your unreliable rain alarm andone of your kids is at the local beach.andP;  Will the baseball game be rainedout?andP;  Will your child get a sunburn?andP;  Consider the belief network shown inFigure 1.andM;The nodes and links of Figure 1 provide a computational framework in which toupdate your belief in whether or not the game will be played.andP;  Some of therelations contained in the net's links include:andM;* If it is cloudy, there is only a 10% chance that your child will get asunburn (he is more likely to remain in the video arcade).andP;  If it is sunny,it is 70% probable he will get a sunburn.andM;* Clouds cause rain 60% of the time and rain cannot occur if clouds areabsent.andM;* If it rains, there is a 95% chance that the baseball game will becancelled.andP;  Otherwise it is certain that the game will be played.andP;  Theconditional probability matrices representing these relations are shown nextto the links in Figure 1.andM;The Clouds node, being the only top node, has a prior probability of .1,reflecting that at this particular locale, it is cloudy 10% of the time.andO;Therefore, the [pi] term for that node is the vector (.1.9).sup.T.andP;  Theremaining anticipatory belief values have been computed by propagating thesepriors throughout the network.andP;  The propagation is accomplished at each stageby matrix multiplication of the transpose of each conditional probabilitymatrix with the belief vector of the parent node.andP;  The initial [lambda] termsare the vector (1 1).sup.T., which indicates the absence of any diagnosticevidence.andP;  (All computations for the figures were performed using four digitsand were then rounded to the two digits shown).andP;  We see that in the absenceof any other information the probability that the baseball game will beplayed is high (.94).andM;Now suppose your rain alarm sounds that afternoon.andP;  How does the arrival ofthis information affect the beliefs throughout the network?andP;  Using Pearl'supdating scheme, the following sequence of events would occur.andP;  The lettersin parentheses identify messages shown in Figure 2 along with the underlyingcomputations:andM;1.andP;  The alarm is treated as a source of virtual evidence and causes thebelief of the Rain node to be revised to .56, as in the earlier example.andP;  TheRain node would send a [pi] message (a) to the Play Game node and a [lambda]message (b) to the Clouds node.andP;  The [pi] message reflects the revised beliefin the Rain node.andP;  The [lambda] message communicates the newly receivedvirtual evidence and is computed by multiplying that evidence with theconditional probability matrix.andM;2.andP;  Upon receipt of the incoming [pi] message, the Play Game node uses thosevalues to revise its internal [pi] term and its belief.andM;3.andP;  Upon receipt of the incoming [lambda] message, the Clouds node uses thosevalues to revise its internal [lambda] term and its belief.andP;  This revisedbelief is sent to the Sunburn node as a [pi] message (c).andM;4.andP;  Upon receipt of the incoming [pi] message, the Sunburn node uses thosevalues to revise its internal [pi] term and its belief.andM;The net result of this computational chain is that your expectation of cloudshas increased and your expectation of seeing a ball game has decreased.andP;  Atleast you do not expect to nurse a sunburned child that evening.andM;Later that afternoon your son calls you on the telephone.andP;  He is reluctant todiscuss the weather, but insists on spending the night with his nearby aunt.andO;After consenting, you muse over the conversation, remembering that he tendsto visit her only when he has something to hide.andP;  You estimate that he wouldcertainly visit her if he were sunburned, while the probability that he wouldvisit her otherwise is only 2%.andP;  How does this new evidence affect theoutlook on the baseball game?andM;The new evidence can be used as virtual evidence impinging on the Sunburnnode, as shown in Figure 3.andP;  The arrival of this evidence would trigger thefollowing sequence of computations:andM;1.andP;  The Sunburn node would revise its belief in light of the new evidence andwould communicate the arrival of virtual evidence by sending a [lambda]message (a) to the Clouds node.andP;  The [lambda] message is computed bymultiplying the new evidence with the conditional probability matrix.andM;2.andP;  Upon receipt of the incoming [lambda] message, the Clouds node uses thosevalues to revise its internal [lambda] term and its belief.andP;  The revised[lambda] term reflects both the new [lambda] message and the earlier [lambda]message received from the Rain node.andP;  The revised belief is sent to the Rainnode as a [pi] message (b).andP;  The computation of the [pi] message is subtlydifferent in this case, however.andP;  Rather than simply sending the beliefintact, the propagation scheme first removes the [lambda] value sent earlierby the Rain node (the symbol [phi] denotes term-by-term division).andP;  Thisremoval prevents the rain alarm evidence from being counted twice in the Rainnode.andM;3.andP;  Upon receipt of the incoming [pi] message, the Rain node uses the newvalues to revise its internal [pi] term and its belief.andP;  This revised beliefis sent to the Play Game node as a [pi] message (c).andM;4.andP;  Upon receipt of the incoming [pi] message, the Play Game node uses thenew values to revise its internal [pi] term and its belief.andM;This second revision cycle provides updated beliefs that take into accountall the evidence, both the sounding of the rain alarm and the phone call.andO;Things look a bit better now--it appears unlikely that it is cloudy orraining, and you assume that your sunburned child will be looked after by hisaunt while you enjoy the ball game.andM;Because each node of our network has at most one cause, our example is nottotally general.andP;  In the general case, an arbitrary number of causes mayexist for any variable.andP;  When this occurs, the conditional probability matrixis generalized to a joint conditional probability tensor summarizing therelation between all causal variables and their common child.andP;  The updatingprocedure is similar but uses tensor operations rather than the simple matrixoperations shown here.andP;  Although all the example's variables had only twovalues, the inference process is identical for multihypothesis variables likethe earlier one depicting fire department activity.andP;  Multihypothesisvariables are accommodated by introducing longer belief vectors andcorrespondingly larger conditional probability matrices.andM;The Bayesian belief network provides an inference mechanism tailored formaking probabilistic inferences to combine uncertain information.andP;  Pearl'supdating scheme provides a computational framework for simultaneous forward(cause-to-effect) and backward (effect-to-cause) inferencing.andP;  How does thisparadigm address the other deficiencies of production rules presentedearlier?andP;  The requirement that the relations between variables be specifiedby a conditional probability matrix forces the knowledge engineer to considerthe various combinations of variable values.andP;  In addition, the specificationof prior probabilities provides the network with background information fromwhich tentative conclusions may be drawn.andP;  For example, in the absence of anyexternal evidence, we could have assumed the ball game would be played.andM;In some circumstances, these features must be viewed as weaknesses ratherthan strengths.andP;  In some domains where it is impossible to provide therequisite prior probabilities for the top nodes, or the appropriateconditional probability matrices, a different approach must be pursued.andP;  Indomains where the necessary data are available, this technique provides anattrative alternative to the more ad hoc approaches, in which uncertainty isintegrated into rule-based approaches.andP;  Therefore, the Bayesian techniquedeserves consideration the next time you design an expert system that mustdeal with uncertainty.andO;</TEXT></DOC>