<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-188-586  </DOCNO><DOCID>08 188 586.andM;</DOCID><JOURNAL>AI Expert  March 1990 v5 n3 p48(6)* Full Text COPYRIGHT Miller Freeman Publications 1990.andM;</JOURNAL><TITLE>An introduction to genetic algorithms. (artificial intelligence)</TITLE><AUTHOR>Austin, Scott.andM;</AUTHOR><SUMMARY>Genetic algorithms are a powerful new technique emerging inartificial-intelligence research.andP;  The basic construction ofgenetic algorithms is built on the principle of natural selectionand involves maintaining a 'population' of data structures thatmay be 'challenged' during each iteration, or 'generation.' Eachgeneration forms a new population of the most viable domainsolutions through crossover, mutation, reproduction, and other'genetic operators.' Reproduction involves a probabilisticselection process that ensures that structures with higher fitnesswill contribute more offspring.andP;  Crossover chooses randompositions in a string of symbols similar to strands of DNA andexchanges segments with the corresponding ones in other strings.andO;Mutation modifies gene values of an existing individuals to createnew individuals.andP;  Parameters in a genetic algorithm includepopulation size, crossover rate, mutation rate, percentage of thepopulation replaced each generation, scaling factors, andselection strategy.andP;  Possible applications of genetic algorithmsinclude dynamic process control, machine learning, and simulatingbiological models of evolution and behavior.andM;</SUMMARY><DESCRIPT>Topic:     AlgorithmsGeneticsArtificial IntelligenceNew TechniqueHeuristic Methods.andM;</DESCRIPT><TEXT>Genetic algorithms can provide efficient search heuristics for a wide rangeof applicationsandM;Genetic algorithms could play a critical role in synthetic-intelligenceresearch.andP;  One of the basic goals of synthetic intelligence is to developsystems that demonstrate, without forced learning, explicit semantic rules orprior instructions and capabilities in pattern recognition, categorization,and association.andP;  Can systems or techniques be developed that demonstrateself-organization and adaption on the basis of exposure to the environmentalone? Proof of such systems already exists: biological organisms.andM;A BIOLOGICAL METAPHORandM;During their evolution, biological systems developed successful strategies ofbehavior adaption and synthesis to enhance the probability of survival andpropagation.andP;  Environmental pressures requiring these strategies haveeffected profound changes in biological organisms.andP;  These changes aremanifested in structural and functional specializations, informationalorganization, and internal knowledge representations.andM;The principle behind genetic algorithms is essentially Darwinian naturalselection.andP;  In The Blind Watch Maker, Richard Dawkins describes the power ofcumulative selection and its transformation of random processes intononrandom ones.andP;  [1] In cumulative selection, each successive incrementalimprovement in a solution structure becomes the basis for the nextgeneration.andP;  In contrast, single-step selection places each new solutionstructure independently of the last.andP;  In the single-step process, nocumulative knowledge acquisition defines what constitutes good performanceand subsequent reward in the problem space.andP;  This argument implies theexistence of an environmental performance measure and reward system.andM;The term &quot;environmental&quot; is used in the broadest possible sense: any problemspace that can be defined by parameters.andP;  In biological evolution, survivalis a performance measure and reproduction into the next generation is itsreward.andP;  Any living creature can be considered a solution structure in itsecosystem.andM;Modifications and serious objections to the infallibility of the Darwinianpremise have been proposed.andP;  D.R.andP;  Brooks and E.O.andP;  Wiley [2] and theNobelist I. Prigogine [3] have focused on mechanisms of self-organization andthe role of entropy in open systems.andP;  These arguments are based on theobservation that a fitness gradient along which evolution proceeds is absent,but a gradient of increasing structural complexity seems to exist.andP;  It oftenappears that evolutionary flux occurs not when selective pressures aregreatest, but when a sudden shift in selective regimes occurs.andP;  This researchdoes not attempt to replace the Darwinian paradigm, but to augment it andprovide a unified and physical theory of biology.andM;Regardless of their accuracy as biological development theories, theprinciples of natural selection and population genetics are intrinsicallypowerful.andP;  Algorithms inspired by these principles have been successful whenapplied to the challenges of machine learning and function optimization.andP;  [4]The past two decades have seen their abstraction, formalization, [5,6] andapplication in modeling a wide range of phenomena.andM;Computing power, not the progress of neuro and genetic science, limits thepace of genetic-algorithm applications.andP;  Although computing power isincreasing much more quickly than knowledge in the neurogenetic domains, thebody of existing knowledge in both disciplines provides a strong foundationfor applications and further theoretical development.andM;GENETIC ALGORITHMSandM;The behavior of genetic algorithms can be subtle, but their basicconstruction and execution cycle is straightforward.andP;  One definition of agenetic algorithm is &quot;an iterative procedure maintaining a population ofstructures that are candidate solutions to specific domain challenges.andO;During each temporal increment (called a generation), the structures in thecurrent population are rated for their effectiveness as domain solutions, andon the basis of these evaluations, a new population of candidate solutions isformed using specific 'genetic operators' such as reproduction, crossover,and mutation.&quot; [7]andM;Most function optimization and hill-climbing methods are techniques thatoften find the nearest local optimum but fail to find the global solution,particularly with multimodal surfaces.andP;  Statistical techniques often avoidthis problem, but they require much computation time with increasingdimensionality.andP;  When faced with more difficult surfaces, the defaultstrategy is often random search.andP;  Genetic algorithms behave much more subtlythan &quot;random search with preservation of the best.&quot; In fact, pure randomsearch provides a lower bound on the performance of genetic algorithms: itignores the information about the environment accumulated throughout theadaption period.andP;  Genetic algorithms use the accumulating information toprune the search space and generate plausible solutions.andM;MODELING ASSUMPTIONSandM;Research has defined a fairly general framework for the specification ofgenetic algorithms.andP;  Several possible elaborations involve choice of geneticoperators, variable population sizes, and so on.andP;  Most genetic-algorithmresearch has concentrated on these assumptions:andM;* The environment and its inputs and outputs can be represented as strings ofsymbols of a fixed length over a given alphabet A. This alphabet is oftentaken to be {1,0}.andP;  (Some evidence exists that the binary alphabet isoptimal.andP;  [5] Arbitrary alphabets whose symbols can represent the problemspace have been researched, [4] but their utility and effectiveness is stilla matter of intense study.)andM;* Each point in the problem space can be considered as an individualrepresented uniquely within the system by a string generated from theenvironmental alphabet.andP;  This string serves as the &quot;genetic material&quot; withspecific positions (loci) on the string (chromosome) containing uniquesymbols or tokens (genes) taking on values (alleles).andM;* At any instant in time, the system maintains a population P(t) of strings(also called classifiers) representing the current set of solutions to theproblem.andP;  The process begins by random generation or designer specificationof a starting population.andM;* The only feedback available to an adaptive strategy is the value of theprocess performance measure (fitness).andP;  This feedback is usually called&quot;zero-order&quot; feedback; the least information demanded for adaption is anindication of how well the adaption process is performing.andM;* Time is measured in discrete intervals called generations.andM;* No a priori information is required for an adaptive strategy concerning theproblem space, although this constraint can be relaxed.andM;EXECUTION CYCLEandM;The basic execution cycle shown in Figure 1 is simple:andM;1.andP;  From the set of existing solutions, select candidates according tofitness for reproduction.andP;  Candidates with the highest fitness factor have agreater probability of contributing offspring.andM;2.andP;  After reproduction, randomly choose pairs for mating through crossover(exchange of genetic material between two selected candidates) and select,again possibly at random, a site where the material will be exchanged,resulting in the creation of children or offspring.andM;3.andP;  Apply the secondary genetic-operator mutation.andM;4.andP;  Evaluate the performance of the new population.andM;5.andP;  Eliminate the weakest performers; iterate the process.andM;A means must be introduced to ensure that the problem space iscomprehensively searched.andP;  This population variation is developed by usingidealized genetic operators.andM;GENETIC OPERATORSandM;Most research has focused on the three primary operators: reproduction,crossover, and mutation.andM;Reproduction:  The initial population P(0) can be chosen heuristically orrandomly.andP;  The structures of the next generation are chosen from the previousgeneration's members by a probabilistic selection process, which ensures thatthe expected number of times a structure is chosen is approximatelyproportional to that structure's performance relative to the rest of thepopulation.andP;  Structures with higher fitness thus have a greater probabilityof contributing offspring.andM;Crossover: Figure 2 illustrates crossover.andP;  Structures are represented bystrings of symbols.andP;  If the symbols are binary, crossover can be implementedby choosing a random position in the string (called the crossover point) andexchanging the segments either to the right or left of this point withanother string similarly partitioned.andP;  Crossover provides new points fortesting within the problem space.andP;  Each evaluation of a string of length Ladds knowledge about the performance of the n[.sup.L] hyperplanes representedby that structure, where n is the number of unique symbols in the alphabet.andO;Genetic algorithms derive their power largely by using simple, selectivemechanisms to exploit this huge amount of accumulating knowledge efficiently.andM;Mutation: Mutation creates new individuals by modifying one or more of thegene values of an existing individual.andP;  Mutation is not a primary geneticoperator.andP;  In biological systems, the probability of a gene mutating issmall, which is the case in our models.andP;  Mutation ensures that theprobability of searching any region in the problem space is never zero andprevents complete loss of genetic material through selection and elimination.andM;Genetic algorithms are extremely flexible; their inputs and outputs canrepresent a broad variety of phenomena.andP;  This variety includes combinatorialoptimization, image processing, pipeline control systems, and machinelearning.andP;  [8-11]andM;GENETIC PARAMETERSandM;K.A.andP;  De Jong has noted the simplicity of representing adaptive systems andtheir behavior as standard feedback control structures.andP;  [12] This techniquehas two advantages.andP;  First, the large body of existing classical controltheory can be focused immediately on the problem; second, it allows arelatively simple formal representation of adaptation.andP;  This formalism can beexpressed in the following set of parameters:andM;* Population size (N).andP;  Population size affects both global performance andgenetic-algorithms efficiency.andP;  Genetic algorithms with small populationsusually perform poorly because the population provides an insufficientcoverage of the problem space.andP;  A large population is more likely to berepresentative of the entire problem domain.andP;  Furthermore, a large populationprevents premature convergence to local instead of global solutions.andM;* Crossover rate (C[.sup.r]).andP;  The frequency with which the crossoveroperator is applied is controlled by the crossover rate.andP;  In each newpopulation, N * Cr structures undergo crossover-the higher the crossoverrate, the more quickly new structures are introduced to the population.andP;  Ifthe crossover rate is too high, good performance structures are removedfaster than selection can produce improvements.andP;  A low crossover rate maystagnate the search.andM;* Mutation rate (MI).andP;  To increase the variability of the population, asecondary search operator, mutation, is used.andP;  Mutation is random; eachfundamental unit (bit, position, or token) in a structure has a finiteprobability of changing.andP;  A low level of mutation prevents a given positionfrom freezing at a single value; a large mutation rate results in essentiallyrandom search.andP;  Approximately Mr * N * L mutations occur per generation whereL is the structure length.andM;* Generation gap (G).andP;  The generation gap controls the percentage of thepopulation to be replaced during each generation.andP;  N * G structures of thepopulation P(t) are chosen to be replaced in P(t + 1).andP;  A value of G = 1.0means that the entire population is replaced during each generation.andM;* Selection strategy (S).andP;  Several selection strategies are possible; thegenetic-algorithm tool METAMORPH considers two of them.andP;  The first is a pureselection strategy where each structure in the current population isreproduced in proportion to the structures fitness.andP;  The second is an elitiststrategy: pure selection is performed first and the structures with the bestperformance are chosen to survive to the next generation, avoiding removal bycrossover, mutation, or sampling error.andM;* Scaling factor (SF).andP;  Maintaining population diversity during evolution isimportant.andP;  A super-performer that dominates the population until no furtherimprovement is possible may appear early in the process.andP;  This geneticplateau should be avoided so that the problem space is sufficiently explored.andO;Similar performers may appear late in the system's life cycle; they must beranked and their respective performance scaled to reflect their relativefitness.andM;APPLICATIONSandM;A system's successful performance in a dynamic environment often requiresadaptive solutions.andP;  Usually inherent domain complexity (such as noise, highdimensionality, multimodal response, and uncertainty) prevents specificationof acceptable a priori solutions.andP;  Adaptive systems attempt to solve domainproblems by accumulating knowledge about the problem and using thisinformation to generate acceptable solutions; these solutions are not alwaysoptimal but usually satisfactory.andP;  Some challenges typically arise in theareas of complex systems configuration such as software design, taskallocation (scheduling algorithms), route selection (traveling-salesmanproblem), and other optimization and machine-learning problems.andP;  A fewexamples:andM;* Dynamic process control.andP;  A nominal approach to this class of problems isto tune the algorithm manually to the average utilization profiles of theprocess.andP;  After the initial stage, the system usually runs automaticallyuntil an anomaly triggers a system degradation.andP;  An adaptive solution wouldaddress this challenge by modifying the underlying algorithms dynamically inresponse to the process variations.andP;  [4]andM;* Induction and optimization of rules.andP;  For this application the majorquestions are how to discover and emphasize rules that work, remove thosethat don't (assuming memory space is limited and noise potentiallydisruptive), and optimally generalize those that are retained.andP;  Geneticalgorithms can infer rules for discrimination from examples of labeled classpatterns.andP;  [5,13]andM;* Discovering new connectivity topologies.andP;  In artificial neural systems,genetic algorithms can lead to the discovery of entirely new architectures.andO;Some architectures may never evolve but still be optimal for a particularapplication.andP;  (These applications encompass both artificial neural-systemsengineering and biological neural modeling.) Investigations have involvedhardware implementations and software simulations.andP;  [14-17]andM;* Simulating biological models of behavior and evolution.andP;  [18,19] Usinggenetic principles to design adaptive synthetic systems of sophisticationcomparable to natural biological systems is one important goal of thisresearch.andM;Genetic algorithms provide a set of efficient, domain-independent searchheuristics for application to a broad spectrum of engineering challenges.andO;Conventional model-based implementations for optimization, search, andsynthetic intelligence require large amounts of explicit, domain-specificknowledge.andP;  Such systems are brittle because considerable human maintenanceis needed to compensate for even modest shifts in the domain behavior.andP;  [13]andM;REFERENCESandM;1.andP;  Dawkins, Richard.andP;  The Blind Watchmaker.andP;  New York N.Y.: W.W.andP;  Norton andamp;Co., 1987.andM;2.andP;  Brooks, D.R., and E.O.andP;  Wiley.andP;  Evolution as Entropy: Toward a UnifiedTheory of Biology, 2nd ed.andP;  Chicago, Ill.: University of Chicago Press, 1988.andM;3.andP;  Prigogine, I. From Being to Becoming.- Time and Complexity in thePhysical Sciences.andP;  San Francisco, Calif.: W. H. Freeman Co., 1980.andM;4.andP;  Goldberg, David E. Genetic Algorithms in Search, Optimization andamp; MachineLearning.andP;  Reading, Mass: Addison-Wesley, 1989.andM;5.andP;  Holland, John H. Adaptation in Natural and Artifical Systems.andP;  Ann Arbor,Mich.: University of Michigan Press, 1975.andM;6.andP;  von Neumann, J. Theory of Self-Reproducing Automata.andP;  Champaign, Ill.:andO;University of Illinois Press, 1966.andM;7.andP;  Grefenstette, John J. &quot;Optimization of Control Parameters for GeneticAlgorithms.&quot; IEEE Transactions on Systems, Man, and Cybernetics SMC-16 1(1986): 122128.andM;8.andP;  Davis, Lawrence, ed.andP;  Genetic Algorithms and Simulated Annealing.andO;London, U.K.: Pitman, 1987.andM;9.andP;  Grefenstette, John J., ed.andP;  Proceedings of the 1st InternationalConference on Genetic Algorithms and their Applications.andP;  Hillsdale, N.J.:andO;Lawrence Erlbaum Associates, 1985.andM;10.andP;  Grefenstette, john J., ed.andP;  Proceedings of the 2nd InternationalConference on Genetic Algorithms and their Applications.andP;  Hillsdale, N.Y.:andO;Lawrence Erlbaum Associates, 1987.andM;11.andP;  Schaffer, David, J., ed.andP;  Proceedings of the 3rd InternationalConference on Genetic Algorithms.andP;  Morgan Kaufmann Publishers, 1989.andM;12.andP;  DeJong, K. A. &quot;Adaptive Systems Design: A Genetic Approach,&quot; IEEETransactions on Systems, Man, and Cybernetics SMC-10 9 (1980): 566-574.andM;13.andP;  Holland, John H. &quot;Escaping Brittleness: The Possibilities of GeneralPurpose Algorithms Applied to Parallel Rule-Based Systems.&quot; In Michelski,R.S., J.G.andP;  Carbonell, and T.M.andP;  Mitchell (eds.) Machine Learning 2 PaloAlto, Calif.: Morgan Kaufman Publishers, 1986.andM;14.andP;  Dress, W.B.andP;  &quot;Frequency-Coded Artificial Neural Networks: An Approach toSelf-Organizing Systems.&quot; Proceedings of the IEEE First Annual InternationalConference on Neural Networks 2 (1987): 25-54.andM;15.andP;  Dress, W.B., and J.R.andP;  Knisley.andP;  &quot;A Darwinian Approach to ArtificialNeural Systems.&quot; Proceedings of the IEEE International Conference on System,Man, and Cybernetics (1987): 572-577.andM;16.andP;  Edelman, Gerald M. Neural Darwinism: The Theory of Neuronal GroupSelection.andP;  New York, N.Y.: Basic Books, 1987.andM;17.andP;  Whitley, D., and T. Starkweather.andP;  &quot;Optimizing Small Neural NetworksUsing a Distributed Genetic Algorithm.&quot; Technical Report CS-89-114, ComputerScience Dept., Colorado State University, Ft.andP;  Collins, 1989.andM;18.andP;  Dress, W.B.andP;  &quot;Synthetic Organisms and Self-Designing Systems.&quot;andO;Forthcoming in Proceedings of the Goddard Conference on Space Applications ofArtificial Intelligence (1989).andM;19.andP;  Wilson, S.W.andP;  &quot;Classifier Systems and the Animat Problem.&quot; MachineLearning 2 (1987): 199-228.andM;Scott Austin is a senior scientist in the AI and signal-processing dept.andP;  ofMcDonnell Douglas Corp., Huntington Beach, Calif.andO;</TEXT></DOC>