<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-168-116  </DOCNO><DOCID>08 168 116.andM;</DOCID><JOURNAL>EXE  Feb 1990 v4 n8 p42(4)* Full Text COPYRIGHT Process Communications Ltd. (England) 1990.andM;</JOURNAL><TITLE>Verification, validation and testing. (debugging lines of programcode) (includes a related article on the 'cleanroom' method ofsystem development)</TITLE><AUTHOR>Bruce, John.andM;</AUTHOR><SUMMARY>The industry standard ratio of 50 errors per thousand lines ofcode can be reduced by a factor of 100, and application of theverification and validation techniques discussed here will helpimprove the reliability and reduce the maintenance costs ofsoftware.andP;  Testing entails the process of verification andvalidation in addition to program execution; the four categoriesof techniques available are manual methods, static analysis,dynamic analysis and functional testing.andP;  Four common manualmethods are walk-through, review, inspection and audit, each ofwhich is described.andP;  Also discussed are code audits and how toconduct meetings involving inspections and audits.andM;</SUMMARY><DESCRIPT>Topic:     New TechniqueDebuggingSoftware ValidationSoftware MetricsTutorialProgram Development TechniquesSoftware maintenance.andO;Feature:   illustrationchartgraphtable.andO;Caption:   Life-cycle model showing review and inspection points. (chart)Comparing error detection by inspection and unit tests. (graph)A comparison of inspection and unit test. (table)andM;</DESCRIPT><TEXT>There's a school of thought that puts the industry standard' bug ratio at 50errors per thousand lines of code (1).andP;  If this is the case then, with alittle thought, there is no reason why this figure should not be improved bya factor of 100.andP;  Doing so would provide increased reliability and reducedmaintenance costs, too.andP;  in this article, I'll highlight some of the ways inwhich verification and validation techniques can be used to help achievefewer errors.andP;  Verification and validation are two sides of the same coin forwhich Boehm (2) gave us these simplifications: * Verification-'Are webuilding the productandM;right?' * Validation-'Are we building the rightandM;product?' In the dictionary sense, to verify is to test the truth, accuracy,or correctness of something.andP;  In our case this is the assertion 'are webuilding the product in the right wavy'.andP;  validation, on the other hand, isthe act of establishing that all necessary conditions are fulfilled.andP;  Thisapplies to the specification by posing the question about 'the rightproduct'.andP;  Confirming, 'is this what the customer asked for?', is perhaps asharper focus.andP;  There can be subtle differences between that answer and whatis actually wanted.andP;  Testing The concept of testing extends to embrace notonly program execution with suitable data, but the processes of verificationand validation as well.andP;  Incidently, none of the methods to be described hererequires that the program be executed, therefore, data-based testing isexcluded.andP;  There are four broad categories of techniques available forsoftware verification and validation.andP;  These va from quite informal manualmethods which do not require any tool, up to very formal mathematicalmethods.andP;  * Manual methods.andP;  * Static analysis.andP;  * Dynamic analysis.andP;  *andO;Functional testing.andP;  Within the first category, four commonly used manualmethods are: * Walk-through.andP;  9 Review.andP;  9 Inspection.andP;  * Audit.andP;  A fifthmethod, invented by IBM, is beginning to gain favour.andP;  it is the Cleanroomtechnique, so named by comparison with the special facilities provided forhardware manufacture where the entry of defects is denied.andP;  (A brief outlineis given in the box entitled The Cleanroom Method of System Development.)andO;Walk-Throughs Essentially, in a walk-through, someone will talk through theobject, explaining in detail how or why he did something, and particularlyhow it is expected to work.andP;  it's like a guided tour.andP;  if it ends there,without any formalities, it is a walk-through.andP;  When the meeting is extendedby having the object introduced first, followed by a walkthrough where errorsare recorded, and concluding with a summary of findings, then we have areview.andP;  The informality of walk-throughs is so variable that no standardapproach can be recommended.andP;  However, a chairman, secretary and an agenda isdesirable.andP;  in most cases the purpose of a review is to examine a singleobject, particularly source code, but systems design, documentation, testplans and so on may also be the subject.andP;  An essential aspect of thesereviews is that they are concerned with error detection, not errorcorrection.andP;  Consequently, a review meeting may discover many errors on onesingle occasion, instead of having to wait until individual errors are foundby normal debugging techniques.andP;  The time saved in this way can significantlyreduce system validation effort.andP;  Those attending walk-throughs should bepeers of the person whose work is being considered, although this may not beso for code audit, or code inspection.andP;  In the psychological sense, it isquite important that the process is non-threatening and does not involveManagement.andP;  Similarly, the results of inspections should not be used forprogrammer performance appraisal.andP;  Defensive behaviour is then avoided.andP;  Itis essential in project management to have a clearly defined sequence ofoperations in a project, and a life-cycle model can provide this.andP;  An exampleis shown in Figure 1, where the whole project is allocated time on the basisof the software engineering general 'rule of thumb', that is 40% design anddevelopment, 20% coding and 40% testing.andP;  Personally, I now regard a 50:10:40split as more appropriate, with the advent of code generators such as thoseavailable from Jackson Systems.andP;  A phase, represented by a rectangular box,is terminated by a checkpoint (milestone or baseline) shown as an oval box.andO;The circles correspond to review or inspection points which are aimed atverifying that the criteria for a given checkpoint has been realised.andP;  Thisbecomes the input to the next phase.andP;  A clean compilation is an example of asatisfactory checkpoint, for Inspection 12 in this case.andP;  One of the mostimportant applications of reviews is a: an approval mechanism in themanagement of a project.andP;  Review Rl in Figure 1 can improve the futureprogress of a project by validating the initial technical specification.andP;  Itis tremendously worthwhile putting as much effort as possible into this, asmany projects have foundered by misinterpreting the original requirement.andP;  inthe same way, R2 is primarily a validation of the design produced for thesystem.andP;  Inspections Here is a technique which has proved to becost-effective.andP;  Some programmers do not see the value of inspections,because they have survived without them in the past or because they thinkthey are suitable only for large projects.andP;  This opinion usually changesafter a few inspections.andP;  Michael E Fagan of IBM (3) claimed that a 23%overall increase in productivity could be realised.andP;  Another IBM case showedthat the inspection process could detect as much as 82% of errors.andP;  Thisfigure has been incorporated into Figure 2.andP;  Inspection gives as much as 40%fewer errors than the informal walk-through.andP;  Fagan stated that theinspection process should be more than a visual scrutiny and should be ahighly directed and formalised process, maintained by the use of feedback.andO;This involves various forms of follow-up, including telling the programmerthe type of errors he is making and how to find/avoid them.andP;  Some of thepoints which a meeting might pursue are: *  Does the code satisfy therequirementsandM;of the detailed design specification? *  Inconsistencies in program logic orandM;coding.andP;  *  Has provision been made for errorandM;conditions specified in the requirementsandM;spec, and for run-time errors? *  Does the program include commentsandM;of a type and degree that would helpandM;future maintenance or modification?andM;This would include cross-referencesandM;to the detailed design spec.andP;  *  How 'estable' is the code under review? inaddition, the team may look for contraventions of sound programming practice,or quality assurance standards.andP;  Fagan concluded that code inspection is notonly desirable but cost-effective.andP;  Clearly the cost of reviews andinspections will be variable.andP;  For reviews involving high-level languages, anaverage rate of 500 LOC (Lines of executable Code) per hour seemsappropriate.andP;  Low-level code may be three to five times slower.andP;  if a onehour preparation time is allowed, then a first review may require onehour/KLOC/person, ie one hour per 1000 lines of code per person on thereview.andP;  Subsequent reviews of the same code should be about twice that rate.andO;For inspections, the rate may vary between 100 and 150 LOC/hour on a firstinspection, but is unlikely to be over 200 LOC.andP;  Preparation rate should beabout the same as for a review.andP;  The cost of reviews and inspections areroughly comparable because the error detection efficiency of inspections isabout double that of reviews.andP;  A company might deduce its own rate byplotting records of error count against time/KLOC.andP;  Keeping records of errorsallows error detection efficiency to be measured.andP;  In future, this couldallow the total number of errors to be estimated.andP;  For example, if efficiencyis known to be 60% and 12 errors are found, then eight remain.andP;  Anotheradvantage is that error-prone modules can be identified and appropriateaction taken, such as more intense testing and/or inspection of that module.andO;A comparison of Inspection and Unit Test, in Figure 3, shows that some typesof error may not be detected without an inspection process.andP;  Figure 2, basedon data by Boehm (2) and others, shows another comparison between Inspectionand Unit Test.andP;  It illustrates the time saved by using Inspection beforeembarking on actual testing.andP;  Here it is assumed that the same length of timehas been allocated to testing as was given to design and development.andP;  Thisfollows from the 40-20-40 rule previously stated.andP;  in the old days, the curvewould terminate at the 100% point (dotted line) as it was assumed thattesting could detect ALL errors.andP;  Presumably, this was because a workingprogram which appeared to work properly was error-free.andP;  It is now realisedthat this is invariably not true.andP;  Some 80-90% of errors may be found foronly about 20% of allocated testing time.andP;  Unit Test may then uncover a goodproportion of remaining errors for another 25% of that time.andP;  The use ofInspection before Unit Test has then required only 45% of that time.andP;  CodeAudits Another title for this type of meeting is a Standards and Codes ofPractice Audit.andP;  Standards may be National/International, and Volume 2 ofReference 4 gives valuable summaries of the most relevant.andP;  They may also becontractual, or set by Management.andP;  Again, the process will be concerned witherrors, but more specifically with the avoidance of methods and constructswhich are themselves error-prone.andP;  Figure 4 from STARTS (4) shows this andalso that consistency and conformance are key features.andP;  Conduct of MeetingsAll of these meetings should have an agenda.andP;  The first calls for a generalfunctional description, which puts the object to be examined in perspective.andO;A review will then proceed to a walk-through, whereas in an inspection thatis replaced by a more specific functional description of the object itself.andO;Inspections and audits cover a wider field and checklists are commonly usedto ensure coverage.andP;  A simple agenda for a review meeting could be based on:* Purpose of object under review.andP;  * Walk-through.andP;  * Summary andconclusions.andP;  * Date and place of next meeting, It is advantageous todistribute relevant documentation in advance (such as a detailed design spec)for members to study, in preparation for what should be a relatively briefmeeting.andP;  This will enable members to follow the commentary in thewalk-through.andP;  Generally, these meetings last for about one hour, seldom morethan two, because concentration falls off it is common practice to limit totwo the number of review meetings ON ANY ONE OBJECT.andP;  The most appropriatetiming for review meetings seems to be when the rate of change in objectdevelopment appears to slow down.andP;  The meeting usually begins by thedesigner, or program author, giving a presentation outlining the purpose ofthe object under review.andP;  This presentation can usually be interrupted on apoint of detail, or even to constructively criticise.andP;  Fagan suggests thatthe best size for these meetings is between four and seven members.andP;  Theirroles might be: * A chairman or moderator, not personallyandM;involved in the project.andP;  *  The designer of the object or program.andP;  *  Theprogrammer involved in the productionandM;of the program.andP;  *  The person responsible for testing theandM;program.andP;  If any individual fulfils more than one function, ie a designer whowas also the programmer, or the programmer who was also responsible fortesting, then someone else should be brought in to fill one function.andO;Sometimes, certain roles are allocated to individual team members.andP;  One mightlook for logical errors, another adherence to quality assurance standards,and another to good programming practice.andP;  Conclusion It is a fact that thesemethods work, and that they save money, although their cost effectiveness mayvary from one company to another.andP;  It is also factual that they improveproductivity, quality and reliability.andP;  They tend to be inexpensive toimplement, and pave the way for the introduction of other softwareengineering methods.andP;  The methods which have been described could not beautomated anyway.andP;  The'Cleanroom' Method of System DevelopmentandM;The technique (5) is based on non-execution-based program development andindependent statistically-based testing.andP;  Figure 5 shows that Cleanroom is anintegration of formal specification/design, incremental non-execution-baseddevelopment, and independent statistically-based testing.andP;  Mathematicalverification replaces debugging and a product of crtifiable reliability isthe aim.andM;The development process is a cycle of producing executable increments whichare passed on for testing.andP;  These software increments accumulate until thesystem is complete.andP;  Next is a Formal Specification, written in a developmentlanguage such as the Vienna Development Method (VDM), OBJ or Z.andP;  Thecorrectness of the program is assured and it is claimed that thisverification process avoids the necessity for program testing.andP;  After this astructured program is produced.andP;  One of the nice features of the cleanroomapproach is that the formal specification can be left in the program asnon-executable comment statements.andP;  It provides an excellent form ofdocumentation.andP;  For many years, Pacal programmers have used this technique ofconstructing a program pseudo-code-type comment statements.andP;  It provides anexcellent form of documentation.andP;  For many years, Pascal programmers haveused this technique of constructing a program in pseudo-code-type commentstatements, and then adding executable statements in the appropriate placesafter words.andP;  Modula-2 and Ada programmers now do the same.andM;In the Cleanroom concept, statistical testing is based on MTTF (Mean Time ToFailure) and expressed asMTTF=MR (sup c) for c software changes where M isinitial time to failure and R is the observed effectiveness ratio forimproving MTTF with software changes.andP;  A technical rationale for this isgiven in Reference 5.andP;  In common with conventional testing, statisticaltesting is intended to simulate an operational environment.andP;  It is a systemof randomly selecting test cases which are based on: 1.andP;  A frequencydistribution of inputs (commands and data)to the system, such as theandM;different types of input transactions in a Order/Entry system, also on.andP;  2.andO;A frequency distribution of machine states.andP;  3.andP;  The range of capability ofthe system as it expands.andP;  It is said that the Cleanroom approach is no moreexpensive than conventional methods.andP;  Mill et al (1987( gives the example ofa 20 KLOC program which had only 53 errors instead of the 1000 expected bythe previously stated estimated industry average of 50 errors per 1000 linesof code.andP;  Mills (et al) state that a post-delivery rate of less than oneerror/KLOC is feasible with Cleanroom, as compared with the normal rate ofone to 10 errors/KLOC for execution-based production.andP;  Also claimed is aproductivity of more than 400 lines per man month, largely due to reducedtesting time.andP;  There is also a very marked imporvement in reliability, whichcuts maintenance costs dramatically.andP;  The technique seems to be a majoradvance in the fundamental principals of software engineering.andP;  1.andO;Sommerville, 1 (1989), SOFTWARE ENGINEERING, THIRD EDITION Addison-Wesley,Wokingham.andP;  2.andP;  Boehm, B W (1981), SOFTWARE ENGINEERING ECONOMICS,Prentice-Hall Inc, Englewood Cliffs, New Jersey.andP;  3.andP;  Fagan,ME(1986),ADVANCES IN SOFTWARE INSPECTIONS, IEEE Trans Software Engineering.,andO;SE-12(7), 74451.andP;  4.andP;  STARTS SOFTWARE TOOLS FOR APPLICATION TO REAL TIMESYSTEMS SECOND ED, 19 Trade andamp; Ind and NCC.andP;  5.andP;  Mills, H D, Dyer, M, Linger,R (1987), CLEANROOM SOFTWARE ENGINEERING, IEEE Software, 4(5), 19-25.andM;CODE AUDIT CHECKS Language AuditandM;a) conformance to project naming conventionsandM;b) absence of duplicate names, especially within theandM;same scope.andM;c) absence of known error-prone language constructs, eg, dataandM;overlays, restrictions on the use of GO TO,  CODE'inserts.andP;  Control FlowAnalysisandM;a) conformance to recursion conventions.andM;b) absence of structurally unreachable code.andM;c) absence of structurally non-terminating loops.andM;d) absence of multiple entries to loops.andP;  Data Use AnalysisandM;a) initialisation of data before use.andM;b) use of all declared variables.andM;c) absence of redundant writes.andP;  MiscellaneousandM;a) conformance to methodology specific rules, for example,andM;the MASCOT rules for passing data between activities.andM;b) conformance to layout conventionsandM;(although a layout editor would be more useful).andM;c) commentedness, for example, is the relative ratio ofandM;commentary to code above the standard level? Are standardandM;header comments included?andO;</TEXT></DOC>