<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-080-060  </DOCNO><DOCID>08 080 060.andM;</DOCID><JOURNAL>AI Expert  Feb 1990 v5 n2 p5(2)* Full Text COPYRIGHT Miller Freeman Publications 1990.andM;</JOURNAL><TITLE>Software quality assurance. (Editorial Intelligence)</TITLE><AUTHOR>Chapnick, Philip.andM;</AUTHOR><SUMMARY>Software quality assurance in artificial-intelligence systems isbecoming a major issue as expert systems are deployed in fieldsthat affect human lives and corporate profits.andP;  Categorizingexpert systems on the basis of actual 'expertise' is useful whenanalyzing quality requirements; inference-based data processingsystems represent the simplest level of AI, while systems thatspecifically emulate the behavior of human experts implement AI atits highest level.andP;  A recent SRI International reportdistinguishes 'competency' and 'service' as the two basicrequirements for evaluating AI software.andP;  Competency is difficultto define, but is more important at the higher heuristic levels;service requirements are readily specified and become the dominantfocus at low levels of expertise.andP;  The AI research community isworking to develop quality-assurance tools for AI software.andM;</SUMMARY><DESCRIPT>Topic:     Software ValidationQuality ControlArtificial IntelligenceExpert SystemsResearch and Development.andM;</DESCRIPT><TEXT>Software Quality AssuranceandM;Now that AI technology has moved into the mainstream of corporate computing(mainly in the form of expert systems), the more prosaic issue of softwarequality assurance raises its ugly head.andP;  It's a problem the high-powered AIresearch community has been hesitant to address.andP;  In the past, exciting AIsystems--due to their nature as research projects expanding the frontiers ofknowledge--had little direct impact on people or profits.andP;  They remainedblissful, solopsistic systems insulated from the pressures on real-worldsoftware.andP;  However, current commercial AI-based systems that underwriteinsurance policies, monitor alarms in nuclear power plants, make medicaldiagnoses, or schedule factories can have a dramatic impact on human livesand corporate bottom lines.andM;According to John Rushby, the author of an excellent SRI International reportentitled Quality Measures and Assurance for AI Software, &quot;The best way todevelop credible and effective quality assurance and evaluation techniquesfor AI software will be to identify the facets of such software that areinherently, or essentially, different from conventional software, and todistinguish them from those facets that are only accidentally orinessentially different.andP;  Inherent differences demand the development of newtechniques; accidental differences--those due simply to culture, history andbias--require only the adaptation of established techniques (and possibly theelimination or reduction of those differences).&quot;andM;When analyzing the quality assurance requirements of AI-technology systems ithelps to categorize them on the basis of how &quot;expert&quot; they really are.andP;  Atone end of the spectrum are systems using the technology in the form ofinference-based data processing.andP;  Rule-based programming paradigms make itsimpler to build and maintain code for systems similar to the ones we alreadyhave in accounting, resource allocation, payroll, and so on.andP;  For example, anautomated-procedures manual or a welfare-eligibility advisor system embodiesexisting sets of procedures.andP;  These systems don't exhibit expert behavior;they simply provide a more convenient means for encoding and enforcingstandards and consistency in decision making.andP;  At the opposite end of thespectrum are systems built specifically to emulate expert-level behavior.andP;  Anautomated currency-trading system performs a very complex task for which nostraightforward algorithmic solutions exist.andP;  Most AI-based systems fallsomewhere between these two extremes: diagnostic systems, for instance,usually combine heuristics derived from the best human troubleshooters withsome form of fault diagnosis tree.andM;Dr.andP;  Rushby distinguishes two sorts of requirements for evaluating AIsoftware: competency and service.andP;  Competency requirements involve the&quot;Dimensions of the overall requirements that concern 'knowledge' or appeal tocomparison with human skills.&quot;andP;  Exactly what constitutes competency issomewhat vague and difficult to specify.andP;  Service requirements, on the otherhand, can be specified in pretty much the same manner for any piece ofsoftware: input and output requirements, help (explanation) facilities,interfaces to other subsystems, required throughput, and so on.andM;Depending upon where an application falls in the expertise spectrum, thequality assurance emphasis shifts from competency to service as thedominating force.andP;  Of course, any system must be both competent andserviceable--it's just the relative focus of the software quality assuranceeffort that changes depending upon the expertise embedded in (and expectedfrom) the application.andM;Problems in assessing the service requirements for AI software often arisebecause of the standard AI development cycle.andP;  Prototyping typically meanssystem-requirements documentation is skimpy at best; often requirementsevolve as development progresses.andP;  The powerful flexibility of AI softwaretechnology--one of its greatest strengths--makes it operationally, though notconceptually, more difficult to address in practice.andM;Assessing competence raises much thornier and less easily addressed issues.andO;In many cases, objectively measuring the competence of the experts to whomthe system is being compared is difficult.andP;  Many current AI developmentenvironments don't support knowledge-level debugging tools; most lackprecisely defined semantics and other software-development features widelyavailable in conventional software development environments.andP;  Practicaltechniques for assessing the completeness and consistency of a knowledge baseare still rudimentary.andM;Rushby believes that &quot;The determining factor in the deployment of AI softwarefor serious applications may not be in the informal evidence of how well itis able to perform, but the extent to which formal guarantees can be given onhow badly it can perform.&quot;andP;  Referring to an expert system that determines theloading sequence for material into the cargo bays of an airplane, Rushbywrites that we must evaluate it by saying &quot;...the system generally seems toget as much material on the plane as an experienced quartermaster, but it isguaranteed never to load the plane in such a way that its center of gravityis outside the allowable range.&quot;andM;According to Rushby, distinguishing between desired and minimal competencymakes feasible &quot;the construction of testable, verifiable specifications ofhow 'badly' a system is allowed to perform.andP;  Given precise minimum competancyrequirements, many design and assurance techniques from conventional softwarebecome available for AI software--for example, systematic testing,reliability analysis, fault tolerance, design for safety, and mathematicalverification.&quot;andM;To maintain high standards of quality in software or in any other product,you need to build them into the product right from the start.andP;  Rapidprototyping may help build systems quickly, but building an incorrect orincomplete one 10 times faster is no gain.andP;  Efforts to developquality-assurance tools for AI software have been underway for some time now,and I expect that the applied-AI research community will redouble its effortsto develop and deploy commercially viable testing environments for AIsoftware.andM;AI developers should welcome this migration of already establishedquality-assurance tools and techniques into their software domains.andP;  Buildingon the more than 30 years of conventional software testing experience willundoubtedly help speed the diffusion of AI technology throughout thecomputing universe.andO;</TEXT></DOC>