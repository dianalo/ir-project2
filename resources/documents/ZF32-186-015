<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO> ZF32-186-015 </DOCNO><DOCID>10 581 496</DOCID><JOURNAL>AI Expert  April 1991 v6 n4 p46(6)* Full Text COPYRIGHT Miller Freeman Publications 1991.andM;</JOURNAL><TITLE>Interpreting neural-network connection weights. (tutorial)</TITLE><AUTHOR>Garson, G. David.andM;</AUTHOR><SUMMARY>Neural networks, unlike expert systems, do not provide an audittrail that explains how the system arrived at its results and arenot designed for exploiting existing expertise.andP;  Neural networksare taught based on intensive computations.andP;  Users can makejudgments about the input or causal variables in a model bypartitioning the relative share of the output predictionassociated with each input variable.andP;  Users employ connectionweights from the input layer to the hidden nodes to the outputlayer for partitioning.andP;  Using a simple four-variable model ofluck, economy and income as an index that ranges from 0 to 100 andvote which varies from zero to one, users can see thatbackpropagation neural networks can be as effective as otherprocedures in correctly classifying dependents and that causalinference using neural-network connection weight partitions is aviable alternative.andP;  Extensive details are presented.andM;</SUMMARY><DESCRIPT>Topic:     Neural NetworksAnalytical TechniquesTutorialModelingNetwork ArchitectureResearch and DevelopmentComputer Learning.andO;Feature:   illustrationcharttable.andO;Caption:   A four-variable model. (chart)Neural-network connection weights for Figure 1. (table)Correlation matrix. (table)andM;</DESCRIPT><TEXT>Neural networks can be quite efficient at classification problems, butthey've been faulted for falling to provide a basis for modeling a set ofcausal factors.andP;  They're often used to predict or classify a given output onthe basis of several inputs or causes.andP;  Although you can compare neural-netprediction or classification success rates with techniques such as multipleregression or discriminant analysis, no method has been accepted thatassesses the relative importance of the input factors used by the network toarrive at its conclusions.andP;  Instead, neural networks have been presented tousers as a sort of &quot;black box&quot; whose unimaginably complex inner workingssomehow magically transform inputs into predicted outputs.andM;It is difficult to understand how neural networks arrive at their results.andO;They do not offer the capacity of expert systems to provide an audit trailthat fully explains how the system reached its conclusions.andP;  Furthermore,neural nets are not designed to exploit existing expertise; instead, they are&quot;taught&quot; through a long process based on intensive computations.andP;  Thislearning process is biased toward commonly encountered (modal) values, makingthe technique possibly less useful for prediction of unusual cases.andM;The black-box image of neural networks is misleading, however.andP;  This articlewill present an innovative but very simple method for using neural networksto interpret input factors for purposes of causal analysis.andP;  The methodutilizes the connection-weight outputs of most if not all neural-net softwarepackages.andP;  The connection weights from the input layer to the hidden nodes tothe output layer can be used to partition the relative share of the outputprediction associated with each input variable--you can employ the partitionto make judgments about the relative importance of input or causal variablesin a model.andM;A SIMPLE EXAMPLEandM;Figure 1 shows a simple four-variable model governed by the following rules:andM;*  A unit change in variable #3 (economy) causes a one-unit change invariable #2 (income)andM;*  A unit change in variable #1 (luck) causes a one-unit change in variable#2 (income)andM;*  A unit change in variable #2 (income) causes a .andP;  1-unit change invariable #7 (vote).andM;In this model, your income is determined by luck and the state of theeconomy, and you vote by your income (wealthier people vote Republican).andO;This model is not exactly realistic, but the point is to keep theillustration simple.andP;  To keep it even simpler, let's make each variable(luck, economy, income) an index that ranges from 0-100, except vote, whichvaries from zero (Democrat) to one (Republican).andP;  Let's also start eachcausal variable at its midpoint, 50, and start vote at .5.andP;  We might have 500people at this starting point and apply the causal rules above 100 times,simulating the passage of 100 time periods.andP;  To introduce variation, we couldintroduce a random element such that each rule would be applied only 90% ofthe time.andP;  We could then have three similar variables (luck_change,economy_change, income_change) that tally the net changes in luck, economy,and income so that when we measure, we're using change variablescorresponding to the rules, not the original amount variables.andM;I wrote a program called Microcosm to do just that: create a model of a&quot;world&quot; with known  causal rules.andP;  While we don't know enough about whatreally causes people to vote, in the Microcosm-generated data we can becertain about the correct causal interpretation.andP;  I will not attempt theconventional process of evaluating procedures by comparing goodness of fitthrough measures such as [R.sup.2andrsqb;; instead, comparisons will be to knowncausal rules that govern generation of the example data set.andP;  This approachgives us a basis for evaluating the inferences we may make by analyzing thedata using neural networks or other techniques.andM;CONNECTION WEIGHTSandM;Neural networking is relatively straightforward.andP;  A training set of examplesof input and output is entered by the user; neural-net algorithms attempt tomodel the process by which the inputs become outputs.andP;  This process isreminiscent of inductive expert systems, which also infer rules from trainingexamples.andP;  However, the iterative passing of data among the processingelements that form a neural net can be much more complex than inductiveexpert-system algorithms allow, which is why you can list the rules in theknowledge base of an expert system to determine &quot;what it knows.&quot; In contrast,you must list the weights and connections in a neural net to analyze itscontent.andM;Neural networks are trained by adjusting input weights manually or by someautomatic algorithm so that the result of stability approximates the desiredoutcomes for the provided inputs.andP;  Early neural systems, such as thatdeveloped in 1957 by Frank Rosenblatt, had only two layers--input andoutput--and are called perceptron systems.andP;  These simple systems could nothandle exclusive-OR (XOR) discrimination problems.andP;  However, more recent andadvanced models now reflect a hierarchical design with an additional layeradded to the input and output layers (the &quot;hidden layer&quot;), which provides thecapacity for handling more complex knowledge-representation problems.andP;  Unlikeearly perceptron models, contemporary models rely on a nonlinear responsefunction (usually the sigmoid function, which is the s-shaped curve oflogistic growth equations, forcing values to remain in the range of 0-1).andM;In a multilayer model, backpropagation may be used for system learning sothat input weights become modified on the basis of error signals arising fromthe output layer.andP;  Halbert White has shown that backpropagation is analternative to nonlinear least squares when the number of cases in thetraining set is large.andP;  Backpropagation is not the only alternative, but itis by far the most common one.andM;Table 1 shows neural-network connection weights for our example asbackpropagation output from NeuroShell (from Ward Systems Group of Frederick,Md.).andP;  This particular neural network is constructed with three input nodesthat correspond to the three causal variables in the model, luck, income, andeconomy.andP;  The top of Table 1 shows the input layer connections, which are theconnection weights from each input node to each of the four nodes in thehidden layer.andP;  The bottom shows the output layer connections, the connectionweights from each of the four hidden nodes to the output node, thatcorrespond to the dependent variable, vote.andP;  The middle section shows thehidden-layer connections, which simply repeat the figures in the top andbottom portions.andP;  Notice the bias weights, which involve the error-feedbackprocess association with the backpropagation algorithm used by Neuroshell andmost other neural-networking packages.andM;Thus, if we use the analog version of neural-net software, which allows useof continuous data such as income, the input nodes correspond to theindependents and the output node to the dependent.andP;  The value of the hiddennodes is a function of the weights of the paths from the input nodes plus thebias path, which is part of the backpropagation algorithm.andP;  The output node'svalue is a function of the weights of the paths from the hidden nodes plusthe bias term.andM;ANALYSIS AND RESULTSandM;In our example, luck and the state of the economy are equal causes of income,the only direct cause of vote.andP;  Can neural networks use information aboutluck, the economy, and income to predict votes correctly? An even trickierquestion: can the underlying true causal model be discovered usingneural-network techniques? First, realize that even for our simple model,this job is not as easy as it sounds.andP;  If we applied the causal rules to ourinitial data and analyzed the data after one iteration, the job would beeasy.andP;  But the rules were applied through 100 iterations, not just one, andat each a random 10% chance occurred that any given rule would not be appliedto that iteration.andP;  As in real life, the data we have to analyze is thecurrent data, not the entire time series.andP;  In fact, we're a little better offthan real life because we know the net change in the causal variables betweenthe current data and the starting point.andM;The result of the iterative process is that the variables do not have a highcorrelation by the 100th iteration, even though we have the true data on allthe relevant variables underlying the causal process.andP;  Table 2 shows thecorrelation matrix from the SPSS/PC+ statistical package for the fourvariables in the example.andP;  Since income is caused by changes in both luck andeconomy, and since these effects sometimes cancel each other out and 10% ofthe time causal rules are suspended, the correlation of either luck oreconomy with income is only moderate .55-.58).andP;  income still has the highestcorrelation with vote of any of the three causes, reflecting that it is thedirect cause of voting.andP;  But since vote is converted to a dichotomousvariable  O = Democrat, 1 = Republican) in the last iteration, information islost, lowering the correlation coefficient.andP;  This result reflects manyeveryday phenomena in which, once a threshold is reached, the phenomenon istipped from one status to another.andM;What all this means is that all the correlations of vote are low, even thatwith the proximate cause, income.andP;  This fact makes prediction difficult byneural networks or any other method.andP;  if we don't have data on all theiterations but only that for the most recent period, and perhaps change froman earlier baseline, we will not be in a good position to make predictions.andM;Number-crunchers sometimes write as if you can derive periodic transitionmagnitudes from datasets from a single point in time.andP;  (If A causes B and A'sregression coefficient is two, then you find assertions that if A changes aunit, then B will change two units.) Actually, these periodic transitionmagnitudes cannot be known on this basis.andP;  What are presented instead aretransition magnitudes across cases, which is entirely different.andP;  Neitherneural networks nor any other technique can possibly recreate the originalcausal relations used in generation of the data, given data for only the mostrecent point in time.andP;  This point may seem obvious, it is one of the mostcommon misuses of multivariate inference.andM;Having outlined the common limitations to prediction based on point-in-timeand even change-from-baseline data, we can examine how well neural networkingcan predict how people will vote given luck, economy, and income.andP;  The issueis muddied because no single solution is possible for a neural-netproblem--you can vary the number of hidden nodes, learning rate, learningtime, and other factors to improve results.andP;  Some programs, such asNeuroShell, produce charts in real time as the neural net is learning.andP;  Bywatching the distribution of learning errors, you can stop the process at atime that yields good predictions.andP;  However, you can never be sure that someother variation in neural-net parameters might not lead to even betterpredictions.andM;Therefore, recognizing that it may not be the maximum possible, after morethan 160,000 learning events the neural network for our example yielded 3 1 0correct predictions out of 500; multiple regression based on all three causalvariables predicted only 302 correctly.andP;  In more complex models and ones withmore noise, neural networks often outperform multiple regression and othermultiple-linear, general-hypothesis procedures by a much wider margin.andP;  Theresult is satisfactory, but what do you do if you want to know thepredictions as well as understand the relative causal importance and order ofthe input variables?andM;Use the input-layer connection weight partition.andP;  Manuals for systems such asNeuroShell usually suggest that the best that can be done to assess therelative importance of causal variables is to examine the relative sizes ofthe input-layer connection weights.andP;  Weights that approach zero indicatesituations in which the investigator may wish to drop that input from themodel.andP;  While an input node with zero connection weights on all hidden nodesmay well have no impact on the output predictions, this advice is not reallyhelpful.andP;  As the NeuroShell hotline technician told me, &quot;That really neverhappens.&quot; It is extremely unlikely in any half-way plausible model that oneof the proposed causal inputs will have zero input-layer weights.andM;Partition the output layer connection weights into input node shares.andP;  Youneed an approach that focuses on the output-rather than input-layerconnection weights.andP;  The weights along the paths from the input to the outputnode indicate the relative predictive importance of the independents--theseweights can be used to partition the sum of effects on the output layer,using the equation shown in Equation 1, while using absolute values of allweights.andM;For each j of [n.sub.H] hidden nodes, sum the product formed by multiplyingthe input-to-hidden connection weight of the input node I of variable V forhidden node j, times the connection weight of output node 0 for hidden nodej, then divide by the sum of such quantities for all variables.andP;  The resultis the percentage of all output weights attributable to the given independentvariable, excluding bias weights arising from the backpropagation algorithm.andO;While this process may seem complicated on first reading, all I've done ispartition the hidden-to-output connection weights of each hidden node intocomponents associated with each input node.andM;You may wonder why the bias connections are not factored into thepartitioning procedure.andP;  Ideally, you'd like to partition the bias factorsinto components associated with the input nodes, adding this complexity tothe algorithm just presented.andP;  Because of the nature of backpropagation,however, there is no feasible way of accomplishing this purpose.andP;  Areasonable estimate of that partition is, in fact, the partition of theconnection weights other than the bias weights.andP;  If you accept thisassumption, taking the bias connection weights into account would make nodifference in the outcome of the procedure.andM;Interpret the partition of output layer connection weights.andP;  Since neural-netpackages don't incorporate this procedure, creating a spreadsheet that doesthe necessary computations on the basis of connection weight data from Table1 is easy.andP;  For our example data, this template is shown in Table 3.andP;  Thisfigure shows that income is the most important input factor, followed closelyby luck; economy is of substantial but somewhat lesser importance.andP;  On thebasis of this partition, you could correctly infer that income is the mostlikely direct cause of vote and that luck and economy are slightly lessimportant but still substantial causes of vote.andP;  You would have no way ofknowing if this result was because each is a more indirect cause of vote orsimply a weaker causal factor.andP;  You would be tempted to view luck as a directcause of vote, whereas its causal link is solely indirect through income.andM;Causal inference is an art, not a science.andP;  These results mean little inabsolute terms, but they become more interesting if we have a basis forcomparison.andP;  In multiple regression, the input variables are made comparableby standardizing (subtracting the mean, dividing by the standard deviation),so when the regression coefficients are computed they are beta weights.andP;  Theratio of the beta weights in regression is interpreted as the ratio of therelative importance of the causal variables in the model.andP;  For this example,the beta weight of income was .35, -.08 was economy, and -.07 was luck.andP;  Pathanalysis (a variant on regression, implemented with Pathfinder software)would yield the same result: the path from income to vote is strong at .35,but the paths from the priors (luck and economy) to income approach zero,with coefficients of only -  .04.andM;On the basis of regression or path analysis, you would correctly infer thatincome was the most important and likely direct cause of vote and that luckand economy were equal but lesser causes.andP;  However, the coefficients are somuch lower for them that you would be tempted, wrongly, to drop them fromconsideration altogether.andP;  More generally, regression techniques favor thestrongest input variable, attributing to it part of the causal pathassociated with less strongly correlated variables.andP;  This problem, calledmulticollinearity, means that such lesser variables are assessed only interms of the residual correlation with the dependent that remains after thestronger variable is entered into the model.andM;I am not asserting that causal inference using neural-network connectionweight partitions is superior to inference based on regression weights.andP;  Bothapproaches have strengths and weaknesses, and any technique has stronginherent limitations.andP;  However, this partitioning procedure does provide areasonable method of using neural networking for modeling as well as forclassfication or prediction.andP;  Although this method is a simple one, to myknowledge it has never been used and stands in sharp contrast to misleadingviews of neural networks as black boxes whose iterative processes are beyondhuman comprehension, even if the predictions are good.andM;A PROVEN CHOICEandM;Unlike other approaches to computing, neural nets are well adapted to handleanalyses of social science topics in which input information is incompleteand output results are approximations.andP;  As a computing strategy, neural netsare relatively fault-tolerant.andP;  Where neural nets are appropriate, they maybe superior to conventional statistical techniques for pattern matching.andM;Alternative procedures have their respective merits, and similar analysis canfollow from any of them.andP;  The least that can be said, however, is thatbackpropagation neural networks seem to be as effective as otherprocedures--and often strikingly more effective--in correctly classifying thedependent, even when the amount of noise in the model is high.andP;  Thiscomplements findings by Philip Schrodt that in split-sample tests oninternational events data, backpropagation outperforms either discriminantanalysis sis or the expert-system ID3 algorithm.andP;  Backpropagation is of lesshelp in causal inference, but it is a valid approach comparable to othercommon techniques.andM;Neural networking may prove to be the tool of choice for certain types ofproblems and should not be rejected out of hand when the purpose is modelingand causal inference.andM;SUGGESTED READINGandM;Bailey, David, and Donna Thompson.andP;  How to Develop Neural-NetworkApplications.&quot; AI Expert, June 1990, pp.38-47.andM;Minsky, Marvin, and Seymour Papert.andP;  Perceptrons.andP;  Cambridge, Mass.: MITPress, 1969.andM;Schrodt, Philip A. &quot;Prediction of interstate conflict outcomes using a neuralnetwork.&quot; Unpublished paper, American Political Science Association, 1990annual meeting, San Francisco, Calif.andM;White, Halbert.andP;  &quot;Consequences and detection of misspecified nonlinearregression models,&quot; in Journal of the American Statistical Association 76,1981: 419-433.andM;White, Halbert.andP;  &quot;Neural-Network Learning and Statistics.&quot; AI Expert, Dec.andO;1989, pp.andP;  48-52.andM;Xenakis, John J. &quot;Brain Thrust.&quot; Information Week, Jan. 29, 1990, pp.41-42.andM;G.andP;  David Garson is associate dean of computing at North Carolina StateUniversity's College of Humanities and Social Sciences and editor of SocialScience Computer Review, published by Duke University Press.andM;TABLE 1.andP;  Neural-network connection weights for Figure 1.andM;Learning events completed: 100497andM;Input layer connectionsandM;LUCKandM;FROM    :    4.82     15.1      -6.38        -24.9andM;FROM    :   -27.6     -4.21     -30.5        -11.2andM;FROM    :    13.7     -7.58     -12.0        -11.4andM;Hidden layer connectionsandM;Hidden node # 1andM;BIAS           :         -3.29andM;TO             :          4.82       -27.6         13.7andM;FROM           :         -1.32andM;Hidden node # 2andM;BIAS           :         -13.7andM;TO             :          15.1       -4.21        -7.58andM;FROM           :         -2.69andM;Hidden node # 3andM;BIAS           :          3.75andM;TO             :         -6.38       -30.5        -12.0andM;FROM           :         -2.56andM;Hidden node # 4andM;BIAS           :          3.34andM;TO             :         -24.9       -11.2        -11.4andM;FROM           :         -2.29andM;Output layer connectionsandM;VOTEandM;BIAS    :                 0.83andM;TO      :    -1.32    -2.69     -2.56        -2.29andM;TABLE 2andM;Correlation matrix.andM;LUCK     INCOME    ECONOMYandM;CORRELATIONS:             .5595andM;INCOME                    .0592     .5843      .1230andM;ECONOMY                   .1220     .2662andM;VOTE                       500andM;N OF CASES:andM;TABLE 3andM;SpreadsheetandM;template.andM;HIDDEN NODEandM;V1        V2         V3        OUTandM;CONNECTION WEIGHTS  INPUT TO HIDDEN)andM;1         4.82     -27.6       13.7     -1.32andM;2         15.1     -4.21      -7.58     -2.69andM;3        -6.38      30.5        -12     -2.56andM;4        -24.9     -11.2      -11.2     -2.29andM;CONNECTION SHARES * HIDDEN NODE INPUTandM;1         0.14      0.79       0.39andM;2         1.51      0.42       0.76andM;3         0.33      1.60       0.63andM;4         1.20      0.54       0.55andM;Sum:       3.18      3.35       2.33andM;INPUT NODE SHARE OF OUTPUT LAYER CONNECTIONS, EXCLUDINGandM;BIAS ONES;andM;35.93%              37.79%            26.28%andM;Luck               income            EconomyandM;Figuration Omitted</TEXT></DOC>