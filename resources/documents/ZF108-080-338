<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-080-338  </DOCNO><DOCID>08 080 338.andM;</DOCID><JOURNAL>UNIX Review  Jan 1990 v8 n1 p42(6)* Full Text COPYRIGHT Miller Freeman Publications 1990.andM;</JOURNAL><TITLE>Interview: Forest Baskett. (interview)</TITLE><AUTHOR>Chandler, David.andM;</AUTHOR><SUMMARY>Forest Baskett, Vice President of Research and Development atSilicon Graphics, discusses his involvement with the developmentof the MIPS microprocessor and the Stanford University Network(SUN) project.andP;  Baskett also answers questions relating to thefuture of computing, including technologies which will see rapidgrowth in the 1990s, such as superscalar RISC design techniquesand multiprocessing, changes to hardware taxonomy over a five- toten-year period, and the likelihood of mass consolidation ofcomputer companies during the '90s.andM;</SUMMARY><DESCRIPT>Company:   Silicon Graphics Inc. (officials and employees).andO;Topic:     Future of ComputingInterview.andO;Feature:   illustrationportrait.andO;Caption:   Forest Baskett. (portrait)Person:    Baskett, Forest (interviews).andM;</DESCRIPT><TEXT>Interview FOREST BASKETTandM;If you had an interest in learning about the technology trends of the 1990s,a logical way to start would be to seek out someone who was actively involvedin the technology trends of the 1980s.andP;  And if you asked a host of computingluminaries who was at the hub of much of that research activity, you'drepeatedly get Forest Baskett's name as an answer.andM;In the late 1970s, Baskett worked under a DARPA contract at StanfordUniversity, where he led a team of researchers on the Stanford UniversityNetwork (SUN) project.andP;  One of his graduate students, a German immigrantnamed Andreas Bechtolsheim, was the primary developer of the project'shardware: a single-user system, driven by a powerful microprocessor, thatwould come to be poularly known as a workstation.andP;  Bechtolsheim himself laterbecame one of the co-founders of Sun Microsystems, a Mountain View, CA,enterprise that, by almost anyone's account, has fared pretty well in the'80s.andM;While at Stanford, Baskett was also a member of the design team thatdeveloped the MIPS microprocessor.andP;  Using this RISC technology as afoundation, his colleague, Stanford Professor John Hennessy, joined severalothers to start up Mips Computer Systems in Sunnyvale, CA.andP;  This companyrecently went public amid high expectations of many on Wall Street, despite agenerally bearish attitude toward most high-tech stocks these days.andM;Baskett's time both prior and subsequent to his activities at Stanford (wherehe remains a consulting professor) has also yielded many technologydividends.andP;  After receiving his PhD in computer science from the Universityof Texas at Austin, he remained there for a time as an assistant professor.andO;He later went on to participate in a series of projects, ranging from onethat produced a microprocessor-powered bitmapped graphics terminal (this was,keep in mind, back in 1974), to one that took place at Los Alamos NationalLaboratory, where he helped develop Demos, an experimental operating systemfor the Cray-1.andM;Following his full-time work at Stanford, Baskett served as director ofDigital Equipment Corp.'s Western Research Laboratory in Palo Alto, CA, wherehe led the project to develop DEC's experimental RISC processor, the Titan.andO;Since 1986, he has been vice president of research and development at SiliconGraphics Inc. in Mountain View.andP;  During his tenure at SGI, Baskett has helpeddesign the multiprocessor structure that is the heart of the company's IrisPower Series workstation product line.andP;  (SGI, by the way, was founded byJames Clark, a Stanford PhD and yet another of Baskett's colleagues fromresearch days gone by.)andM;REVIEW: Describe your involvement in two well-known, DARPA-sponsored researchprojects done at Stanford during the last decade--the SUN project and theMIPS project.andP;  What was the mission of each?andM;BASKETT: I was the co-principal investigator on a long-term DARPA program atStanford.andP;  Those two projects, which I initially sponsored, invovled somemajor development work by some of my colleagues.andP;  Andy [Bechtolsheim] didmost of the technical work on the SUN workstation project, and John Hennessycame aboard and became the primary navigator on the MIPS project.andM;My interest in both projects derived from early work I'd done with somegraduate students when DRAMs and microprocessors first came on the scene.andP;  Webuilt our first raster-graphics system at Stanford and SLAC (the StanfordLinear Accelerator Center) in 1974, using 4-kilobit DRAMs as the frame bufferand the Intel 8080 as the CPU.andP;  The technology had reached a point where youcould build something that was more interesting and more flexible than whatexisted before.andP;  Tektronix storage scopes were the only graphics displays inuse at that time--they were serviceable, but had a lot of limitations.andP;  Itwas fun to build something a lot more flexible.andM;When the next generation of microprocessors came out, I got interested inresuming my earlier research.andP;  First it was the 8086, but then the Z8000appeared, which seemed a little more promising than the 8086, and then camethe 68000, which surpassed both.andP;  At that point we had the SUN workstationproject cranked up, and sure enough, it proved to be a pretty nice setupusing the 68000.andM;The MIPS project developed because a major facet of the DARPA program wascentered around VLSI design, and this technology was accessible to ordinarydesigners, rather than being mystical and something only practiced by wizardsinside semiconductor companies.andP;  It seemed to some of us that it was becominga lot more feasible to work with experimental computer architectures.andP;  Youdidn't have to be bound by what was forced onto you by--in our rather brashview--large companies that didn't necessarily produce good designs.andM;So the presence of VLSI research in the DARPA program suggested thatprocessor design could be pursued in a university setting--a phenomenonunheard of for a long time.andP;  You had to go back to the 1950s and '60s to findtimes when people were creating processor designs in universities.andP;  Processordesign also seemed like a good vehicle to advance the state of the art inVLSI design; you can't build tools and technologies without something to usethem on.andP;  So the MIPS project came out of that.andP;  Both John and I had ideasabout processors.andP;  Mine came from experiences with various machines built bySeymour Cray over the years.andP;  Many of John's ideas came from his work withcompilers.andP;  They converged to produce a pretty nice set of results.andM;REVIEW: You were involved early on, then, in researching many of thetechnologies that became very important to the computer business of the '80s.andO;In this light, what are your thoughts on budding technologies as we enter the'90s?andM;BASKETT: In terms of the kinds of technologies that I believe are going tosee similar growth in the next decade, I'll respond by beginning where I justleft off.andP;  Certainly RISC machines were what the MIPS effort was all about.andO;We've recently reached the beginning of what you might consider the nextgeneration of RISC machines.andP;  I like to characterize that next generation as&quot;superscalar&quot;.andP;  RISC machines have been promoted as being successfulgeneral-purpose computers--they perform a wide variety of tasks quiteefficiently.andP;  Building superscalar machines is an attempt to achieve higherlevels of micro-parallelism through technology than we can get usingcarefully designed instruction sets alone.andM;Pipelining was a very successful parallelism technique for the firstgeneration of RISC machines.andP;  Superscalar machines--or &quot;superpipelined&quot;, assome implementations are called--take us to the point where we have machinesthat can truly execute multiple instructions per cycle, rather than justgetting close to 1.andP;  So, given a certain level of process technology or gatespeed, this kind of architectural innovation and implementation results in afaster machine.andP;  The superscalar approach will become a key element of thesuccess of the next round of RISC machines.andP;  In this respect, the RISC warsare not over; they're just reaching a higher level of sophistication.andM;At the same time, we've reached the point at which systems utilizingmicroprocessors are sufficiently easy to build, and where multiprocessing hasbecome quite a successful and accessible technology.andP;  At Silicon Graphics andother companies, multiprocessing workstations are being built.andP;  So farthey've been what you might call high-end workstations, but as we become morecomfortable with the technology, as the software for it develops, and asopportunities for using this kind of tightly-coupled multiprocessing continueto expand, we'll see general-purpose multiprocessing workstations become thelow end of the workstation market.andP;  application developers are beginning tounderstand that it works and, as a consequence, the market for a broaderarray of multiprocessor systems will grow.andP;  So, multiprocessing is going tobe a reasonable part of our standard computing environment.andM;When I say these things, I'm speaking of small-scale multiprocessing--thatis, two, four, eight, maybe sixteen processors.andP;  It's what we can do mosteasily and effectively.andP;  Large-scale multiprocessing is still more of aresearch challenge: the market opportunities are not well-established, andthe implementation techniques, programming enviroinments, and technologiesare still very diverse.andP;  When you get up into the realm of hundreds orthousands of processors, it becomes much more difficult to use amultiprocessor structure efficiently.andP;  Machines built with ten to a hundredhave reached the point where they're useful in a variety of circumstances.andM;REVIEW: So with small-scale multiprocessing, application development issomething that can be accomplished by mere mortals?andM;BASKETT: Exactly.andP;  It's not as widespread now as it will be, but systems wehave already developed have been discovered by a lot of people, and we've gotapplications working across a large number of problem domains wheremultiprocessing works very well.andP;  People are beginning to understand when andwhy it works, and how to apply that understanding to solving many problems.andM;REVIEW: Given what you say about two important advancements--superscalartechniques for advances in RISC design, and multiprocessing--is it the casethat system designers feel they're coming up against a performance wall forsingle-processor systems?andP;  Does that apprehension serve as a motivation formoving to multiprocessing?andM;BASKETT: No, I don't think that's so.andP;  The notion of a wall is a popular one,but that's not really how researchers work.andP;  Technology is still improving ata rapid rate, as is our ability to manage complex designs.andP;  As our ability tomanage complex designs improves, we are able to build systems that areincreasingly parallel--and parallelism is always good, when it works.andO;Building a parallel system--whether it's a pipelined RISC machine,superscalar RISC machine, superpipelined machine, or a multiprocessor--is anatural extension of our capabilities.andM;REVIEW: You made a comment earlier about these technologies and theirimplementations in high-end machines.andP;  If RISC designs continue to improveand multiprocessing systems become more efficient and more common, then whatgeneral technologies might be implemented in using all of that processingpower in a desktop system?andM;BASKET: Certainly there's a lot of hype about multimedia.andP;  We do a lot ofthat sort of thing at SGI today.andP;  But aside from the hype, video capabilitiesare still exciting, and we see a lot of potential in developing audiocapabilities as well.andP;  With more powerful and more available computingresources to go with those kinds of high-bandwidth input and high-bandwidthoutput capabilities, we'll be able to do some pretty amazing things.andP;  Themultimedia hype is probably not very well focused on the kinds of thingspeople will end up doing, but it does suggest some ways of augmenting ourmainstay computing systems and using them in a variety of tasks notpreviously considered as computing problems.andM;REVIEW: Do any examples come to mind?andM;BASKETT: Well, yes, the easy ones that have been around a while--like voicerecognition and character recognition.andP;  But with enough computing power, youcould do scene recognition as well.andP;  You could build systems that can takevideo input and generate three-dimensional models of what the video inputdevice is perceiving.andP;  New modes of interacting with your environment andwith your computing systems can result from coupling significant computingresources with video and audio capabilities.andP;  So, there are some obviousapplications in fields ranging from architecture to computer design.andP;  Thereare other, more serious applications, but the ones mentioned are probablymore affordable in the near term.andM;REVIEW: Do you foresee any changes in the general taxonomy of hardware overthe next five to ten year?andP;  Ten years from now, what labels, will we have forhardware platforms?andP;  Will there be supercomputers?andP;  Mainframes?andO;Workstations?andM;BASKETT: It's hard to predict ten years ahead--although historically thesethings seem to change more slowly than we imagine.andP;  But it is likely that thedistribution of market shares of different kinds and styles of computing willchange.andP;  Some niches will get smaller and some larger.andM;REVIEW: There's a fair amount of speculation that the mainframe will go away,while the opposing school of thought contends that the mainframe will alwaysbe needed as a central repository for a network of systems.andP;  What's yourpersonal view on distributed computing architectures, particularly onnetworks and the role of the mainframe?andM;BASKETT: I think large organizations need coherent computing systems.andP;  Maybe&quot;coherent computing systems&quot; is what we should talk about rather thanmainframes.andP;  Certainly in the past mainframes have been a source of unity andconsistency and coherence for large organizations doing cooperative work ontasks that involved large numbers of users.andP;  Can networks of workstations beviewed as coherent computing environments?andP;  Theoretically it's certainlypossible.andP;  Will a place remain for whatever we choose to call mainframes?andO;Yes, probably.andM;Economies of scale can be achieved in the administration of coherentcomputing environments implementing the sizes of secondary and other storagesystems that will continue to exist.andP;  Whether that market share goes up ordown is hard to say.andP;  Will mainframes disappear?andP;  I don't think so--but then,my view of a mainframe as a coherent computing environment may not be whatmany people mean when they say &quot;mainframe&quot;.andM;In this regard, there is the chance that fiber optics will play a major rolein changing the pragmatic definition of a mainframe.andP;  With the kind ofhigh-speed connections over longer distances that fiber optics promises, ourcoherent computing environments could become more geographically spread outthan conventional machines have been to date.andP;  Fiber-optics technology couldthus have a significant effect on the physical appearance of computingsystems.andP;  And it presents some challenges for system development as well: howdo you define and build your systems so that you really take advantage oftheir technology--use them in ways that today might seem pretty&quot;mainframe-y&quot;, if you will, and at the same time make them more accessible tocollections of smaller machines?andP;  If you look at, for example, what Digitalcalls &quot;clusters&quot;, you can imagine that with fiber-optic technology, all theworkstations in a large building could become part of a cluster.andP;  If youcould make that work, would you want to?andP;  It might be nice--there might besome real opportunities there.andM;REVIEW: While we wish to avoid &quot;pie-in-the-sky&quot; projections here, there issome value in addressing a &quot;wide-open&quot; question now and again, and this isprobably one of them: in the year 2000, what will a workstation look like?andO;Or if that's just too far removed, what will one look like in 1995?andM;BASKETT: I have no idea how it will look ten years from now.andP;  I can speculateabout some possibilities that are feasible and that I think would be fun;whether they turn out or not is a more complex question concerningmanufacturing and distribution, and the needs and abilities of localorganizations.andP;  It certainly would be fun to have a workstation that subsumesthe functions of your telephone, your answering machine, and your faxmachine, and provides videophone and teleconferencing capabilities.andP;  Allthose things are moderately straightforward technology problems.andP;  You canenvision a fairly integrated gadget that subsumes all those functions, andalso provides the computing and storage capabilities to make all thosefunctions more powerful than they've been in the past, allowing them to bemore easily interconnected and able to leverage one another.andM;Whether all of these capabilities will be realized or not is an interestingquestion.andP;  Electronic mail has been around for a long time as something thatthe hard-core computing community has relied on and used a lot, but it'snever really taken off.andP;  What has?andP;  Fax machines--their manufacturers took asomewhat different organizational approach to the marketplace that was easierto pull off.andP;  As computing researchers, we can really be misled by ourtoo-close-to-the-technology perceptions of what will be popular andaccessible to the world at large.andP;  E-mail is still not accessible to theworld at large, but faxes are.andP;  All kinds of things have contributed to thatsituation.andP;  Perhaps DARPA's development of the Arpanet did not promote butrather inhibited the widespread adoption and availability of e-mail.andO;Permission to be connected to the net became a real political issue.andP;  There'sno political issue surrounding the use of faxes.andM;REVIEW: How would you anticipate that the UNIX operating system will changeover the next several years?andP;  We've heard some folks say that over the nextfew years the question of operating systems will become essentiallyirrelevant--that system designers and hard-core software developers will haveto be concerned about it, but it's not a question that will concern manypeople beyond them.andM;BASKETT: Many people expect that the users of things like workstations or PCswill eventually be insulated from changes in what we've traditionally thoughtof as an operating system--be it MS-DOS or UNIX--by an interactive systemlayer that covers all that up: types of window systems, interactions withsystems that make use of things like window systems--these may in fact becomethe important issue.andP;  The hard-core developers will still have to workunderneath, making the pieces fit together, but maybe questions aboutoperating systems will become more like questions of system design.andP;  Take theelectrical power system: the people that design and build systems componentsknow about the electrons, but nobody else worries about them.andP;  Maybeoperating-system calls will become like electrons--not things the averageperson wants to be bothered with.andM;REVIEW: We mentioned &quot;hardcore&quot; software developers.andP;  How might theirenvironments change?andP;  How will software be developed five years down theroad?andM;BASKETT: I don't know.andP;  Certainly many people talk about productivity toolsand other means of dramatically improving the productivity of people tryingto develop software.andP;  It's a popular subject.andP;  The cynical view is that,&quot;Goodness, if you look at the history of software development, progress inproductivity levels seems to inch along, and maybe it will continue to inchalong.andP;  Maybe there won't be any silver bullets or breakthroughs.andP;  It's toughand may stay tough, as much as we might like to think that object-orientedprogramming or CASE or whatever else is going to get us out of the trenches.andO;Ten years from now we may still be in the trenches.&quot;andP;  It would be nice if thecynics were wrong.andM;REVIEW: What factors other than these new technologies will we need toconsider when we want to implement them in real products?andP;  In other words, inthe context of our earlier conversation, what will be necessary to producethat fully integrated, fun workstation in 1995?andM;BASKETT: Well, for one thing, it may prove cheaper to continue having allthose different functions provided by separate boxes.andP;  Economies of scale involume manufacturing, and the potential volumes of pieces integrated intoapplications and environments foreign to our hypothetical fun workstation,would encourage manufacturers to keep those things separate.andM;One of the challenges for constructing any computing environment is, &quot;What doyou leave out?&quot;andP;  You might elect to leave out a great deal, and so wewouldn't get that integrated, fun workstation.andP;  It may be that the rightmarket decision is to make pieces, and plug them together sometimes but notplug them together at other times, depending on your micro-market.andP;  It's verypossible, technologically speaking, to integrate the components we'vediscussed into a single desktop system--but whether we can develop a marketthat can justify that kind of integrated technology is a different question.andO;Maybe that's where innovative software applications are actually the key.andM;REVIEW: There has been some talk of wholesale consolidation of computercompanies in the '90s.andP;  As the industry continues to mature, this is one ofits anticipated phases of development.andP;  Your thoughts?andM;BASKETT: Companies come and go.andP;  Some get larger, some get smaller, somedisappear, new ones are created.andP;  Is IBM going to be around in ten years?andO;Probably.andP;  Is XYZ startup going to be around in ten years?andP;  Well, chancesare, no.andP;  These two points define the spectrum.andP;  Where do all of us fall inthat spectrum?andP;  To use my favorite statistician's terms, if you just playstraight probabilities, the bigger companies have a higher probability ofsurviving than the smaller companies; but the variance in those probabilitiesis enormous.andM;I don't see that the world is noticeably different now from what it was tenyears ago, in this respect.andP;  You can say that today you have workstationcompanies in the position occupied by minicomputer companies a decade ago;ten years from now there may be some other term to refer to the companies inthe middle of the spectrum.andP;  And some companies that ten years ago wereminicomputer companies are today workstation companies, so ten years from nowsome of those same companies may be something else--and some of them will begone, and there will be some new players.andM;REVIEW: Even with all the upheaval, though, I get the impression that you'restill quite pleased to continue working in the computer business.andM;BASKETT: I've been doing computing for a long time, but one thing I continueto remark on is that it's still not boring.andP;  You've heard the saying, &quot;Areyou having fun yet?&quot;andP;  A different way of looking at it--one that's a bettercharacterization for the computer industry--is, &quot;Are you bored yet?&quot;andP;  Notyet.andO;</TEXT></DOC>