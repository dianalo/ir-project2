<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF109-378-029  </DOCNO><DOCID>09 378 029.andM;</DOCID><JOURNAL>Datamation  Sept 1 1990 v36 n17 p22(5)* Full Text COPYRIGHT Cahners Publishing Co. 1990.andM;</JOURNAL><TITLE>Relief for slow storage systems. (redundant arrays of inexpensivedisks)</TITLE><AUTHOR>Moad, Jeff.andM;</AUTHOR><SUMMARY>Redundant arrays of inexpensive disks (RAID) may providecost-effective and faster memory subsystem performance for everfaster central-processing units (CPUs), but input/output (I/O) andwrite operation performance problems must still be solved to makeRAIDs useful for commercial applications.andP;  New generations of fastmicroprocessor and multiprocessor CPU architectures spend too muchtime waiting for data stored on disk subsystems, reducing theoverall performance of host systems.andP;  Advances in capacity,reliability and performance of small hard disk drives make theRAID approach a more viable performance strategy.andP;  Unfortunately,most commercial applications perform a large number of randomreads, writes and updates of small records, which slow RAID I/Oand write performance can not adequately handle.andP;  A five-levelRAID architecture is being developed to resolve these problems.andM;</SUMMARY><DESCRIPT>Topic:     Disk DrivesArraysNew TechniqueProduct DevelopmentApplicationsHard DiskRedundancy (Engineering).andO;Feature:   illustrationchartportrait.andO;Caption:   Conventional storage vs disk arrays. (chart)Randy H. Katz. (portrait)andM;</DESCRIPT><TEXT>For years, most system architectures have suffered from a common affliction:while CPU performance has increased dramatically, disk storage performancehas not kept up.andP;  In an attempt to mask this problem, the people who buildsystems have had to work overtime rewriting system software and adding thingslike memory caches.andP;  That's getting harder to do, however, as multiprocessorand reduced instruction set computing (RISC) architectures spur faster CPUperformance gains.andP;  As a result, most central-processing units-fromsupercomputers to low-cost personal computers-still spend far too much timewaiting for data stored on disk.andP;  That means users are paying for MIPS thatthey can't use.andM;Lately, however, several leading systems vendors have embraced an approachthat could help eliminate the expensive mismatch between CPUs and disksubsystems.andP;  The idea is to redesign the subsystems: rather than basing themon large, expensive disk drives, as many now are, RAID technology use arraysof many inexpensive 5/4-inch or smaller hard disks similar to those currentlyused in PCs and workstations.andP;  Proponents say a move to such so-calledredundant arrays of inexpensive disks (RAID) could significantly improve disksubsystem performance and revolutionize data availability.andM;But there's a catch.andP;  In many environmentsparticularly commercial transactionprocessing-the RAID cure could have significant performance side effects.andO;Input/ output rates can be hit hard, and the speed of write operations candecrease dramatically.andP;  Accordingly, even some strong array proponents aresaying the architecture won't be a significant factor in commercial,transaction-oriented environments until these unwanted effects areeliminated, which isn't expected to happen until sometime in the mid-1990s,if ever.andM;Still, that isn't stopping several vendors from pouring development dollarsinto RAID technology.andP;  Consider the list: * IBM, an early RAID investigator,has rekindled its interest originally sparked in the late 1970s.andP;  The companyrecently started designing a new RAID prototype at its Almaden ResearchLaboratory in San jose.andP;  The project will hook at least 32 small drives to a3090 mainframe via a 100-megabyte-per-second interface.andP;  IBM is alsosupporting RAID research at the University of California, Berkeley, which hasexcited widespread interest.andP;  * Tandem Computers Inc. recently acquiredBoulder, Colo.-based Array Technology Corp., a 20-person start-up developingan advanced RAID design for Tandem and other environments.andP;  * StorageTechnology Corp. of Louisville, Colo., is hard at work on an advanced arrayinitially for the IBM 3090 mainframe.andP;  The first implementation is due to beannounced later this year and is expected to be available sometime around thesecond quarter of next year.andP;  Code-named Iceberg, the technology could alsobe sold into other environments.andP;  * Compaq Computer Corp.recently startedshipping one of the first disk arrays for networked PC applications.andP;  Calledthe Intelligent Drive Array, the product is a relatively simple RAIDimplementation packaged with Compaq's SystemPRO servers.andP;  San Francisco-basedBank of America NT andamp; SA is evaluating the product for an important branchcash-vault application in which data availability is critical.andP;  * Othervendors such as Control Data Corp., Data General Corp. and Memorex TelexCorp. have either announced plans to ship an array design or are said to bedeveloping one.andM;Many vendors believe arrays will be less costly, more reliable and moreversatile than other storage-boosting technologies such as solid-state disks,fixed-head disks or parallel transfer disks.andM;Furthermore, vendors are finding the array architecture attractive as achance to build storage subsystems for a variety of systems out of the samebasic building blocks, rather than designing different devices dedicated tomainframe, PC, workstation or midrange storage.andM;The reliability and performance leaps that small disks have made in recentyears make it possible for vendors of commercial systems to take the RAIDapproach more seriously.andP;  The raw logic needed to drive arrays has becomeaffordable as RISC microprocessors, such as the Intel Corp. 80960CA and MipsComputer Systems Inc. R3000, have come onto the market.andP;  Small 5 1/4-inchdisks that just a few years ago failed every 10,000 hours now run 150,000hours on average before failing.andM;It's little wonder, then, that systems vendors want to jump on that fastertechnology track.andP;  &quot;We believe arrays will become the prevalent device in[the IBM mainframe] environment,&quot; says Tricia Harper, vice president forstorage product marketing at Memorex Telex in Tulsa, Okla.andP;  Raiding theCommercial SectorandM;Of course, the idea of disk arrays has been around for several years.andP;  IBMbegan its own disk array research in 1478 and already holds several importantarray patents.andP;  And several systems vendors, particularly those inhigh-performance niches like scientific or engineering computing, are alreadyshipping disk array products.andP;  They include Cray Research Inc. and ControlData.andM;Advantages to using disk arrays in more general purpose and commerciallyoriented applications are threefold.andP;  First, packaging together dozens oreven hundreds of small drives will give users lots of relatively inexpensivegigabytes that take up less space and use less power than current large disksubsystems.andM;Second, as users build more and more critical online systems, they aredemanding fault tolerant data storage in addition to fault tolerantprocessing.andP;  Vendors including IBM and Tandem have begun offering what theycall disk-mirroring features that allow users to make a second copy of everydata file as it is written.andP;  That approach to fault tolerant data storage,however, requires users to buy twice as much disk as they would otherwiseneed, and many are reluctant to make that investment.andP;  RAID technology couldprovide reliability equal to or better  than  that  gained through diskmirroring with an overhead cost of only about 10%.andM;Rather than backing up disks on a one-for-one basis as in mirroring, arraysuse an efficient error correction scheme called parity to keep track of datastored in a domain of the subsystem and to regenerate it in case of afailure.andP;  Parity is what allows arrays to back up disk storage with much lessoverhead than mirroring.andM;Arrays can maintain data availability in the case of a disk failure inanother way.andP;  Because the small disks are less expensive, vendors can affordto build standby disks into their systems.andP;  When one disk in the array fails,a spare automatically fills in.andP;  Data is rebuilt  rom the parity disk, andthe system never stops running.andP;  Early work at IBM has shown that a 500-diskarray using drives capable of running 400,000 hours between failures and ninestandby disks could operate for at least six months before requiring any kindof repair.andM;Many users are keenly interested in that kind of data reliability with littleoverhead.andP;  Most of the airline reservation systems, for example, currentlymake several mirrored copies of their critical on-line reservations data.andP;  Aspokeswoman for American Airlines Inc.'s says the company is currentlystudying the use of arrays for its Semi-Automated Business ReservationEnvironment (SABRE) system.andM;Other users also want high availability and simply can't afford theredundancy of mirroring.andP;  The Church of jesus Christ of Latter Day Saints inSalt Lake City, for example, has been looking for a way to back up themassive family history databases it keeps on line.andP;  &quot;It's too expensive tomirror all of it,&quot; says development manager Charles White.andP;  &quot;But several ofthe vendors now are coming up with alternatives like arrays that would bevery attractive to us.&quot;andM;The final advantage of disk arrays for commercial users is the one that hasmade the architecture popular in the scientific and engineering sectors:increased data transmission rates.andP;  The need for better disk storageperformance in the commercial sphere is intensifying as the imbalance betweenCPU and storage subsystem performance continues to increase.andP;  IBM officialsestimate that disk performance has improved at about 9% annually for the lastseveral years, whereas uniprocessor performance has jumped by 18% per year.andM;Arrays have the potential to offer vastly improved data transmission ratesbecause they can take advantage of the increased number of disk actuators inthe array to service a single logical I/O request or many independent I/Os inparallel.andP;  At its most explosive, for example, an array could spread the bitsof a record evenly across several physical drives.andP;  Then, when the CPU asksfor the data, the array could access each bit in parallel and blast theanswer through multiple parallel channels to the CPU.andP;  The result is anorder-of-magnitude performance improvement in data transmission rates.andM;That is essentially the way high-performance computer manufacturers such asCray and Thinking Machines Corp. of Cambridge, Mass., have used arrays.andO;Because their systems already have very fast channels, and because mosttechnical and scientific applications are set up to use very large blocks ofdata, supercomputers can take advantage of the large bandwidth and parallelcharacteristics of arrays.andM;But for many commercial applications, the story is different.andP;  Rather thanperforming relatively few operations on large blocks of data, commercialapplications perform many operations on small blocks of data.andP;  Mostcommercial applications-particularly those that are transaction oriented-feedoff of a large number of random reads, writes and updates of relatively smallrecords.andP;  So those applications need very efficient, fast I/O performancemuch more than they need high bandwidth or massive data transfer.andP;  RAIDarchitectures don't necessarily help there.andP;  In fact, some RAID architecturesactually can cripple I/O performance, experts warn.andP;  The I/O ProblemandM;One of RAID's problems is that, in transaction-oriented environments, it'snot such a great thing to spread data at the bit level evenly across manyactuators.andP;  That's because such an approach would require many actuators todo work even when the system is asking only for a small block of data.andP;  Thatmeans more seek and latency delays and compromised I/O performance.andM;Several vendors have learned the hard way about the I/O problems inherent inarrays.andP;  Vendors such as Maxtor Corp. of San Jose and Chatsworth, Calif.basedMicropolis Corp. have announced so-called parallel arrays over the last fewyears, only to scuttle the projects for lack of demand.andP;  Observers say thoseearly array vendors a so ran into distribution problems.andM;Researchers at Berkeley, IBM, StorageTek and elsewhere are working on ways toresolve RAID's problems in transaction environments.andM;Just over two years ago, the Berkeley research project published a paper thathelped developers begin to solve some of the I/O problems inherent in array.andO;The Berkeley project, headed by professors Randy  H. Katz and David A.andO;Patterson, described a five-level RAID taxonomy.andP;  At the top was a RAIDarchitecture that would allow both parallel and independent reads and writesto arrayed disks.andP;  Under this model, small blocks of data could be written toand accessed from a single drive in an array for better performance, whilelarge blocks could still be dealt with in parallel.andP;  Boosting Performance andReliabilityandM;The RAID Level Five architecture also advocates spreading parity informationacross all of the disks in an array rather than locating it on a dedicateddevice in order to improve performance and reliability.andP;  The Berkeleyresearch, which was funded by the National Science Foundation and supportedby several vendors-Digital Equipment Corp., IBM, Intel and Sun MicrosystemsInc.-indicated that the RAID Level Five approach could improve reads of smalldata blocks by 1,200% compared with more common parallel arrays.andM;Several vendors, including Array Technology, IBM and StorageTek aredeveloping RAID Level Five devices, although none so far is @hipping the newarchitectures.andP;  &quot;It remains to be seen whether anyone can make this stuffwork, but I'm optimistic,&quot; says Berkeley's Katz.andM;Dealing with small blocks of data is not the only array problem.andP;  An evenbigger problem for arrays in commercial transaction-oriented environments isintroduced by the parity approach to reliability.andP;  Although parity savesstorage overhead in providing data backup, the tradeoff is that it entails amore complicated way of writing data to disk.andP;  In fact, basic parityalgorithms require a total of two read operations and two write operationsfor every logical write.andP;  In other words, applications could run writeoperations four times slower on systems using arrays with parity than onsystems using nonarrayed storage subsystems.andM;Although Berkeley's Katz says the effect can be ameliorated through,ironically, the use of memory caches and other techniques, he estimates thebest that could be hoped for would be a 33% degradation on write operationsin arrays with parity.andP;  Since write operations make up about a third of mosttypical commercial applications, a 33% degradation is still a big problem.andM;Researchers say this is the major roadblock to bringing  disk arrays tocommercial users.andP;  &quot;I've got to figure out how to do arrays without the writeperformance hit, hopefully with a gain in performance,&quot; says James T. Bradysenior technical staff member working on IBM'S RAID project.andP;  &quot;That's thehard part.andP;  &quot;andM;Brady says he is confident the architectural problems with disk arrays can besolved.andP;  But it could take until the mid-1990s to do it.andM;In addition to solving the write degradation problem, vendors hoping to bringarrays into the IBM environment have some special problems to deal with.andP;  Forone, IBM mainframes use count key data-a storage-formatting system that makesparity impossibly complicated and is at odds with the fixed block formattingsystem used by all inexpensive small disk drives.andP;  That means IBM and vendorsof IBM-compatible storage devices need to come up with an efficient way totranslate between count key data and fixed block formats on the fly at thedisk controller level.andM;As if that weren't enough, IBM and other potential array vendors face stillmore challenges.andP;  To take advantage of the high bandwidth capabilities ofarrays, systems will need very fast channels to and from the data.andP;  Ethernetat 10 megabits per second or even IBM's 3090 channels at 4.5 megabytes persecond are just not fast enough.andP;  Standards groups are working on a100-megabyte connection called the High-Performance Peripheral Interconnect,and IBM will soon introduce fast fiber-optic channels for its mainframes.andO;But neither is in place today.andM;Vendors will also have to redesign their file systems to take advantage ofthe new capabilities and increased performance of disk arrays.andP;  Researchershave just begun to consider how to do that.andP;  Ultimately, many experts believethat disk arrays and operating system software will be closely integrated.andO;But that integration will take a long time to pull off.andM;&quot;This, for the DASD community, is a design space with many more dimensionsthan we normally operate in,&quot; says Brady, with more than a hint ofunderstatement.andM;The multitude of RAID roadblocks has some storage vendors taking await-and-see approach.andP;  Plug-compatible mainframe vendor Hitachi Data SystemsCorp., for example, believes current large disk architectures will be thenorm for several years to come.andP;  Although HDS, like others, is exploringarrays, &quot;We don't see that [they] can be done today and done cost effectivelybetter than what we're offering today [a 3380compatible disk],&quot; says HitachiData Systems storage vice president Gary Holtwick.andM;Similarly, executives at UNIX fileserver vendor Auspex Systems of Santa Claraquestion whether arrays make sense at all for I/O-intensive applications.andO;&quot;We've done all the hardware design for a full RAID Five implementation,&quot;says president Larry Boucher.andP;  &quot;But, from the software standpoint, it turnsout to be fairly complex.andP;  And it turns out there are questions in terms ofperformance.andP;  In fact, I've come to the conclusion that RAID Five is probablynot going to make sense.&quot;andM;Nevertheless, some vendors feel that the time for disk arrays is now.andO;StorageTek, for example, is expected to announce the first of seven Icebergmodels by the end of the year, for delivery in the second quarter of 1991.andO;The device is expected to implement an advanced RAID Five architecture, withinternal fiber-optic channels connecting disk drives.andP;  An associated newcontroller, code-named Penguin, will do the count key data-to-fixed-blockconversion.andP;  Later, the highly intelligent controller will be used tointegrate Iceberg into non-IBM environments.andP;  So potent is Penguin thatStorageTek vice president Don Swatik says it has the equivalentmicroprocessing power of 100 million instructions per second.andP;  Penguin:Dressed Up With Places to GoandM;&quot;We have basically taken the array architecture dramatically beyond thesimple examples [seen so far].&quot; says Swatik.andP;  &quot;Instead of having performanceproblems relative to classical DASD, we actually have significant performanceadvantages,&quot; even in transaction-oriented environments, he maintains.andM;Ultimately, says Swatik, Iceberg, in conjunction with Penguin, will allowStorageTek and its customers to erase the gap between CPU and storagesubsystem performance.andP;  If Swatik is right, users could find that disk arraysare just what the doctor ordered.andP;  Small Disks From Big BlueandM;IBM has been interested in disk arrays as far back as 1978.andP;  Big Blueactually claims to hold several important disk array patents, a fact othervendors may one day find out about the hard way should the market everembrace the technology in a big way.andM;IBM lost interest in arrays, however, in the early 1980s.andP;  The poorreliability of small-diameter disks and I/O performance problems posed byarrays made the architecture impractical in IBM's bread-and-butter market:commercial, transaction-oriented applications.andM;Recently, however, the availability of more reliable small disks and theadvent of high-speed channel technologies such as the High-PerformancePeripheral Interconnect (HPPI) standard have convinced IBM to renew itsinterest in arrays.andP;  IBM storage experts at the company's Almaden ResearchLaboratory and its General Products division facility in San jose recentlystarted designing an array prototype, which they hope to begin building bythe end of the year.andP;  The IBM prototype, attached to a 3090 mainframe viaHPPI, features a control unit with dual, high-speed buses and IPI-3 adapterand interface cards.andP;  The controller is powered by multiple Intel 80960processors.andM;Before theory becomes reality, researchers need to answer a host ofquestions: What is the best way to improve the performance of writeoperations in parity-equipped disk arrays? What is the effect on systemperformance when one of the devices in an array fails? How much time shouldit take to rebuild the data from a failed device via a parity disk?andM;According to IBM senior technical staff member James T. Brady, IBM shouldstart answering some of those questions next year after the prototype isbuilt.andP;  But, Brady says he doesn't expect disk arrays to become a reality inthe commercial market until the mid-1990s.andP;  By then, he says, fast fiberchannels and other necessary innovations will be in place.andO;</TEXT></DOC>