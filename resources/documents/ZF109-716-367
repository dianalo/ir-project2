<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF109-716-367  </DOCNO><DOCID>09 716 367.andM;</DOCID><JOURNAL>Communications of the ACM  Dec 1990 v33 n12 p46(18)* Full Text COPYRIGHT Association for Computing Machinery 1990.andM;</JOURNAL><TITLE>Experiences with the Amoeba distributed operating system.andO;(technical)</TITLE><AUTHOR>Tanenbaum, Andrew S.; Renesse, Robbert van; Staveren, Hans van;Sharp, Gregory J.; Mullender, Sape J.; Jansen, Jack; Rossum, Guidovan.andM;</AUTHOR><SUMMARY>Amoeba 4.0 is a prototype of a distributed operating system thatis used by researchers to analyze the process of connectingmultiple computers to produce the illusion of one high-leveltimesharing system.andP;  The Amoeba project was developed jointly bythe Vrije Universiteit and the Centrum voor Wiskunde enInformatica, both in Amsterdam.andP;  The central goal of the projectis to design a distributed system that is transparent to itsusers.andP;  Components include diskless workstations, pool processorsthat can be allocated as needed, specialized servers, and gatewaysthat link systems from different sites and even differentcountries.andM;</SUMMARY><DESCRIPT>Topic:     Distributed Operating SystemsConnectivityVrije UniversiteitTime Sharing.andO;Feature:   illustrationcharttable.andO;Caption:   The Amoeba architecture. (chart)A directory with three user classes, four entries, and fiverights. (table)Wide-area communication in Amoeba involves six processes. (chart)andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>EXPERIENCES WITH THE AMOEBA DISTRIBUTED OPERATING SYSTEMandM;The Amoeba project is a research effort aimed at understanding how to connectmultiple computers in a seamless way [16, 17, 26, 27, 31].andP;  The basic idea isto provide the users with the illusion of a single powerful timesharingsystem, when, in fact, the system is implemented on a collection of machines,potentially distributed among several countries.andP;  This research has led tothe design and implementation of the Amoeba distributed operating system,which is being used as a prototype and vehicle for further research.andP;  In thisarticle we will describe the current state of the system (Amoeba 4.0), andshow some of the lessons we have learned designing and using it over the pasteight years.andP;  We will also discuss how this experience has influenced ourplans for the next version, Amoeba 5.0.andM;Amoeba was originally designed and implemented at the Vrije Universiteit inAmsterdam, and is now being jointly developed there and at the Centrum voorWiskunde en Informatica, also in Amsterdam.andP;  The chief goal of this work isto build a distributed system that is transparent to the users.andP;  This conceptcan best be illustrated by contrasting it with a network operating system, inwhich each machine retains its own identity.andP;  With a network operatingsystem, each user logs into one specific machine--his home machine.andP;  When aprogram is started, it executes on the home machine, unless the user gives anexplicit command to run it elsewhere.andP;  Similarly, files are local unless aremote file system is explicitly mounted or files are explicitly copied.andP;  Inshort, the user is clearly aware that multiple independent computers exist,and must deal with them explicitly.andM;In contrast, users effectively log into a transparent distributed system as awhole, rather than to any specific machine.andP;  When a program is run, thesystem--not the user--decides upon the best place to run it.andP;  The user is noteven aware of this choice.andP;  Finally, there is a single, system-wide filesystem.andP;  The files in a single directory may be located on differentmachines, possibly in different countries.andP;  There is no concept of filetransfer, uploading or downloading from servers, or mounting remote filesystems.andP;  A file's position in the directory hierarchy has no relation to itslocation.andM;The remainder of this article will describe Amoeba and the lessons we havelearned from building it.andP;  In the next section, we will give a technicaloverview of Amoeba as it currently stands.andP;  Since Amoeba uses theclient-server model, we will then describe some of the more important serversthat have been implemented so far.andP;  This is followed by a description of howwide-area networks are handled.andP;  Then we will discuss a number ofapplications that run on Amoeba.andP;  Measurements have shown Amoeba to be fast,so we will present some of our data.andP;  After that, we will discuss thesuccesses and failures we have encountered, so that others may profit fromthose ideas that have worked out well and avoid those that have not.andP;  Finallywe conclude with a very brief comparison between Amoeba and other systems.andM;Before describing the software, however, it is worth saying something aboutthe system architecture on which Amoeba runs.andM;Technical Overview ofandM;AmoebaandM;System ArchitectureandM;The Amoeba architecture consists of four principal components, as shown inFigure 1.andP;  First are the workstations, one per user, on which users can carryout editing and other tasks that require fast interactive response.andP;  Theworkstations are all diskless, and ar e primarily used in intelligentterminals that do window management, rather than as computers for runningcomplex user programs.andP;  We are currently using Sun-3s, VAXstations andX-terminals as workstations.andM;Second are the pool processors, a group of CPUs that can be dynamicallyallocated as needed, used, and then returned to the pool.andP;  for example, themake command might need to do six compilations; so six processors could betaken out of the pool for the time necessary to do the compilation and thenreturned.andP;  Alternatively, with a five-pass compiler, 5 X 6 = 30 processorscould be allocated for the six compilations, further gaining speedup.andP;  Manyapplications, such as heuristic search in artificial intelligence (AI)applications (e.g., playing chess), use large numbers of pool processors todo their computing.andP;  We currently have 48 single board VME-based computersusing the 68020 and 68030 CPUs.andP;  We also have 10 VAX CPUs forming anadditional processor pool.andM;Third are the specialized servers, such as directory servers, file servers,database servers, boot servers, and various other servers with specializedfunctions.andP;  Each server is dedicated to performing a specific function.andP;  Insome cases, there are multiple servers that provide the same function, forexample, as part of the replicated file system.andM;Fourth are the gateways, which are used to link Amoeba systems at differentsites and different countries into a single, uniform system.andP;  The gatewaysisolate Amoeba from the peculiarities of the protocols that must be used overthe wide-area networks.andM;All the Amoeba machines run the same kernel, which primarily providesmultithreaded processes, communication services, I/O, and little else.andP;  Thebasic idea behind the kernel was to keep it small, to enhance itsreliability, and to allow as much as possible of the operating system to runas user processes (i.e., outside the kernel), providing for flexibility andexperimentation.&quot;andM;Objects and CapabilitiesandM;Amoeba is an object-based system.andP;  It can be viewed as a collection ofobjects, each of which contains a set of operations that can be performed.andO;For a file object, for example, typical operations are reading, writing,appending, and deleting.andP;  The list of allowed operations is defined by theperson who designs the object and who writes the codes to implement it.andP;  Bothhardware and software objects exist.andM;Associated with each object is a capability [8], a kind of ticket or key thatallows the holder of the capability to perform some (not necessarily all)operations on that object.andP;  For example, a user process might have acapability for a file that permits it to read the file, but not to modify it.andO;Capabilities are protected cryptographically to prevent users from tamperingwith them.andM;Each user process owns some collection of capabilities, which together definethe set of objects it may access and the types of operations that may beperformed on each.andP;  Thus capabilities provide a unified mechanism for naming,accessing, and protecting objects.andP;  From the user's perspective, the functionof the operating system is to create an environment in which objects can becrated and manipulated in a protected way.andM;This object-based model visible to the users is implemented using remoteprocedure call [5].andP;  Associated with each object is a server process thatmanages the object.andP;  When a user process want to perform an operation on anobject, it sends a request message to the server that manages the object.andO;The message contains the capability for the object, a specification of theoperation to be performed, and any parameters the operation requires.andP;  Theuser, known as the client, then blocks.andP;  After the server has performed theoperation, it sends back a reply message that unblocks the client.andP;  Thecombination of sending a request message, blocking, and accepting a replymessage forms the remote procedure call, which can be encapsulated using stubroutines, to make the entire remote operation look like a local procedurecall.andP;  (For other possibilities see [28]).andM;The structure of a capability is shown in Figure 2.andP;  It is 128 bits long andcontains four fields.andP;  The first field is the server port, and is used toidentify the (server) process that manages the object.andP;  It is in effect a48-bit random number chosen by the server.andM;The second field is the object number, which is used by the server toidentify which of its objects is being addressed.andP;  Together, the server portand object number uniquely identify the object on which the operation is tobe performed.andM;The third field is the rights field, which contains a bit map telling whichoperations the holder of the capability may perform.andP;  If all the bits are 1s,all operations are allowed.andP;  However, if some of the bits are 0s, the holderof the capability may not perform the corresponding operations.andP;  Since theoperations are usually coarse grained, 8 bits is sufficient.andM;To prevent users from just turning all the 0 bits in the rights field into 1bits, a cryptographic protection scheme is used.andP;  When a server is asked tocreate an object, it picks an available slot in its internal tables, and putsthe information about the object in there along with a newly generated 48-bitrandom number.andP;  The index for the table is put into the object number fieldof the capability, the rights bits are all set to 1, and the newly generatedrandom number is put into the check field of the capability.andP;  This is anowner capability, and can be used to perform all operations on the object.andM;The owner can construct a new capability with a subset of the rights byturning off some of the rights bits and then XOR-ing the rights field withthe random number in the check field.andP;  The result of this operation is thenrun through a (publicly known) one-way function to produce a new 48-bitnumber that is put in the check field of the new capability.andM;The key property required of the one-way function, f, is that given theoriginal 48-bit number, N (from the owner capability) and the unencryptedrights field, R, it is easy to compute C = f(N XOR R), but given only C it isnearly impossible to find an argument to f that produces the given C.andP;  Suchfunctions are known [9].andM;When a capability arrives at a server, the server uses the object field toindex into its tables to locate the information about the object.andP;  It thenchecks to see if all the rights bits are on.andP;  If so, the server knows thatthe capability is (or is claimed to be) an owner capability, so it justcompares the original random number in its table with the contents of thecheck field.andP;  If they agree, the capability is considered valid and thedesired operation is performed.andM;If some of the rights bits are 0, the server knows that it is dealing with aderived capability, so it performs an XOR of the original random number inits table with the rights field of the capability.andP;  This number is then runthrough the one-way function.andP;  If the output of the one-way fuction agreeswith the cotents of the check field, the capability is deemed valid, and therequested operation is performed if its rights bit is set to 1.andP;  Due to thefact that the one-way function cannot be inverted, it is not possible for auser to &quot;decrypt&quot; a capability to get the original random number in order togenerate a false capability with more rights.andM;Remote OperationsandM;The combination of a request from a client to a server and a reply from aserver to a client is a remote operation.andP;  The request and reply messagesconsist of a header and a buffer.andP;  Headers are 32 bytes, and buffers can beup to 30 kilobytes.andP;  A request header contains the capability of the objectto be operated on, the operatio code, and a limited area (8 bytes) forparameters to the operation.andP;  For example, in a write operation on a file,the capability identifies the file, the operation code is write, and theparameters specify the size of the data to be written, and the offset in thefile.andP;  The request buffer contains the data to be written.andP;  A reply headercontains an error code, a limited area for the result of the operation (8bytes), and a capability field that can be used to return a capability (e.g.,andO;as the result of the creation of an object, or of a directory searchoperation).andM;The primitives for doing remote operatins are listed below:andM;get_request(req-header, req-buffer, req-size)andM;put_reply(rep-header, rep-buffer, rep-size)andM;do_operation(req-header, req-buffer, req-size, rep-header, rep-buffer,rep-size)andM;When a servier is prepared to accept requests from clients, it executes aget_request primitive, which causes it to block.andP;  When a request messagearrives, the server is unblocked and the formal parameters of the call toget_request are filled in with the information from the inncoming request.andO;The server then performs the work and sends a reply using put_reply.andM;On the client side, to invoke a remote operation, a process usesdo_operation.andP;  This action causes the request message to be sent to theserver.andP;  The request header contains the capability of the object to bemanipulated and various parameters relating to the operation.andP;  The caller isblocked until the reply is received, at which time the three rep-parametersare filled in and a status returned.andP;  The return status of do_operation canbe one of three possibilities:andM;1.andP;  The request was delivered and has been executed.andM;2.andP;  The request was not delivered or executed (e.g., server was down).andM;3.andP;  The status is unknown.andM;The third case can arise when the request was sent (and possible evenacknowledged), but no reply was forthcoming.andP;  That situation can arise if aserver crashes part way through the remote operatio.andP;  Under all conditions oflost messages and crashed servers, Amoeba guarantees that messages aredelivered at most once.andP;  If status 3 is returned, it is up to the applicationor run time system to do its own fault recovery.andM;Remote Procedure CallsandM;A remote procedure call actually consists of more than just the request/replyexchange described above.andP;  The client has to place the capability, operationcode, and parameters in the request buffer, and on receiving the reply it hasto unpack the results.andP;  The server has to check the capability, extract theoperation code and parameters from the request, and call the appropriateprocedure.andP;  The result of the procedure has to be placed in the reply buffer.andO;Placing parameters or results in a message buffer is called marshalling, andhas a nontrivial cost.andP;  Different data representations in client and serveralso have to be handled.andP;  All of these steps must be carefully designed andcoded, lest they introduce unacceptable overhead.andM;To hide the marshalling and message passing from the users, Amoeba uses stubroutines [5].andP;  For example, one of the file system stubs might start with:andM;int read_file(file_cap, offset, nbytes, buffer, bytes_read) capability_t*file_cap; long offset; long *nbytes; char *buffer; long *bytes_read;andM;This call read nbytes starting at offset from the file identified by file_capinto buffer.andP;  If returns the number of bytes actually read in bytes_read.andO;The function itself returns 0 if it executed correctly or an error codeotherwise.andP;  A hand-written stub for this code is simple to construct: it willproduce a request header containing file_cap, the operation code forread_file, offset, and nbytes, and invoke the remote operation:andM;do_operation(req_hdr, req_buf, req_bytes, rep_hdr, buf, rep_bytes);andM;Automatic generation of such a stub from the procedure header above isimpossible.andP;  Some essential information is missing.andP;  The author of thehandwritten stub uses several pieces of derived information to do the job.andM;1.andP;  The buffer is used only to receive information from the file server; itis an output parameter, and should not be sent to the server.andM;2.andP;  The maximum length of the buffer is given in the nbytes parameter.andP;  Theactual length of the buffer is the returned value if there is no error andzero otherwise.andM;3.andP;  File_cap is special; it defines the service that must carry out theremote operation.andM;4.andP;  The stub generator does not know what the server's operation code forread_file is.andP;  This requires extra information.andP;  But, to be fair, the humanstub writer needs this extra information too.andM;In order to be able to do automatic stub generation, the interfaces betweenclient and servers have to contain the information listed above, plusinformation about type representation for all language/machine combinationsused.andP;  In addition, the interface specifications have to have an inheritancemechanism which allows a lower-level interface to be shared by several otherinterfaces.andP;  The read_file operation, for instance, will be defined in alow-level interface which is then inherited by all file-server interfaces,the terminal-server interface, and the segment-server interface.andM;The Amoeba Interface Language (AIL) is a language in which the extrainformation for the generation of efficient stubs can be specified, so thatthe AIL compiler can produce stub routines automatically [33].andP;  The read_fileoperation could be part of an interface (called a class in AIL) whosedefinition could look something like this:andM;class simple_file_server [100..199] { read_file(*, in unsigned offset, in outunsigned nbytes, out char buffer [nbytes:NBYTES]);andM;write_file(*,...);andM;From this specification, AIL can generate the client stub of the exampleabove with the correct marshalling code.andP;  It can also generate the servermain loop, containing the marshalling code corresponding to the client stubs.andO;The AIL specification tells the AIL compiler that the operation codes for thesimple_file_server can be allocated in the range 100 to 199; it tells whichparameters are input parameters to the server and which are output parametersfrom the server, and it tells that the length of buffer is at most NBYTES(which must be a constant) and that the actual length is nbytes.andM;The Bullet File Server, one of the file servers operational in Amoeba,inherits this interface, making it part of the Bullet File Server interface:andM;class bullet_server [200..299] { inherit simple_file_server;creat_file(*,...); };andM;AIL supports multiple inheritance so the Bullet server interface can inheritboth the simple file interface and, for instance, a capability managementinterface for restricting rights on capabilities.andM;Currently, AIL generates stubs in C, but Modula stubs and stubs in otherlanguages are planned.andP;  AIL stubs have been designed to deal with differentrepresentations--such as byte order and floating-point representation--onclient and server machines.andM;ThreadsandM;A process in Amoeba consists of one or more threads that run in parallel.andO;All the threads of a process share the same address space, but each one has adedicated portion of that address space of use as its private stack, and eachone has its own program counter.andP;  From the programmer's point of view, eachthread is like a traditional sequential process, except that the threads of aprocess can communicate using shared memory.andP;  In addition, the threads can(optionall) synchronize with each other using mutexes or semaphores.andM;The purpose of having multiple threads in a process is to increaseperformance through parallelism, and still provide a reasonable semanticmodel to the programmer.andP;  For example, a file server could be programmed as aprocess with multiple threads.andP;  When a request comes in, it can be given tosome thread to handle.andP;  That thread first checks an internal (software) cacheto see if the needed data are present.andP;  If not, it performs remote procedurecall (RPC) with a remote disk server to acquire the data.andM;While waiting for the reply from the disk, the thread is blocked and will notbe able to handle any other requests.andP;  However, new requests can be given toother threads in the same process to work on while the first thread isblocked.andP;  In this way, multiple requests can be handled simultaneously, whileallowing each thread to work in a sequential way.andP;  The point of having allthe threads share a common address space is to make it possible for all ofthem to have direct access to a common cache--something that is not possibleif each thread is its own address space.andM;The scheduling of threads within a process is done by code within the processitself.andP;  When a thread blocks, either because it has no work to do (i.e., ona get_request) or because it is waiting for a remote reply (i.e., on ado_operation), the internal scheduler is called, the thread is blocked, and anew thread can be run.andP;  Thus threads are effectively co-routines.andP;  Threadsare not pre-empted, that is, the currently running thread will not be stoppedbecause it has run too long.andP;  This decision was made to avoid raceconditions.andP;  There need be no worry that a thread, when halfway throughupdating some critical shared table, will be suddenly stopped by some otherthread starting up and trying to use the same table.andP;  It is assumed that thethreads in a process were all written by the same programmer and are activelycooperating.andP;  That is why they are in the same process.andP;  Thus the interactionbetween two threads in the same process is quite different from theinteraction between two threads in different processes, which may be hostileto one another and for which hardware memory protection is required and used.andO;Our evaluation of this approach is discussed later.andM;ServersandM;The Amoeba kernel, as we described, essentially handles communication andsome process management, and little else.andP;  The kernel takes care of sendingand receiving messages, scheduling processes, and some low-level memorymanagement.andP;  Everything else is done by user processes.andP;  Even capabilitymanagement is done entirely in user space, since the cryptographic techniquediscussed earlier makes it virtually impossible for users to generatecounterfeit capabilities.andM;All of the remaining functions that are normally associated with a modernoperating system environment are performed by servers, which are justordinary user processes.andP;  The file system, for example, consists of acollection of user processes.andP;  Users who are not happy with the standard filesystem are free to write and use their own.andP;  This situation can be contrastedwith a system like Unix[TM], in which there is a single file system that allapplications must use, no matter how inappropriate it may be.andP;  In [24] forexample, the numerous problems that Unix creates for database systems aredescribed at great length.andM;In the following sections we will discuss the Amoeba memory server, processserver, file server, and directory server, as examples of typical Amoebaservers.andP;  Many others exist as well.andM;The Memory and ProcessandM;ServerandM;In many applications, processes need a way to create subprocesses.andP;  In Unix,a subprocess is created by the fork primitive, in which an exact copy of theoriginal process is made.andP;  This process can then run for a while, attendingto housekeeping activities, and then issue an exec primitive to overwrite itscore image with a new program.andM;In a distributed system, this model is not attractive.andP;  The idea of firstbuilding an exact copy of the process, possibly remotely, and then throwingit away again shortly thereafter is inefficient.andP;  Consequently, Amoeba uses adifferent strategy.andP;  The key concepts are segments and process descriptors.andM;A segment is a contiguous chunk of memory that can contain code or data.andO;Each segment has a capability that permits its holder to perform operationson it, such as reading and writing.andP;  A segment is somewhat like an in-corefile, with similar properties.andM;A process descriptor is a data structure that provides information about astunned process, that is, a process not yet started or one being debugged ormigrated.andP;  It has four components.andP;  The first describes the requirements forthe system where the process must run: the class of machines, whichinstruction set, minimum available memory, use of special instructions suchas floating point, and several more.andP;  The second component describes thelayout of the address space: number of segments and, for each segment, thesize, the virtual address, how it is mapped (e.g., read only, read-write,code/data space), and the capability of a file or segment containing thecontents of the segment.andP;  The third component describes the state of eachthread of control: stack pointer, stack top and bottom, program counter,processor status word, and registers.andP;  Threads can be blocked on certainsystem calls (e.g., get_request); this can also be described.andP;  The fourthcomponent is a list of ports for which the process is a server.andP;  This list ishelpful to the kernel when it comes to buffering incoming requests andreplying to port-locate operations.andM;A process is created by executing the following steps.andM;1.andP;  Get the process descriptor for the binary from the file system.andM;2.andP;  Create a local segment or a file and initialize it to the initialenvironment of the new process.andP;  The environment consists of a set of namedcapabilities (a primitive directory, as it were), and the arguments to theprocess (in Unix terms, argc and argv).andM;3.andP;  Modify the process descriptor to make the first segment the environmentsegment just created.andM;4.andP;  Send the process descriptor to the machine where it will be executed.andM;When the processor descriptor arrives at the machine where the process willrun, the memory server there extracts the capabilities for the remotesegments from it, and fetches the code and data segments from wherever theyreside by using the capabilities to perform READ operations in the usual way.andO;In this manner, the physical locations of all the machines involved areirrelevant.andM;Once all the segments have been filled in, the process can be constructed andthe process started.andP;  A capability for the process is returned to theinitiator.andP;  This capability can be used to kill the process, or it can bepassed to a debugger to stun (suspend) it, read and write its memory, and soon.andM;The File ServerandM;As far as the system is concerned, a file server is just another userprocess.andP;  Consequently, a variety of file servers have been written forAmoeba in the course of its existence.andP;  The first one, Free UniversityStorage System (FUSS) [15] was designed as an experiment in managingconcurrent access using optimistic concurrency control.andP;  The current one, thebullet server was designed for extremely high performance [30, 31, 32].andM;The decrease in the cost of disk and RAM memories over the past decade hasallowed us to use a radically different design from that used in Unix andmost other operating systems.andP;  In particular, we have abandoned the idea ofstoring files as a collection of fixed-size disk blocks.andP;  All files arestored contiguously, both on the disk and in the server's main memory.andP;  Whilethis design wastes some disk space and memory due to fragmentation overhead,we feel that the enormous gain in performance more than offsets the smallextra cost of having to buy, say, an 800 MB disk instead of a 500 MB disk inorder to store 500 MB worth of files.andM;The bullet server is an immutable file store.andP;  Its principal operations areread_file and create_file.andP;  (For garbage collection purposes there is also adelete_file operation.)andP;  When a process issues a read_file request, thebullet server can transfer the entire file to the client in a single RPC,unless it is larger than the maximum size (30,000 bytes), in which casemultiple RPCs are needed.andP;  The client can then edit or otherwise modify thefile locally.andP;  When it is finished, the client issues a create_file RPC tomake a new version.andP;  The old version remains intact until explicitly deletedor garbage collected.andP;  It should be noted that different versions of a filehave different capabilities, so they can co-exist, allowing for thestraightforward implementation of source code control systems.andM;The files are stored contiguously on disk, and are cached in the fileserver's memory (currently 12 Mbytes).andP;  When a requested file is notavailable in this memory, it is loaded from disk in a single large DMAoperation and stored contiguously in the cache.andP;  (Unlike conventional filesystems, there are no &quot;blocks&quot; used anywhere in the file system.)andP;  In thecreat_file operation one can request the reply before the file is written todisk (for speed), or afterwards (to know that it has been successfullywritten).andM;When the bullet server is booted, the entire &quot;i-node table&quot; is read intomemory in a single disk operation and kept there while the server is running.andO;When a file operation is requested, the object number field in the capabilityis extracted, which is an index into this table.andP;  The entry thus locatedgives the disk address as well as the cache address of the contiguous file(if present).andP;  No disk access is needed to fetch the &quot;i-node&quot; and at most onedisk access is needed to fetch the file itself, if it is not in the cache.andO;The simplicity of this design trades off some space for high performance.andM;The Directory ServerandM;The bullet server does not provide any naming services.andP;  To access a file, aprocess must provide the relevant capability.andP;  Since working with 128-bitbinary numbers is not convenient for people, we have designed and implementeda directory server to manage names and capabilities.andM;The directory server manages multiple directories, each of which is a normalobject.andP;  Stripped down to its barest essentials, a directory maps ASCIIstrings onto capabilities.andP;  A process can present a string, such as a filename, to the directory server, and the directory server returns thecapability for that file.andP;  Using this capability, the process can then accessthe file.andM;In Unix terms, when a file is opened, the capability is retrieved from thedirectory server for use in subsequent read and write operations.andP;  After thecapability has been fetched from the directory server, subsequent RPCs godirectly to the server that manages the object.andP;  The directory server is nolonger involved.andM;It is important to realize that the directory server simply provides amapping function.andP;  The client provides a capability for a directory (in orderto specify which directory to search) and a string, and the directory serverlooks up the string in the specified directory and returns the capabilityassociated with the string.andP;  The directory server has no knowledge of thekind of object that the capability controls.andM;In particular, it can be a capability for another directory on the same or adifferent directory server--a file, a mailbox, a database, a processcapability, a segment capability, a capability for a piece of hardware, oranything else.andP;  Furthermore, the capability may be for an object located onthe same machine, a different machine on the local network, or a capabilityfor an object in a foreign country.andP;  The nature and location of the object iscompletely arbitrary.andP;  Thus the objects in a directory need not all be on thesame disk, for example, as is the case in many systems that support &quot;remotemount&quot; operations.andM;Since a directory may contain entries for other directories, it is possibleto build up arbitrary directory structures, including trees and graphs.andP;  Asan optimization, it is possible to give the directory server a complete path,and have it follow it as far as it can, returning a single capability at theend.andM;Actually, directories are slightly more general than just simple mappings.andO;It is commonly the case that the owner of a file may want to have the rightto perform all operations on it, but may want to permit others read-onlyaccess.andP;  The directory server supports this idea by structuring directoriesas a series of rows, one per object, as shown in Figure 3.andM;The first column gives the string (e.g., the file name).andP;  The second columngives the capability that goes with that string.andP;  The remaining columns eachapply to one user class.andP;  For example, one could set up a directory withdifferent access rights for the owner, the owner's group, and others, as inUnix, but other combinations are also possible.andM;The capability for a directory specifies the columns to which the holder hasaccess as a bit map in part of the rights field (e.g., 3 bits).andP;  Thus inFigures 3, the bits 001 might specify access to only the other column.andO;Earlier we discussed how the rights bits are protected from tampering by useof the check field.andM;To see how multiple columns are used, consider a typical access.andP;  The clientprovides a capability for a directory (implying a column) and a string.andP;  Thestring is looked up in the directory to find the proper row.andP;  Next, thecolumn is checked against the (singleton) bit map in the rights field, to seewhich column should be used.andP;  Remember that the cryptographic schemepreviously described prevents users from modifying the bit map, henceaccessing a forbidden column.andM;Then the entry in the selected row and column is extracted.andP;  Conceptuallythis is just a capability, with the proper rights bits turned on.andP;  However,to avoid having of store many capabilities, few of which are ever used, anoptimization is made, and the entry is just a bit map, b.andP;  The directoryserver can then ask the server that manages the object to return a newcapability with only those rights in b.andP;  This new capability is returned tothe user and also cached for future use, to reduce calls to the server.andM;The directory server supports a number of operations on directory objects.andO;These include looking up capabilities, adding new rows to a directory,removing rows from directories, listing directories, inquiring about thestatus of directories and objects, and deleting directories.andP;  There is alsoprovision for performing multiple operations in a single atomic action, toprovide for fault tolerance.andM;Furthermore, there is also support for handling replicated objects.andP;  Thecapability field in Figure 3 can actually hold a set of capabilities formultiple copies of each object.andP;  Thus when a process looks up an object, itcan retrieve the entire set of capabilities for all the copies.andP;  If one ofthe objects is unavailable, the others can be tried.andP;  The technique issimilar to the one used by Eden [20].andP;  In addition, it is possible toinstruct the system to automatically generate replicas and store them in thecapability set, thus freeing the user from this administration.andM;In addition to supporting replication of user objects, the directory serveris itself duplicated.andP;  Among other properties, it is possible to install newversions of the directory server by killing off one instance of it,installing a new version as the replacement, killing off the other (original)instance, and installing a second replacement also running the new code.andP;  Inthis way bugs can be repaired without interrupting service.andM;Wide-Area AmoebaandM;Amoeba was designed with the idea that a collection of mahcines on a localarea network (LAN) would be able to communicate over a wide-area network witha similar collection of remote machines.andP;  The key problem here is thatwide-area networks are slow and unreliable, and use protocols such as X.25,TCP/IP, and OSI; they do not use RPC.andP;  The primary goal of the wide-areanetworking in Amoeba has been to achieve transparency without sacrificingperformance [29].andP;  In particular, it is undesirable that the fast local RPCbe slowed down due to the existence of wide-area communication.andP;  We believethis goal has been achieved.andM;The Amoeba world is divided into domains, each domain being an interconnectedcollection of local area networks.andP;  The key aspect of a domain (e.g., acampus), is that broadcasts done from any machine in the domain are receivedby all other machines in the domain, but not by machines outside the domain.andM;The importance of broadcasting has to do with how ports are located inAmoeba.andP;  When a process does an RPC with a port not previously used, thekernel broadcasts a locate message.andP;  The server responds to this broadcastwith its address, which is then used and also cached for future RPCs.andM;This strategy is undesirable with a wide-area network.andP;  Although broadcastcan be simulated using a minimum spanning tree [7] it is expensive andinefficient.andP;  furthermore, not every service should be available worldwide.andO;For example, a laser printer serve in the physics building at a university inCalifornia may not be of much use to clients in New York.andM;Both of these problems are dealt with by introducing the concept ofpublishing.andP;  When a service wishes to be knwon and accessible outside its owndomain, it contacts the Service for Wide-Area Networks (SWAN) and asks thatits port be published in some set of domains.andP;  The SWAN publishes the port bydoing RPCs with SWAN processes in each of those domains.andM;When a port is published in a domain, a new process called a server agent iscreated in that domain.andP;  The process typically runs on the gateway machine,and does a get_request using the remote server's port.andP;  It is quiescent untilits server is needed, at which time it comes to life and performs and RPCwith the server.andM;Now let us consider what happens when a process tries to locate a remoteserver whose port has been published.andP;  The process' kernel broadcasts alocate, which is retrieved by the server agent.andP;  The server agent then buildsa message and hands it to a link process on the gateway machine.andP;  The linkprocess forwards it over the wide-area network to the server's domain, whereit arrives at the gateway, causing a client agent process to be created.andO;This client agent then makes a normal RPC to the server.andP;  The set ofprocesses involved here is shown in Figure 4.andM;The beauty of this scheme is that it is completely transparent.andP;  Neither userprocesses nor the kernel know which processes are local and which are remote.andO;The communication between the client and the server agent is completelylocal, using the normal RPC.andP;  Similarly, the communication between the clientagent and the server is also completely normal.andP;  Neither the client nor theserver knows that it is talking to a distant process.andM;Of course, the two agents are well aware of what is going on, but they areautomatically generated as needed, and are not visible to users.andP;  The linkprocesses are the only ones that know about the details of the wide-areanetwork.andP;  They talk to the agents using RPC, but to each other using whateverprotocol the wide-area network requires.andP;  The point of splitting off theagents from the link processes is to completely isolate the technical detailsof the wide-area network in one kind of process, and to make it easier tohave multiway gateways, which would hae one type of link process for eachwide-area network type to which the gateway is attached.andM;It is important to note that this design causes no performance degradationfor local communication.andP;  An RPC between a client and a server on the sameLAN proceeds at full speed, with no relaying of any kind.andP;  Clearly there issome performance loss when a client is talking to a server located on adistant network, but the limiting factor is normally the bandwidth of thewide-area network, so the extra overhead of having messages being relayedseveral times is negligible.andM;Another useful aspect of this design is its management.andP;  To start with,services can only be published with the help of the SWAN server, which cancheck to see if the system administration wants the port to be published.andO;Another important control is the ability to prevent certain processes (e.g.,andO;those owned by students) from accessing wide-area services, since all suchtraffic must pass through the gateways, and various checks can be made there.andO;Finally, the gateways can do accounting, statistics gathering, and monitoringof the wide-area network.andM;ApplicationsandM;Amoeba has been used to program a variety of applications.andP;  We will nowdescribe several of them, including Unix emulation, parallel make, travelingsalesman, and alpha-beta search.andM;Unix EmulationandM;One of the goals of Amoeba was to make it useful as a program developmentenvironment.andP;  For such an environment, one needs editors, compilers, andnumerous other standard software.andP;  It was decided that the easiest way toobtain this software was to emulate Unix and then to run Unix and MINIX [25]compilers and other utilities on top of it.andM;Using a special set of library procedures that do RPCs with the Amoebaservers, it has been possible to construct an emulation of the Unix systemcall interface--which was dubbed Ajax--that is good enough that about 100 ofthe most common utility programs have been ported to Amoeba.andP;  The Amoeba usercan now use most of the standard editors, compilers, file utilities and otherprograms in a way that looks very much like Unix, although in fact it isreally Amoeba.andP;  A session server has been provided to handle stateinformation and do fork and exec in a Unix-like way.andM;Parallel MakeandM;As shown in Figure 1, the hardware on which Amoeba runs contains a processorpool with several dozen processors.andP;  One obvious application for theseprocessors in a Unix environment is a parallel version of make [10].andP;  Theidea here is that when make discovers that multiple compilations are needed,they are run in parallel on different processors.andM;Although this idea sounds simple, there are several potential problems.andP;  forone, to make a single target file, a sequence of several commands may have tobe executed, and some of these may use files created by earlier ones.andP;  Thesolution chosen is to let each command execute in parallel, but block when itneeds a file being made but not yet fully generated.andM;Other problems relate to technical limitations of the make program.andP;  Forexample, since it expects commands to be run sequentially, rather than inparallel, it does not keep track of how many processes it has forked off,which may exceed various system limits.andM;Finally, there are programs, such as yacc [11] that write their output onfixed name files, such as y.tab.c.andP;  When multiple yaac's are running in thesame directory, they all write to the same file, thus producing gibberish.andO;of these problems have been dealt with by one means or another, as describedin [2].andM;The parallel compilations are directed by a new version of make, calledamake.andP;  Amake does not use traditional makefiles.andP;  Instead, the user tells itwhich source files are needed, but not their dependencies.andP;  The compilershave been modified to keep track of the observed dependencies (e.g., whichfiles they in fact included).andP;  After a compilation, this information goesinto a kind of minidatabase that replaces the traditional makefile.andP;  It alsokeeps track of which flags were used, which version of the compiler was used,and other information.andP;  Not having to even think about makefiles, not evenautomatically generated ones, has been popular with the users.andP;  The overheaddue to managing the database is negligible, but the speedup due toparallelization depends strongly on the input.andP;  When making a programconsisting of many medium-sized files, considerable speedup can be achieved.andO;However, when a program has one large source file and many small ones, thetotal time can never be smaller than the compilation time of the large one.andM;The Traveling SalesmanandM;ProblemandM;In addition to various experiments with the Unix software, we have also triedprogramming some applications in parallel.andP;  Typical applications are thetraveling salesman problem [13] and alpha-beta search [14] which we brieflydescribe here.andP;  More details can be found in [3].andM;In the traveling salesman problem, the computer is given a starting locationand a list of cities to be visited.andP;  The idea is to find the shortest paththat visits each city exactly once, and then return to the starting place.andO;Using Amoeba we have programmed this application in parallel by having onepool processor act as coordinator, and the rest as slaves.andM;For example, suppose the starting place is London, and the cities to bevisited include New York, Sydney, Nairobi, and Tokyo.andP;  The coordinator mighttell the first slave to investigate all paths starting with London-New York;the second slave to investigate all paths starting with London-Sydney; thethird slave to investigate all paths starting with London-Nairobi; and so on.andO;All of these searches go on in parallel.andP;  When a slave is finished, itreports back to the coordinator and gets a new assignment.andM;The algorithm can be applied recursively.andP;  For example, the first slave couldallocate a processor to investigate paths starting with London - New York -Sydney, another processor to investigate London-New York-Nairobi, and soforth.andP;  At some point, of course, a cutoff is needed at which a slaveactually does the calculation itself and does not try to farm it out to otherprocessors.andM;The performance of the algorithm can be greatly improved by keeping track ofthe best total path found so far.andP;  A good initial path can be found by usingthe &quot;closest city next&quot; heuristic.andP;  Whenever a slave is started up, it isgiven the length of the best total path so far.andP;  If it ever finds itselfworking on a partial path that is longer than the best-known total path, itimmediately stops what it is doing, reports back failure, and asks for morework.andP;  Initial experiments have shown that 75% of the theoretical maximumspeedup can be achieved using this algorithm.andP;  The rest is lost tocommunication overhead.andM;Alpha-Beta SearchandM;Another application that we have programmed in parallel using Amoeba is gameplaying using the alpha-beta heuristic for pruning the search tree.andP;  Thegeneral idea is the same as for the traveling salesman.andP;  When a processor isgiven a board to evaluate, it generates all the legal moves possible startingat the board, and hands them off to others to evaluate in parallel.andM;The alpha-beta heuristic is commonly used in two-person, zero-sum games toprune the search tree.andP;  A window of values is established, and positions thatfall outside this window are not examined because better moves are known toexist.andP;  In contrast to the traveling salesman problem, in which much of thetree has to be searched, alpha-beta allows a much greater pruning if thepositions are evaluated in a well-chosen order.andM;For example, on a single machine, we might have three legal moves A, B, and Cat some point.andP;  As a result of evaluating A we might discover that looking atits siblings in the tree, B and C was pointless.andP;  In a parallelimplementation, we would do all at once, and ultimately waste the computingpower devoted to B and C.andP;  The result is that much parallel searching iswasted, and the net result is not that much better than a sequentialalgorithm on a single processor.andP;  Our experiments running Othello (Reversi)on Amoeba have shown that we were unable to utilize more than 40% of thetotal processor capacity available, compared to 75% for the travelingsalesman problem.andM;PerformanceandM;Amoeba was designed to be fast.andP;  Measurements show that this goal has beenachieved.andP;  In this section, we will present the results of some timingexperiments we have done.andP;  These measurements were performed on Sun 3/60s (20MHz 68020s) using a 10 Mbps Ethernet.andP;  We measured the performance for threedifferent configurations:andM;1.andP;  Two user processes running on Amoeba.andM;2.andP;  Two user processes running on Sun OS 4.0.3 but using the Amoebaprimitives, which were added to the Sun Kernel.andM;3.andP;  Two user processes running on Sun OS 4.0.3 and using Sun RPC.andM;The latter two were for comparison purposes only.andP;  We ran tests for the localcase (both processes on the same machine) and for the remote case (eachprocess on a separate machine, with communication over the Ethernet).andP;  In allcases communication was from process to process, all of which were running inuser mode outside the kernel.andP;  The measurements represent the average valuesof 100,000 trials and are highly reproducible.andM;For each configuration (pure Amoeba, Amoeba primitives on Unix, Sun RPC onUnix), we tried to run three test cases: a 4-byte message (1 integer), an 8Kbyte message, and a 30 Kbyte message.andP;  The 4-byte message test is typicalfor short control messages, the 8-Kbyte message is typical for reading amedium-sized file from a remote file, and the 30-Kbyte test is the maximumthe current implementation of Amoeba can handle.andP;  Thus, in total we shouldhave nine cases (three configurations and three sizes).andP;  However, thestandard Sun PRC is limited to 8K, so we have measurements for only eight ofthem.andP;  It should also be noted that the standard Amoeba header has room for 8bytes of data, so in the test for 4 bytes, only a header was sent and no databuffer.andP;  On the other hand, on the Sun, a special optimization is availablefor the local case, which we used.andM;In Figure 5 we illustrate the delay and the bandwidth of these eight cases,both for local processes (two distinct processes on the same machine) andremote processes (processes on different machines).andP;  The delay is the time asseen from the client, running as a user process, between the calling of, andreturning from, the RPC primitive.andP;  The bandwidth is the number of data bytesper second that the client receives from the server, excluding headers.andP;  Themeasurements were done for both local RPCs, where the client and serverprocesses were running on the same processor, and for remote RPCs over theEthernet.andM;The interesting comparisons in these tables are the comparisons of pureAmoeba RPC and pure Sun OS RPC both for short communications, where delay iscritical, and long ones, where bandwidth is the issue.andP;  A 4-byte Amoeba RPCtakes 1.1 msec, v. 6.7 msec for Sun RPC.andP;  Similarly, for 8 Kbyte RPCs, theAmoeba bandwidth is 721 Kbytes/sec, v. only 325 Kbytes for the Sun RPC.andP;  Theconclusion is that Amoeba's delay is six times better and its throughput istwice as good.andM;While the Sun is obviously not the only system of interest, its widespreaduse makes it a convenient benchmark.andP;  We have looked in the literature forperformance figures from other distributed systems and have shown thenull-RPC latency and maximum throughput in Figure 6.andM;The RPC numbers for the other systems listed in Figure 6 are taken from thefollowing publications: Cedar [5], x-Kernel [19], Sprite [18], V [6], Topaz[22], and Mach [19].andM;The numbers shown here cannot be compared without knowing about the systemsfrom which they were taken, since the speed of the hardware on which thetests were made varies by about a factor of 3.andP;  On all distributed systems ofthis type running on fast LANs, the protocols are largely CPU bound.andP;  Runningthe system on a faster CPU (but the same network) definitely improvesperformance, although not linearly with CPU MIPS because at some point thenetwork saturates (although none of the systems quoted here even come closeto saturating it).andP;  As an example, in [31] we reported a null RPC time of 1.4msec, but this was for Sun 3/50s.andP;  The current figure of 1.1 sec is for thefaster Sun 3/60s.andM;In Figure 6 we have not corrected for machine speed, but we have at leastmade a rough estimate of the raw total computing power of each system, givenin the fifth column of the table in MIPS (Millions of Instructions PerSecond).andP;  While we realize that this is only a crude measure at best, we seeno other way to compensate for the fact that a system running on a 4 MIPSmachine (Dorado) or on a 5 CPU multiprocessor (Firefly) has a significantadvantage over slower workstations.andP;  As an aside, the Sun 3/60 is indeedfaster than the Sun 3/75; this is not a misprint.andM;Cedar's RPC is about the same as Amoeba's although it was implemented onhardware that is 33% faster.andP;  Its throughput is only 30% of Amoeba's, butthis is partly due to the fact that it used an early version of the Ethernetrunning at 3 megabits/sec.andP;  Still, it does not even manage to use the full 3megabits/sec.andM;The x-Kernel has a 10% better throughput than Amoeba, but the publishedmeasurements are kernel-to-kernel, whereas Amoeba was measured from userprocess to user process.andP;  If the extra overhead of context switches fromkernel to user and copying from kernel buffers to user buffers areconsidered, (to make them comparable to the Amoeba numbers), the x-kernelperformance figures would be reduced to 2.3 msec for the null RPC with athroughput of 748 kbytes/sec when mapping incoming data from kernel to userand 575 kbytes/sec when copying it (L.andP;  Peterson, private communication).andM;Similarly, the published Sprite figures are also kernel-to-kernel.andP;  Spritedoes not support RPC at the user level, but a close equivalent is the time ittakes to send a null message from one user process to another and get areply, which is 4.3 msec.andP;  The user-to-user bandwidth is 170 kbytes/sec [34].andM;V uses a clever technique to improve the performance for short RPCs: theentire message is put in the CPU registers by the user process and taken outby the kernel for transmission.andP;  Since the 68020 processor has eight 4-bytedata registers, up to 32 bytes can be transferred this way.andM;Topas RPC was obtained on Fireflies, which are VAX-based multiprocessors.andO;The performance obtained in Figure 6 can only be obtained using several CPUsat each end.andP;  When only a single CPU is used at each end, the null RPC timeincreases to 4.8 msec and the throughput drops to 313 kbytes/sec.andM;The null RPC time for Mach was obtained from a paper published in May 1990[19] and applies to Mach 2.5, in which the networking code is in the kernel.andO;The Mach RPC performance is worse than any of the other systems by more thana factor of 3 and is 10 times slower than Amoeba.andP;  A more recent measurementon an improved version of Mach gives an RPC time of 9.6 msec and a throughputof 250,000 bytes/sec (R.andP;  Draves, private communication).andM;Like Amoeba itself, the bullet server was designed with fast performance as amajor objective.andP;  Next we present some measurements of what has beenachieved.andP;  The measurements were made between a Sun 3/60 client talking to aremote Sun 3/60 file server equipped with a SCSI disk.andP;  Figure 7 gives theperformance of the bullet server for tests made with files of 1 Kbyte, 16Kbytes, and 1 Mbyte.andP;  In the first column the delay and bandwidth for readoperations is shown.andP;  Note that the test file will be completely in memory,and no disk access is necessary.andP;  In the second column a create and a deleteoperation together is measured.andP;  In this case, the file is written to disk.andO;Note that both the create and the delete operations involve disk requests.andM;The careful reader may have noticed that user process can pull 813 kbytes/secfrom the bullet server (from Figure 7), even though the user-to-userbandwidth is only 783 kbytes/sec (from Figure 5).andP;  The reason for thisapparent discrepancy is as follows: As far as the clients are concerned, thebullet server is just a black box.andP;  It accepts requests and gives replies.andO;No user processes run on its machine.andP;  Under these circumstances, we decidedto move the bullet server code into the kernel, since the users could nottell the difference anyway, and protection is not an issue on a free-standingfile server with only one process.andP;  Thus the 813 kbyte/sec figure isuser-to-kernel for access to the file cache, whereas the 783 kbyte/sec one isuser-to-user, from memory-to-memory without involving any files.andP;  The pureuser-to-kernel bandwidth is certainly higher than 813 kbytes/sec, but some ofit is lost to file server overhead.andM;To compare the Amoeba results with the Sun NFS file system, we have measuredreading and creating files on a Sun 3/60 using a remote Sun 3/60 file serverwith a 16 Mbyte of memory running Sun OS 4.0.3.andP;  Since the file server hadthe same type of disk as the bullet server, the hardware configurations were,with the exception of extra memory for NFS, identical to those used tomeasure Amoeba.andP;  The measurements were made at night under a light load.andP;  Todisable local caching on the Sun 3/60 we locked the file using the Sun Unixlockf primitive while doing the read test.andP;  The timing of the read testconsisted of repeated measurement of an lseek followed by a read system call.andO;The write test consisted of consecutively executing creat, write and close.andO;(The creat has the effect of deleting the previous version of the file.)andP;  Theresults are depicted in Figure 8.andM;Observe that reading and creating 1 Mbyte files results in lower bandwidthsthan for reading and creating 16 Kbyte files.andP;  This effect is due to theBullet server's need to do more complex buffer management with large files.andO;The Bullet file server's performance for read operations is two to threetimes better than the Sun NFS file server.andP;  For create operations, the Bulletfile server has a constant overhead for producing capabilities, which givesit a relatively better performance for large files.andM;EvaluationandM;In this section we will take a critical look at Amoeba and its evolution andpoint out some aspects that we consider successful and others that weconsider less successful.andP;  In areas where Amoeba 4.0 was found wanting, wewill make improvements in Amoeba 5.0, which is currently under development.andO;The following discussion lists these improvements.andM;One area where little improvement is needed is portability.andP;  Amoeba startedout on the 680x0 CPUs, and has been easily moved to the VAX, and Intel 80386.andO;SPARC and MIPS ports are underway.andP;  The Amoeba RPC protocol has also beenimplemented as part of MINIX [25] and as such is in widespread use around theworld.andM;Objects and CapabilitiesandM;On the whole, the basic idea of an object-based system has worked well.andP;  Ithas given us a framework which makes it easy to think about the system.andP;  Whennew objects or services are proposed, we have a clear model to deal with andspecific questions to answer.andP;  In particular, for each new service, we mustdecide what objects will be supported and what operations will be permittedon these objects.andP;  The structuring technique has been valuable on manyoccasions.andM;The use of capabilities for naming and protecting objects has also been asuccess.andP;  By using cryptographically protected capabilities, we have a uniquesystem-wide fixed length name for each object, yielding a high degree oftransparency.andP;  Thus it is simple to implement a basic directory as a set of(ASCII string, capability) pairs.andP;  As a result, a directory may contain namesfor many kinds of objects, located all over the world and windows can bewritten on by any process holding the appropriate capability, no matter whereit is.andP;  We feel this model is conceptually both simpler and more flexiblethan models using remote mounting and symbolic links such as Sun's NFS.andO;Furthermore, it can be implemented just as efficiently.andM;We have no experience with capabilities on huge systems (thousands ofsimultaneous users).andP;  On one hand, with such a large system, somecapabilities are bound to leak out, compromising security.andP;  On the otherhand, capabilities provide a kind of firewall, since a compromised capabilityonly affects the security of one object.andP;  It is difficult at this point tosay whether such fine-grained protection is better or worse in practice thanmore conventional schemes for huge systems.andM;We are also satisfied with the low-level user primitives.andP;  In effect thereare only three principal system calls--get_request, put_reply, anddo_operation--each easy to understand.andP;  All communication is based on theseprimitives, which are much simpler than, for example, the socket interface inBerkeley Unix, with its myriad of system calls, parameters, and options.andM;Amoeba 5.0 will use 256-bit capabilities, rather than the 128-bitcapabilities of Amoeba 4.0.andP;  The larger Check field will be more secureagainst attack.andP;  Other security aspects will also be tightened, including theaddition of secure, encrypted communication between client and server.andP;  Also,the larger capabilities will have room for a location hint which can beexploited by the SWAN servers for locating objects in the wide-area network.andO;Third, all the fields of the new 256-bit capability will be aligned at 32-bitboundaries, which potentially may give better performance.andM;Remote Procedure CallandM;For the most part, RPC communication is satisfactory, but sometimes it givesproblems [28].andP;  In particular, RPC is inherently master-slave andpoint-to-point.andP;  Sometimes both of these issues lead to problems.andP;  In a UNIXpipeline, such as:andM;pic file | eqn | tbl | troff andgt;outfileandM;for example, there is no inherent master-slave relationship, and it is not atall obvious if data movement between the elements of the pipeline should beread driven or write driven.andM;In Amoeba 4.0, when an RPC transfers a long message it is actually sent as asequence of packets, each of which is individually acknowledged at the driverlevel (stop-and-wait protocol).andP;  Although this scheme is simple, it slows thesystem down.andP;  In Amoeba 5.0 we will only acknowledge whole messages, whichwill allow us to achieve higher bandwidths than shown in Figure 5.andM;Because RPC is inherently point-to-point, problems arise in parallelapplications like the traveling salesman problem.andP;  When a process discovers apath that is better than the best known current path, what it really wants todo is send a multicast message to a large number of processes to inform allof them immediately.andP;  At present this is impossible, and must either besimulated with multiple RPCs or finessed.andM;Amoeba 5.0 will fully support group communication using multicast.andP;  A messagesent to a group will be delivered to all members, or to none at all.andP;  Ahigher-level protocol has been devised to implement 100% reliablemulticasting on unreliable networks at essentially the same price as RPC (twomessages per reliable broadcast).andP;  This protocol is described in [12].andP;  Thereare many applications (e.g., replicated databases of various kinds) which aresimplified by reliable broadcasting.andP;  Amoeba 5.0 will use this replicationfacility to support fault tolerance.andM;Although not every LAN supports broadcasting and multicasting in hardware,when it has this capability (e.g., Ethernet), it can provide an enormousperformance gain for many applications.andP;  For example, a simple way to updatea replicated database is to send a reliable multicast to all the machinesholding copies of the database.andP;  This idea is obvious and we should haverealized it earlier and put it in from the start.andM;Although it has long since been corrected, we made a truly dreadful decisionin having asynchronous RPC in Amoeba 2.0.andP;  In that system the sendertransmitted a message to the receiver and then continued executing.andP;  When thereply came in, the sender was interrupted.andP;  This scheme allowed considerableparallelism, but it was impossible to program correctly.andP;  Our advice tofuture designers is to avoid asynchornous messages like the plague.andM;Memory and ProcessandM;ManagementandM;Probably the worst mistake in the design of Amoeba 4.0 process managementmechanisms was the decision to have threads run to completion, that is, notbe preemptable.andP;  The idea was that once a thread started using some criticaltable, it would not be interrupted by another thread in the same processuntil it logically blocked.andP;  This scheme seemed simple to understand, and itwas certainly easy to program.andM;Problems arose because programmers did not have a very good concept of when aprocess blocked.andP;  For example, to debug some code in a critical region, aprogrammer might add some print statements in the middle of the criticalregion code.andP;  These print statements might call library procedures thatperformed RPCs with a remote terminal server.andP;  While blocked waiting for theacknowledgement, a thread could be interrupted, and another thread couldaccess the critical region, wreaking havoc.andP;  Thus the sanctity of thecritical region could be destroyed by putting in print statements.andP;  Needlessto say, this property was very confusing to naive programmers.andM;The run-to-completion semantics of thread scheduling in Amoeba 4.0 alsoprevents a multiprocessor implementation from exploiting parallelism andshared memory by allocating different threads in one process to differentprocessors.andP;  Amoeba 5.0 threads will be able to run in parallel.andP;  No promisesare made by the scheduler about allowing a thread to run until it blocksbefore another thread is scheduled.andP;  Threads sharing resources mustexplicitly synchronize using semaphores or mutexes.andM;Another problem concerns the lack of timeouts on the duration of remoteoperations.andP;  When the memory server is starting up a process, it uses thecapabilities in the process descriptor to download the code and data.andP;  It isperfectly legal for these capabilities to be for somebody's private fileserver, rather than for the bullet server.andP;  However, if this server ismalicious and simply does not respond at all, a thread in the memory serverwill just hang forever.andP;  We probably should have included service time-outs,although doing so would introduce race conditions.andM;Finally, Amoeba does not support virtual memory.andP;  It has been our workingassumption that memory is becoming so cheap that the saving derived fromusing virtual memory with its added complexity is not worthwhile.andP;  Mostworkstations have at least 4M RAM these days, and will have 32M within acouple of years.andP;  Simplicity of design and implementation and high speed havealways been our goals, so we really have not yet decided whether to implementvirtual memory in Amoeba 5.0.andM;In a similar vein, we do not support process migration at present, eventhough the mechanisms needed for supporting it already exist.andP;  Whetherprocess migration for load balancing is an essential feature or just anotherfrill is still under discussion.andM;File SystemandM;One area of the system which we think has been eminently successful is thedesign of the file server and directory server.andP;  We have separated it intotwo distinct parts: the bullet server, which just handles storage, and thedirectory server, which handles naming and protection.andP;  The bullet serverdesign allows it to be extremely fast, while the directory server designgives a flexible protection scheme and also supports file replication in asimple and easy-to-understand way.andP;  The key element here is the fact thatfiles are immutable, so they can be replicated at will, and copiesregenerated if necessary.andM;The entire replication process takes place in the background (lazyreplication), and is entirely automatic, not bothering the user at all.andP;  Weregard the file system as the most innovative part of the Amoeba 4.0 design,combining high performance with reliability, robustness, and ease of use.andM;An issue that we are becoming interested in is how one could handle databasesin this environment.andP;  We envision an Amoeba-based database system that wouldhave a very large memory for an essentially &quot;in-core&quot; database.andP;  Updateswould be done in memory.andP;  The only function of the disk would be to makecheckpoints periodically.andP;  In this way, the immutability of files would notpose any problems.andM;A problem that has not arisen yet, but might arise if Amoeba were scaled tothousands of users, is caused by the splitting of the directory server andfile server.andP;  Creating a file and then entering its capability into adirectory are two separate operations.andP;  If the client should crash betweenthem, the file exists but is inaccessible.andP;  Our current strategy is to havethe directory server access each file it knows about once every k days, andhave the bullet server automatically garbage collect all files not accessedby anyone in n days (n andgt;andgt; k).andP;  With our current setup and reliable hardware,this is not a problem, but in a huge, international Amoeba system it mightbecome one.andM;InternetworkingandM;We are also pleased with the way wide-area networking has been handled, usingserver agents, client agents, and the SWAN.andP;  In particular, the fact that theexistence of wide-area networking does not affect the protocols orperformance of local RPCs at all is crucial.andP;  Many other designs (e.g.,andO;TCP/IP, OSI) start out with the wide-area case, and then use this locally aswell.andP;  This choice results in significantly lower performance on a LAN thanthe Amoeba design, and no better performance over wide-area networks.andM;One configuration that was not adequately dealt with in Amoeba 4.0 is asystem consisting of a large number of local area networks interconnected bymany bridges and gateways.andP;  Although Amoeba 4.0 works on these systems, itsperformance is poor, partly due to the way port location and message handlingis done.andP;  In Amoeba 5.0, we have designed and implemented a completely newlow-level protocol called the Fast Local Internet Protocol (FLIP), that willgreatly improve the performance in complex internets.andP;  Among other features,entire messages will be acknowledged instead of individual packets, greatlyreducing the number of interrupts that must be processed.andP;  Port location isalso done more efficiently, and a single server agent can now listen to anarbitrary number of ports, enormously reducing the number of quiescent serveragents required in the gateways for large systems.andM;One unexpected problem that we had was the poor quality of the wide-areanetworks that we had to use, especially the public X.25 ones.andP;  Also, toaccess some machines we often had to traverse multiple networks, each withtheir own problems and idiosyncracies.andP;  Our only insight to futureresearchers is not to blindly assume that public wide-area networks willactually function correctly until this has been experimentally verified.andM;Unix EmulationandM;The Amoeba 4.0 Unix emulation consists of a library and a session server.andP;  Itwas written with the goal of getting most of the Unix software to workwithout having to expend much effort on our part.andP;  The price we pay for thisapproach is that we will never be able to provide 100% compatibility.andP;  Forexample in a capability-based system, it is very difficult to get the wholeconcept of user-ids and group-ids right.andP;  Our view of protection is totallydifferent.andM;Furthermore, Amoeba is essentially a stateless system.andP;  This means that it isvirtually impossible to get right the various subtle properties of Unixrelating to how files are shared between parent and child.andP;  In practice wecan live with this, but for someone who demands binary compatibility, ourapproach has some shortcomings.andM;Parallel ApplicationsandM;Although Amoeba was originally conceived as a system for distributedcomputing, the existence of the processor pool with dozens of CPUs closetogether has made it quite suitable for parallel computing as well.andP;  That is,we have become much more interested in using the processor pool to achievelarge speedups on a single problem.andP;  To program these parallel applications,we are currently engaged in implementing a language called Orca [4].andM;Orca is based on the concept of globally shared objects.andP;  Programmers candefine operations on shared objects, and the compiler and run-time systemtake care of all the details of making sure they are carried out correctly.andO;This scheme gives the programmer the ability to atomically read and writeshared objects that are physically distributed among a collection of machineswithout having to deal with any of the complexity of the physicaldistribution.andP;  All the details of the physical distribution are completelyhidden from the programmer.andP;  Initial results indicate that close to linearspeedup can be achieved on some problems involving branch and bound,successive overrelaxation, and graph algorithms.andP;  for example, we have redonethe traveling salesman problem in Orca and achieved a ten-fold speedup with10 processors (compared to 7.5 using the non-Orca version described earlier).andO;Alphabeta search in Orca achieves a factor of six speedup with 10 processors(compared to four without Orca).andP;  It appears that using Orca reduces thecommunication overhead, but it remains true that for problems with manyprocesses and a high interaction rate (i.e., small grain size), there willalways be a problem.andM;PerformanceandM;Performance, in general, has been a major success story.andP;  The minimum RPCtime for Amoeba is 1.1 msec between two user-space processes on Sun 3/60s,and interprocess throughput is over 800 kbytes/sec.andP;  The file system lets usread and write files at about the same rate.andM;User InterfaceandM;Amoeba originally had a homebrew window system.andP;  It was faster than X-windowsand, in our view, cleaner.andP;  It was also much smaller and easier tounderstand.andP;  For these reasons we thought it would be easy to get people toaccept it.andP;  We were wrong.andP;  Technical factors sometimes play second fiddle topolitical and marketing ones.andP;  We have abandoned our window server andswitched to X windows.andM;SecurityandM;An intruder capable of tapping the network on which Amoeba runs can discovercapabilities and do considerable damage.andP;  In a production environment someform of link encryption is needed to guarantee better security.andP;  Althoughsome thought has been given to a security mechanism [26] it was notimplemented in Amoeba 4.0.andM;Two potential security systems have been designed for Amoeba 5.0.andP;  The firstversion can only be used in friendly environments where the network andoperating system kernels can be assumed secure.andP;  This version uses one-wayciphers and, with caching of argument/result pairs, can be made to runvirtually as fast as the current Amoeba.andP;  The other version makes noassumptions about the security of the underlying network or the operatingsystem.andP;  Like MIT's Kerberos [23] it uses a trusted authentication server forkey establishment and encrypts all network traffic.andM;We hope to install both versions and investigate the effects on performanceof the system.andP;  We are researching the problems of authentication in verylarge systems spanning multiple organizations and national boundaries.andM;Comparison With OtherandM;SystemsandM;Amoeba is not the only distributed system in the world.andP;  Other well-knownones include Mach [1], Chorus [21], V[6], and Sprite [18].andP;  Although acomprehensive comparison of Amoeba with these would no doubt be veryinteresting, it is beyond the scope of this article.andP;  Nevertheless, we wouldlike to make a few general remarks.andM;The main goal of the Amoeba project differs somewhat from the goals of mostof the other systems.andP;  It was our intention to develop a new operating sytemfrom scratch, using the best ideas currently available, without regard forbackward compatibility with systems designed 20 years ago.andP;  In particular,while we have written a library and server that provide enough Unixcompatibility that over 100 Unix utilities runo n Amoeba (afer relinking witha special library), total compatibility has never been a goal.andP;  Although froma marketing standpoint, not aiming for complete compatibility with the latestversion of Unix may scre off potential customers with large existing softwarebases, from a research point of view, having the freedom to selectively usethe good ideas from Unix and reject the bad ones is a plus.andP;  Some othersystems take a different viewpoint.andM;Another difference between Amoeba and other sytsems is our emphasis on Amoebaas a distributed system.andP;  It was intended from the start to run on a largenumber of machines.andP;  One comparison with Mach is instructive on this point.andO;Mach uses a clever optimization to pass messages between processes running ondifferent machines.andP;  That page containing the message is mapped from thesender's address space to the receiver's address space, thus avoidingcopying.andP;  Amoeba does not do this because we consider the key issue in adistributed system to be the communication speed between process running ondifferent machines.andP;  That is the normal case.andP;  Only rarely will two processeshappen to be on the same physical processor in a true distributed system,especially if there are hundreds of processors; therefore we have put a lotof effort into optimizing the distributed case, not the local case.andP;  This isclearly a philosophical difference.andM;ConclusionandM;The Amoeba project has clearly demonstrated that it is possible to build anefficient, high-performance distributed operating system on current hardware.andO;The object-based nature of the system, and hte use of capabilities provide aunifying theme that holds the various pieces together.andP;  By making the kernelas small as possible, most of the key features are implemented as userprocesses, which means that the system can evolve gradually as needs changenad we learn more about distributed computing.andM;Amoeba has been operating satisfactorily for several years now, both locallyand to a limited extent over a wide-area network.andP;  Its design is clean andits performance is excellent.andP;  By and large we are satisfied with theresults.andP;  Nevertheless, no operating system is ever finished, so we arecontinually working to improve it.andP;  Amoeba is now available.andP;  For informationon how to obtain it, please contact Tanenbaum, preferably by electronic mailat AST@CS.VU.NL.andM;ReferencesandM;[1] Accetta, M., Baron, R., Bolosky, W., Golub, D., Rashid, R., Tevanian, A.,andO;and Young, M. Mach: A new kernel foundation for Unix Development.andP;  InProceedings of the Summer Usenix Conference (Atlanta, GA, July 1986).andM;[2] Baalbergen, E.H., Verstoep, K., and Tanenbaum, A.S.andP;  On the design of theAmoeba configuratoin manager.andP;  In Proceedings of the 2d InternationalWorkshop on Software Configuration Management ACM, N.Y., (1989).andM;[3] Bal, H.E., Van Renesse, R., and Tanenbaum, A.S.andP;  Implementing distributedalgorithms using remote procedure call.andP;  In Proceedings of the NationalComputer Conference, AFIPS (1987), pp.andP;  499-505.andM;[4] Bal, H.E., and Tanenbaum, A.S.andP;  Distributed programming with shared data.andO;IEEE Conference on Computer Languages, IEEE (1988), pp.andP;  82-91.andM;[5] Birrell, A.D., and Nelson, N.J.andP;  Implementing remote procedure calls.andO;ACM Trans.andP;  Comput.andP;  Syst.andP;  2 (Feb.andP;  1984), 39-59.andM;[6] Cheriton, D.R.andP;  The V distributed system.andP;  Commun.andP;  ACM 31 (March 1988),314-333.andM;[7] Dalal, Y.K.andP;  Broadcast protocols in packet switched computer networks.andO;Ph.D.andP;  dissertation, Stanford Univ., 1977.andM;[8] Dennis, J., and Van Horn, E. Programming semantics for multiprogrammedcomputation.andP;  Commun.andP;  ACM 9 (March 1966), 143-155.andM;[9] Evans, A., Kantrowitz, W., and Weiss, E.andP;  A user authentication schemenot requiring secrecy in the computer.andP;  Commun.andP;  ACM 17 (Aug.andP;  1974),437-442.andM;[10] Feldman, S.I.andP;  Make--A program for maintaining computer programs.andO;Software--Practice and Experience 9 (April 1979), 25-265.andM;[11] Johnsn, S.C.andP;  Yacc--yet another compiler compiler.andP;  Bell Labs Tech.andO;Rep., Bell Labs, Murray Hill, N.J., 1978.andM;[12] Kaashoek, M.F., Tanembaum, A.S., Flynn Hummel, S., and Bal, H.E.andP;  Anefficient reliable broadcast protocol.andP;  Oper.andP;  Syst.andP;  Rev.andP;  23 (Oct 1989),5-19.andM;[13] Lawler, E.L., and Wood, D.E.andP;  Branch and bound MEthods A Survery.andP;  Oper.andO;Res.andP;  14 (July 1966), 699-719.andM;[14] Marsland, T.A., and Campbell, M.andP;  Parallel search of strongly orderedgame trees.andP;  Comput.andP;  Surv.andP;  14 (Dec.andP;  1982),.andP;  533-551.andM;[15] Mullender, S.J., and Tanenbaum, A.S.andP;  A distributed file service basedon optimistic concurrency control.andP;  In Proceedings of the Tenth SymposiumOperating System Principles (Dec.andP;  1985), pp.andP;  51-62.andM;[16] Mullender, S.J., and Tanenbaum, A.S.andP;  The design of a capability-baseddistributed operating system.andP;  Comput.andP;  J. 29 (Aug.andP;  1986), 289-299.andM;[17]  Mullender, S.J., van Rossum, G., Tanenbaum, A.S., van Renesse, R.,andO;vanStaveren, J.M.andP;  Amoeba--A distributed operating system for the 1990s.andO;IEEE Comput.andP;  23 (May 1990), 44-53.andM;[18] Ousterhout, J.K., Cherenson, A.R., Douglis, F., Nelson, M.N., and Welch,B.B.andP;  The sprite network operating system.andP;  IEEE Comput.andP;  21 (Feb.andP;  1988),23-26.andM;[19] Peterson, L., Hutchinson, N., O'Malley, S., and Rao, H.andP;  The x-kernel: aplatform for accessing Internet resources.andP;  IEEE Comput.andP;  23 (May 1990),23-33.andM;[20] Pu, C., Noe, J.D., Proudfoot, A.andP;  Regeneration of replicated objects: atechnique and its Eden implementation.andP;  In Proceedings of the 2ndInternational Conference on Data Engineering (Feb.andP;  1986), pp.andP;  175-187.andM;[21] Rozier, M., Abrossimov, V., Armand, F., Boule, I., Gien, M., Guillemont,M., Hermann, F., Kaiser, C., Langlois, S., Leonard, P., and Neuhauser, W.andO;CHORUS distributed operating system.andP;  Comput.andP;  Syst.andP;  1 (Fall 1988), 299-328.andM;[22] Schroeder, M.D., and, burrows, M. Performance of the firefly RPC.andP;  InProceedings of the Twelfth ACM Symposium of Operating System Principles, ACM,N.Y.andP;  (Dec.andP;  1989), 83-90.andM;[23] Steiner, J.G., Neuman, C., and Schiller, J.I.andP;  Kerberos AnAuthentication Service for Open Network Systems.andP;  In Proceedings of theUsenix Winter Conference, USENIX Assoc.andP;  (1988), pp.andP;  191-201.andM;[24] Stonebraker, M.andP;  Operating system support for database management.andO;Commun.andP;  ACM 24 (July 1981) 412-418.andM;[25] Tanenbaum, A.S.andP;  A Unix clone with source code for operating systemscourses.andP;  Oper.andP;  Syst.andP;  Rev.andP;  21 (Jan.andP;  1987), 20-29.andM;[26] Tanenbaum, A.S., Mullender, S.J., and Van Renesse, R.andP;  Using sparsecapabilities in a distributed operating system.andP;  In Proceedings of the SixthInternational Conference on Distributed Computer Systems, IEEE (1986),558-563.andM;[27] Tanenbaum, A.S., and Van Renesse, R. Distributed operating systems.andO;Comput.andP;  Surv.andP;  17 (Dec.andP;  1985), 419-470.andM;[28] Tanenbaum, A.S., and Van Renesse, R. A critique of the remote procedurecall paradigm.andP;  In Proceedings of Euteco '88 (1988), pp.andP;  775-783.andM;[29] Van Renesse, R., Tanenbaum, A.S., Van Staveren, H., and Hall, J.andO;Connecting RPC-based distributed systems using wide-area networks.andP;  InProceedings of the Seventh International Conference on Distributed ComputingSystems, IEEE (1987), pp.andP;  28-34.andM;[30] Van Renesse, R. Tanenbaum, A.S., and Wilschut, A.andP;  The design of ahigh-performance file server.andP;  In Proceedings of the Ninth InternationalConference on Distributed Computer Systems, IEEE (1989), pp.andP;  22-27.andM;[31] Van Renesse, R., Van Staveren, H., and Tanenbaum, A.S.andP;  Performance ofthe world's fastest distributed operating system.andP;  Oper.andP;  Syst.andP;  Rev.andP;  22(Oct.andP;  1988), 25-34.andM;[32] Van Renesse, R., Van Staveren, H., and Tanenbaum, A.S.andP;  Performance ofthe Amoeba-distributed operating system.andP;  Software--Practice and Experience19 (March 1989) 223-234.andM;[33] Van Rossum, G. AIL--A class-oriented stub generator for Amoeba.andP;  InProceedings of the Workshop on Experience with Distributed Systems, J.andO;Nehmer, Ed., Springer Verlag, N.Y., 1990.andP;  To be published.andM;[34] Welch, B.B.andP;  and Ousterhout, J.K.andP;  Pseudo devices: User-level extensionsto the Sprite file system.andP;  In Proceedings of Summer USENIX Conference (June1988), pp.andP;  37-49.andM;ANDREW S. TANENBAUM is the principal architect of three operatingsystems--TSS-11, MINIX, and Amoeba, as well as the chief designer of theAmsterdam Compiler Kit.andP;  He is currently a professor of computer science atthe Vrije Universiteit in Amsterdam where he does research in the areas ofoperating systems, networks, and distributed systems.andP;  He is also the authorof 3 widely used textbooks and over 60 published papers.andM;ROBBERT van RENESSE is a researcher in the computer science department at theVrije Universiteit as well as a fellow of the Royal Dutch Academy ofSciences.andP;  He is presently working on management of distributed systems toimprove their robustness, performance, and scalability.andM;HANS van STAVEREN is one of the implementors of the Amoeba-distributedoperating systems.andP;  His primary research interests include network protocolsand kernel efficiency.andM;GREGORY J. SHARP has spent the past five years working on the Amoeba project,first developing a window system, then its kernel and file system.andP;  Hisresearch interests include operating systems and user interfaces.andM;SAPE J. MULLENDER heads the distributed systems and computer networksresearch group at the Centrum voor Wiskunde en Informatica.andP;  He is also oneof the designers of the Amoeba-distributed operating system.andP;  Mullender'sresearch interests include high performance distributed computing and thedesign of scalable fault-tolerant services.andM;JACK JANSEN joined the distributed systems group at CWI in 1985 afterteaching computer science for several years.andP;  His professional interestsinclude kernel programming and process management.andM;GUIDO van ROSSUM joined the Amoeba project three years ago, creating its RPCinterface specification language (AIL), its Unix emulation facility (Ajax),and worked on system integration and user interface issues.andP;  His currentresearch topics include prototyping languages and user interfaces for powerusers.andO;</TEXT></DOC>