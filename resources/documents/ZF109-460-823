<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF109-460-823  </DOCNO><DOCID>09 460 823.andM;</DOCID><JOURNAL>Software Magazine  Sept 1990 v10 n11 p69(5)* Full Text COPYRIGHT Sentry Publishing Company Inc. 1990.andM;</JOURNAL><TITLE>To get to distributed, go past communications: worlds of datamanagement, communication collide around client/serverdistribution.andO;</TITLE><AUTHOR>Rich, Mary L.andM;</AUTHOR><SUMMARY>Data management and communications are merging as a result of themove toward client/server architectures and distributed databases.andO;Database and communications professionals must try to betterunderstand each other's needs.andP;  Effective client/server solutionsare based on a solid, robust database engine, network technologiesand operating systems.andP;  Analysts claim, however, that softwarerequired for implementing the architectures has not yet beendelivered.andP;  Network technology needs improvements offered by FiberDistributed Data Interface (FDDI) and other such enhancements;also required are intelligent optimization and solutions to theproblem of heterogeneous data.andP;  Products supporting distributeddata are described from JYACC and XDB.andP;  The two methods used indistributed systems to maintain updates are referential integrityand two-phase commit; each is described.andM;</SUMMARY><DESCRIPT>Topic:     Client/Server ArchitectureDistributed Data BasesData Base Management SystemsEnhancementsSoftware PublishersUser NeedsProgram Development ToolsApplications ProgrammingDistributed Systems.andO;Feature:   illustrationtablephotograph.andO;Caption:   Representative client/server DBMS tools. (table)andM;</DESCRIPT><TEXT>TO GET TO DISTRIBUTED, GO PAST COMMUNICATIONSandM;The move to client/server architecture and distributed database is causing acollision between the worlds of data management and communications.andM;This requires professionals in the database and communication software campsto try to understand more about each other's needs.andM;The client/server platform can serve as the base for a distributed databasestrategy.andP;  Effective solutions are based on a solid, robust database engine.andO;However, other technologies, such as the network and the operating system,are equally important.andM;The price/performance advantages of micro-based servers and workstations arepushing the evolution.andP;  However, much of the software needed to run in thisemerging architecture is on the drawing board.andM;TECHNOLOGY STILL IMMATUREandM;According to Dwayne Walker, SQL server product manager at Microsoft Corp.,andO;Redmond, Wash., three areas require technological advances.andM;Network technology needs the next level of improvements, including moving toFDDI (Fiber Distributed Data Interface) for more horsepower and achievingbetter fault tolerance in the network.andP;  &quot;If a user is going to have datathat's not all stored in a single machine but all across a network, he wantsthat network to have optimum uptime when distributing data, especiallygeographically,&quot; Walker said.andM;Intelligent optimization is the second area requiring technologicaladvancements, and the third is the problem of heterogeneous data.andM;In addition, many organizations are just beginning to get a handle on whatdata they do have.andP;  There is not a clear migration path to distribution, andfew front-end tools to assist in the process.andP;  Numerous questions remain incritical areas such as standards, security and integrity.andM;In a distributed relational system, a query or update usually requires datafrom multiple tables physically located on one or many machines.andP;  Withoutoptimization, the path accessed by the join is highly dependent on the orderin which the SQL Select statements are written.andM;Query optimization for a single database can use database statistics andother information to optimize the order and the path of the join within thedatabase.andP;  As database are distributed, the need for global queryoptimization across databases and across networks becomes imperative.andO;Without this, data is retrieved from wherever it is stored and returned tothe requestor machine for the join and processing.andM;However, a request from a workstation may need to join 10,000 records fromthe server to one million records in a table on the mainframe to obtain asimple average.andP;  Under the concept that the data is returned to therequestor, a system would try to download one million records for processingon the PC.andM;XDB Systems, Inc. of College Park, Md., has implemented a query optimizerthat uses multilevel indexes for search, sort and join operations.andM;XDB President S. Bing Yao has worked with query optimizztion for many yearsas a researcher and college professor.andP;  He noted, &quot;The performance of adistributed database system is critically dependent on the ability of thequery optimization algorithm to derive efficient query processingstrategies.&quot;andM;The next step in query optimization is to build in intelligence using aknowledge base or other advanced technique.andP;  But the ultimate goal of anoptimizer that intelligently selects paths and chooses how it looks at dataon different nodes on the network is still in the future.andM;Most firms have built up a huge store of heterogeneous data--data stored ondifferent platforms in a variety of formats and file structures.andM;Distributed DBMSs today are primarily homogeneous and are a number of releaseaway from a true heterogeneous environment.andP;  Microsoft and Sybase, Inc.,andO;Emeryville, Calif., have announced an Open Server architecture.andP;  This open,gateway-type technology will allow SQL Servers to interface with non-SQLServers databases.andM;The two companies will build the interfaces to some other products.andP;  Forexample, Microsoft is working with Micro DecisionWare, Inc., Boulder, Colo.,andO;to build an an SQL interface to DB2 from PCs.andM;Both application development and network management tools are needed forimplementing and managing a distributed database system.andP;  Network performanceanalyzers, capacity planning aids and security tools are widely available forminis and mainframes, but they are just beginning to emerge for LANs.andM;NEED FOR FLEXIBLE TOOLSandM;Developers of applications that rely on distributed data need flexible andsophisticated front-end tools.andM;One vendor that specializes in such tools in JYACC of New York.andP;  JAM (JYACCApplication Manager) and JAM/DBI (Data Base Interface) currently support 11databases, including Oracle from Oracle Corporation, Redwood City, Calif.;andO;Ingres from Ingres Corporation, Alameda, Calif.; Sybase; SQL Server fromSybase/Microsoft; VAX SQL/Services and Rdb from Digital EquipmentCorporation, Maynard, Mass.; and XDB from XDB Systems.andM;JAM is independent of the underlying database, the supplier maintains Thus,developers are said to be able to build a JAM screen or query on oneplatform, then compile and execute it on another, without changing theunderlying code.andM;XDB also offers a set of tools for systems development and is closely linkedwith Micro Focus Cobol from Micro Focus, Inc., Palo Alto, Calif.andP;  Yaodescribed the XDB database as a &quot;DB2 clone for the PC.&quot;andM;DB2 applications written in Cobol and running under CICS can be directlyported to the XDB database, he said.andM;Yao believes today's developers face a major challenge in trying to exploitthe PC personality in their development efforts.andM;Any serious inquiry into distributed DBMS quickly leads to a discussion ofpreserving data integrity.andM;When data is highly disbursed, maintaining synchronized updates acrossmultiple databases is a challenge, even when the databases are on the samemachines.andP;  It is more difficult when there are multiple databases ondifferent machines that may be geographically disbursed.andM;Two methods are used in distributed systems to maintain updates: referentialintegrity and two-phase commit.andM;Nearly all vendors have some form of referential integrity.andP;  The supportranges from IBM relational databases, such as the OS/2 Extended EditionDatabase Manager, which has referential integrity implemented with thedatabase engine itself, to providing modules that the user has to embed inthe application program.andM;Two-phase commit, or commit/rollback, is not as widely implemented.andM;According to Murphy, planning and training made the system successful.andO;&quot;Also, you have to bring the user in early, make them see the benefits,consult them and provide adequate training and support,&quot; he said.andM;Over 2,000 people have been trained for ATS.andP;  &quot;The use of this technology nowis in decision-making,&quot; Murphy noted.andP;  &quot;Now that all kinds of data isavailable, it's almost like management training.&quot;andM;Parichay Saxena, software engineer at General Electric in Schenectady, N.Y.,andO;is working on a pilot project to develop applications for the electricalutility industry to do power studies.andP;  GE has a Sun server, networked toDOS-based PCs, and connected to a VAX cluster for data transmission viaDECnet.andP;  The PCs run a version of Sun's NFS.andP;  The Oracle DBMS runs on theserver and on the PCs.andM;To do a power study, the user would initially download data from the VAX tothe Sun server, if the data was not already on the server.andP;  Then the datacould be moved to the PC or accessed directly from the server for processing.andO;Security is not a major problem for this applicaiton because there typicallywill only be eight or 10 users.andP;  However, data integrity causes a lot ofconcern.andM;&quot;If a couple of users are trying to update the data at the same time, howwill we pick up the pieces if the network breaks down?&quot;andP;  Saxena asked.andM;Saxena said his experience with the various vendors has not always beenpleasant.andP;  Nonetheless, he is &quot;totally convinced that this is a good concept,especially from a cost/performance aspect.&quot;andP;  He does, however, advise othersto wait until the technology settles down.andM;When Resource Dynamics, a direct mail firm in Reston, Va., decided toautomate its functions in-house, its people decided to skip the mainframe andgo straight to PCs and LANs.andP;  The firm is running the Unix version of Oracleon Compaq 386/33 servers over two LANs, one an Excelan Ethernet and the otherNovell.andP;  Some data is still stored on PCs under dBase, which is joined to theOracle server for reporting.andP;  The Oracle database consumes 2.4Gb of storagespace, and is expected to double.andM;There are design in place for a ditributed database model that replicatessome data for local use.andP;  The goal is to allow the clients to manipulatetheir data, but still keep, for example, the donor's name and mailinginformation stored just once.andP;  Since many clients can own the same name, theydo not want to allow one client to change something that will affect severalothers.andM;Luigi Canali, systems manager at Resource Dynamics, created the design anddid much of the implementation himself.andP;  He depened on the front-end toolsfrom JYACC to get this system running, and will use JAM heavily in thefuture.andP;  He emphasizes that the JAM/DBI interface between SQL and the 4GLmakes accessing the data on the server very easy, and also appreciates theportability.andP;  He can develop a module on the PC under DOS, and then move itto Unix and compile with no changes.andM;Security and integrity are not big issues now, because all of the access isin-house.andP;  However, when the client system is deployed, integrity will becritical.andP;  Many updates will involve more than one server.andP;  Canali expects tohandle the integrity issues himself, because Oracle does not supporttwo-phase commit.andM;Canali's problem is to keep the system optimized.andP;  His advice is to &quot;chooseyour hardware correctly.andP;  When you deal with this much data on a smallmachine, you have to optimize everything--hardware and software.andP;  Hardware isreally the bottleneck; you need fast drives.&quot;andM;Doug Vaughan has an overall view of the growth of client/server systems asthe vice president of marketing for Marathon Systems, a consulting andservices organization in San Francisco.andP;  Marathon is a reseller forMicrosoft's SQL Server.andM;Vaughan said that their &quot;client base is starting to plan and deploydistributed processing applications.andP;  The PC has grown from a single-userproductivity tool to a platform for fairly large systems and, therefore,fairly large databases.&quot;andP;  He expects the releases of server systems scheduledover the next year to have a more open architecture.andM;One problem in going to a distributed architecture is that companies arestruggling to determine what data goes on the mainframe and what goes on adepartment LAN.andP;  They also must determine if a third tier, like a mini orAS/400, is needed.andP;  Vaughan also said that he believes that most largecompanies are concerned about security, but &quot;Sybase and the SQL Server is avery secure system.&quot;andM;Vaughan agrees that the state of the technology is one of the draw-backs towider use of cooperative and distributed systems.andP;  However, he said anotherreason is that MIS directs technology in large firms, and MIS has not boughtinto cooperative and distributed technology yet.andM;END-USER ACTIONandM;&quot;We see the action happening out in the end-user community,&quot; Vaughan said.andO;&quot;Companies that marry analysts with users to form groups to bring newtechnologies directly to the end user will gain the benefits of more flexiblesystems, increased productivity, better decision-making and moreresponsiveness to customers.&quot;andM;Vaughan said the biggest problem he faces is &quot;finding good people--peoplethat know both the mainframe and micro worlds, that can quickly pick up newtechnologies, be responsive to the user and understand business problems.andO;Project teams are more consolidated, with each person doing multiple tasksand interacting with the business environment.&quot;andM;In an environment where organizations are dealing with the globalization ofbusiness, increasing autonomy of subsidiaries and regional offices, andincreasing pressure on profitability, distributed systems become a step thatcannot be avoided.andP;  When an enterprise begins to run out of mainframehorsepower, offloading to microbased networks becomes an economicalalternative to expensive upgrades.andM;In addition, the increasing demand from users for access to timelyinformation is driving the evolution.andP;  If MIS departments are not responsiveto user needs and do not begin implementing systems that meet theirrequirements in a planned way, the users will simply do it themselves.andM;On the other hand, the state of today's technology is not supportive forlarge-scale movement toward distributed systems.andP;  Firms pioneering in thisarea have to build a lot of their own tools, interfaces, protocols andapplications.andP;  It is difficult to architect a system so that private code canbe uncoupled from the application and the vendor's code incorporated when itbecomes available.andM;Many unanswered questions remain.andP;  Walker cited an example of backing up adistributed database and asked, &quot;How do you intelligently do the backup?andP;  Doyou back up off of each machine onto local devices?andP;  Or do you bring it alltogether and then back it up?&quot;andP;  For example, if you back up locally at thesame time every day, your distributed databases could get out of sync,especially if your locations are in different time zones.andP;  &quot;This type ofadministration issue is one of the tough ones.&quot;andM;The immature technology should not prevent planning and developing pilotprojects so as to be positioned to take full advantage of this technology asit becomes available.andP;  As with any new technological development, it alwayshelps to have a blueprint of where the enterprise is headed and what thetechnology can do for it.andP;  This should not be just an exercise.andP;  To besuccessful, it should provide a benefit to the company, however that benefitis measured.andM;The trend toward distributed systems is a continuation of what has beenhappening over the last 25 years.andP;  Mainframe were the only choice in the1960s.andP;  The '70s saw the introduction of minicomputers and the beginning ofthe dispersal of function.andP;  PCs came into their own in the '80s, furtherdispersing function and data, but in a totally nonintegrated form.andP;  Now, the'90s are an opportunity to built truly distributed and integrated systems.andM;Rich is president of PFS, Inc., El Segundo, Calif., a consulting firmspecializing in the design and deployment of end-user-oriented databasesystems.andO;</TEXT></DOC>