<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-339-809  </DOCNO><DOCID>07 339 809.andM;</DOCID><JOURNAL>PC-Computing  March 1989 v2 n3 p64(10)* Full Text COPYRIGHT Ziff-Davis Publishing Co. 1989.andM;</JOURNAL><TITLE>Whatever happened to AI? (artificial intelligence)</TITLE><AUTHOR>Shipley, Chris.andM;</AUTHOR><SUMMARY>Artificial intelligence began to be recognized at a conference ofeducators, mathematicians, electronic engineers and doctors atDartmouth College in 1956.andP;  In more than three decades thetechnology has proliferated, although not to the ends envisionedby its detractors.andP;  The term artificial intelligence becameassociated with images of computers smarter than human beings.andO;Instead, artificial intelligence programs simply lay out a database of limitations from which conclusions can be drawn.andP;  Theseconclusions must still be verified by human minds.andP;  Commercial AIproducts began to proliferate in the early 1980's as hardwarebecome powerful to absorb and process the amounts of datarequired.andP;  The focus began to shift away from the technology intospecific solutions in which AI is transparent to the user.andP;  Thesesystems put the experiences of humans into a problem solvingelectronic tool.andM;</SUMMARY><DESCRIPT>Topic:     Artificial intelligenceExpert SystemsHistory of ComputingUser BehaviorIndustry AnalysisProduct Development.andO;Feature:   illustrationtablephotograph.andO;Caption:   AI Milestones (1947-1990). (table)AI dictionary. (table)andM;</DESCRIPT><TEXT>Whatever Happened to AI?andM;&quot;I Thought Oz was a great Head,&quot; said Dorothy.andP;  &quot;And I thought Oz was alovely Lady,&quot; said the Scarecrow.andP;  &quot;And I thought Oz was a terrible Beast,&quot;said the Tin Woodman.andP;  &quot;And I thought Oz was a Ball of Fire,&quot; exlaimed theLion.andP;  &quot;No, you are all wrong,&quot; said the little man meekly....andP;  &quot;I'm just acommon man.&quot;andM;Artificial intelligence.andP;  To these words each of us brings his owndefinition.andP;  To some it is a noble science of grandiose proportions.andP;  Toothers, it's about computers gone mad.andP;  Some see it as a business venturethat bottomed out.andP;  And there are those who think of it simply as theendeavor of mild-mannered researches and lo mein-slurping programmers.andM;None of these notions, of course, speaks to the technology itself.andP;  But todiscuss the words is to remove the shroud they place over technology andreveal a pursuit with profound ambitions and modest successes, an idea moreevolutionary than revolutionary, a technology that must be remade and renamedeach time it leaves the lab and enters the marketplace.andM;What's in a Name?andM;Often, the name of a thing empowers or disenfranchises the thing itself.andO;Never in computer science has this been more true than with artificialintelligence.andP;  The academis who gathered at  Dartmouth College in 1956 todiscuss the study of computer-simulated thought did not realize what anominous tone they would bring to the field when they chose to name itartificial intelligence.andP;  Harmlessly enough, they meant these simple words toidentify the study of the nature of human thought processes, and of how thoseprocesses might be represented digitally.andM;The ambition of these scientists was to develop computers that could learnand accommodate themselves to the needs and desires of their users, computersthat could solve complex problems with blinding speed and hair-splittingaccuracy.andP;  Instead, the phrase artificial intelligence bred images ofmachines smarter than the humans who programmed them.andP;  Machines that wouldtake jobs from factory workers, clerks, secretaries, and, ultimately,professionals.andP;  Machines that would wrest control from their users and actwithout human intervention.andM;Now, more than 30 years later, AI still represents to many people a thing tobe feared rather than anticipated.andM;Artificial intelligence.andP;  The words have few, if any, positive connotations.andO;They are eerie.andP;  They have the feel of black arts and laboratory weirdness.andO;&quot;The term panders to a popular morbid curiosity of the grotesqueness andfreakiness,&quot; says Jerrold Kaplan, president and CEO of the GO Corporation andformer principal technologist at the Lotus Development Corporation, where hecoauthored Agenda, one of the few PC applications that uses programmingtricks that have come out of AI research.andM;To true believers, on the other hand, the words artificial intelligence ringof grand promises and fantastic dreams.andP;  They imbue the technology withgenius far beyond its practical achievements and bring to mind roboticcompanions that converse intelligently, protect their owners from harm, evenbrew and serve the morning coffee.andM;Of course, when the thunder dies, the smoke clears, and the screen is pulledaway, AI is none of these things.andP;  Certainly not yet and certainly not for along, long time.andM;Like the Great Wizard revealed to disillusioned believers, artificialintelligence is much simpler and much more real.andP;  And it most certainly oughtto be known by another name.andM;The View from AcademiaandM;In its purest form, artificial intelligence defines an abstract andexploratory science of human cognition--how people think and reason.andP;  Somepeople consider it one of the most important and dramatic problems tackled byscience, equal to the quests to understand the cosmos and to discover theorigin and nature of life.andP;  At its most profound, reserachers believe, theendeavor can unlock the secrets of the mind, so that no problem will remainunsolved.andM;But artificial intelligence is more than thinking about thinking.andP;  Itstheories are extrapolated to computer systems in an attempt to emulatethought and reasoning.andP;  And this is where the concept starts to get fuzzy.andO;Because artificial intelligence is an ambition more than a product, thetechnologies and methodologies that grow out of this field are not AI.andO;Instead, artificial intelligence research is leaving a trail of tools andtechniques that are enhancing the state of the art in computer applicationsdevelopment but are in no real way intelligent themselves.andP;  Or, as thewell-known adage in the AI research community goes, artificial intelligencerefers to the things we don't know how to do today.andP;  As soon as we figure outhow to do them, they won't be AI.andM;&quot;We Typically don't name fields for their aspirations,&quot; says Dr. EdwardFeigenbaum, the Stanford University computer scientist widely acknowledged asthe father of expert systems--computer programs that follow preprogrammedrules to reach likely solutions to specific problems.andP;  &quot;As problems movedthrough AI and into commercialization, they became renamed.andP;  AI becomes thehome of the unsolved problem, the home of the no-win guys,&quot; Feigenbaum says.andM;The point may seem simple, but it is absolutely essential to understandingthe misunderstanding, disillusionment, and initial failure of commercial AI.andM;The Commercialization of AIandM;In the early 1980s, several technologies and ideas converged to spark the AIboom.andP;  Inferencing techniques (used by programs to draw conclusions) andstructures for knowledge bases (the part of a program that contains facts,assumptions, and rules about a particular problem) had developed to a pointwhere compact and specific expert systems were commercially viable products.andO;Modest successes in natural-language processing sparked promises ofapplications that would accept simple English-language commands rather thancryptic computer instructions.andP;  High-performance workstations optimized forLISP--a language developed and used by AI researchers--were less expensiveand more widely available.andP;  These fruits of AI research piqued the interestof corporations that hoped to use the new technologies for competitive gain.andO;And the researchers and scientists themselves saw an opportunity tocapitalize on their work.andM;And so a frenzy stirred up around these words and ideas.andP;  Convinced theirtechnologies were good, AI researchers established companies and started tosell AI on its own merits.andP;  More accurately, they sold expert systemdevelopment tools that were tied to application-specific workstations, oftenwithout regard to practical, corporate-minded applications.andM;Harvey Newquist, publisher of the AI Trends newsletter, tells the story of acompany that demonstrated its expert system technology to prospectivecorporate customers by showing a wine adviser.andP;  The program helped a userselect the proper wine to accompany a particular meal.andM;&quot;they were so far from the real world to assume this demo would show thevalidity of their technology,&quot; Newquist says.andP;  &quot;They didn't show how thiswould help a corporate MIS department or improve productivity on the factoryfloor.andM;&quot;There was an egotism in this business that they could sell this to corporateAmerica because they had a product they believed would change the world.andO;There is a practical use for this technology.andP;  It can be used specifically toenhance the way things are done, but you cannot sell AI as a panacea.&quot;andM;Researchers were not the only ones hawking AI.andP;  By the mid-1980s, vendorswere pedding PC software by virtue of its &quot;artificial intelligence.&quot;andP;  Themarket saw decision support systems, statistical software, even wordprocessors, all stamped (New and improved, with AI added.&quot;andP;  And whileartificial intelligence made for fascinating technology, fascinating reading,and fascinating talk, it just wasn't a fascinating mass-market product.andO;After all, what real benefit was there to a word processor that would try tomake a guess at which word you were typing based on the first few characters,then pop up a list from which you could select the proper word?andM;That was Mind Reader, a product Business Soft hyped in 1985.andP;  And that wastypical of how applications vendors exploited the popular appeal ofartificial intelligence to sell products.andP;  It didn't take too many MindReaders for the market to become disillusioned.andP;  If this was AI, buyersfailed to see what all the fuss was about, and soon it was almost anathema tobuy any product that said &quot;AI&quot; on the package.andM;Lessons LearnedandM;Developers whose products depended on specialized hardware, those who had notenvisioned practical, real-world applications, and those who used the allureof AI to sell their wares struggled.andP;  In late 1987 and early 1988, the &quot;AImarket&quot; was at its darkest.andP;  Workstation developer LISP Machines filed forbankruptcy; Symbolics posted eight straight quarters of deficit, endingfiscal 1988 with a $46 million loss; Gold Hill Computers, a developer of LISPlanguage products, lost nearly half its staff to layoffs and resignations;Teknowledge, an expert system development company cofounded by Kaplan, cutjobs, closed area offices, and restructured its business plan.andP;  Theexperience of these companies was the rule, not the exception.andM;Yet as they began to restructure, AI companies also started to recognize therealities of the marketplace.andP;  The truth that people buy products to solveproblems--that they don't buy technologies--began to sink in.andP;  Those whocontinued to focus on expert system development products or specializedworkstations shifted their emphasis from artificial intelligence towell-defined vertical markets.andP;  And they began to retreat from the AI label.andO;From one quarterly report to the next, for example, IntelliCorp, which sellsthe KEE expert system development tools, went from calling itself an&quot;artificial intelligence company&quot; to referring to itself as a &quot;knowledgecompany.&quot;andM;Applications developers, who once hitched their products to the AI star,stopped mentioning it.andP;  Instead, they married Ai-wrought methodologies totraditional applications to build better, &quot;smarter&quot; software.andM;&quot;A lot of the pluses of AI approaches are creeping into and becoming a partof mass market products,&quot; says Larry Geisel, president and CEO of IntelligentTechnology Group (ITG), in Pittsburgh.andP;  &quot;Ultimately, that's the way thisparticular technology will find its match with the marketplace.andP;  It will bestrictly embedded.&quot;andM;The integration of traditional and AI methodologies might yieldcomputer-aided design software, for example, with an expert system thatanalyzes structures and warns of faulty design.andP;  Or it might give aspreadsheet an intelligent sublayer that watches for patterns and shiftingmarket trends.andP;  &quot;If you've got the right representation, you can do thingsthat you can't even conceive of doing in standard structured ways,&quot; says FredLuconi, chairman and CEO of Applied Expert Systems, in Cambridge,Massachusetts.andM;Lotus Agenda makes use of these ideas to give it what its developers see asan edge over other personal information managers.andP;  By using some underlyingAI methodologies, the program is able to make rudimentary associations.andP;  Youcan, for example, enter &quot;next Thursday,&quot; and Agenda recognizes that you meanMarch 16.andP;  The program is what coauthor Jerrold Kaplan calls &quot;a goodmixed-initiative system.andP;  Either the user or the program can initiateactions.&quot;andM;Kaplan believes the &quot;reintegration of AI technology into mainstream dataprocessing and applications is nearly complete,&quot; and you can bet that as newproducts with embedded intelligence make their way to market, they won't besold as AI products, but as CAD and spreadsheets and databases andinformation managers and a variety of other applications.andM;&quot;Product marketers got past the initial love affair with AI because theyrealized that it's not going to work anymore.andP;  It's not going to be brighterand whitter,&quot; says Mark Linesch, manager of third-party software productmarketing for Texas Instruments' computer systems division, which isresponsible for TI's artificial intelligence research and productdevelopment.andP;  &quot;During the hype times, just about everything that came out hada little AI in it.andP;  Now, saying whether or not it has AI isn't the point.andP;  Aproduct has to have a higher level of funtionality and offer a greaterbenefit than before.&quot;andM;ITG, for one, won't promote the &quot;AI&quot; in its products.andP;  The company developedan expert system called the Intelligent Portfolio Manager.andP;  Instead ofselling it directly to users, ITG formed a subsidiary, Intelligent InvestmentManagement, which uses the product to manage others' investments.andP;  Thesystem, Geisel says, &quot;far exceeds&quot; the average performance of the stockmarket.andM;Like other companies that are embedding artificial intelligence technologiesinto their product lines, ITG &quot;made the clear choice of not even mentioningAI, feeling that would be a negative that we would have to overcome,&quot; Geiselsays.andP;  And ITG chose not to market expert system development tools, Geiselsays, &quot;because we think it would be a losing strategy.&quot;andM;The Rise of Expert SystemsandM;While developers are shying away from the AI label, the one application areamost synonymous with AI is flourishing.andP;  Expert systems are no doubt the mostmature and resilient products to come out of the AI research community.andP;  Dr.andO;Feigenbaum began developing the first expert system at Stanford University in1965, and after 20 years of progress and experience, developers were inaunique position to respond to the marketplace in the mid-1980s.andP;  They wereable to move the technology from expensive, system-unique hardware (such asLISP workstations) to general-application machines like PCs.andM;Early adopters of the technology also realized that if they could applyexpert systems to very specific, highly valued, knowledge-intensiveapplications, these applications would return high yields.andP;  And now, much asconventional application programs showed early and measurable success whenthey were adopted, so too is the record of success building for expertsystems.andM;Feigenbaum, pursuing a &quot;parential interest&quot; in expert systems, describes thesuccess record of corporate expert systems in his new book The Rise of theExpert Company, coauthored by Pamela McCorduck and Feigenbaum's wife, H.andO;Penny Nii.andP;  (For a review, see the Books department in this issue.)andP;  Thebook, which is subtitled How Visionary Companies Are Using ArtificialIntelligence to Achieve Higher Productivity and Profits, details whatFeigenbaum describes as the first wave of applications to &quot;flow fromcorporate decisions to invest in this technology.&quot;andM;In deed, the productivity and profit gains from these systems are immense.andO;The productivity of knowledge workers--those who make decisions, analyzeinformation, or perform other &quot;non-touch&quot; tasks--typically improves by morethan a factor of ten when they use expert systems.andP;  Feigenbaum tells of anapplication that allows knowledge workers to accomplish in half a man-daywhat previously required eight man-weeks.andP;  &quot;That's a factor-of-80 improvementin productivity.andP;  It's almost two orders of magnitude, and that's thedifference between walking and jet planes.&quot;andM;In addition to making knowledge workers more efficient, expert systemsimprove the quality of their work.andP;  &quot;By putting an expert system in the handsof an average performer, you can raise average performance,&quot; Feigenbaum says.andO;Expert systems free workers from mundane tasks so that they can spend theirtime on more difficult problems or more creative endeavors.andP;  Decisions aremade consistently from worker to worker, and the know-how of top employeesand specialists can be distributed throughout the corporation.andM;Expert systems also translate directly into cost savings.andP;  An IBM diagnosticsystem saved $12 million per year (a &quot;medium-size&quot; payback, according toFeigenbaum) by avoiding misdiagnoses and the accidental disposal of goodparts.andP;  DuPont, a true believer in expert systems, spends on average $25,000to build an system that promises an initial payback of $100,000.andP;  AndAmerican Express protected itself from a $27 million loss in bad credit andfraud with a credit approval expert system that cost $4 million to build.andM;These systems are only the tip of the iceberg.andP;  Feigenbaum estimates thatsome 2,000 expert systems--&quot;power tools to the minds of knowledgeworkers&quot;--are in regular use today, and 80 percent of them are implemented onPCs.andM;Where Do We Go From Here?andM;As the expert success stories pile up and more and more applications lacedwith AI programming techniques and methodologies are passed out of researchlabs, the stigma attached to artificial intelligence will fade, but certainlythe impact of the technology will not.andM;&quot;Over the last year or two, we've begun to see the fourth wave of computing,&quot;says TI's Linesch.andP;  &quot;Computers are primarily used today for reading, writing,and arithmetic, but we'll start to see computers addressing more of theseproblems that get at the heart of company operations--to improve productivityand to improve competitiveness.andP;  The opportunities are frankly enormous.andO;Overall, there are a lot of very bright opportunities for users to get muchbetter software and much better solutions.&quot;andM;Those who have followed this field through its ups and downs foresee &quot;smart&quot;software that is more accommodating to users, software that raises the levelof what we are able to do with our computers, and computers that combinevoice and natural-language technologies in order to liberate users from theirkeyboards.andP;  &quot;I have no doubts whatsoever that this will become a deminant,important technology,&quot; declares Applied Expert Systems' Luconi.andP;  &quot;Andprobably the people who learn it then won't even think of it as artificialintelligence.&quot;andM;Still, there will always be some people who speculate about the possibilityof intelligent machines.andP;  To that Dr.andP;  Feigenbaum responds, &quot;The ultimateachievability of intelligent machines is unknown.andP;  Some philosophers believethat intelligence can't be captured, that there is something vital that acomputer cannot duplicate.andP;  But to the dyed-in-the-wool AI-ers, it is anarticle of faith that the mind is a symbol manipulator and that we should beable to capture its ability to do that.andM;&quot;But then, we're so far from that point it's not worth speculating about.&quot;andO;</TEXT></DOC>