<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-172-068  </DOCNO><DOCID>07 172 068.andM;</DOCID><JOURNAL>AI Expert  Feb 1989 v4 n2 p61(7)* Full Text COPYRIGHT Miller-Freeman 1989.andM;</JOURNAL><TITLE>Neural networks primer: Part VI. (includes related article on anavalanche simulator)</TITLE><AUTHOR>Caudill, Maureen.andM;</AUTHOR><SUMMARY>The process of modifying the outstar learning algorithm to createa network that learns temporal or time-varying sequences ofspatial patterns is discussed.andP;  The construction of outstar isdetailed and the avalanche network, its operation and purpose arealso discussed.andP;  The avalanche network offers a method ofreproducing spatiotemporal patterns of almost infinite flexibilityand the outstar can be used to learn spatiotemporal patterns.andM;</SUMMARY><DESCRIPT>Topic:     Neural NetworksTutorialNew TechniqueSoftware DesignAlgorithmsMathematics of ComputingNetwork Analysis.andO;Feature:   illustrationchart.andO;Caption:   processes involved in creating the avalanche network. (chart)andM;</DESCRIPT><TEXT>Neural Networks PRIMERandM;In the last article of this series (&quot;Neural Networks Primer, Part V,&quot; AIEXPERT, Nov. 1988, pp.andP;  57-65) we introduced a learning algorithm calledoutstar learning that exhibited characteristics of Pavlovian conditioning.andO;In this article we will see how the outstar can be modified to create anetwork that can learn temporal or time-varying sequences of spatialpatterns.andP;  Such sequences might occur, for example, in speech signals, thereplace of robotic arm motions, or in many other applications.andP;  Before webegin, however, let's recall how outstar learning works.andM;The outstar learning equations we worked through last time consisted of twodifferential equations: an activity equation and a learning equation.andP;  Thesetwo formulas taken together provide a mathematical framework that can be usedto describe the activity of each neurode in the network at any time and themanner in which the weights on the interconnections between the neurodesmodify during training.andP;  Since these are the fundamental features of interestin the network, they completely specifiy the stae of the network for ourpurposes.andP;  (In saying this, we are obviously assuming that theinterconnections of the network are stable and unchanging.andP;  This clearly isnot the case for biological systems, since neurons can and do grow newconnections to other neurons.andP;  For an artificial neural network sudh as theones we discuss here, however, we can begin with a higher degree ofinterconnectivity than we really need, then allow the learning law to reduceweights on unnecessary interconnections to near-zero.andP;  This is not asbiologically accurate as permitting changing interconnects would be, but itis generally much easier to implement than a true-to-biology model, and thismethod can still exhibit any desired level of interconnectivity.)andM;OUTSTAR ACTIVITY EQUATIONandM;The activity equation for the outstar leaning network specifies the level ofexcitement or activity of each neurode in the network at any given time.andP;  Thenetwork under considertion is shown in Figure 1; we specify the activity ofthe ith neurode in the network with the activity equation:andM;In this equation we are investigating the activation of neurode i, whichreceives inputs from the outside world (I.sub.i.(t)) and the outputs of otherneurodes in the network (the summation term).andP;  The activity of neurode i(y.sub.i.(t)) is a function of time, and the equation specifies this timedependence.andP;  The first term in the equation indicates how activit decays whenall stimuli are removed; it defines an exponential decay term.andM;The second term defines how the neurode activity will increase if an externalinput signal is applied to the neurode; in a biological experiment this mightcorespond to applying an external electrical probe to a neural cell.andP;  Sincethe external stimulus may or may not be present ( and at varying levels),this external input is time-dependent.andM;Finally, the third term specifies how the activations ( for example, outputs)of the other neurodes in the network contribute to the activity level of theith neurode.andP;  The total input to the ith neurode from the rest of the networkis the weighted sum of the inputs from the network neurodes with a thresholdvalue subracted.andP;  Only inputs greater han this threshold are permitted tocontribute to the summation--the sume contains no negative terms.andP;  Since itrequires some finite time t.sub.o for any output from neurode j to reachneurode i, the activity level involved is the activity level generated byneurode j t.sub.o time units ago.andP;  Note that nothing in this equationprohibits neurode i from contributing to the summation term, allowingfeedvack from i to itself, if we desire.andM;The constants in this equation, A and B, can be set as a parameters to thenetwork.andP;  In Part V we saw that although B can be easily set to 1.0, wenormally want the activity of the neurodes to die off very quickly when theexternal stimulus is removed.andP;  Thus we want A to be set to some fairly largevalue that should cause rapid exponential decay, where &quot;rapid&quot; is relative toother network functions.andP;  In such a network, an individual outstar wouldexhibit pulses of activity like those seen in figure 2 whenever an externalstimulus was applied.andM;OUTSTAR LEARNING EQUATIONandM;The learning equation for the outstar network is slightly simpler in format:andM;Here, as in the activity equation above w.sub.ij is the weight on theinterconnect that links the output of the jth neurode to the input of the ithneurode.andP;  Just as in the activity equation, the first term consists of anexponential decay term; however, it is not the neurode activity that isdecaying, but the value of the weight on the interconnect between twoneurodes.andP;  Since memory consists of the network weights and interconnections,and we have arbitrarily fixed the physical interconnections to some constantstate, memory in this network is really contained in the weights themselves.andO;allowing the value of the weights to decay eprmits the entwork to forget aswell as learn.andP;  Thus F is caleed the &quot;forgetting&quot; constant since it controlsthe rate at which memories are lost.andP;  The other learning term is very similarto the summation term in the activity equation.andP;  We use the product ofneurode i's current output with that of neurode j's incoming signal toprovide a Hebbian learning law, as discussed in Part V.andP;  The constant G iscalled the &quot;gain&quot; and is the learning constant.andP;  It conrols the speed atwhich the weights learn new patterns; a larger value implies faster learning,a smaller value implies slower learning.andP;  All constants in both equations aregenerally limited to the range of zero to one, and all are always positive.andM;In the outstar discussion (Part V), we pointed out that for this network, wegenerally want the decay of each neurode's activity to occur on a much fastertime scale than the decay of the weights.andP;  Therefore we stated that theconstant A, controlling the activity decay, should be to or three orders ofmagnitude larger than the constant F.andP;  This time, however, we want to setthese two constants differently and see how such an arrangement can be usedto learn patterns that change in time.andM;SIMPLE TIME-PATTERN LEARNINGandM;The outstar can be used in several ways to learn spatiotemporal patterns.andO;the simplest method consists of a single outstar neurode that feeds back toitself through several connections, as shown in Figure 3.andP;  In a biologicalneuron, a cell has a single output, called an axon, which has many branches,called collaterals.andP;  The axon can be thought of as a very long tail extendingfrom the neuron with branches off to either side.andP;  The branches end atsynaptic junctions at the input sides (dendrites) of other neurons.andM;If we set up a neurode with a similar arrangement, we can send the branchesback, not to other neurodes, but to the inputs of the outstar itself.andO;(Recall that nothing in the activity or learning equations prohibits suchfeedback.)andP;  We can suppose that some external input to the outstar causes itto become active and send a pulse of activity down the output line.andP;  Eachtime it reaches a branch where a collateral interconnect leaves the main linethe pulse is split and goes down both the main interconnect and thecollateral interconnect.andP;  The collateral interconnect leads back to the inputside of the neurode, which causes the neurode to become active and againproduce a pulse of activity.andP;  In the meantime, the original pulse continuestraveling down the main interconnect to the next branch, splits, and feedsback to the outstar's inputs.andP;  This continues with each pulse feeding back tothe input and producing other pulses of activity, until each eventually endsup at collateals that lead not to the outstar, but to the outside world.andP;  Theoutside world sees the entire collection of pulses as a time-varying patternof outputs that is the spatiotemporal pattern.andM;This scheme is relatively simple to explain, but it has some significantproblems.andP;  First, although it is easy to see how such a system could getstarted, it is less easy to see how it stops.andP;  Some level of inihibitory(negative weight) connections that damp out the pattern would have to existsomewhere along the system of branches.andP;  Further, if we had many varyingpatterns for the outstar to learn in a temporal sequence, we could probablyhave to allow signal amplification at each branch so the pulse would stayreasonably high as it travels down the axon.andM;Worse than this is the rigidity of the network.andP;  The only temporal patternthis system can learn is that defined by the locations of the collateralbranches.andP;  The outstar must be built with branches at precisely the rightlocations so the pace of the pattern changes can operate correctly.andP;  Finally,because we have only a single output, we are limited in the kinds of spatialpatterns we can represent to a single real number.andM;Spatial pattern representation can be improved somewhat by having thebranches feed back not to the outstar, but to an array of neurodes similar tothe grid neurodes in the outstar discussed in Part V.andP;  Figure 4 shows thisarrangement.andP;  Here the outstar's output still travels down the long axon,branching at selected temporal points, but the pattern we can reproduce isimporved to permit, say, the reproduction of a pixel image on the gridneurodes.andP;  As the output reaches each branch point, the pulse transmits toeach grid neurode, causing the grid to reproduce the specified pattern.andO;Since each branch point corresponds to a separate set of weights to the grid,we can get as many different patterns on the grid as we have branch points.andO;The grid can reproduce &quot;A,&quot; &quot;B,&quot; &quot;C,&quot; and so on in sequence, all as a resultof single outstar firing.andM;Even this scheme is not flexible enough for very complex patterns.andP;  Supposewe want to train a network to reproduce a pixel pattern, followed by a robotarm control movement, followed by an adjustment of a valve.andP;  The same set ofgrid neurodes would be insufficient for these different tasks in nearly anywell-designed system.andP;  Instead, we would want to have one set of gridneurodes to provide the pixel display, another to control the robot arm, andstill another to control the valve.andM;We can set up this kind of system by using the design shown in Figure 5.andO;Here, each branch point has an interneuron that branches to a completelyseparate set of grid neurodes.andP;  Each grid can be independent of all othergrids and can perform widely varying functions.andP;  Otherwise, thid design worksthe same as the previous two versions.andM;Even this scheme for learning spatiotemporal patterns has some severe flaws.andO;First, it is unclear exactly how one would build such a system for anarbitrary problem.andP;  The strong dependence these designs have on maintainingan exact distance between the interconnect branches means they are highlyinflexible in their temporal variability.andP;  And the training scheme is unclearand obscure.andP;  There must be a better way!andP;  And there is--through theavalanche network.andM;THE AVALANCHEandM;The avalanche network presents a clean, straightforward method of reproducingspatiotemporal patterns of nearly infinite flexibility.andP;  Let's see how itworks.andP;  (Im the following discussion we use a highly simplified system ofinputs, outputs, and interconnects as an example.andP;  This example shouldclarify the discussion; the avalanche network is not in any way limited tosuch a simple design.andP;  Spatiotemporal patterns are difficult to discussclearly without an animated display, which is currently unavailable in thepages of a magazine!)andM;Let's begin with a three-layered network as shown in Figure 6.andP;  We will keepthe work design very small, with the neurodes arranged as a single row ineach layer.andP;  We have 10 neurodes in each of the input and middle layers, witheach input layer neurode connecting to all middle layer neurodes.andP;  The outputlayer defines the format of our output; again for simplicity we will assume asingle kind of output grid neurode, which will reproduce a 7X10-pixel image.andO;The middle, avalanche layer is the interesting layer: let's direct ourattention to it.andM;The avalanche layer neurodes are highly interconnected to the other neurodeswithin the layer.andP;  For our network, we will assume each neurode in theavalanche layer has connections to all other neurodes in the layer.andP;  Theseconnections are modififable; they can be trained using the outstar learningequation.andP;  We will modify the activity equations of these outstars slightlyby setting the activation decay parameter, A, to a new value.andP;  Rather thanhaving the activity of the avalanche layer neurodes decay very quickly asbefore, we will set the parameter A so that the activation decays slowly.andM;Figure 7 shows how a brief external input to such an outstar would produce adistinctly different pulse of activity than we saw before.andP;  Let's assume forclarity that each avalanche-layer neurode that fires requires two timeperiods to reduce its activity below the threshold value T.andP;  Finally, we willassume that all interconnects (whether interlayer or intralayer) requireexactly one time unit to travel.andP;  We are now ready to explain the network byreviewing how a training avalanche network operates and discussing how we cantrain it to work this way.andM;THE AVALANCHE IN OPERATIONandM;Figure 8 shows how the fully-trained avalanche network would reproduce atemporal sequence of spatial patterns, namely the alphabet.andP;  Beginning at 8A,we see snapshots of the network at every tick of the clock from t=0 to t=4.andM;* Time t-0: An external input pattern, consisting of a binary pattern withonly one &quot;1&quot; bit, is presented to the network.andP;  Input neutrode 1 becomesactive, transmitting its signal to all avalanche-layer neurodes.andP;  The inputneurode's output will arrive in one time unit.andM;* Time t=1: The input pattern has arrived at the avalanche layer, causingneurode 3 in that layer to fire.andP;  Neurode 3's output is sent to the outputlayer and to neurodes 2 and 6 in the avalance layer.andP;  (Other intralayerconnections have near-zero weights and can thus be ignored.)andM;* Time t=2: Neurodes 2 and 6 receive the input signal from neurode 3.andP;  Inaddition, each sees the pattern from the input layer, which has now decayedto half-strength.andP;  Neurode 6 has weights on its inputs from the input layerand neurode 3 so it becomes active.andP;  Neurode 2 does not become active;neurode 6 fires.andP;  It sends its output toward neurodes 2 and 5 and the outputlayer.andP;  At the output layer, neurode 3's signal has been received and itcauses the letter &quot;A&quot; to be reproduced on the grid.andM;* Time t=3: Neurodes 2 and 5 receive neurode 6's input; neurode 2 also seesneurode 3's output, although that has now decayed to half strength.andP;  (Theinput pattern has decayed to below threshold by now.)andP;  Neurode 2 hassufficient stimulation to become active, so it fires and sends its output toneurodes 5 and 7 and to the output layer.andP;  Neurode 5 sees neurode 6's inputsignal, but that is insufficient (because of the weights on theinterconnects) for neurode 5 to fire.andP;  At the output layer, neurode 6'ssignal is received, and the grid neurodes reproduce &quot;B.&quot;andM;* Time t=4: Neurodes 5 and 7 receive neurode 2's output signal.andP;  Neurode 5sees the remaining half-signal from neurode 6 as well, and this combinedinput puts neurode 5 above threshold; it fires.andP;  Neurode 7 is insufficientlystimulated as yet, so it remains inactive.andP;  Neurode 5's output is sent toneurodes 7, 1, and the output layer.andP;  At the output layer, neurode 2's outputhas been received, and the grid neurodes reproduce &quot;C.&quot;andM;It should be evident by now exactly how the avalanche works.andP;  We have set theactivation decay parameter so that each output signal requires a couple oftime units to decay below threshold, and we have set the threshold such thata single incoming signal is insufficient to cause the neurode to fire.andP;  (Thefirst neurode in the sequence is an exception to this; the input pattern byitself is sufficient to cause the first neurode to become active.)andP;  This isjust the simplest case of the avalanche network; many variations andmodifications can be added to make the network behave in any mannerappropriate to the problem.andM;TRAINING THE AVALANCHEandM;Training the avalanche to perform as we have described may sound daunting,but really is quite straightforward.andP;  Let's first talk about how we get theoutput layer to reproduce the letters &quot;A,&quot; &quot;B,&quot; &quot;C,&quot; and so on.andP;  From theoutput layer neurodes' perspective, the task is exactly the same as it wasfor the gird neurodes in the outstar simulator from Part V.andP;  Whenever theysee a strong (that is, full-strength) stimulus from a specific neurode in theavalanche layer, they can be conditioned using standard outstar learningtechniques to reproduce the appropriate letter on the grid.andP;  As we saw lasttime, this works simply and well.andP;  But how about the avalance layerinterconnections?andP;  How do we get these trained?andM;If we try to make a biologically consistent model, we will have to use a moresophisticated version of the activity and learning equations; however, if weare satisfied to generate a practical, working system, we can use theequations we have and make our network slightly more complex.andP;  We need to setup a system that will monitor the response of each avalance layer neurode toeach stimulus.andP;  It must choose the neurode with the greatest activity levelat any given time and apply sufficient additional (instantaneous) stimulus tothat neurode to force it to have a +1 output.andP;  This places the neurode underthe same Hebbian learning situation as the output layer neurodes: the neurodeis forced to be active at the same time it receives a particular set ofincoming signals, which causes outstar learning to kick in and theneurode tobecome more sensitive to the incoming signals in the future (that is, theweights increase on those input synapses.)andM;In a biological system this winner-take-all effect could be achieved by alateral inhibition architecture (discussed in Part IV); in a computersimulation we need only take the MAX function at each tick of the clock andpermit only the winning neurode to output a signal.andP;  We also want to allowonly the winning neurode and the second-highest response neurode to adjusttheir weights according to the outstar learning equation; all other neurodes'weights are allowed to decay only.andP;  Notice that this implies we will take theMAX function twice at each tick of the clock--once to determine the winner,and once again on the remaining neurodes to determine the runner-up.andP;  This issimilar to the Kohonen network training mechanism described in Part IV (AIEXPERT, August, 1988, pp.andP;  61-67).andM;Allowing the runner-up and the winner to adjust their weights makes thesystem train a bit faster, but is not strictly required.andP;  This tends to biasthe avalanche, so the next winner will be the runner-up at this instant.andO;This has an elegance and simplicity about it that make it easy to understand.andO;In general, however, the winner each time could be randomly related to theprevious winner and near-winner.andP;  Also, although we used single-neurodefirings for ease and clarity of discussion, we could also make the avalanchenetwork generate a pattern of activity instead.andP;  This would make the networkmore robust (losing an avalanche-layer neurode would not destroy the recallof any given pattern) and would make the output system able to generate alarger number of spatiotemporal pattern responses without increasing the sizeof the network.andM;AVALANCHE ADVANTAGESandM;Why is the avalance so much better than the other approaches tospatiotemporal pattern learning?andP;  First, it has a realistic training method;we no longer have to build the network so that it physical suits the patternsequence it needs to learn.andP;  In a way, this means the avalanche networkbegins as a general-purpose spatiotemporal network that only through traininglearns to specialize in a particular sequence of patterns.andM;The simpler systems discussed earlier transmit a pulse down the axon that ismore or less unstoppable once started.andP;  In contrast, the avalanche can havesophisticated &quot;start from here&quot; and &quot;stop now&quot; capabilities built in byjudicious use of inhibitory weights and external inputs.andP;  If we allow aglobally inhibiting signal to the avalanche layer, we can stop the sequenceplayback at any time.andP;  If we want to start from the middle of the sequence,we need only externally prod the appropriate avalanche neurodes into actionover a couple of time periods to start it up from that point.andM;In the next article in this series we will take one more look at biologicallyconsistent learning networks and discuss a system that is even better atmimicking Pavlovian conditioning than the outstar network.andP;  This is calledDrive Reinforcement Training, and it has important implications for all kindsof time-dependent training.andO;</TEXT></DOC>