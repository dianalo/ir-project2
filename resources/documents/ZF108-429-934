<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-429-934  </DOCNO><DOCID>08 429 934.andM;</DOCID><JOURNAL>Communications of the ACM  May 1990 v33 n5 p563(13)* Full Text COPYRIGHT Association for Computing Machinery 1990.andM;</JOURNAL><TITLE>Self-assessment procedure XXI: a self-assessment procedure onconcurrency. (twenty-one)</TITLE><AUTHOR>Rudolph, Brian A.andM;</AUTHOR><SUMMARY>The 21st self-assessment procedure on concurrency is intended toallow computer professionals to test their knowledge of thegeneral concepts of concurrency.andP;  Concurrency refers to theparallel execution of several processes or tasks.andP;  The procedureincludes questions regarding terminology, specifying concurrency,formal topics, classical problems and process coordination.andO;Self-assessment is an educational experience; it refers to theidea that a procedure can be devised to help a person appraise anddevelop her or his knowledge about a given topic.andM;</SUMMARY><DESCRIPT>Topic:     Self InstructionProceduresProgrammersDiagnostic AssessmentConcurrent Programming.andO;Feature:   illustrationtablechart.andO;Caption:   Previous self-assessment procedures. (table)Two petri-net graphs. (chart)A precedence graph. (chart)andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>What is Self-Assessment Procedure XXI? This is the 21st self-assessmentprocedure.andP;  All the previous ones are listed on the facing page.andP;  The first13 are available from ACM in a single loose-leaf binder to which laterprocedures may be added.andM;This procedure is intended to allow computer professionals to test theirknowledge of the general concepts of concurrency, that is, the parallelexecution of several processes or tasks.andP;  It includes questions concerningterminology, formal topics, specifying concurrency, process coordination, andclassical problems.andP;  In all except a few cases, there is supposed to be onlyone correct answer for each of the multiple-choice questions.andM;The next few paragraphs repeat the introduction and instructions given withearlier procedures.andP;  Those who read them before may advance directly to thequestions.andM;What is Self-Assessment?andM;Self-assessment is based on the idea that a procedure can be devised thatwill help a person appraise and develop his or her knowledge about aparticular topic.andP;  It is intended to be an educational experience for aparticipant.andP;  The questions are only the beginning of the procedure.andP;  Theyare developed to help the participant think about the concepts and decidewhether to pursue the matter further.andP;  The primary motivation ofself-assessment is not for an individual to satisfy others about his or herknowledge; rather it is for a participant to appraise and develop his or herown knowledge.andP;  This means that there are several ways to use aself-assessment procedure.andP;  Some people will start with the questions.andO;Others will read the answers and refer to the references first.andP;  Theseapproaches and others devised by the participants are all acceptable if atthe end of the procedure the participant can say, &quot;Yes, this has been aworthwhile experience&quot; or &quot;I have learned something.&quot;andM;How to Use the Self-Assessment ProcedureandM;We suggest the following way of using the procedure, but as noted earlier,there are others.andP;  This is not a timed exercise; therefore, plan to work withthe procedure when you have an hour to spare, or you will be shortchangingyourself on this educational experience.andP;  Go through the questions, and markthe responses you think are most appropriate.andP;  Compare your responses withthose suggested by the Committee.andP;  In those cases where you differ with theCommittee, look up the references if the subject seems pertinent to you.andP;  Inthose cases in which you agree with the Committee, but feel uncomfortablewith the subject matter, and the subject is significant to you, look up thereferences.andM;Some ACM chapters may want to devote a session to discussing thisself-assessment procedure or the concepts involved.andM;The Committee hopes some participants will send comments.andM;Previous Self-Assessment ProceduresandM;Self-Assessment Procedure IandM;Three concept categories within the programming skillsandM;and techniques areaandM;May 1976andM;Self-Assessment Procedure IlandM;System organization and control with informationandM;representation, handling, and manipulationandM;May 1977andM;Self-Assessment Procedure IIIandM;Internal sortingandM;September 1977andM;Self-Assessment Procedure IVandM;Program development tools and methods, data integrity,andM;and file organization and processingandM;February 1978andM;Self-Assessment Procedure VandM;Database systemsandM;Peter Scheuermann and C. Robert CarlsonandM;August 1978andM;Self-Assessment Procedure VIandM;Queueing network models of computer systemsandM;J. W. Wong and G. Scott GrahamandM;August 1979andM;Self-Assessment Procedure VIIandM;Software scienceandM;M. H. Halstead and Victor SchneiderandM;August 1980andM;Self-Assessment Procedure VIIIandM;The programming language AdaandM;Peter WegnerandM;October 1981andM;Self-Assessment Procedure IXandM;Ethics in computingandM;Edited by Eric A. Weiss, from a book by Donn B. ParkerandM;March 1982andM;Self-Assessment Procedure XandM;Software project managementandM;Roger S. GourdandM;December 1982andM;Self-Assessment Procedure XIandM;One part of early computing historyandM;Eric A. WeissandM;July 1983andM;Self-Assessment Procedure XIIandM;Computer architectureandM;Robert I. Winner and Edward M. CarterandM;january 1984andM;Self-Assessment Procedure XIIIandM;Binary search trees and B-TreesandM;Gopal K. GuptaandM;May 1984andM;Self-Assessment Procedure XIVandM;Legal issues of computingandM;Jane P. Devlin, William A. Lowell, and Anne E. AlgerandM;May 1985andM;Self-Assessment Procedure XVandM;File processingandM;Martin K. Solomon and Riva Wenig BickelandM;August 1986andM;Self-Assessment Procedure XVIandM;Computer organization and logic designandM;Glen G. Langdon, Jr.andM;November 1986andM;Self-Assessment Procedure XVIIandM;ACMandM;Eric A. WeissandM;October 1987andM;Self-Assessment Procedure XVIIIandM;Data CommunicationsandM;John C. MunsonandM;March 1988andM;Self-Assessment Procedure XIXandM;Copyright LawandM;Riva W. BickelandM;April 1989andM;Self-Assessment Procedure XXandM;Operating SystemsandM;1.andP;  Rosenberg, A. L. Ananda, andandM;B. SrinivasanandM;February 1990andM;Approved and submitted by the ACM Committee on Self-Assessment,andM;a committee of the ACM Education BoardandM;Chairman Neal S. CoulterandM;Department of Computer ScienceandM;Florida Atlantic UniversityandM;Boca Raton, FL 33431andM;Members Richard E. FairleyandM;George Mason UniversityandM;Mark J. JensenandM;IBM-Austin, TXandM;Randy E. MichelsenandM;Los Alamos National LaboratoryandM;Edward G. Pekarek, jr.andM;Appalachian State UniversityandM;Eric A. WeissandM;EditorandM;Self-Assessment Procedure XXIandM;This self-assessment procedure is not sanctioned as a test or endorsed in anyway by ACM.andP;  Any person using any of the questions in this procedure for thetesting or certification of anyone other than him- or herself is violatingthe spirit of this self-assessment procedure and the copyright on thismaterial.andM;ContentsandM;Part I.andP;    QuestionsandM;Part Il.andP;   Suggested ResponsesandM;Part 111.andP;  ReferencesandM;Part 1.andP;    QuestionsandM;GENERAL CONCEPTSandM;The notion of a process (often termed a task) is difficultandM;to capture precisely, while at the same time being ofandM;foremost importance in the study of concurrency.andP;  TheandM;first part of this self-assessment procedure is aboutandM;fundamental processes and concurrency concepts.andM;1.andP;  Processes may be described as physically concurrentandM;or logically concurrent.andP;  The distinction betweenandM;these types of concurrency is analogous to theandM;distinction between:andM;a. Synchronous processes and asynchronousandM;processes.andM;b. Real processors and virtual processors.andM;c. Explicit parallelism and implicit parallelism.andM;d. Batch processing and interactive processing.andM;2.andP;  Physical concurrency in a uniprocessor system:andM;a. Can occur among operating system routines.andM;b. Can occur with peripherals that communicateandM;via interrupts.andM;c. Occurs through context switching.andM;d. Cannot occur.andM;3.andP;  Within a process, a critical section consists of anyandM;sequence of instructions that:andM;a. Produce a result necessary for the successfulandM;completion of a subsequent instruction.andM;b. Are frequently executed on behalf of theandM;process.andM;c. Must be accessed on a mutually exclusiveandM;basis.andM;d. Have a high-priority value associated withandM;them.andM;4.andP;  When the result of a computation depends on theandM;speed of the processes involved, there is said to be:andM;a. Process syncopation.andM;b. A time lock.andM;c. Cycle stealing.andM;d. A race condition.andM;5.andP;  The relative speed of a process in execution cannotandM;reliably be determined due primarily to theandM;variations in:andM;a.andP;  The timing of context switching amongandM;processes.andM;b.andP;  The speed of system hardware.andM;c.andP;  The number of instructions included in aandM;process.andM;d.andP;  The types of the instructions included in aandM;process.andM;6.andP;  The major distinction between lightweight andandM;heavyweight processes centers around:andM;a.andP;  The amount of memory that must beandM;allocated to the process.andM;b.andP;  The average number of instructions executedandM;by the process.andM;c.andP;  The amount of overhead associated withandM;process creation and context switching.andM;d.andP;  The number of 1/0 requests made by theandM;process.andM;7.andP;  A technique which derives parallelism by decomposingandM;a task into a number of distinct stagesandM;which may be overlapped in an assembly-lineandM;fashion is called:andM;a.andP;  Phase transition.andM;b.andP;  Pipelining.andM;c.andP;  Linear displacement.andM;d.andP;  Fragmentation.andM;FORMAL CONCURRENCY TOPICSandM;The study of concurrency is based on formal models ofandM;concurrent computation and the properties of their parallelandM;algorithms.andP;  Many attempts have been made to introduceandM;formalisms that are both sufficiently powerfulandM;and clear, but none have become dominant.andP;  This sectionandM;focuses on a sampling of these models and on otherandM;formal aspects of concurrency.andM;8.andP;  A sequential algorithm with input size i performsandM;W(i) operations in the worst case.andP;  Given a machineandM;with n identical processors, the best worst caseandM;complexity of a parallel implementation of thisandM;algorithm would be on the order of:andM;a. W(i)/log n.andM;b. W(i)[Suare root]nandM;c. W(i)/nandM;d. W(i)/n[.sup.2]andM;9.andP;  Bernstein's conditions use the concepts of read setsandM;and write sets to determine:andM;a.andP;  If a group of processes and resources haveandM;become involved in a deadlock.andM;b.andP;  If there are any processes suffering fromandM;indefinite postponement.andM;c.andP;  If a resource allocation request can beandM;granted safely.andM;d.andP;  If performing multiple operations in parallelandM;will preserve determinacy.andM;10.andP;  The NC problem class consists of problems thatandM;can be solved by a parallel algorithm with polynomiallyandM;many processors in time proportional to aandM;fixed power of the log of their input size.andP;  Which ofandM;the following problems is most likely not in classandM;NC?andM;a.andP;  Sorting a list of records on a particular key.andM;b.andP;  Searching an unordered list for the recordandM;with the largest key.andM;c.andP;  Weighted average computation.andM;d.andP;  Finding the greatest common divisor of twoandM;integers.andM;11.andP;  Flynn's taxonomy of parallel computationalandM;models uses the concepts of instruction streamsandM;and data streams to determine classification.andP;  TheandM;conventional view is that no existing computersandM;can be classified as:andM;a.andP;  Single-instruction stream, single data streamandM;(SISD).andM;b.andP;  Single-instruction stream, multiple dataandM;stream (SIMD).andM;c.andP;  Multiple-instruction stream, single dataandM;stream (MISD).andM;d.andP;  Multiple-instruction stream, multiple dataandM;stream (MIMD).andM;12.andP;  The number of messages buffered in Hoare'sandM;Communicating Sequential Processes is:andM;a. Zero.andM;b. One.andM;c. Bounded by some nandM;d. Unbounded.andM;13.andP;  Which of the following does not completely distributeandM;through the nondeterministic choice operatorandM;under the laws established in Hoare's text onandM;communicating sequential processes?andM;a. Recursion.andM;b. Interleaving.andM;c. Prefixing.andM;d. Concealment.andM;14.andP;  Petri nets provide a method to mathematicallyandM;analyze systems that contain concurrent activities.andM;Consider the two Petri net graphs in Figure 1.andP;  ForandM;an initial node marking of n tokens, which of theandM;following observations regarding the execution ofandM;these two Petri nets is incorrect?andM;a.andP;  All places in both Petri nets are n-safe.andM;b.andP;  All places in both Petri nets will have beenandM;marked during execution.andM;c.andP;  One of the two Petri nets is not strictlyandM;conservative.andM;d.andP;  Exactly n tokens will remain in each PetriandM;net when execution halts.andM;15.andP;  When message transmission systems send emptyandM;messages asynchronously, they are effectivelyandM;equivalent to:andM;a. Petri nets.andM;b. Semaphore-based systems.andM;c. Finite state machines.andM;d. Turing machines.andM;16.andP;  In the actor paradigm, computational agents calledandM;actors communicate by message passing and carryandM;out their actions concurrently.andP;  Each actor has aandM;mail address and an associated behavior.andP;  Which ofandM;the following does not characterize the behavior ofandM;an actor?andM;a.andP;  An actor may process multiple communicationsandM;simultaneously.andM;b.andP;  An actor may process only those tasksandM;whose target corresponds to its mail address.andM;c.andP;  An actor may create new actors upon acceptanceandM;of a communication.andM;d.andP;  An actor must compute a replacement behaviorandM;upon acceptance of a communication.andM;17.andP;  The paralation model is an architecture-independentandM;model for parallel programming that can beandM;combined with any base language to produce aandM;concrete parallel programming language.andP;  It consistsandM;of a single data structure (called a field) andandM;three carefully chosen operators.andP;  Which of the followingandM;is not an operator in the basic paralationandM;model?andM;a. Merge.andM;b. Elementwise evaluation.andM;c. Move.andM;d. Match.andM;18.andP;  Which model below lends itself most easily to theandM;specification of potentially massive parallelism?andM;a. Finite state machines.andM;b. Monitors.andM;c. Neural networks.andM;d. Communicating sequential processes.andM;19.andP;  When taking the axiomatic approach to the verificationandM;of concurrent programs:andM;a.andP;  A concurrent program is transformed to anandM;equivalent sequential program for furtherandM;analysis.andM;b.andP;  Interleaving scenarios are employed toandM;characterize all possible behaviors of aandM;concurrent program.andM;c.andP;  A functional relationship is establishedandM;between the initial and final set of values inandM;a concurrent program.andM;d.andP;  Statements in a concurrent program areandM;viewed as relations between predicates in aandM;formal logic system.andM;SPECIFYING CONCURRENCYandM;The following questions are concerned with a few ofandM;the problems associated with specifying concurrency.andM;The exercises give an opportunity to specify concurrencyandM;using some basic primitives.andM;20.andP;  Coroutines are not suitable for specifying trueandM;parallel processing since:andM;a. They do not permit the simultaneous executionandM;of multiple processes.andM;b.andP;  They do not provide a well-defined methodandM;for transfer of control.andM;c.andP;  They are not sufficiently powerful to implementandM;multiprogramming.andM;d.andP;  They do not provide a mechanism for processandM;synchronization.andM;21.andP;  Statement sequences that cannot be executed inandM;parallel are said to contain dependences.andP;  ConsiderandM;the program fragment given in Listing 1.andP;  IdentifyandM;the flow dependences, antidependences, and outputandM;dependences present between the statements in thisandM;fragment.andM;Listing 1andM;S[.sub.1]: W =  X +   YandM;S[.sub.2]: X =  W - ZandM;S[.sub.3]:Y=3+ WandM;S[.sub.4]: W = X + ZandM;22.andP;  Parallelism inherent in loop structures but notandM;explicitly specified by the programmer can be extractedandM;by a compiler capable of detecting parallelismandM;automatically.andP;  In the absence of dependences,andM;such a compiler can restructure the loop and ultimatelyandM;create a vector statement for each individualandM;case.andP;  This type of transformation is called:andM;a. Loop optimization.andM;b. Loop distribution.andM;c. Loop blocking.andM;d. Loop interchange.andM;23.andP;  Express the precedence graph in Figure 2 as aandM;concurrent program using fork, join, and quitandM;primitives.andP;  The program should permit maximumandM;parallelism.andM;24.andP;  Express the precedence graph in Figure 2 as a concurrentandM;program using the parbegin/parend (alsoandM;known as cobegin/coend) concurrent statement.andM;The program should again permit maximum parallelism.andM;25.andP;  Suppose an edge from node S3 to node S4 wereandM;added to the precedence graph in Figure 2.andP;  WhatandM;effect would this have on the programs developedandM;in questions 23 and 24?andM;a.andP;  The modification would have no effect onandM;either program.andM;b.andP;  The fork, join, and quit primitives could notandM;be used to derive maximum parallelism.andM;c.andP;  The parbegin/parend concurrent statementandM;could not be used to derive maximum parallelism.andM;d.andP;  Neither construct could be used to deriveandM;maximum parallelism.andM;PROCESS COORDINATIONandM;Processes must often synchronize and communicate toandM;accomplish their tasks.andP;  Process coordination problemsandM;provide one of the most intellectually challengingandM;aspects of concurrency.andP;  This portion of the self-assessmentandM;procedure examines some problems andandM;concerns associated with these issues.andM;26.andP;  Which of the following is not a proper statementandM;concerning critical regions?andM;a.andP;  Critical regions involving distinct data mayandM;be executed concurrently.andM;b.andP;  One critical region cannot be nested insideandM;another critical region.andM;c.andP;  A process should remain inside a critical regionandM;for only a finite amount of time.andM;d.andP;  A process should not be permitted to terminateandM;inside a critical region.andM;27.andP;  Starvation occurs when:andM;a.andP;  At least one process is continually passedandM;over and not permitted to execute.andM;b.andP;  The priority of a process is adjusted basedandM;upon its length of time in the system.andM;c.andP;  At least one process is waiting for an eventandM;that will never occur.andM;d.andP;  Two or more processes are forced to accessandM;critical data in strict alternation with eachandM;other.andM;28.andP;  A common assumption underlying mutual exclusionandM;algorithms in shared memory systems is that:andM;a. Time-critical threats of process starvationandM;can effectively be ignored.andM;b. A memory reference to an individual wordandM;is mutually exclusive.andM;c. A single instruction executes faster than aandM;group of instructions.andM;d. A process executing a busy wait will receiveandM;a lower scheduling priority.andM;29.andP;  An objection to Dekker's two-process mutualandM;exclusion algorithm concerns the fact that:andM;a. It relies on race conditions to achieveandM;mutual exclusion.andM;b. It does not prevent the indefinite postponementandM;of a process.andM;c. It cannot be generalized to provide mutualandM;exclusion among more than two processes.andM;d. It uses a common variable that can beandM;altered by any process.andM;30.andP;  Consider busy waiting for entry into a criticalandM;section in a shared memory system.andP;  In whichandM;scenario (or scenarios) below would this not beandM;considered an unreasonable approach?andM;a.andP;  When there are few CPU-bound processes inandM;existence.andM;b.andP;  When a dedicated processor can be assignedandM;to perform the busy wait.andM;c.andP;  When the expected wait is less than theandM;time needed to perform a context switch.andM;d.andP;  None of the above-busy waiting is alwaysandM;unreasonable since it does nothing but wasteandM;processor cycles.andM;31.andP;  The first mutual exclusion algorithm independentandM;of any centralized device serialized the requestsandM;from competing processes desiring entry into aandM;critical section.andP;  This famous algorithm is knownandM;as:andM;a. Conway's Algorithm.andM;b. Schott's Algorithm.andM;c. Lamport's Bakery Algorithm.andM;d. Dijkstra's Banker's Algorithm.andM;32.andP;  In shared memory systems, process synchronizationandM;can be supported by special hardware instructionsandM;that perform multiple actions atomicallyandM;such as the reading and modification of a singleandM;memory location.andP;  Many of these instructions areandM;termed blocking since they can be executed onlyandM;by one process at a time.andP;  Conversely, nonblockingandM;primitives permit many processors to access aandM;shared variable simultaneously and obtain uniqueandM;results.andP;  Which of the following hardware primitives,andM;when used in conjunction with an interconnectionandM;network that can combine requests boundandM;for the same memory location, is nonblocking?andM;a. The test-and-set instruction.andM;b. The fetch-and-add instruction.andM;c. The lock instruction.andM;d. The swap instruction.andM;33.andP;  A general (or counting) semaphore:andM;a.andP;  Provides less synchronization capabilityandM;than a binary semaphore.andM;b.andP;  Provides synchronization capability equivalentandM;to a binary semaphore.andM;c.andP;  Provides more synchronization capabilityandM;than a binary semaphore.andM;d.andP;  Bears no comparable relationship to a binaryandM;semaphore.andM;34.andP;  A condition in a monitor is associated with:andM;a. An integer variable, which is initially zero.andM;b. A binary semaphore, which is initially zero.andM;c. A queue, which is initially empty.andM;d. A boolean variable, which is initially false.andM;35.andP;  A monitor has all of the following advantages overandM;a semaphore except:andM;a. Being a more powerful synchronizationandM;construct than a semaphore.andM;b.andP;  Being a higher-level synchronization constructandM;than a semaphore.andM;c.andP;  Providing automatic mutual exclusionandM;within its boundaries.andM;d.andP;  Collecting all routines that modify a set ofandM;shared data into one location.andM;36.andP;  One advantage of path expressions over monitors isandM;that path expressions:andM;a.andP;  Are more easily implemented within aandM;compiler.andM;b.andP;  Can be used to convey condition synchronization.andM;c.andP;  Allow the specification of an ordering inandM;which to resume blocked processes.andM;d.andP;  Eliminate the need for explicit synchronizationandM;code.andM;37.andP;  When working with message-passing systems,andM;time-outs are used to:andM;a.andP;  Limit the number of times that a messageandM;may be transmitted.andM;b.andP;  Determine that a transmitted message hasandM;become lost.andM;c.andP;  Temporarily suspend the transmission ofandM;messages.andM;d.andP;  Limit the size of a transmitted message.andM;38.andP;  A distinct advantage of message-passing overandM;semaphores is that:andM;a.andP;  Message-passing is readily extensible to aandM;distributed environment.andM;b.andP;  Message-passing primitives do not necessarilyandM;block a process when executed.andM;c.andP;  Message-passing imposes a hierarchicalandM;structure on the design of an operatingandM;system.andM;d.andP;  Processes engaged in message-passing cannotandM;become involved in a deadlock.andM;39.andP;  In many cases, a group of cooperating processesandM;must all arrive at a common location before any ofandM;them are permitted to proceed.andP;  This location isandM;termed:andM;a. An artificial rendezvous point.andM;b. A barrier synchronization point.andM;c. A conditional critical region.andM;d. A synchronization bottleneck.andM;40.andP;  Event counts and sequencers can be used to solveandM;the bounded-buffer producer/consumer problem:andM;a.andP;  Without requiring mutual exclusion betweenandM;the producer and consumer processes.andM;b.andP;  Only in the case of a single producer processandM;and a single consumer process.andM;c.andP;  Only when the producer and consumerandM;processes run at the same relative speed.andM;d. Only when the information transmitted betweenandM;the producer and consumer processesandM;is passed by value.andM;41.andP;  A major distinction between tightly-coupled systemsandM;and loosely-coupled systems is that processandM;synchronization:andM;a.andP;  Is simplified in a loosely-coupled systemandM;since all processors in the system can accessandM;a shared global memory.andM;b.andP;  Is simplified in a loosely-coupled systemandM;since a single operating system must controlandM;all processors in the system.andM;c.andP;  Is more difficult in a loosely-coupled systemandM;since there is only minimal message trafficandM;between processors.andM;d.andP;  Is more difficult in a loosely-coupled systemandM;since there is typically no shared memory orandM;clocks.andM;42.andP;  Transaction processing systems such as airlineandM;reservation systems must provide a mechanism,andM;which guarantees that each transaction is immuneandM;from interference by other transactions that mayandM;be occurring at the same time.andP;  Two-phase transactionsandM;obey a protocol that insures this atomicity.andP;  InandM;two-phase transactions:andM;a.andP;  All read operations occur before the firstandM;write operation.andM;b.andP;  All lock actions occur before the first unlockandM;action.andM;c.andP;  A shared lock on an object must be obtainedandM;before an exclusive lock on the object canandM;be obtained.andM;b.andP;  Any currently locked object must be unlockedandM;before another object can be locked.andM;43.andP;  Remote procedure calls can be specified in one ofandM;two ways: either as a procedure declaration that isandM;implemented as a server process or as a specialandM;statement.andP;  The Ada rendezvous takes the latter approachandM;by requiring the server side to execute:andM;a. A call statement.andM;b. A null statement.andM;c. An accept statement.andM;d. An entry statement.andM;44.andP;  Which of the following is not an advantage of theandM;Ada rendezvous mechanism?andM;a.andP;  One server can provide multiple services.andM;b.andP;  Communication between the client andandM;server is guaranteed within a finite amountandM;of time.andM;c.andP;  A server can achieve different effects forandM;client calls to the same service.andM;d.andP;  Client calls can be serviced at times determinedandM;by the server.andM;45.andP;  The Ada select statement is an example of aandM;guarded command.andP;  The guards:andM;a.andP;  Prevent conflicting tasks from simultaneouslyandM;executing the select statement.andM;b.andP;  Provide mutual exclusion among the alternativesandM;in the select statement.andM;c.andP;  Determine which select alternatives can beandM;executed.andM;d.andP;  Determine which specific event will beandM;serviced.andM;46.andP;  Which of the following is not a characteristic of anandM;algorithm that exhibits large-grain parallelism?andM;a.andP;  It performs relatively many operations betweenandM;synchronizations.andM;b.andP;  It generates an abundance of message traffic.andM;c.andP;  It can typically take advantage of additionalandM;processors as the size of a problem increases.andM;d.andP;  It can be implemented on both multiprocessorandM;systems and multicomputer systems.andM;CLASSIC CONCURRENCY PROBLEMSandM;This segment is a collection of problems and exercises,andM;which have become classics in concurrency.andM;47.andP;  Dijkstra's Dining Philosophers problem involves aandM;group of five philosophers whose existence isandM;based solely on two activities: thinking and eating.andM;The philosophers sit around a circular table.andP;  In theandM;center of the table is a bowl of spaghetti, which isandM;constantly replenished (the bowl is never empty).andM;The only eating utensils available are five forks.andM;One of the forks is located between each adjacentandM;pair of philosophers.andP;  A hungry philosopher, therefore,andM;must acquire the forks to the immediate leftandM;and right in order to eat.andP;  The life of a philosopherandM;constantly cycles between the thinking and eatingandM;states.andP;  Consider designing a concurrent programandM;that simulates the activities of the philosophersandM;without severely inhibiting their actions.andP;  The primaryandM;task in developing an acceptable solution toandM;this problem concerns:andM;a.andP;  Selecting an appropriate mutual exclusionandM;primitive.andM;b.andP;  Avoiding deadlock and process starvation.andM;c.andP;  Selecting an appropriate representation forandM;the resources.andM;d.andP;  Serializing the use of the resources.andM;48.andP;  The Cigarette Smokers' problem consists of anandM;agent process and three smoker processes.andP;  TheandM;agent has access to an infinite supply of the threeandM;commodities necessary to make and use a cigarette:andM;paper, tobacco, and matches.andP;  One of theandM;smoker processes has access to an infinite supplyandM;of paper, another has access to an infinite supplyandM;of tobacco, and the third has access to an infiniteandM;supply of matches.andP;  The agent begins by placingandM;two of the three commodities on the table.andP;  TheandM;smoker process with the missing ingredient mustandM;then acquire the two commodities on the table,andM;make and smoke a cigarette, and notify the agentandM;when it has completed.andP;  The process then repeatsandM;with the agent placing two more of its commoditiesandM;on the table.andP;  This is an example of a synchronizationandM;problem that cannot be solved:andM;a. Using a Petri net.andM;b. Using only ordinary semaphore operations.andM;c. Using only asynchronous message passing.andM;d. Using any model of parallel computation.andM;Questions 49 and 50 refer to Listing 2 in which a producerandM;and a consumer process synchronize to share aandM;common buffer.andM;Listing 2andM;varandM;mutex, item-available: semaphore;andM;procedure producer;andM;beginandM;repeatandM;produce_item;andM;P(mutex);andM;append_to_buffer;andM;V(mutex);andM;V(item_available)andM;until falseandM;end;andM;procedure consumer;andM;beginandM;repeatandM;P(item_available);andM;P(mutex);andM;retrieve_from_buffer;andM;V(mutex);andM;consume_itemandM;until falseandM;end;andM;beginandM;semaphore_init(mutex, 1);andM;semaphore_init(item_available, 0);andM;parbeginandM;producer;andM;consumerandM;parendandM;end.andM;49.andP;  What would be the effect of executing the programandM;in Listing 2 with the two P operations in theandM;consumer process interchanged?andM;a. The producer and consumer processes couldandM;deadlock.andM;b. The producer or consumer process couldandM;become a victim of starvation.andM;c. Mutual exclusion would be violated.andM;d. The modification would have no effect onandM;the correctness of the program.andM;50.andP;  What would be the effect of executing the programandM;in Listing 2 with the two V operations in theandM;producer process interchanged?andM;a.andP;  The producer and consumer processes couldandM;deadlock.andM;b.andP;  The producer or consumer process couldandM;become a victim of starvation.andM;c.andP;  Mutual exclusion would be violated.andM;d.andP;  The modification would have no effect onandM;the correctness of the program.andM;51.andP;   Determine the proper lower-bound and upper-boundandM;on the final value of the shared variableandM;tally output by the concurrent program in ListingandM;3.andP;  Assume that the processes can execute at anyandM;speed and that a value can only be incrementedandM;after it has been loaded into an accumulator by aandM;separate machine instruction.andM;Listing 3andM;constandM;n = 50;andM;varandM;tally: integer;andM;procedure total;andM;varandM;count: integer;andM;beginandM;for count   :=     1 to n doandM;tally  :=     tally + 1andM;end;andM;beginandM;tally := 0;andM;parbeginandM;total;andM;totalandM;parend;andM;writeIn(tally)andM;end.andM;Suppose that an arbitrary number of these incrementandM;processes are permitted to execute in parallel under theandM;previous assumptions.andP;  What effect will this modificationandM;have on the range of final values of tally?andM;52.andP;  When the concurrent processes in Listing 4 areandM;executing, what relationship will exist betweenandM;the values of the shared variables count 1 andandM;count2? Again assume that the processes canandM;execute at any speed and that a value can onlyandM;be incremented after it has been loaded into anandM;accumulator by a separate machine instruction.andM;a. count 1 and count2 will remain equal.andM;b. count 1 will remain greater than or equal toandM;count2.andM;c. count2 will remain greater than or equal toandM;count1.andM;d. The values of count 1 and count2 willandM;exhibit no consistent relationship.andM;Listing 4andM;varandM;blocked: array [0..1l of boolean;andM;turn, count1, count2: integer;andM;procedure process(id: integer);andM;beginandM;repeatandM;blocked[id] := true;andM;while turn andless; andgt; id doandM;beginandM;while blocked[1 - id) do;andM;turn := idandM;end;andM;count1 := count1 + 1;andM;blocked[id] := false;andM;count2 := count2 + 1andM;until falseandM;end;andM;beginandM;blocked[0) := false; blocked[1] =  false;andM;turn := 0; count1 := 0; count2  =  0;andM;parbeginandM;process(0);andM;process(1)andM;parendandM;end.andM;Part II.andP;  Suggested ResponsesandM;GENERAL CONCEPTSandM;1.andP;  b   [6, pp.andP;  36-37; 32, pp.andP;  62-65; 19, p. 22]andM;2.andP;  b   [32, pp.andP;  12-15; 6, pp.andP;  296-300; 9, pp.andP;  26-27]andM;3.andP;  c   [6, pp.andP;  46-48; 32, pp.andP;  83-84; 9, pp.andP;  76-771andM;4.andP;  d   [19, p. 19; 2, p. 366]andM;5.andP;  a   [5, pp.andP;  22-24; 34, pp.andP;  70-72; 19, p. 22]andM;6.andP;  c   [2, pp.andP;  272-273; 13, p. 338]andM;7.andP;  b   [28, pp.andP;  9-10, 13-15; 9, pp.andP;  29-30; 15, p. 270]andM;FORMAL CONCURRENCY TOPICSandM;8.andP;  c [28, pp.andP;  42-44, 131; 4, p. 363; 15, p. 260]andM;9.andP;  d [21, pp.andP;  12-14; 26, pp.andP;  52-53, 70-73]andM;10.andP;  d [8, pp.andP;  2-22; 4, pp.andP;  365-366; 15, pp.andP;  271-275]andM;11.andP;  c [2, pp.andP;  19, 111-112; 28, pp.andP;  16-17; 9, pp.andP;  317andM;-     318] Pipelined vector processors are sometimesandM;classified as MISD, however.andM;12.andP;  a [17, pp.andP;  134-135, 142; 18, p. 285; 32, pp.andP;  125andM;-     127,132-133]andM;13.andP;  a [17, pp.andP;  101-104, 111-112, 119-120] The recursionandM;operator is not distributive through nondeterministicandM;choice except in the trivial case whereandM;identical operands are supplied.andM;14.andP;  b [26, pp.andP;  16-21, 40, 81-84] Since the first threeandM;transitions in Net A cause a mark to visit everyandM;place by creating an additional token after eachandM;firing, Net A is not strictly conservative.andP;  The finalandM;transition removes these duplicate tokens, leavingandM;n tokens in the final place when execution halts.andM;The arrangement of the places and transitions,andM;however, limits the number of tokens in a givenandM;place to n, thus making them n-safe.andM;The execution of Net B contains a sequence ofandM;transitions that are in conflict, causing each tokenandM;to be preserved as it follows one &quot;path&quot; of transitionsandM;from the initial place to the final place.andP;  SinceandM;no tokens are created or destroyed, Net B isandM;strictly conservative, all places are n-safe, and nandM;tokens are left in the final place when executionandM;halts.andP;  But the firing of transitions is nondeterministic,andM;so there is no guarantee that all places in NetandM;B will have been marked.andM;15.andP;  b  [26, pp.andP;  220-226; 19, pp.andP;  33-36; 7, p. 93]andM;16.andP;  a  [1, pp.andP;  23-251andM;17.andP;  a  [31, pp.andP;  7-8, 11-36]andM;18.andP;  c  [30, pp.andP;  129-136; 11, pp.andP;  170-187; 14, p. 1611andM;19.andP;  d  [23, pp.andP;  319-340; 24, pp.andP;  279-285; 3, pp.andP;  6-9,andM;32-33, 52-53; 29, pp.andP;  56-58; 10]andM;SPECIFYING CONCURRENCYandM;20.andP;  a [5, pp.andP;  30-32; 3, p. 10; 7, p. 1311andM;21.andP;  [25, pp.andP;  1184-1187; 27, pp.andP;  15-18; 22, pp.andP;  2-10andM;-     2-12]andM;Flow Dependences:andM;W:    S[.sub.1][delta]S[.sub.2], S[.sub.1][delta]S[.sub.3]andM;X:    S[.sub.2][delta]S[.sub.4]andM;Antidependences:andM;W:    S[.sub.2][.sup.-][delta]S4, S[.sub.3][.sup.-]andM;[delta]S[.sub.4]andM;X :   S[.sub.1][.sup.-][delta]S[.sub.2]andM;Y:    S[.sub.1][.sup.-][delta]S[.sub.3]andM;Output Dependence:andM;W:    S[.sub.1][delta[.sup.o]S[.sub.4]andM;22.andP;  b [27, pp.andP;  21-27; 2, pp.andP;  226-229; 9, pp.andP;  322-3231andM;23.andP;  [6, pp.andP;  42-44; 2, pp.andP;  154-157; 19, pp.andP;  18-19]andM;Sample Solution:andM;Threads:= 4;andM;S,;fork Process1;forkandM;Process2;   fork Process3;quit;andM;Process1:   S[.sub.2]; S[.sub.4]; join Threads,Continue;andM;quit;andM;Process2:   S3; fork Process4; S5; joinandM;Threads, Continue; quit;andM;Process3:   S,; join Threads,Continue;andM;quitandM;Process4:   S6; S8; join Threads,Continue;andM;quit;andM;Continue:   Sq; quitandM;24.andP;  [2, pp.andP;  154-158; 7, pp.andP;  57-60; 6, pp.andP;  40-42]andM;Sample Solution:andM;S,;andM;parbeginandM;beginandM;S2 ; S4andM;end;andM;beginandM;S3 ;andM;parbeginandM;S 5 ;andM;beginandM;S6 ; S[.sub.8]andM;endandM;parendandM;end;andM;S,andM;parend;andM;S,andM;25.andP;  c [6, pp.andP;  40-41; 2, pp.andP;  54, 57; 3, pp.andP;  11-12]andM;PROCESS COORDINATIONandM;26.andP;  b [32, pp.andP;  107-110; 7, pp.andP;  83-86; 13, pp.andP;  291-292]andM;27.andP;  a [32, pp.andP;  99-100; 13, p. 275; 15, pp.andP;  275-283)andM;28.andP;  b [5, p. 8; 29, p. 40; 13, p. 276; 7, p. 87]andM;29.andP;  d [9, pp.andP;  84-85; 5, pp.andP;  38-39, 43; 29, pp.andP;  18-22]andM;30.andP;  b, c [13, pp.andP;  283-284; 6, pp.andP;  56-57; 2, pp.andP;  162andM;-     163]andM;31.andP;  c [29, pp.andP;  50-52; 5, pp.andP;  44-46, 93; 21, pp.andP;  207-208;andM;9, p. 87] Each process &quot;takes a ticket&quot; (chooses aandM;number in a non-decreasing fashion) when desiringandM;to enter a critical section, similar to the numberedandM;ticket system employed in a busy bakery.andM;32.andP;  b   [32, pp.andP;  92-95; 29, pp.andP;  40-44; 2, pp.andP;  162-167]andM;33.andP;  b   [16, pp.andP;  7-8; 6, pp.andP;  56-57; 19, pp.andP;  30-31]andM;34.andP;  c   [5, pp.andP;  73-78; 6, pp.andP;  62-66; 19, pp.andP;  98-99]andM;35.andP;  a   [5, pp.andP;  86-88; 32, pp.andP;  120-121; 6, pp.andP;  65-661andM;36.andP;  d   [6, pp.andP;  68-72; 13, pp.andP;  306-308; 3, pp.andP;  36-39]andM;37.andP;  b   [32, pp.andP;  135-136; 21, p. 189; 2, p.169]andM;38.andP;  a   [7, pp.andP;  127-130; 6, pp.andP;  72-73; 5, p. 93; 34,andM;p. 105]andM;39.andP;  b [2, pp.andP;  165-166; 22, pp.andP;  2-16; 27, pp.andP;  44-45, 86]andM;40.andP;  a [13, pp.andP;  302-305; 21, pp.andP;  17-23]andM;41.andP;  d   [28, pp.andP;  35-42; 32, p. 415; 9, pp.andP;  329-330]andM;42.andP;  b   [33, pp.andP;  380-381; 13, pp.andP;  240-241; 21, pp.andP;  244andM;-     246]andM;43.andP;   c [3, pp.andP;  48-51, 56-57; 21, pp.andP;  82-92; 6, pp.andP;  78-82;andM;9, pp.andP;  125-127; 2.andP;  pp.andP;  167-169]andM;44.andP;   b   [3, pp.andP;  49-50: 5, pp.andP;  93-105; 28, pp.andP;  70-71]andM;45.andP;   c [32, pp.andP;  123-125; 5, pp.andP;  99-104; 21, pp.andP;  85-88;andM;9, pp.127-129]andM;46.andP;   b   [12, pp.andP;  21-22; 28, pp.andP;  60-61]andM;CLASSIC CONCURRENCY PROBLEMSandM;47.andP;   b   [19, pp.andP;  115-121; 13, pp.andP;  136-138; 21, pp.andP;  30andM;-      31]andM;48.andP;   b   [26, pp.andP;  192-193, 216-217, 224-226; 5, pp.andP;  71andM;-      72; 21, pp.andP;  31-33]andM;49.andP;   a   [34, pp.andP;  66-70.: 5, pp.andP;  58-601andM;50.andP;   d   [34, pp.andP;  66-70:.andP;  5, pp.andP;  58-60]andM;51.andP;   [5, pp.andP;  7-8, 17; 7, pp.andP;  82-83; 13, p. 313] On casualandM;inspection it appears that tally will fall in theandM;range 50   tally   100 since from 0 to 50 incrementsandM;could go unrecorded due to the lack of mutualandM;exclusion.andP;  The basic argument contends thatandM;by running these two processes concurrently weandM;should not be able to derive a result lower thanandM;the result produced by executing just one of theseandM;processes sequentially.andP;  The logic of it all is quiteandM;appealing.andP;  But consider the following interleavedandM;sequence of the load, increment, and store operationsandM;performed by these two processes whenandM;altering the value of the shared variable:andM;(1)   Process A loads the value of tally, incrementsandM;tally, but then loses the processor (it hasandM;incrementedandM;its accumulator to 1, but has not yetandM;stored this value).andM;(2)   Process B loads the value of tally (still zero) andandM;performs forty-nine complete increment operations,andM;losing the processor after it has stored theandM;value 49 into the shared variable tally.andM;(3)   Process A regains control long enough to performandM;its first store operation (replacing the previousandM;tally value of 49 with 1) but is then immediatelyandM;forced to relinquish the processor.andM;(4)   Process B resumes long enough to load 1 (theandM;current value of tally) into its accumulator, butandM;then it too is forced to give up the processorandM;(note that this was process B's final load).andM;(5)   Process A is rescheduled, but this time it is notandM;interrupted and runs to completion, performingandM;its remaining 49 load, increment, and store operationsandM;which subsequently sets the value of tallyandM;to 50.andM;(6)   Process B is reactivated with only one incrementandM;and store operation left to perform before itandM;terminates.andM;Since it has already performed its finalandM;load, it increments its accumulator to 2 andandM;stores this value as the final value of the sharedandM;variable! Both processes have terminated, butandM;the value of tally has fallen considerably shortandM;of 50.andM;Is 2 the absolute lower bound? It would appearandM;so.andP;  Process A must perform a store operation inandM;order to corrupt the value of the shared variable,andM;which Process B has incremented to 49.andP;  ThisandM;means that Process A had to perform at least oneandM;increment operation, implying that 49 will beandM;replaced by a minimum value of 1.andP;  Once ProcessandM;B has loaded this value into its accumulator, itandM;must still perform a final increment before thisandM;value can be stored.andP;  Thus 2 is the proper lowerandM;bound.andM;All values in the range 2 through 49 are likewiseandM;potential results.andP;  The obvious interleavedandM;sequences cause Process B to initially lose theandM;processor after completing 50-k increment cyclesandM;(1- k   48) in step (2).andM;Although these sequences would hardly everandM;occur, they are nonetheless possible.andP;  Thus theandM;proper range of final values is 2   tally   100.andM;For the generalized case of p increment processes,andM;the proper range of results would be 2 [less thanandM;or equal to]andM;tally [less than or equal to] 50p since it is possibleandM;for all other processesandM;to be initially scheduled and run to completionandM;in step (5) before Process B would finallyandM;destroy their work by finishing last.andM;52.andP;  d [32, p. 141; 29, p. 25; 20, p. 45] This concurrentandM;program is based upon Hyman's incorrect mutualandM;exclusion algorithm.andP;  Since mutual exclusion is notandM;properly enforced (both processes can be in theirandM;critical sections simultaneously) and the executionandM;speed of the processes cannot be determined, noandM;consistent relationship can be stated.andM;Part III.andP;  Reference TitlesandM;Suggested ReferencesandM;1.andP;  Agha, G.A.andP;  Actors: A Model of Concurrent ComputationandM;in Distributed Systems.andP;  The MIT Press,andM;Cambridge, Mass., 1986.andM;2.andP;  Almasi, G.S., and Gottlieb, A. Highly ParallelandM;Computing.andP;  Benjamin/Cummings PublishingandM;Company, Redwood City, Calif., 1989.andM;3.andP;  Andrews, G.R., and Schneider, F.B.andP;  ConceptsandM;and notations for concurrent programming.andP;  InandM;Concurrent Programming, N. Gehani and A.D.andM;McGettrick, Eds.andP;  Addison-Wesley, Reading,andM;Mass., 1988, pp.andP;  3-69.andP;  (First published in Comput.andM;Surv.andP;  15, 1 (Mar.andP;  1983), 3-43.andM;4.andP;  Baase, S. Computer Algorithms.andP;  2d ed.andP;  AddisonandM;-        Wesley, Reading, Mass., 1988.andM;5.andP;  Ben-Ari, M. Principles of Concurrent Programming.andM;Prentice Hall, Englewood Cliffs, N.J., 1982.andM;6.andP;  Bic, L., and Shaw, A.C.andP;  The Logical Design of OperatingandM;Systems.andP;  Prentice Hall, Englewood Cliffs,andM;N.J., 1988.andM;7.andP;  Brinch Hansen, P. Operating System Principles.andM;Prentice Hall, Englewood Cliffs, N.J., 1973.andM;8.andP;  Cook, S.A.andP;  A taxonomy of problems with fastandM;parallel algorithms.andP;  Inf.andP;  and Cont.andP;  64  1985), 2-22.andM;9.andP;  Deitel, H.M.andP;  Operating Systems.andP;  2d ed.andP;  AddisonandM;-        Wesley, Reading, Mass., 1990.andM;10.andP;   Dijkstra, E.W.andP;  A Discipline of Programming.andP;  PrenticeandM;Hall, Englewood Cliffs, N.J., 1976.andM;11.andP;   Feldman, J.A., Fanty, M.A., Goddard, N.H., andandM;Lynne, K.J.andP;  Computing with structured connectionistandM;networks.andP;  Commun.andP;  ACM 31, 2 (Feb.andM;1988), 170-187.andM;12.andP;   Finkel, R.A.andP;  Large-Grain Parallelism-ThreeandM;case studies.andP;  In The Characteristics of ParallelandM;Algorithms,andM;L.H.andP;  Jamieson, D.B.andP;  Gannon, and R.J.andM;Douglass, Eds.andP;  The MIT Press, Cambridge, Mass.,andM;1987,pp.21-63.andM;13.andP;   Finkel, R.A.andP;  An Operating Systems VADEandM;MECUM.andP;  2d ed.andP;  Prentice Hall, Englewood Cliffs,andM;N.J., 1988.andM;14.andP;  Gehani, N., and McGettrick, A.D., Eds.andP;  ConcurrentandM;Programming.andP;  Addison-Wesley, Reading,andM;Mass., 1988.andM;15.andP;  Harel, D. Algorithmics.andP;  Addison-Wesley, Reading,andM;Mass., 1987.andM;16.andP;  Hemmendinger, D. Comments on &quot;A correct andandM;unrestrictive implementation of general semaphores.&quot;andM;Oper.andP;  Syst.andP;  Rev.andP;  23, 1 (jan.andP;  1989), 7-8.andM;17.andP;  Hoare, C.A.R.andP;  Communicating Sequential Processes.andM;Prentice Hall, Englewood Cliffs, N.J., 1985.andM;18,  Hoare, C.A.R.andP;  Communicating sequential processes.andM;In Concurrent Programming, N. GehaniandM;and A.D.andP;  McGettrick, Eds.andP;  Addison-Wesley,andM;Reading, Mass., 1988, pp.andP;  278-308.andP;  (First publishedandM;in Commun.andP;  ACM 21, 8 (Aug.andP;  1978), 666andM;-     677.)andM;19.andP;  Holt, R.C.andP;  Concurrent Euclid, The UNIX System,andM;and TUNIS.andP;  Addison-Wesley, Reading, Mass.,andM;1983.andM;20.andP;  Hyman, H. Comments on a problem in concurrentandM;programming control.andP;  Commun.andP;  ACM 9, 1andM;(Jan.andP;  1966), 45.andM;21.andP;  Maekawa, M., Oldehoeft, A.E., and Oldehoeft,andM;R.R.andP;  Operating Systems: Advanced Concepts.andM;Benjamin/CummingsandM;Publishing Company, MenloandM;Park, Calif., 1987.andM;22.andP;  Osterhaug, A., Ed.andP;  Guide to Parallel ProgrammingandM;on Sequent Computer Systems.andP;  2d ed.andP;  PrenticeandM;Hall, Englewood Cliffs, N.J., 1989.andM;23.andP;  Owicki, S.S., and Gries, D. An axiomatic proofandM;technique for parallel programs.andP;  Acta Inf.andP;  6andM;(1976), 319-340.andM;24.andP;  Owicki, S.S., and Gries, D. Verifying propertiesandM;of parallel programs: An axiomatic approach.andM;Commun.andP;  ACM 19, 5 (May 1976), 279-285.andM;25.andP;  Padua, D.A., and Wolfe, M.J.andP;  Advanced compilerandM;optimizations for supercomputers.andP;  Commun.andM;ACM 29,12 (Dec.andP;  1986), 1184-1201.andM;26.andP;  Peterson, J.L.andP;  Petri Net Theory and the Modeling ofandM;Systems.andP;  Prentice Hall, Englewood Cliffs, N.J.,andM;1981.andM;27.andP;   Polychronopoulos, C.D.andP;  Parallel Programming andandM;Compilers.andP;  Kluwer Academic Publishers, Boston,andM;Mass., 1988.andM;28.andP;   Quinn, M.J.andP;  Designing Efficient Algorithms for ParallelandM;Computers.andP;  McGraw-Hill Book Company,andM;New York, 1987.andM;29.andP;   Raynal, M. Algorithms for Mutual Exclusion.andP;  TheandM;MIT Press, Cambridge, Mass., 1986.andM;30.andP;   Rumelhart, D.E., and McClelland, J.L., Eds.andP;  ParallelandM;Distributed Processing: Explorations in theandM;MicrostructureandM;of Cognition.andP;  Vol.andP;  1, Foundations.andP;  MITandM;Press/Bradford Books, Cambridge, Mass., 1986.andM;31,   Sabot, G.W.andP;  The Paralation Model.andP;  The MIT Press,andM;Cambridge, Mass., 1988.andM;32.andP;   Silberschatz, A., and Peterson, J.L.andP;  Operating SystemandM;Concepts.andP;  Addison-Wesley, Reading, Mass.,andM;1988.andM;33.andP;   Ullman, J.D.andP;  Principles of Database Systems.andP;  2d ed.andM;Computer Science Press, Inc., Rockville, Md.,andM;1982.andM;34.andP;   Whiddett, D. Concurrent Programming for SoftwareandM;Engineers.andP;  Ellis Horwood Ltd., Chichester, GreatandM;Britain, 1987.andM;Additional ReferencesandM;35.andP;   Akl, S.G.andP;  The Design and Analysis of ParallelandM;Algorithms.andM;Prentice Hall, Englewood Cliffs, N.J.,andM;1989.andM;36.andP;   Bach, M.J.andP;  The Design of the UNIX Operating System.andM;Prentice Hall, Englewood Cliffs, N.J.,andM;1986.andM;37.andP;   Berstein, A.J.andP;  Program analysis for parallelandM;processing.andM;IEEE Trans.andP;  Elect.andP;  Comput.andP;  EC-15, 5 (Oct.andM;1966), 757-762.andM;38.andP;   Bustard, D., Elder, J., and Welsh, J. ConcurrentandM;Program Structures.andP;  Prentice Hall, EnglewoodandM;Cliffs, N.J., 1988.andM;39.andP;   Chandy, K.M., and Misra, J. Parallel ProgramandM;Design: A Foundation.andP;  Addison-Wesley, Reading,andM;Mass., 1988.andM;40.andP;   Cherry, G.W.andP;  Parallel Programming in ANSI StandardandM;Ada.andP;  Reston Press, Reston, Va., 1984.andM;41.andP;   Coffman, E.G., and Denning, P.J.andP;  Operating SystemsandM;Theory.andP;  Prentice Hall, Englewood Cliffs,andM;N.J., 1973.andM;42.andP;   Crichlow, J.M.andP;  An Introduction to Distributed andandM;Parallel Computing.andP;  Prentice Hall, EnglewoodandM;Cliffs, N.J., 1988.andM;43.andP;   Desrochers, G.R.andP;  Principles of Parallel andandM;Multiprocessing.andM;Intertext Publications, Inc., McGrawandM;-      Hill Book Company, New York, 1987.andM;44.andP;   Hoare, C.A.R.andP;  Monitors: An operating systemandM;structuring concept.andP;  In Concurrent Programming,andM;N. Gehani and A.D.andP;  McGettrick, Eds.andP;  AddisonandM;-      Wesley, Reading, Mass., 1988 pp.andP;  256-277.andP;  (FirstandM;published in Commun.andP;  ACM 17, 10 (Oct.andP;  1974),andM;549-557.)andM;45.andP;   Hsieh, C.S.andP;  Further comments on implementationandM;of general semaphores.andP;  Oper.andP;  Syst.andP;  Rev.andP;  23, 1andM;(jan.andP;  1989), 9-10.andM;46.andP;   Jamieson, L.H., Gannon, D.B., and Douglass, R.J.,andM;Eds.andP;  The Characteristics of Parallel Algorithms.andP;  TheandM;MIT Press, Cambridge, Mass., 1987.andM;47.andP;   Krakowiak, S. Principles of Operating Systems.andM;The MIT Press, Cambridge, Mass., 1988.andM;48.andP;   Lister, A.M.andP;  Fundamentals of Operating Systems.andM;3d ed.andP;  Springer-Verlag, New York, 1984.andM;49.andP;   Lorin, H. Parallelism in Hardware and Software:andM;Real and Apparent Concurrency.andP;  Prentice Hall,andM;Englewood Cliffs, N.J., 1972.andM;50.andP;   Lusk, E., Overbeek, R., et al.andP;  Portable ProgramsandM;for Parallel Processors.andP;  Holt, Rinehart and WinstonandM;Inc., New York, 1987.andM;51.andP;   Madnick, S.E., and Donovan, J.J.andP;  Operating Systems.andM;McGraw-Hill, New York, 1974.andM;52.andP;   Milenkovic, M. Operating Systems Concepts andandM;Design.andP;  McGraw-Hill, New York, 1987.andM;53.andP;   Raynal, M. Distributed Algorithms and Protocols.andM;John Wiley andamp; Sons, New York, 1988.andM;54.andP;   Reed, D.P., and Kanodia, R.K.andP;  SynchronizationandM;with event counts and sequencers.andP;  Commun.andM;ACM 22, 2 (Feb.andP;  1979), 115-123.andM;55.andP;   Theaker, C.J., and Brookes, G.R.andP;  A PracticalandM;Course on Operating Systems.andP;  Springer-Verlag,andM;New York, 1983.andM;56.andP;   Turner, R.W.andP;  Operating Systems Design andandM;Implementations.andM;Macmillan, New York, 1986.andM;57.andP;   Yuen, C.K.andP;  Essential Concepts of Operating Systems.andM;Addison-Wesley, Reading, Mass., 1986.andM;EpilogueandM;Now that you have reviewed this self-assessment procedure and have comparedyour responses to those suggested, you should ask yourself whether this hasbeen a successful educational experience.andP;  The Committee suggests that youconclude that it has only if you have -discovered some concepts that you didnot previously know about or understand, or increased your understanding ofthose concepts that were relevant to your work or valuable to you.andO;</TEXT></DOC>