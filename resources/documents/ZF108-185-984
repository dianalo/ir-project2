<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-185-984  </DOCNO><DOCID>08 185 984.andM;</DOCID><JOURNAL>Datamation  Feb 15 1990 v36 n4 p119(3)* Full Text COPYRIGHT Cahners Publishing Co. 1990.andM;</JOURNAL><TITLE>Hallmark's formula for quality. (Hallmark Cards Inc.'s approach tosoftware quality) (includes a related article on the Japanesejust-in-time manufacturing philosophy) (company profile)</TITLE><AUTHOR>Johnson, James R.andM;</AUTHOR><SUMMARY>Hallmark Cards Inc makes software developers responsible for thequality of the programs they develop rather than a separatequality assurance department and uses concepts borrowed from theJapanese just-in-time (JIT) manufacturing philosophy, includingline management control, correcting one's own errors, continuouserror detection and easy-to-see quality.andP;  The company'smainframe-based operation uses COBOL to develop and maintainsystems for finance, marketing, order processing, distribution,personnel, manufacturing and other strategic corporate systems.andO;The Systems Development Department employs 200 professionals andgenerates between 40 and 60 products annually; the productsaverage 35,000 lines of code, 300 to 400 function points and 400to 500 worker-days to produce.andP;  The operation of Hallmark's'software factory' and its approach to quality assurance aredescribed.andM;</SUMMARY><DESCRIPT>Company:   Hallmark Cards Inc. (data processing).andO;Topic:     Programming ManagementProgram Development TechniquesApplicationsSoftware QualityQuality ControlApplications ProgrammingProject Management.andO;Feature:   illustrationtable.andO;Caption:   How JIT principles can improve software quality. (table)Hallmark's quality measurements. (table)How three projects fared. (table)andM;</DESCRIPT><TEXT>Hallmark's Formula For QualityandM;What is poor quality in software?andP;  It can be defined as unacceptable softwareperformance; user dissatisfaction with an interface; missing or incorrectfunctions; many errors, program bugs and other implementation problems; ormaintenance headaches.andM;Hallmark Cards Inc. had adopted an approach to quality assurance that focuseson what is called &quot;operational quality,&quot; or sometimes &quot;technical quality,&quot; asopposed to functional quality.andP;  In line with this, the Kansas City, Mo.-basedgreeting card giant assigns responsibility for quality to the softwaredevelopers themselves and not to a separate quality assurance (QA)department.andP;  Hallmark identifies this approach with certain Japanesejust-in-time (JIT) manufacturing techniques, including line managementcontrol, correcting one's own errors, continuous error detection andeasy-to-see quality.andM;Hallmark's computing environment is a large mainframe-based operation usingCOBOL, which builds and maintains strategic corporate systems for functionalareas like finance, marketing, order processing, distribution, personnel andmanufacturing.andP;  The Systems Development Department is what Hallmark calls asoftware factory, consisting of more than 200 professionals generatingbetween 40 and 60 products per year, 95% of them from scratch.andP;  The averageproduct requires 400 to 500 man-days to produce, consists of 35,000 lines ofcode and has 300 to 400 function points.andM;The phrase &quot;software factory&quot; applies to the manufacture of programs; morespecifically, to programming system products or documented, integratedbusiness applications.andP;  Hallmark's term for this product is a &quot;productionsystem,&quot; by which is meant a product that requires creator independence andallows end-user modification for routine operation via tables or parameters.andM;Furthermore, the term &quot;production system&quot; has the following descriptiveattributes: it is documented, is integrated with other production systems,has a significant number of data fields (over 100), involves complexprocessing, is used by a number of people, requires a major effort to develop(at least two man-years) and has a significant number of input/output(screens, reports, etc.) elements.andM;In Hallmark's software factory, the project team is responsible for qualitycontrol; a separate quality organization does not exist.andP;  Also, thedevelopers have post-implementation responsibility: maintenance is nottransferred to a separate group immediately after implementation.andM;Years ago, after one particularly poor implementation, Hallmark consideredcreating a separate QA organization.andP;  However, improved testing procedures,created by the project group concerned, solved the implementation problem.andO;The end users, who were not satisfied with the quality of the system either,agreed that the proposed testing methods, which included creating a duplicatesystem for parallel testing, were adequate.andP;  Subsequent results have proventhem correct.andM;This is not to imply that every IS organization should forego establishing aseparate QA department, of course.andP;  The advantage of having an outsider checkthe less obvious and less frequently used features of a system has merit.andO;Also, an organization with an inexperienced staff or with obsolete,antiquated methodologies may not have a successful track record.andP;  Thus,having an independent group test the software is a safe way to improved theproduct.andP;  But if an experienced staff organization has proven methods and aseries of successes, then giving that staff complete responsibility forquality is a motivating factor.andP;  And the principle of allowing linemanagement to be in control will work.andM;The Necessity of a Written PlanandM;At Hallmark, the success and quality of a project implementation is directlyrelated to the quality of the system test plan.andP;  For critical projects, aformal written plan is a requirement.andP;  For less critical projects, Hallmarkemploys an informal written plan.andP;  The company has defined four primarytesting levels: unit, integration, system and user acceptance.andP;  The formalwritten test plan encompasses the last three levels.andP;  The followingdefinitions explain these primary tests:andM;* Unit.andP;  Testing of all logic paths in the programs with generated (test) orproduction data to ensure correctness of individual programs.andM;* Integration.andP;  Coordinated testing of multiple programs with generated orproduction data.andP;  The purpose is to ensure correctness of individualprograms.andM;* System.andP;  Execution of the system in a production-like environment to ensurethat the system operates properly from both program and proceduralstandpoints.andM;* User Acceptance.andP;  User's participation in planning and testing, as well asin in-putting test data and reviewing the results.andP;  Ensures that the userunderstands the system's operational requirements, capabilities anddeliverables.andP;  The user acceptance test may be part of the system test.andM;Other test plans, such as disaster recovery or volume tests, are performed asneeded.andM;The written test plan includes an overview, a test plan procedure, test plandetails, conversion plan and an appendix.andP;  The level of detail in the testingrequired by the plan may vary considerably from one system to another.andP;  Foreach primary testing level, the plan should call for testing divided intocycles, such as a daily cycle, a weekly cycle, a monthly cycle, etc.andP;  Eachcycle is then divided into steps made up of setting up test cases andpredictions of expected results.andP;  Including the name of the individualassigned to specific tests may also be appropriate.andP;  Details of theconditions to be tested for each step are usually placed in the appendix.andM;Who teaches the staff how to write a good test plan?andP;  Hallmark's approach isto circulate the best written plans to all project groups.andP;  Thus, incrementalimprovements in writing test plans and in the testing itself have occurredover the years.andM;Using a computer-aided software engineering methodology, which automatesstructured design and programming activities, can obviously also improvequality.andP;  But even for those companies that have both the upper CASE analysisand design tools and the lower CASE code generator systems in operation, awritten system test plan technique is a useful complement to the CASE tools.andM;How To Measure QualityandM;To determine quality, measurements and reports must exist.andP;  Hallmark'sapproach is to use a problem management system linked to quality measures anda post implementation procedure to analyze projects.andP;  Under the problemmanagement system, all technical problems (programming, procedural, data,hardware, etc.) are documented in an Unusual Condition Report (UCR).andP;  EachUCR represents and records a single problem.andM;For example, the UCRs for all systems installed during 1988 were recorded foran arbitrary three-month period following their installation.andP;  After thethree-month period, each system is considered to be in maintenance.andP;  Asexpected, more errors occurred during the installation period than inmaintenance.andM;Hallmark computers technical quality for its systems using a quantitativeformula: the number of lines of code (LOC) in a system divided by the numberof UCRs issued for that system, yielding a ratio.andP;  The higher the ratio, thehigher the quality of the product.andM;The table, &quot;Hallmark's Quality Measurements,&quot; shows the combined ratio forall of the 1988 projects.andP;  The ratio reflects the operational quality of thesystems produced and the thoroughness of project installation planning.andP;  Thismeasure does not measure user functionality or how the system contributes tothe goals of the corporation, however.andP;  Is the ratio fair?andP;  The denominator,number of UCRs, is an independently recorded factor for all projects.andP;  Butwhat if the numerator, LOC, is inflated?andP;  Each organization must verify thevalidity of its LOC statistics.andP;  Still, extreme emphasis can result innegative ramifications.andP;  Hallmark uses this formula primarily as an internalmeasure of its own IS performance.andP;  No single quality measure is usedindependent of anything else.andM;The objective in 1988 was for all systems was to exceed 8,000 LOC per UCR.andO;Three projects, ranging in size from 319 to 1,044 man-days, are listed in thechart entitled &quot;How Three Projects Fared.&quot;andP;  Since the quality ratios varydramatically (5,360 to 59,400) among projects, is it a reasonable measure?andO;By itself, without amplifying information, probably not.andP;  Those viewing theresults might ask, How critical were the errors?andP;  Did external dates force anabbreviated test?andP;  Was extensive parallel testing possible?andP;  Were antiquatedsystems changed?andP;  However, from a technical standpoint, all things beingequal, the project manager of project C produced a very high-quality system,almost seven times over the 8,000 LOC/UCR objective.andM;Monitoring UCRs in the maintenance stage is the objective of a second qualityratio measurement.andP;  This figure measures the general operational quality of asystem after installation.andP;  The maintenance measure concentrates on thesupport function, which includes production fixes and enhancements that takeless than 75 man-days.andP;  (Enhancements that take longer than 75 man-days wouldprobably be classed as a separate project.)andP;  Only UCRs caused by the SystemsDevelopment Department are counted.andP;  Other problems, are excluded.andM;For some installations, improving operational quality might be the primaryobjective of the performance measurement program.andP;  However, under Hall-mark'ssystem, operational quality has been considered to be more than acceptableover the past few years.andP;  For example, in 1988 only one UCR was issued forevery 12,000 LOC installed.andP;  The general objective was to hold steady orincrease above the 12,000 level for the maintenance quality measure.andM;The Post Implementation AuditandM;Post implementation audits provide a database to assess quality.andP;  About halfof the projects completed receive an audit by internal personnel (thoseemployed by the software factory versus external auditors).andP;  Some typicalquestions for performing a post-implementation audit are:andM;* How well has the installed system performed in the production environment?andM;* Was the system easy to use?andM;* Were the users satisfied with the system's capabilities?andM;* How many enhancements have been requested?andM;* Has Systems Development been able to support the system easily?andM;* Has the Data Center been able to meet the production schedule?andM;* How many UCRs were written during the first three months afterinstallation?andM;For example, one recent system at Hallmark has performed very well inproduction; only three UCRs were written during the first three months afterinstallation.andP;  The users find the system easy to use and are satisfied withits capabilities.andP;  The minor enhancements requested have been installed inless than five man-days.andM;Although many companies use conventional quality control departmentssuccessfully, our approach links Japanese manufacturing principles to thesoftware development and maintenance process (motivation, learning, removingerrors and measuring).andP;  By assigning responsibility for quality directly toproject managers, line management becomes responsible for correcting errorsand for final system quality.andP;  A thorough testing procedure specified by awritten plan for system and acceptance tests assures continuous errordetection.andP;  Production problem metrics and post-implementation audits promoteeasy-to-see quality.andP;  This approach many not apply to every organization, butit does work for Hallmark.andM;James R. Johnson is data center manager at Hallmark Cards.andP;  He is the authorof The Software Factory: Managing Software Development and Maintenance.andM;Johnson, James R., The Software Factory: Managing Software Development andMaintenance, (Wellesley, Mass.: QED Information Sciences Inc., 1989).andM;Schonberger, Richard J., Japanese Manufacturing Techniques: Nine HiddenLessons in Simplicity (New York: The Free Press 1982).andO;</TEXT></DOC>