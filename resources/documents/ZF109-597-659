<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF109-597-659  </DOCNO><DOCID>09 597 659.andM;</DOCID><JOURNAL>Communications of the ACM  Nov 1990 v33 n11 p88(11)* Full Text COPYRIGHT Association for Computing Machinery 1990.andM;</JOURNAL><TITLE>SCISOR: extracting information from on-line news. (System forConceptual Information Summarization, Organization and Retrieval)(Computing Practices)</TITLE><AUTHOR>Jacobs, Paul S.; Rau, Lisa F.andM;</AUTHOR><SUMMARY>The System for Conceptual Information Summarization, Organizationand Retrieval (SCISOR) is a prototype system that carries outquestion answering and text analysis in constrained domains.andO;SCISOR selects and analyzes stories from an on-line financialservice and processes news at the rate of about six stories perminute.andP;  The system has also been ported to obtain informationfrom other kinds of messages in different subject areas.andP;  SCISORsymbolizes one vision of the future of natural language textprocessing.andP;  The system's design combines artificial intelligence(AI), knowledge representation, natural language processing andinformation retrieval techniques with word-based text search andlexical analysis.andP;  This design strategy uses the broadfunctionality of AI without sacrificing processing speed orrobustness.andP;  SCISOR design and operation is discussed in detail.andM;</SUMMARY><DESCRIPT>Topic:     Artificial intelligenceOn-Line SearchingText Data BasesBottom-Up DesignTop-Down DesignInformation Storage and RetrievalNew Technique.andO;Feature:   illustrationdiagram.andO;Caption:   SCISOR information flow. (diagram)Filter topic analyzer. (diagram)Integrating bottom-up and top-down analysis. (diagram)andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>SCISSOR: Extracting Information from On-line NewsandM;New technologies, such as high-speed networks, inexpensive massive storage,and optical-character readers, have combined to produce a sharp increase inthe availability of on-line text.andP;  The overflow of information demandsadvanced techniques for organizing and accessing texts, including theautomatic extraction of selected information from on-line sources [9].andM;Taking advantage of text information in many applications requires more thanwhat text retrieval systems can offer, including higher accuracy inconstrained domains as well as a broader range of information retrievalcapabilities.andP;  Most text retrieval methods use potentially complex booleanqueries with systems that perform word-based statistical matching and produceinadequate, albeit state-of-the-art, results [1].andP;  Although automaticfull-text retrieval systems are more accurate than manually indexed retievalsystems [17], the typical precision rate one can expect is 75 percent with arecall rate of 20 percent.andP;  While the widespread commercial applications ofthese methods demonstrates their usefulness, they are inaccurate andunsuitable for many tasks.andP;  The systems often require users to readirrelevant texts as well as relevant ones and cannot perform functions thatdemand an analysis of the content of the documents, such as textsummarization and the automatic generation of databases from texts.andM;The System for Conceptual Information Summarization, Organization, andRetrieval (SCISOR) is a prototype system that performs text analysis andquestion answering in constrained domains.andP;  Developed over the last fouryears, SCISOR operates on financial news, selecting and analyzing storiesabout corporate mergers and acquisitions from an on-line financial service(Dow Jones[TM]).andP;  It runs in real time on a Sun[TM] workstation in CommonLisp (Lucid) under UNIX[TM].andP;  It has also been ported to extract informationfrom other types of messages in various subject areas.andM;SCISOR processes news at the rate of about six stories per minute.andP;  Itperforms the following tasks:andM;* The lexical analysis of the input character stream, including names, dates,numbers, and contractions.andM;* The separation of the raw news feed into story structures, with separateheadline, byline, and dateline designations.andM;* A topic determination for each story, indicating whether it is about acorporate merger, acquisition, or other topic;andM;* The natural language analysis of each selected story using an integrationof two interpretation strategies--&quot;botton-up&quot; linguistic analysis and&quot;top-down&quot; conceptual interpretation.andM;* The storage and retrieval of conceptual representations of the processedtexts into and out of a knowledge base.andM;The design of SCISOR combines artificail intelligence (AI) methods,especially natural language processing, knowledge representation, andinformation retrieval techniques, with more robust but superficial methods,such as lexical analysis and word-based text search.andP;  This approach providesthe broad functionality of AI systems without sacrificing robustness orprocessing speed.andP;  In fact, the system has a throughput for real text greaterthan any other text extraction system we have seen (e.g., [18, 19]), whileproviding knowledge-based capabilities such as producing answers to Englishquestions and identifying key conceptual roles in the text (such as thesuitor, target, and per-share price of a merger offer).andP;  SCISOR consists ofroughly 50,000 lines of Common Lisp code.andP;  It was developed entirely on Sunworkstations.andM;The rest of this article will present a brief overview of SCISOR and samplesof SCISOR in operation, with the reasons behind many of the design choices inthe system.andP;  The discussion will give details on each of the major componentsof the system, followed by the results achieved in experimenting with SCISORand an analysis of the methods available for evaluating these results.andM;System DesignandM;SCISOR's design provides each system component with access to a rich,hand-coded knowledge base, but each component applies the knowledgeselectively, avoiding the computation that a complete analysis of each textwould require.andP;  The architecture of the system allows for levels of languageanalysis, from rough skimming to in-depth conceptual interpretation.andM;Figure 1 shows the information flow in SCISOR.andP;  Input texts feed in from thenews service.andP;  The prefilter program distinguishes headlines and otherstructured information from the stories.andP;  The filter component (or topicanalyzer) selects stories about mergers and acquisitions and performs thelexical analysis of names, dates, numbers, and other special inputs.andP;  Thenatural language components, using a combination of language-driven(bottom-up) and conceptual (top-down) analysis, process the takeover texts,identifying key roles such as target, suitor, and price, as well as otherfeatures like financing, company products, or legal complications.andP;  Theresult of this analysis is a single representation of each story that theprogram adds to a central knowledge base.andP;  The conceptual retrieval componentaccess information in this knowledge base by analysis English questions inthe same manner and matching the questions to the story representationsstored in the knowledge base.andP;  Later we will give more details on each of theprocesses.andM;SCISOR provides the user with information in multiple forms.andP;  Users canbrowse the headlines and the original texts.andP;  A &quot;hot window&quot; continuouslydisplays the target, suitor, and price of the latest takeover stores, and itflashes when a new takeover story comes across the newswire.andP;  For moregeneral information needs, an &quot;ask question&quot; window allows the user to typein simple English questions (e.g., &quot;What was offered for Polaroid?&quot;) as wellas query fragments (e.g., &quot;acquisitions by Shamrock&quot;).andM;Figure 2 shows a Sun workstation screen during the operation of SCISOr.andP;  The&quot;Master Control&quot; window in the lower right allows the user to open or accessthe various features of the system.andP;  The &quot;Healines&quot; and &quot;Display Control&quot; inthe lower center show the headlines of all stories (with headlines oftakeover stories in bold) and guide the selection of texts for browsing.andP;  The&quot;Hot Window,&quot; or alert feature, is at the lower left, alerting users at themoment a new, potentially relevant article comes across the newswire.andP;  The&quot;Raw Text&quot; and &quot;Trump Representation&quot; windows at the top display eachselected story, showing key portions of text in boldface with a summary ofthe language analysis in the upper right.andM;The windows all currently use Sun and Unix utilities such as tool-tool [14],less, and shell scripts.andP;  The Lisp process that performs the text and queryanalysis is hidden, often running on a different machine.andP;  This design makesthe natural language part of the system a &quot;server,&quot; processing the news andqueries while users browse the results.andP;  As a result, the system could beextended for many users to select, highlight, and retrieve differentinformation for each user according to that user's prescribed interests.andM;The main bottleneck with this approach presently is that the Lisp &quot;server&quot;process must be interrupted when any user asks an English question (sincethere is only one natural language program at work).andP;  Each question takes afew seconds to answer, so frequent interruptions might cause the textprocessing to lag slightly behind the news feed.andP;  These delays, however, arequickly recovered, as the natural language program is capable of performingits analysis of texts faster than news comes across the newswire.andM;This section has covered the overall design and look and feel of SCISOR.andP;  Thediscussion that follows will give the technical highlights of each of themajor components of the system.andM;The Topic AnalyzerandM;The topic analyzer, or filter, breaks up the steady stream of stories anddetermines whether a given story is about a merger or an acquisition.andP;  Thefilter applies a series of screening processes, increasing in the degree ofcomputational complexity and linguistic analysis, to weed out stores notrelated to the topic.andP;  The function of this component (to decide to includeor exclude a document from the set of selected documents) is similar totraditional information retrieval; however, the design is unusual in threeimportant ways.andM;First, it was built with a modular architecture to support its primaryfunction as an experimental research vehicle.andP;  This design supports theplugging in of new algorithms to filter the stories at any stage in thefiltering process.andP;  Programs automatically compare the results againstprevious system configurations.andP;  Second, some general knowledge aboutlinguistic structure (such as the relationship between verbs and objects)augments word-based statistics.andP;  Finally, the analyzer relies on negative aswell as positive information, eliminating articles that are not abouttakeovers in order to increase precision while not missing any takeoverstories.andM;By the final stages of the filter, about 10 percent of the total incomingstories relate to mergers and acquisitions, with slightly over 90 percent(combined recall and precision) accuracy.andP;  When a story appears in the &quot;hotwindow,&quot; it not only must relate to an acquisition but must identify either atarget or suitor (thus excluding divestitures, strategic holdings, orcorporate buybacks of stock).andM;Figure 3 illustrates one successful combination of filtering processesapplied by the topic analysis program in its analysis of the newswire.andP;  Thecorrect classifications in all of our experiments are those made by oneperson.andP;  We estimate about a 10 percent margin of error caused by differencesin classification of the stories' subjects by various people.andP;  The numbersthat appear after the labels in the layers indicate the number of stories ina randomly selected day of news stories that passed through each stage of thefilter.andM;The filter is too complex a program to describe fully here; more details canbe found in [15].andP;  The discussion that follows provides some basicinformation on the primary methods of filtering stories.andM;The first processing stage the filter uses breaks the news feed intostructures consisting of a headline, optional byline, story, and dateline.andO;Some headlines indicate recurrent update stories that can be immediatelydiscarded, such as &quot;DOW JONES STOCK AVERAGES&quot; or &quot;NYSE MOST ACTIVES.&quot;andO;Stories that begin with these present headlines are known with 100 percentcertaity not to be about the topic of takeovers.andM;After this headline filtering, the program applies keywords first to just theheadlines of the articles, then to just the articles, and then to both theheadlines and the articles together.andP;  Keyword filtering looks for thepresence of certain prespecified keywords, such as buy, merger, andacquisition, to signal that a story could be about a takeover.andP;  There arecurrently about 150 keywords used during this stage.andP;  Each keyword has aweight associated with it, and each article has a threshold determined by thelength of the article and the total number of keywords in the article.andP;  Thesenumbers are determined automatically after a user selects sample storiesabout the subject.andM;After keyword analysis, a pattern-matching process scans only those storiesthat pass through these first stages, applying both positive patterns(indicating the story is about the subject), and negative patterns(indicating that the story is not about the topic).andP;  For example, a storyincluded on the basis of a positive keyword such as buy may be discardedbecause of a negative pattern such as buy side or buy andamp;andamp;andamp; debt obligations,if there is no other positive evidence to outweigh this.andP;  In this example,the andamp;andamp;andamp; indicates where the pattern will match some small number ofintervening words.andP;  For example, a sentence that contained the words BUYFOREIGN DEBT OBLIGATION would match this pattern.andP;  The total score for astory is the sum of the scores for positive (confirming) patterns minus thesum of the scores for negative (refuting) patterns.andM;The most computation-intensive stage of the filter takes as input thosestories that the previous stages could not definitely categorize and subjectsthose stories to linguistic and conceptual analysis.andP;  This process, forexample, can use knowledge that the conceptual $Iobject$N of a takeover is acompany in order to determine that a story about the sale of the Sears Toweris not a takeover story.andM;Bottom-up and Top-downandM;Analysis:  TRUMP andandM;TRUMPETandM;Scisor's text-processing algorithm is one of two features that sets it apartfrom other natural language programs (the knowledge) base design, describedlater in this article, is the other).andP;  Text processing in SCISOR combines twoanalysis strategies--bottom-up, language-driven interpretation, and top-down,expectation-driven processing.andP;  Bottom-up analysis starts with a parse ofeach sentence, identifying linguistic structures into a conceptual framework.andO;Top-down analysis starts with conceptual expectations, such as the knowledgethat takeovers involve two companies, and tries to fill these expectationsgiven partial information from the text.andM;Each of the two processing strategies has strengths and weaknesses.andO;Bottom-up analysis [4-6]uses knowledge about language and can produceaccurate, if only partial results, in arbitrary texts and texts that containunexpected information.andP;  Top-down analysis [3, 13] is much more tolerant ofunknown words and grammatical lapses, but is often fooled or missesinformation in unusual situations.andP;  For example, top-down analysis may havetrouble understanding a story involving the so-called &quot;Pac Man&quot; defense wherea smaller company, in response to an unwanted takeover offer, turns thetables and attempts to take over the hostile suitor.andP;  The top-down strategymight cause a system to assume that a company must be either a target orsuitor in a given takeover story (but not both) and rely on that assumptionto fill in these roles.andM;Processing in the SCISOR domain seems to require the combination of the twostrategies.andP;  The language of financial news is rich enough to require a depthof linguistic knowledge in order to accurately identify targets and suitors,but it is also constrained enough that top-down analysis can aid theinterpretation task.andP;  For example, the sentence &quot;Acme initiated an offr&quot;places Acme in a different role from &quot;Acme rejected an offer.&quot;andP;  Onlyknowledge about language, including grammatical and lexical information, canaccurately determine whether Acme is the target or suitor in this sort ofexample.andP;  Because of the specifics of corporate takeovers, however, (e.g.,andO;that there are typically two companies involved, one a target and one asuitor), it is reasonable to assume that some company mentioned in a mergerstory is either a target or a suitor.andP;  This top-down information often helpsto fill in a missing role where the bottom-up component is only able to fillone.andP;  For example, in the headline &quot;Kimberly Clark Up, Rumor Perelman MakingBid Tonight&quot; (Dow Jones, Oct. 5, 1988), the correct interpretation (withKimberley Clark as the target) stems from the top-down assumption that itmust be since it is not the suitor.andP;  Also lending credence to this assumptionis the expectation that the target of the takeover is typically the samecompany whose stock rises.andM;The manner in which top-down and bottom-up analysis interact in SCISORdistinguises the system from some other programs that are otherwise quitesimilar.andP;  For example, FRUMP [3], IPP [12], and POLITICS [2] were all systemsthat processed news stories and claimed to be integrated and extensible.andO;SCISOR gives considerably more weight to linguistic knowledge than any ofthese systems and can even produce a fair amount of syntactic and semanticinformation from a text in a completely new domain.andP;  Another difference is inthe degree to which the systems have actually been extended; handling avolume of hundreds of texts per hour in multiple domains requires morerobustness than these earlier systems exhibited, although they were allsignificant in their time.andM;The bottom-up analyzer of SCISOR, TRansportable Understanding MechanismPackage (TRUMP) [7] is a general-purpose parser and semantic interpreter thatapplies knowledge about language to the task of producing a conceptualinterpretation.andP;  TRUMP derives a frame-like semantic representation of eachphrase or sentence, taking into account word meanings and surface structuresbut not domain-specific knowledge.andP;  TRUMP Expectation Tool (TRUMPET) performsthe top-down component of analysis, matching TRUMP's conceptual structureswith expectations.andP;  For example, TRUMP will analyze the input &quot;Ace receivedan offer from Acme&quot; to identify the offerer and offeree whie TRUMPET relatesthose roles to the target and suitor of an acquisition.andP;  More detail on theintegration of these two language-processing mechanisms is found in [16].andM;Figure 4 shows an example of the combination of language analysis strategies.andO;The input sentence is &quot;Revere said it had received an offer from aninvestment group to be acquired for $16 a share, or about $127 million.&quot;andO;TRUMP understands all the words in the story, but through bottom-up analysisalone it cannot draw some of the required conclusions.andP;  For example, thephrase starting with &quot;to be acquired&quot; might attach to &quot;an investment group&quot;or &quot;an offer,&quot; but in this case &quot;Revere&quot; is the subject of the phrase.andP;  TRUMPlearns from TRUMPET that the offerer must be the same as the acquirer andthat the acquirer must be different from the acquiree, so &quot;Revere&quot; is theacquiree and therefore the target of the takeover.andP;  TRUMPET alsodistinguishes the per share value ($-per-share-price) from the total value ofthe acquisition.andM;As TRUMP scans the input text, it looks ahead for words that link to concepsassociated with expectations in TRUMPET's knowledge base and then usessyntactic knowledge to draw boundaries in the text where information from thetext modifies key concepts.andP;  Determiners (e.g., &quot;the&quot; and &quot;a&quot;), coordinatingconjunctions (e.g., &quot;and&quot; and &quot;or&quot;), and certain punctuation (e.g., colon,semicolon, or parenthesis) help to determine these boundaries by definitivelymarking the beginning or end of a phrase.andP;  This preliminary segmentation ofthe text serves three purposes.andM;(1) It makes the parser faster by allowing it to skip sections of the textthat are irrelevant or too complex.andM;(2) It determines roughly where the bottom-up component should prevail overexpectations, that is, where there are strong linguistic preferences.andM;(3) It highlights in boldface type the crucial segments of the raw text inputfor display to the user.andM;Language analysis perfoms several functions in SCISOR: it is the final stageof the filtering process.andP;  If the combination of analysis strategies cannotaccurately determine a target or suitor, this is usually evidence that thetext is not about a takeover.andP;  The analyzer also helps in the text-browsingfacility by highlighting relevant portions of text.andP;  Then it directs keyfeatures of the text into the &quot;hot window.&quot;andP;  Finally, the synthesized resultsof the language analysis, including the role that each company plays in atakeover, become part of SCISOR's conceptual knowledge base.andM;Story Storage andandM;RetrievalandM;After TRUMP and TRUMPET have completed an analysis of a story, SCISOR storesthe conceptual representation of the story as a network of unique instancesin long-term memory.andP;  The instances are individual members of conceptualcategories, such as companies, offers, and mergers, and these serve asindices for information retrieval.andP;  Figure 5 shows a representation of aportion of a takeover story involving the companies Bruck Plastics and M. A.andO;Hanna, with the constituent instances in boldface.andP;  The analysis of a user'squestions by TRUMP and TRUMPET produces a representation in a similar form,also shown in the figure.andM;Retrieval of an answer to an input question uses a conceptual graph-matchingalgorithm that ranks and compares the representation of the question torepresentations of stories.andP;  This process avoids excessive comparisons byusing a two-step method of conceptual retrieval.andP;  The first step is a rough,efficient comparison of features of the question with features of storedrepresentations of texts; the second pass is a more careful match ofrelationships that are asked for or implicit in the question.andP;  Figure 5, forexample, shows the retrieval process in response to the question: &quot;How muchwas Bruck Plastics sold for?&quot;andP;  This question relates to the answer &quot;Termswere not disclosed&quot; through the MERCHANDISE-TRANSFER category and theinheritance and refinement of the TENDER role of MERCHANDISE-TRANSFER to theTERMS role of a CORPORATE-TAKEOVER.andP;  The names of the companies are theprimary contributors to the retrieval of this network; however, any instancecan contribute to the retrieval of a candidate story.andM;After the system retrieves a set of candidate stories, the graph matchercompares the question and story representations and computes a score for eachcomparison.andP;  The semantics of the nodes and links in these representationsguide the determination of how the question matches parts of the story andhelps to determine the score for each match.andP;  For example, in Figure 5, thematch between the merchandise role in the question and the target role of thestory gets a high score.andP;  This matching process selects both the best story(for reference to the user) and the answer to the question, where applicable.andM;Other Features of SCISORandM;Many of the appealing features of SCISOR stem from its central knowledgebase, which the system components use to perform different levels ofanalysis.andP;  For example, the central system lexicon includes knowledge aboutwords and word meanings that applies to topic analysis, bottom-up andtop-down text processing, and response generation.andP;  This knowledge-baseddesign has helped the flexibility and transportability of the system.andM;Core Lexicon and LinguisticandM;KnowledgeandM;SCISOR uses a general lexicon of about 10,000 word roots, with about 75affixes (prefixes and suffixes) that can derive variations from those roots.andO;Each lexical entry includes the linguistic properties of a word root and aset of senses, which link to a core concept hierarchy of 1,000 generalconceptual categories from state-change (including many events and verbsenses) to animate-internal-part (including microbes, organs, and otheranatomical entities).andP;  This organization helps to apply the word knowledge inthe lexicon to new domains, either by adding new senses or refining existinglexical knowledge.andP;  In the domain of mergers and acquisitions, the corelexicon covers over 95 percent of word occurrences (exclusive of propernames).andP;  The Mandamp;A lexicon includes only 12 words outside of the core lexicon(such as debenture and CEO), although many words have preferred(domain-specific) senses.andP;  The domain knowledge also includes 23 lexicalcombinations (such as seek control and make a bid) and 32 specific concepts.andM;Text processing requires substantial lexical analysis beyond individualwords, such as handling proper names, special text structures and symbols,tables, abbreviations, numbers, and codes.andP;  SCISOR uses a lex-stylefinite-state based lexical analyzer for translating these inputs into astream of tokens, which often contribute to TRUMP's interpretation of a text.andO;In addition, the program uses a special multitoken analyzer for findingpreviously unknown company names in an input, the correctly identifies mostnew company names using special words such as &quot;Partners,&quot; &quot;Inc.,&quot; and &quot;Ltd.&quot;andO;Once the full name of a company has been identified, another special programgenerates potential variations of the company name such as its acronym orother abbreviated references.andP;  the new company and its potential variationsare then added to the company name database.andM;The TRUMP analyzer shares the entire linguistic knowledge base, including thelexicon and grammar, with a language generator called Knowledge INtensiveGenerator (KING) [8], which can produce English responses to questions.andP;  Inaddition to being more efficient than having separate knowledge bases, thissharing of linguistic knowledge assures that the different components of thesystem &quot;speak&quot; the same language; e.g., a specific phrase like &quot;tender offer&quot;in the vocabulary of the financial domain is available to the analysis andgeneration components.andP;  In the current system, responses to questions arequite simple; however, as the program expands, KING will become moreimportant in constructing summaries of complex events.andM;Portability to New DomainsandM;SCISOR has been designed for transportability, from the lowest level of thedesign of its knowledge base [10] to acquisition algorithms [11, 21] that canhelp to customize the system's lexicon and determine some of the meanings ofnew words in context.andP;  The system developers and several other locations inGeneral Electric have applied most of the system components to other domains.andO;Substantial prototypes (e.g., extracting thousands of conceptual structuresor database fields with high accuracy from hundreds of texts) in these otherapplication areas have required no more than a few person-months of effort.andM;Shortly after the completion of SCISOR, the program was ported from themergers and acquisitions domain to the domain of military OPREP-3 messages aspart of a government-sponsored effort to evaluate natural language systemscalled MUCK-II [19].andP;  The task in this domain involved the extraction of tenfeatures from over 200 messages, and we have collected results from portingSCISOR to this new task.andM;We estimate that it took approximately 40 person-days (1.3 person-months), toport the entire system to OPREP-3 messages.andP;  The time inccudes knowledgeengineering, system development, scoring of results, documentation of theeffort, and modification of the demonstration environment.andP;  Systemenhancements included the addition of a spelling checker and telegraphicparsing mode, broader recovery strategies for ill-formed input, acontext-switching mechanism, a concretion (or simple inference) mechanism,and a few domain-specific heuristics.andP;  Our success in porting the entiresystem to a very different application area with a minimum of effort makes usconfident of the system's general port-ability.andM;In addition to text-processing applications, TRUMP also serves as the naturallanguage front end to an organizational directory, called DEUCE (DirectoryExtraction Using Common English).andP;  Figure 6 shows some of the capabilities ofthis system, including handling pronoun references, abbreviations,contractions, and database joins.andP;  This application required a few months ofcustomization, mainly devoted to integrating the database package with thenatural language program.andM;In general, our preliminary estimates show that each new application requiresabout a 5 percent margin of labor from the original system.andP;  In other words,if an application uses tools that result from three person-years of effort,about two person-months suffice for a prototype in that application.andM;Performance EvaluationandM;It would be difficult and probably futile to perform a controlled study ofSCISOR against a traditional IR system, for two reasons.andM;(1) Traditional IR systems are tested on arbitrary, unconstrained texts,while natural language systems still work only in constrained domains.andM;(2) SCISOR performs many tasks other than document retrieval, such asextracting information from stories and directly answering users' questions.andM;Only the filter portion of the program has a set of documents as its output.andO;Comparing the filter with a traditional IR system would be possible if theinput to the IR system were a broad topic classification, such as &quot;takeoverstories&quot; or &quot;stories about stock buybacks.&quot;andP;  We have performed experiments todetermine the recall and precision of the filter under one topic area (seethe Topic Analyzer section) but have not compared these numbers with a searchof the same document set using other IR systems.andM;Evaluation problems of the entire system stem from the unique functionalityof the SCISOR system.andP;  Document retrieval systems, even sophisticated oneslike RUBRIC [20], do not extract features from the documents they retrieve;thus it is impossible to compare them to SCISOR.andP;  We have performed sometests, however, that do measure SCISOR's accuracy.andM;The government-sponsored MUCK-II [19] evaluation is, to our knowledge, themost meaningful test of natural language text processing, but theparticipants in the MUCK-II evaluation were not at liberty to release thespecific results of the experiment.andP;  We will try, however, to summarize thestatus of performance evaluation in general terms.andP;  Evaluation ofcontent-based, text-processing systems such as SCISOR is not nearly asestablished as evaluation methods in information retrieval.andP;  There are manytasks to be tested in this emerging type of system, including accuracy ofquestion answering, helpfulness of alerts, and coverage of structuredinformation (such as target and suitor).andP;  No mature methods exist for testingany of these tasks.andM;Aside from text categorization (as done by the filter component of SCISOR,which does somewhat resemble traditional IR), the easiest result to evaluateis the accuracy with which a system produces &quot;fixed field&quot; or &quot;fixed format&quot;information from free text.andP;  These results, however, depend on the difficultyof the texts, the nature of the fixed field information, and the method forscoring errors.andP;  Producing the results over a large set of texts is timeconsuming and may test the accuracy of the human solution keys as much as thesystem output.andM;In spite of the problems with evaluating this sort of system, we would liketo be informative about how our program performs.andP;  As a rule, it can extractkey features from large sets of constrained texts with 80-90 percent(combined re-call and precisions) accuracy.andP;  It can achieve better results(and has) with more constrained texts, but would also produce almost nothinguseful, for instance, in reading the entire Wall Street Journal.andP;  It isrealistic to expect 90 percent accuracy for certain a useful, carefullyconstructed tasks, and unrealistic to expect much higher than this.andP;  (1) Many difficulties in reading texts appear when trying to achieve betterresults, but the most common limitation seems to be the degree of realinference required for understanding.andP;  In spite of its fairly sophisticatedmethods for combining linguistic and world knowledge, SCISOR really has verylittle of the latter.andM;In a recent test of SCISOR, the program analyzed one day's worth of storiesdirectly from the newswire source.andP;  Of the 729 stories, the filter achievedslightly over 90 percent of averaged recall and precision in itsdetermination of which stories were about mergers and acquisitions (69 inall).andP;  SCISOR correctly identified the target and suitor in 90 percent of allthe stories.andP;  When dollar-per-share amounts of offers were present in thestories, SCISOR extracted this quantity correctly 79 percent of the time andthe total value of the offer 82 percent of the time.andM;Summary and ConclusionandM;SCISOR represents a prototype implementation of one vision of the future ofnatural language text processing, setting artificial intelligence techniquesin the context of an information retrieval problem.andP;  The program accuratelyprocesses financial news, selects items of interest, provides a userinterface that allows easy access to results, and extracts importantinformation in a structured form.andP;  This is all done with sufficientflexibility to port to new domains and applications.andP;  As the proliferation ofon-line text continues, we see this sort of text-based conceptual informationsystem at the heart of intelligent systems technology.andM;(1) The FRUMP [3] program, for comparison purposes, achieved 38 percentaccuracy in one test of unseen newswire stories.andM;ReferencesandM;[1] Blair, D.C., and Maron, M.E.andP;  An evaluation of retrieval effectivenessfor a full-text document retrieval system.andP;  Commun.andP;  ACM 28, 3(Mar.andP;  1985),289-299.andM;[2] Carbonell, J.andP;  Towards a self-extending parser.andP;  In Proceedings of the17th Annual Meeting of the Association for Computational Linguistics (LaJolla, Ca., Aug. 11-12).andP;  ACL, Menlo Park, Ca., 1979, pp.andP;  3-7.andM;[3] DeJong, G. Prediction and substantiation: A new approach to naturallanguage processing.andP;  Coq.andP;  Sci.andP;  3, 3(Mar.andP;  1979), 251-273.andM;[4h Grishman, R., and Hirschman, L. PROTEUS and PUNDIT: Research in textunderstanding.andP;  PROTEUS Proj.andP;  Memo.andP;  1, NYU, New York, 1986.andM;[5] Grishman, R., and Kittredge, R., Eds.andP;  Analyzing Language in RestrictedDomains: Sublanguage Description and Processing.andP;  Lawrence Erlbaum,Hillsdale, N.J., 1986.andM;[6] Hobbs, J.R.andP;  Site report: Overview of the TACITUS project.andP;  Comput.andO;Ling.andP;  12, 3(Mar.andP;  1986), 220-222.andM;[7] Jacobs, P.S.andP;  Language analysis in not-so-limited domains.andP;  InProceedings of the ACM-IEEE Computer Society Fall Joint Computer Conference(Dallas, Tx., Nov. 2-6).andP;  ACM and IEEE-CS, New York and Washington, D.C., pp.andO;247-259.andM;[8] Jacobs, P.S.andP;  Knowledge-intensive natural language generation.andP;  Artif.andO;Intel.andP;  33, 3(Nov.andP;  1987), 325-378.andM;[9] Jacobs, P.S., Ed.andP;  Proceedings of the AAAI Spring Symposium Series:Text-Based Intelligent Systems.andP;  The Amer.andP;  Assoc.andP;  for ArtificialIntelligence, (Palo Alto, Ca., 1990).andM;[10] Jacobs, P.S., and Rau, L.F.andP;  Ace: Associating language with meaning.andP;  InProceedings of the Sixth European Conference on Artificial Intelligence(Pisa, Italy, Sept. 5-7).andP;  AICA/AISB, pp.andP;  137-146.andM;[11] Jacobs, P.S., and Zernik, U.andP;  Acquiring lexical knowledge from text: Acase study.andP;  In Proceedings of the 7th National Conference on ArtificialIntelligence (St.andP;  Paul, Mn., 1988), pp.andP;  739-744.andM;[12] Lebowitz, M.andP;  Memory-based parsing.andP;  Artif.andP;  Intel.andP;  21, 4(Dec.andP;  1983).andM;[13] Lytinen, S., and Gershman, A. ATRANS: Automatic processing of moneytransfer messages.andP;  In Proceedings of the 5th National Conference onArtificial Intelligence (Philadelphia, Pa., 1089-1093.andM;[14] Musciano, C. Tooltool User's Guide.andP;  Advanced Technology Dept., HarrisCorp., 1989.andM;[15] Povinelli, R. Topic analysis: Filter.andP;  Tech.andP;  Rep., GE Corporate Randamp;D,Schenectady, N.Y., 1989.andM;[16] Rau, L.F., and Jacobs, P.S.andP;  Integrating top-down and bottom-upstrategies in a text-processing system.andP;  In Proceedings of the 2nd Conferenceon Applied Natural Language Processing (Morristown, N.J.andP;  ACL, Menlo Park,CA., 1988), pp.andP;  129-135.andM;[17] Salton, G.andP;  Another look at automatic text-retrieval systems.andP;  Commun.andO;ACM 29, 7(July 1986), 648-656.andM;[18] Sondheimer, N.andP;  Proceedings of DARPA's 1986 strategic computing naturallanguage processing workshop.andP;  Tech.andP;  Rep.andP;  ISI/SR-86-172, Univ.andP;  SouthernCalifornia, 1986.andM;[19] Sundheim, B.andP;  Second message understanding conference (MUCK-II) testreport.andP;  Tech.andP;  Rep.andP;  1328, Naval Oceans System Center, San Diego, Ca., 1990.andM;[20] Tong, R.M., et al.andP;  RUBRIC III: An object-oriented expect system forinformation retrieval.andP;  In Proceedings of the 2nd Annual IEEE Symposium onExpert Systems in Government (McLean, Va., Oct. 20-24).andP;  IEEE-CS, Washington,D.C., 1986, pp.andP;  106-115.andM;[21] Zernik, U.andP;  Lexical acquisition: Learning from corpus by capitalizing onlexical categories.andP;  In Proceedings of the 11th International JointConference on Artificial Intelligence (Detroit, Mi., 1989), pp.andP;  1556-1562.andM;PAU S. JACOBS is currently a computer scientist with the GE Research andDevelopment Center in Schnectady, NY.andP;  His current research interests includeinvestigation of natural language text skimming, lexicon development, andmethods for broad-coverage semantic interpretation.andM;LISA F. RAU is currently a computer scientist at G E Research and DevelopmentCenter.andP;  Her current research interests include advanced methods for memoryorganization and retrieval, integrated text processing, and conceptualinformation processing.andO;</TEXT></DOC>