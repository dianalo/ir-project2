<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO> ZF32-067-107 </DOCNO><DOCID>11 276 333</DOCID><JOURNAL>Communications of the ACM  Sept 1991 v34 n9 p122(1)* Full Text COPYRIGHT Association for Computing Machinery 1991.andM;</JOURNAL><TITLE>The not-so-accidental holist. (Inside Risks) (column)</TITLE><AUTHOR>Neumann, Peter G.andM;</AUTHOR><DESCRIPT>Topic:     Software engineeringSystem designSpecial Interest Group on SoftwareEfficiency.andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>The System ViewpointandM;We consider here the importance of an overall systems viewpoint in avoidingcomputer-related risks.andP;  According to Webster's, a system is a regularlyinteracting or interdependent group of items forming a unified whole.andP;  Incomputer systems, one person's components, may be another person's system,and one person's system may in turn be one of another person's components.andO;That is, each layer of abstraction may have its own concept of a system.andP;  Wespeak of a memory system, a multiprocessor system, a distributed system, amultisystem system, a networked system, and so on.andP;  A system design can mosteffectively be considered as a unified whole when it is possible to analyzethe interdependent subsystems individually and then to evaluate, reasonabout, and test the behavior of the entire system based on the interactionsamong the subsystems.andP;  This is particularly true of distributed systems thatmask the presence of distributed storage, processing, and control.andP;  At eachlayer of abstraction, it is desirable to design (sub)systems that arecontext-free, but in reality there may be subtle interactions that must beaccommodated--particularly those involving the operating environment.andM;One of the problems that we encounter throughout research, development, andindeed life is that we tend to compartmentalize our endeavors.andP;  Individualsbecome specialists in relatively narrow areas of expertise, often failing tosee the bigger picture.andP;  In many system developments there are times at whichit is crucial to bring together the different communities--people who reallyunderstand hardware, software, networks, and the intended applications, aswell as people who understand the importance of the human interface.andP;  In toomany cases these folks have not communicated with each other, resulting insystem glitches that illustrate Conway's Law: The organization of a systemdirectly reflects the organization of the group of people developing thesystem.andP;  For example, weaknesses in human communication typically begetanalogous weaknesses in computer communication.andP;  In other cases, it is onlyafter the occurrence of an accident or system failure that there is awarenessof certain hitherto invisible system interactions and the latent flaws thatthey may trigger.andM;Risks of Nonholistic ViewsandM;The Risks Forum annals contain numerous cases in which a failure to considerthe whole system resulted directly or indirectly in serious consequences.andO;The Hubble telescope problems are cited as such an example, in which nosystem tests were performed, only subassembly tests that succeeded becausethey satisfied an erroneous monitoring program.andP;  The October 1980 ARPANETcollapse and the January 1990 ATandamp;T long-distance slow-down (noted in previous&quot;Inside Risks&quot;) involved a confluence of hardware and software problems thathad not been adequately anticipated.andP;  Telephone problems in June 1991continued to demonstrate the intrinsic risks in making highly distributedsystems robust and efficient.andP;  The two-day delay in launching the firstShuttle resulted from a multicomputer clock synchronization problem thatcould not be detected locally.andP;  Many system and network penetrations haveresulted from a lack of a suitable system perspective on the part ofdevelopers, administrators, and/or users.andP;  In addition, the Challengerdisaster reminds us that the physical environment is also a vital part of thesystem.andM;There is a pressing need to integrate what is known about differentdisciplines.andP;  In some cases it is vital to accommodate different requirementssuch as reliability, availability, confidentiality, integrity, human safety,real-time performance, and massive throughput, and to do so simultaneouslyand dependably.andP;  It is recognized that sometimes these requirements are inconflict with one another, in which case sound engineering judgments becomeessential.andP;  In such cases, development methodologies, design languages, andgood programming practices cannot overcome the need for sage individuals witha suitably holistic system perspective.andM;OpportunitiesandM;The forthcoming ACM SIGSOFT '91 (Conference on Software for Critical Systems,New Orleans, Dec. 4-6, 1991) presents some of the pieces of the puzzle in anappropriately holistic context.andP;  That meeting is an attempt to unify thewidely diverse software engineering field with respect to the problems ofdeveloping critical systems--for which conventional programming, debugging,and testing techniques are often by themselves inadequate.andP;  (The preliminarytechnical program and other pertinent information are included in thisissue.)andP;  It is also encouranging to note the recent increase in conferencesthat span different ACM SIGs and other professional organizations, attemptingto get more interdisciplinary perspectives on the problems confronting us.andO;However, further efforts are needed to link all of the relevant communities,not just a few pairwise, and to get practical system and software engineeringapproaches into the daily lives of developers of critical systems.andO;</TEXT></DOC>