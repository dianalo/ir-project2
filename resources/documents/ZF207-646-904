<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-646-904  </DOCNO><DOCID>07 646 904.andM;</DOCID><JOURNAL>Communications of the ACM  Sept 1989 v32 n9 p1102(7)* Full Text COPYRIGHT Assn. for Computing Machinery, Inc. 1989.andM;</JOURNAL><TITLE>CASE productivity perceptions of software engineeringprofessionals. (computer-aided software engineering) (technical)</TITLE><AUTHOR>Norman, Ronald J.; Nunamaker, Jay F. Jr.andM;</AUTHOR><SUMMARY>Functional and behavioral aspects of computer-aided softwareengineering (CASE) are studied to determine its impact onproductivity over manual methods of software engineering.andP;  Thestudy focuses on the perceptions of management information systems(MIS) professionals, who felt their productivity improved throughthe use of CASE technology.andP;  The parts of a specific CASE productthat were perceived to provide the most productivity areidentified, as are those that offered the smallest improvements inproductivity.andP;  Several improvements are attributed to adherence tosystems development standards.andP;  Software engineering may be movinginto an era where CASE-like technology will be necessary for largesystems development.andM;</SUMMARY><DESCRIPT>Topic:     Computer-Aided Software EngineeringSystems ProgrammingSoftware EngineeringStudyProductivity.andO;Feature:   illustrationtable.andO;Caption:   Survey stimulus items. (table)CASE functions ranking (n=91). (table)SPSS-X ALSCAL MDS 3-dimensional solution. (table)andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>CASE Productivity PErceptions of Software Engineering Professionals As wemove closer to the 1990s, business and scientific software engineeringworkbench tools are becoming a pervasive market commodity.andP;  Perhaps the mostnotable methodology that is being supported by these automated tools is thestructured methodology and its many variants.andP;  Referred to as CASE, theseautomated tools represent many years of research on integrated developmentenvironments (IDE) [5, 8, 9, 12, 25].andP;  CASE can be viewed as an environmentthat supports the software engineering process.andM;It is estimated that thousands of medium and large enterprises are using CASEproducts as part of their system-building process based on the intuition thatthis is the way to go for improved productivity and system quality.andP;  Over thelast thirty years, software engineering has focused more on the software thatis closest to the machine such as compilers, operating systems, and databasemanagement systems, but is now moving rapidly into the problem solving domainof the software engineer (systems analyst).andM;Recent CASE advertisements suggest that users are reporting productivityimprovements ranging from 30 to 300 percent; however, we are not aware of anyempirical studies in the research literature that investigate CASE technologyor its effects on productivity.andP;  Our automated workbench tool-supportresearch dates back to PSL/PSA [18, 19] and SODA [15], and the motivation forthis research comes primarily from the discussions we have had with MISdirectors and managers who must make the decision to embrace currentgeneration CASE technology or continue looking beyond these CASE products.andO;This study was undertaken to investigate which functional and behavioralaspects of CASE technology, from the software engineer's point of view,contribute the most favorably toward increasing their productivity overcomparable manual methods.andM;THE RESEARCH METHODOLOGYandM;This study focuses specifically on the perceptions of management informationsystems (MIS) professionals, who perform systems analysis functions usingCASE technology.andP;  We will refer to this group as software engineersthroughout the study.andP;  The results of these perceptions will allow us to makesome inferences and observations about specific functional parts of CASEtechnology as well as the effectiveness of CASE technology to enhance thecommunicative and standardizational aspect of information systems developmentefforts.andM;Since there is a dearth of research on the productivity of softwareengineers, several studies that investigated programmer-productivitytechniques and tools were reviewed [4, 6, 14, 20, 26].andP;  One study [4]specifically investigated prioritization of tools using programmerperceptions and is foundational to this study.andM;The study we will describe was performed to determine the ordering andunderlying relationships of CASE technology.andP;  A preference map of similarityranking was constructed using a psychometric scaling method calledmultidimensional scaling (MDS) [10, 17, 21, 22].andP;  Psychometric scalingmethods are used for measurements of mental traits, abilities, and processes.andO;The method is called &quot;metric&quot; because it requires psychological estimates ofmetric distances between the stimuli [17].andP;  It can help systematize data inareas where organizing concepts and underlying dimensions are not welldeveloped [16].andP;  MDS is a useful mathematical tool that enables us torepresent the similarities of objects spatially as in a map.andM;Basically, the MDS technique endeavors to place n stimuli in a k-dimensionaleuclidean space (k [is less than] n) such that all pairwise similaritiesbetween stimuli are preserved.andP;  In other words, if the similarity between twostimuli has stimuli j and l more similar than j and k, then the correspondingdistance in an MDS space between stimuli j and k should be greater than thatdistance between stimuli j and l [4].andP;  This configuration reflects the hiddenstructure in the data and often makes the data much easier to comprehend[10].andP;  Sometimes, however, structure can be observed in the multidimensionalspace in addition to or instead of that provided by dimensionalinterpretation.andP;  Neighborhoods or regions of the space may have meaning.andO;Guttman [3] argued that a neighborhood or pattern approach is preferable tothe traditional dimensional approach.andP;  One way to locate or interpretneighborhoods involves the application of hierarchical clustering [1, 23,24].andP;  The clusters can be drawn in the multidimensional space as loops aroundthe relevant stimulus points.andP;  Once this is done, we can seek somecharacteristic common to the objects in a cluster.andP;  Usually this is donesubjectively, as an act of creative interpretation.andP;  Since MDS is almostalways used as a descriptive model for representing and understanding thedata, other considerations enter into decisions about the appropriatedimensionality such as interpretability, ease of use, and stability [10].andM;In the present study, subjects ranked pairs of CASE product functions (i.e.,andO;data flow diagrams, structure charts, presentation graphics, etc.) in termsof how they perceived the similarity of each one affecting theirproductivity.andP;  Two additional factors which were considered very importantduring system development were also included along with the CASE productfunctions.andP;  They were:andM;(1) communication among project team members, andandM;(2) adherence to the enterprise's system development standards.andM;For purposes of this study, productivity was left underfined so that therespondents' perceptions would be based on their own definition ofproductivity.andP;  The pairwise ranking allows the MDS technique to construct aspace of a smaller number of dimensions than the total number of stimuli fromwhich the pairwise rankings were obtained.andP;  In this way, the stimuli aremapped onto a smaller set of features that the subjects may have used to maketheir judgments about all of the stimuli.andP;  The underlying features of thisspace can be suggested from the relationships that exist in the space and theclusters that associate with a particular dimension.andM;The 91 subjects were all using CASE technology in performing softwareengineering tasks.andP;  Sixty-seven percent of the target systems being analyzedby these subjects were scheduled to use either COBOL or a 4th-generationlanguage (4GL).andP;  The remaining target systems were to be developed using C (8percent), Pascal or BASIC (0 responses), &quot;other&quot; (23 percent), or &quot;nolanguage&quot; (2 percent).andP;  The subjects were from 47 different enterprisesacross the U.S.andP;  and Canada representing over a dozen standard industry codes(SIC), a wide variety of enterprise sizes, and MIS budgets.andM;A stimulus list of 15 technological functions of one CASE product wasprepared, and the two behavioral functions mentioned earlier were added tothe list.andP;  This is illustrated in Table I.andP;  All subjects were users ofEXCELERATOR, a leading, commercially available CASE product in order to holdthis part of the research constant.andP;  Although the implementation oftechnological functions may vary in other CASE products, most of thecompeting CASE products support an equivalent function.andP;  Testing of all 17functions required that 136 paired comparisons be made by the subjects.andM;For the survey, we chose a personal computer (PC)-based survey instrument.andO;It was designed to capture perceptions of the subjects' productivity with theuse of CASE technology compared to manual methods as shown in Figure I.andP;  Thisapproach yielded a higher completed survey response rate than traditionalpaper-based surveys.andP;  Prior to administering the actual PC survey, aprototype was tested at an annual user's conference, and adjustments weremade to the instrument.andP;  Ninety-nine subjects started the actual survey and91 completed all 136 comparisons.andP;  Subjects could request on-line helpdefinitions (Appendix A) of the presented pair of stimuli at any time duringthe survey.andP;  Complete details of the research methodology are reported in[13].andM;RESULTSandM;The method of paired comparisons is usually assumed to yield a more reliableordering than that obtained by requiring a respondent to order a whole groupof objects directly [2].andP;  Checking for outliers (i.e., consistency of asubject's responses) can be done by calculating the number of inconsistenttriads among a subject's responses and used to define a coefficient ofconsistence [7].andP;  In so doing, we found that all 91 subjects were respondingwith a consistent pattern that was significantly better than chance.andP;  The twoprimary results were a dominance ranking for the CASE functions and a clusteranalysis of the functions based on perceived productivity ratings.andM;Dominance RankingsandM;The rank order of the 17 stimuli (based on 12,376 choices) according to thepreference of the 91 subjects is shown in Table II.andP;  The top-ranked stimulus,Data Flow Diagram, comes as no surprise, as the manual use of this tool todraw and revise requirements has been viewed as extremely time consuming[27].andP;  The establishment and maintenance of a Data Dictionary to supporteither data flow or data modeling techniques requires significant manuallabor and may account for its placing second in the results.andP;  Adherence toenterprise system development standards, Project Standardization in Table II,ranked a surprising third.andP;  We consider this to be a significant result sincemost CASE products are sold (and purchased) primarily on their ability toallow software engineers to produce models of the user's requirements.andO;Therefore, CASE technology may enforce enterprise systems developmentstandards in an unobtrusive way.andP;  The fourth ranked stimulus, screen/reportdesign, may indicate a high use of prototyping by the subjects, and CASEtechnology affords them a significant productivity improvement in developingscreens and reports.andM;This rank ordering, however, only reveals part of the picture, since thesestimuli can be chosen over one another based on more than one attribute.andP;  Forexample, although Data Flow Diagram and Data Dictionary are generallypreferred over all other CASE functions, the Data FLow Diagramming function,on a dimension of completeness and consistency checking, may be consideredless important than, for example, the three Analysis functions that performthese functions.andP;  The ranking order could change depending on how general orhow refined the question.andP;  The next analysis attempts to unfold thesepreferences in a more complete way by using the implied features andattributes the subjects may have been using to make their selections.andM;Multidimensional Scaling and Cluster Analysis ofandM;CASE FunctionsandM;As described earlier, the rankings of similarity can be decomposed into anumber of dimensions that represent all the original rankings.andP;  This can bedone by plotting each of the 136 choices on a visually interpretable graph.andO;Since inconsistent triads may occur, plotting each of the 136 choices on asingle dimension would result in an intransitivity.andP;  This means that thethree stimuli could not be arranged linearly and preserve the pairwisepreferences.andP;  Adding a second dimension will eliminate this intransitivity,as one of the stimuli can be placed in the two-dimensional plane at anapproximate distance between the other two.andP;  in this way, MDS attempts toaccomodate all possible 136 ranks and potential intransitivities in first onedimension, then two, three, or more.andM;For the software engineer's prefernces, the preferred representation of the136 similarity rankings was in three dimensions with 88 percent of the totaloriginal pairwise ranks accounted for.andP;  The SPSS-X ALSCAL MDS program [1] wasused, and Table III presents the preferred three-dimensional solution.andM;The representation of these similarities judgments is presented in Figure 2.andO;Each axis has a suggested interpretation identifier which is based on thecoordinate position of each of the stimuli and the clusters of stimuli thatwere determined from a hierarchical cluster analysis [1, 2, 24].andP;  SPSS-X'sCLUSTER program, which uses Ward's [24] clustering method, was used.andO;Although the clustering was performed using the stimuli points on all threedimensions, for visual clarity, these clusters are only shown in the plane ofFigure 2 as an area circumscribing the appropriate subset of functions.andO;Those functions that lie below the plane are represented by upside-down,dotted-line flag poles.andM;MDS advocates claim that it is not essential that all axes be labeled, andthey caution against arbitrary axis labeling [10, p. 49].andP;  In analyzing theresulting MDS map, we chose to label all three of the axes.andP;  However, ourinterpretation of the third axis was more tenous then the other two.andO;Included in our analysis for the interpretation of the axes was the dominancerankings of the CASE functions, the clusters closest to each axis, and thestrength of a particular function relative to each axis.andM;Our labeled interpretation of the x-axis is &quot;Most Productivity--LeastProductivity&quot; because it roughly correlates with the preference rankingsshown in Table II.andP;  There seems to be general agreement between therespondents that the functions closest to the right side of Figure 2 affordthem much more in terms of productivity than those functions located to thefar left side of the figure.andP;  At least two inferences can be drawn from thisinterpretation.andP;  First, the respondents may find more productivityimprovement with the functions on the far right, gradually reducing theirproductivity improvement as they make use of functions on the left side.andO;Second, it is possible that some of the respondents do not make use of thefunctions on the left side of the figure, and they may intuitively feel thatthese functions would deliver less productivity improvement compared to theones on the right.andP;  It clearly appears from the responses, which are mappedinto Table II and Figure 2, that the Data Flow Diagram and the DataDictionary functions of the CASE product are contributing the most to thesoftware engineer's productivity improvements over manual methods.andM;The interpretation label given to the y-axis is &quot;Simple Modelingfunctions--Complex Modeling Finctions.&quot;andP;  Simple and complex are used herewith reference to the power associated with each of the CASE product'sfunctional parts.andP;  To illustrate, the finctions nearer to the top of theplane in the figure such as &quot;Presentation Graphics&quot; and &quot;Screen andamp; ReportDesign&quot; (all corresponding letters are listed in the figure legend) deliversimple, although very useful, functionally to the software engineer.andO;&quot;Structure Diagrams&quot; and &quot;Structure Charts,&quot; whose base of their flag pole isnear the center of the plane, and more sophisticated (powerful) modelingfunctions, and &quot;Data Flow Diagrams&quot; and &quot;Data Dictionary,&quot; along with itsassociated &quot;Analysis--Entity,&quot; could represent maximum modeling power forthis group of software engineers.andM;The z-axis, labeled &quot;Data Modeling--Data Flow Modeling,&quot; roughly correlateswith the two prevailing schools of thought for modeling an informationsystem.andP;  To illustrate, &quot;Data Flow Diagrams&quot; and &quot;Data Dictionary,&quot; twofunctions below the plane in Figure 2, are representative of the Data FlowModeling methodology while &quot;Entity/Relationship Model&quot; and &quot;Data Model,&quot;whose flag pole tops are closed to the top of the page in the figure, arerepresentative of the Data Modeling methodology.andP;  As mentioned earlier, wehad some difficulty labeling this axis as the remaining functions may be usedregardless of which methodology is being used.andM;In addition to our interpretation of the axes in Figure 2, some inferencesand interpretations can be made from the evaluation of the clusters thatrepresent groupings of stimuli based on distance between stimuli.andP;  Figure 3presents the dendrogram of the hierarchical clustering (please refer to thelegend in Figure 2).andP;  As MDS is almost always used as a descriptive model forrepresenting and understanding the data, we preferred five clusters (visuallyshown in figure 2) based on the response data for this work.andP;  The SPSS-XCLUSTER program presented all cluster combinations.andP;  However, we saw littlevalus in considering more than six clusters or less than four clusters aseither of these two groups would have provided less meaningful clusterinformation.andP;  The cluster containing &quot;Data Flow Diagram,&quot; &quot;Data Dictionary,&quot;and &quot;Analysis--Entity&quot; appears to be a cluster that affects softwareengineers' productivity in a very similar (and positive) way.andP;  In Figure 2,these three stimuli are positioned close to the axis labeled &quot;MostProductivity.&quot;andP;  The cluster is also located close to the axis labeled&quot;Complex Modeling Functions&quot; which means that a high degree of power isafforded to the user by these stimuli.andP;  The combination of &quot;most productive&quot;and &quot;complex modeling&quot; could be interpreted as being beneficial to softwareengineers' productivity.andP;  This cluster also contains the two most common DataFlow moeling tools--the Data Flow Diagram and the Data Dictionary.andM;The cluster containing &quot;Lan Support&quot; and &quot;PC to MainFrame&quot; appears to affectsoftware engineers' productivity in a similar, but converse, way.andP;  The effecton their productivity improvement over manual methods when using thesefunctions appears to be minimal.andP;  A review of Figure 2 shows these twostimuli very near the &quot;Least Productivity&quot; axis within the figure.andP;  A thirdcluster containing &quot;Screen-Report,&quot; &quot;Present Graph,&quot; and others also appearsto have similar effects on their productivity.andP;  The effect appears to affordthe user simpler (less powerful) modeling capability yet contributespositively to productivity.andP;  This interpretation is made based on theobservation that all of the functions in this cluster, with the exception ofone, lay in the upper right quadrant of the plane, and the one stimuli thatis not in that quadrant is very close to it.andM;The fourth cluster in Figure 2 groups the &quot;Communication,&quot; &quot;EnterpriseAdherence to Standards,&quot; and &quot;Import/Export Facility&quot; stimuli together.andP;  Ourinterpretation of this cluster is that the three stimuli appear to provideless productivity for the user than the twelve other stimuli.andP;  The fifth andfinal cluster in Figure 2 has grouped the two most prominent Data Modelingtools, Entity/Relationship Diagrams and Data Modeling, with two otherstimuli, and the interpretation of this cluster is that these stimuli appearto positively affect productivity over manual methods.andM;RECOMMENDATIONSandM;The above observations form the basis for several informationalrecommendations.andM;(1) This study shows, via software engineers' perceptions, that theirproductivity improved with the use of CASE technology.andM;(2) It identified the functional parts of a specific CASE product that wereperceived to provide the most productivity as well as those that offered theleast improved productivity.andP;  Software engineers that use other CASE productsmay be able to draw some inferences from this study as many of the CASEproducts have generic equivalents of the stimuli used in this survey.andM;(3) The study indicates that there are perceived productivity improvementsattributed to adherence to the enterprise's systems development standardswhen using CASE technology.andP;  This is significant since most of the largerenterprises must enforce rigorous system development methodologies andassociated standards.andM;(4) This study is a step towards rigorous validation of the effects of CASEtechnology on software engineers' productivity.andM;(5) The results imply that CASE technology is perceived to improveproductivity, and that adherence to enterprise system development standardsdeserves enterprise attention and evaluation.andP;  Merlyn [11] suggests that CASEtechnology come under an organizational umbrella called the DevelopmentCenter.andP;  This organization would view the systems development process in thesame way as development of an information system.andP;  Its charter would be toassist in the investigation, introduction, monitoring, and on-going supportof new technologies which can be applied to the systems development process.andM;(6) Software engineering vendors should continue to enhance their productofferings to address those facets of the software engineer's job that willdeliver the greatest increases in productivity coupled with increased systemquality.andM;(7) This study implies that CASE product offerings need not be as robust infunctionality as the one used in the study in order to positively affectproductivity.andM;(8) Software engineering researchers should continue to push the frontiers oftechnology that continue to automate more of the software engineer's jobresponsibilities.andP;  Increased system quality as well as increased productivityshould result from this.andM;SUMMARY AND CONCLUSIONSandM;This study did not attempt to measure the degree of productivity improvementusing CASE technology, but represents a step in that direction.andP;  It also didnot investigate the many costs associated with implementing the technology,all of which may have an impact on overall productivity.andP;  The intuitiveclaims about improved productivity made by CASE vendors have been supportedthrough this research, while the amount of productivity improvement was notinvestigated.andM;As we turn the corner into the 1990s, the information systems being developedare much more sophisticated, integrated, interactive, and distributed thantheir predecessors.andP;  For the human mind to be fully knowledgeable of thesystem, and do completeness, consistency, and integrity checking in a timelymanner, automated support will be required.andP;  The software engineeringdiscipline may be moving into an era where large systems development effortsmust be assisted by CASE or CASE-like technology.andM;REFERENCESandM;[1.] Everitt, B. Cluster Analysis.andP;  Halsted Press, New York, 1974.andM;[2.] Ferguson, G. A.andP;  Statistical Analysis in Psychology and Education.andP;  3ded.andP;  McGraw-Hill, New York, 1971.andM;[3.] Guttman, L.andP;  The structure of interrelations among intelligence tests.andO;In Handbook of Multivariate Experimental Psychology, R. B. Cattell Ed.andP;  RandMcNally, Chicago, 1965, pp.andP;  438-458.andM;[4.] Hanson, S. J., and Rosinski, R. R. Programmer perceptions ofproductivity and programming tools.andP;  Commun.andP;  ACM 28, 2 (Feb.andP;  1985),180-189.andM;[5.] Hoffnagle, G. F., and Beregi, W. E. Automating the software developmentprocess.andP;  IBM Syst.andP;  J. 24, 2 (1985).andM;[6.] Jones, T. C.andP;  Measuring programming quality and productivity.andP;  IBM Syst.andO;J. 17, 1 (1978), 39-63.andM;[7.] Kendall, M. G.andP;  Rank Correlation Methods.andP;  3d ed.andP;  Charles Griffin andamp;Company Limited, London, 1962.andM;[8.] Konsynski, B. R.andP;  Advances in information system design.andP;  J. Manage.andO;Inf.andP;  Syst.andP;  1, 3 (Winter 1984/85), 5-32.andM;[9.] Konsynski, B. R., et al.andP;  PLEXSYS-84: An integrated developmentenvironment for information systems.andP;  J. Manage.andP;  Inf.andP;  Syst.andP;  1, 3 (Winter1984/85), 64-104.andM;[10.] Kruskal, J. B., and Wish, M.andP;  Multidimensional Scaling.andP;  SagePublications, Beverly Hills, Ca., 1978.andM;[11.] Merlyn, V.andP;  The backlog stops here.andP;  Computerworld.andP;  June 22, 1987,61-66.andM;[12.] Newman, P. S.andP;  Towards an integrated development environment IBM Syst.andO;J. 21, 1 (1982), 81-107.andM;[13.] Norman R. J.andP;  Integrated development environments in support ofinformation systems design methodologies and systems analysts' productivity.andO;Ph.D.andP;  dissertation, Univ.andP;  of Arizona, 1987.andM;[14.] Nowaczyk, R. H.andP;  The relationship of problem-solving ability and courseperformance among novice programmers.andP;  Int.andP;  J. Man-Machine Stud.andP;  21,(1984), 149-160.andM;[15.] Nunamaker, J. F., Jr.andP;  A methodology for the design and optimization ofinformation processing systems.andP;  In Proceedings of the Spring Joint ComputerConference (SJCC) (Atlantic City, N.J., May 18-20).andP;  AFIPS, Montvale, N.J.,andO;1971, pp.andP;  283-294.andM;[16.] Schiffman, S. S., Reynolds, M. L., and Young, F. W. Introduction toMultidimensional Scaling.andP;  Academic Press, New York, 1981.andM;[17.] Shepard, R. N.andP;  Multidimensional scaling, tree-fitting, and clusteringSci.andP;  210, 24 (Oct.andP;  1980), 390-398.andM;[18.] Teichroew, D.andP;  Problem statement analysis: Requirements of the problemstatement analyzer (PSA).andP;  In Systems Analysis Techniques, J. D. Couger andR. Knapp, Eds.andP;  John Wiley andamp; Sons, New York, 1974.andM;[19.] Teichroew D., and Hershey E. A., III PSL/PSA: A computer-aidedtechnique for structured documentation and analysis of information processingsystems.andP;  IEEE Trans.andP;  Softw.andP;  Eng.andP;  SE-3, 1 (Jan.andP;  1977), 41-48.andM;[20.] Thadhani, A. J.andP;  Factors affecting programmer productivity duringapplication development.andP;  IBM Syst.andP;  J. 23, 1 (1984), 19-35.andM;[21.] Torgerson, W. S.andP;  Psychometrika, 17, 401 (1952).andM;[22.] Torgerson, W. S.andP;  Theory and Methods of Scaling.andP;  John Wiley andamp; Sons,New York, 1958.andM;[23.] Veldman, D. J.andP;  Fortran Programming for the Behavioral Sciences.andP;  Holt,Rinehart andamp; Winston, New York, 1967.andM;[24.] Ward, J. H.andP;  Hierarchical grouping to optimize an objective function.andO;J. Am.andP;  Stat.andP;  Assoc.andP;  58, (1963), 236-244.andM;[25.] Wasserman, A. I., and Gutz, S.andP;  The future of programming.andP;  Cummun.andO;ACM 25, 3 (Mar.andP;  1982), 196-206.andM;[26.] Wiedenbeck, S.andP;  Novice/expert differences in programming skills.andP;  Int.andO;J. Man-Machine Stud.andP;  23, (1985), 383-390.andM;[27.] Yourdon, E. T.andP;  What ever happened to structured analysis? DATAMATIONJune 1, 1986, 133-138.andM;CR Categories and Subject Descriptors: D.2.0 [Software Engineering]:General--standard; D.2.1 [Software Engineering]:Requirements/Specifications--methodologies; tools; D.2.8 [SoftwareEngineering]: Metrics--software science; D.2.9 [Software Engineering]:Management--productivity; H.1.2 [Models and Principles]: User/MachineSystems--human information processing; J.m [Computer Applications]:Miscellaneous; K.6.1 [Management of Computing and Information Systems]:Project and People Management--systems analysis and design; systemsdevelopment; K.6.3 [Management of Computing and Information Systems]:Software Management--software development; software maintenance.andM;General Terms: Experimentation, Human Factors, Management, Measurement,StandardizationandM;Additional Key Words and Phrases: Cluster analysis, Computer-Aided SoftwareEngineering (CASE), multidimensional scaling, preference, psychologicalmodelsandM;ABOUT THE AUTHORS:andM;RONALD J. NORMAN is currently an associate professor of Information andDecision Systems at San Diego State University.andP;  He is a holder of theCertificate in Data Processing (CDP).andP;  His research interests arecomputer-aided software engineering (CASE) technology, technology transferand organizational change issues, and seamless integration of enterpriseapplications.andP;  He has served as facilities chairman for the InternationalConference on Information Systems and was the program committee chairman forCASE '88.andP;  Author's Present Address: Information and Decision Systems,College of Business Administration, San Diego State University, San Diego, CA92182-0127.andM;JAY F. NUNAMAKER, JR., is head of the Department of Management InformationStstens and is a professor of Management Information Systems (MIS) andComputer Science at the University of Arizona.andP;  He is also chair of theAssociation for Computing Machinery's (ACM) Curriculum Committee onInformation Systems.andP;  Author's Present Address: Department of ManagementInformation Systems, College of Business and Public Administration, TheUniversity of Arizona, Tucson, AZ 85721.andO;</TEXT></DOC>