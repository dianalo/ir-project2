<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-752-180  </DOCNO><DOCID>08 752 180.andM;</DOCID><JOURNAL>Communications of the ACM  August 1990 v33 n8 p30(19)* Full Text COPYRIGHT Association for Computing Machinery 1990.andM;</JOURNAL><TITLE>Cyc: toward programs with common sense. (attempt to assemble amassive knowledge base spanning human consensusknowledge)(includes related article on examples) (technical)</TITLE><AUTHOR>Lenat, Douglas B.; Guha, Ramanathan; Pittman, Karen; Pratt,Dexter; Shepherd, Mary.andM;</AUTHOR><SUMMARY>Cyc, a massive project to create a knowledge base spanning allhuman consensus knowledge, is discussed.andP;  The project will requirethe development of a new logic language for expressing knowledgebefore sets of procedures can be created and the knowledge baseitself built.andP;  Cyc programmers developed CycL, a uniquerepresentation language and inference engine.andP;  Inferencing in Cycat the heuristic level involves a variety of 'logicallysuperfluous' mechanisms that make procedures more efficient, aswell as highly specialized inference rules.andP;  The dependencyanalysis procedure used in the knowledge base is also described.andO;Objects and properties can be either 'spatially' or 'temporally'intrinsic.andP;  Several application programs making use of Cyc arecurrently under development.andM;</SUMMARY><DESCRIPT>Topic:     Artificial intelligenceKnowledge-Based SystemsExpert SystemsHeuristic MethodsTechnology.andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>CYC: TOWARD PROGRAMS WITH COMMON SENSEandM;Motivation: TheandM;Brittleness BottleneckandM;For three decades, Artificial Intelligence researchers have grappled withissues like control of search in problem solving, organization of memory,logic for the representation of knowledge, perception, and so on, driven bytasks ranging from infants exploring their &quot;worlds&quot; through expertsperforming some intricate reasoning task.andP;  Despite many types of successes,today's AI software--and in many ways non-AI software as well--has reached akind of bottleneck which is limiting its competence and usability.andP;  Thisarticle begins with a discussion of the nature of that bottleneck, and thendescribes the Cyc project: a serious attempt, begun in late 1984, to overcomethis limitation.andM;The Path to ArtificialandM;IntelligenceandM;One of the principle tenets of AI, is that one can explicitly, declarativelyrepresent a body of knowledge, in a way that renders it usable by a number ofprograms.andP;  This is in principle no different from the way in which a book&quot;encodes&quot; knowledge in tables and English text on the assumption that a wideaudience will be able to use that data in myriad, possibly unanticipatedways.andP;  Since programs do not (yet) read and understand natural language, theencodings we use must be rather different, in particular much less ambiguous.andM;So achieving an AI comprises three tasks:andM;i) Develop a language (actually a logic) for expressing knowledge.andP;  Since wewould like to allow many different programs to use this knowledge, this&quot;representation language&quot; needs a declarative semantics.andM;ii) Develop a set of procedures for manipulating (i.e., using) knowledge.andO;Some of these will of necessity be heuristic, some will be strategic ormeta-level, some will be aimed at truth maintenance and default reasoning,some will be inductive rather than deductive, and so on.andM;iii) Build the knowledge base(s).andP;  For example, encode knowledge in thelanguage developed in i) above, so that one (person or machine) can apply toit the reasoning mechanisms of ii).andM;AI has largely concentrated on i) and ii).andP;  This is unfortunate, since it istask iii) that grounds the whole enterprise in reality.andP;  McCarthy [21] wasthe first to point out the importance of being able to represent knowledge ina program and initiated the task of devising representations for assortedtopics such as time, agenthood, etc.andP;  Feigenbaum was one of the first toactually build programs which depended upon a significant amount of knowledgeas their primary source of power.andP;  Later dubbed &quot;expert systems,&quot; theseprograms showed that impressive levels of performance could be attained bytaking iii)--knowledge--even half-seriously.andP;  For example, reasonableperformance in narrow task domains may be achieved with modest-sizedknowledge bases (KBs) (10 (2} to 10 (3) domain-specific assertions or rules.)andM;The Source of SoftwareandM;BrittlenessandM;There is indeed a strong local maximum of cost-effectiveness: by investingone or two person-years of effort, one can end up with a powerful expertsystem.andP;  The trouble is that this is just a local maximum.andP;  Knowing aninfinitesimal fraction as much as the human expert, the program has only theveneer of intelligence.andP;  Let us illustrate what this means.andM;Programs often use names of concepts such as predicates, variables, etc.,andO;that are meaningful to humans examining the code; however, only a shadow ofthat rich meaning is accessible to the program itself.andP;  For example, theremight be some rules that conclude assertions of the form laysEggsInWater(x),and other rules triggered off of that predicate, but that is only a fragmentof what a human can read into &quot;laysEggsInWater.&quot;andP;  Suppose an expert systemhas the following four rules:andM;IF frog(x), THEN amphibian(x) IF amphibian(x), THEN laysEggsInWater(x) IFlaysEggsInWater(x), THEN livesNearLotsOf(x, Water) IF livesNearLotsOf(x,Water), THEN ~livesInDesert(x)andM;Given the assertion frog(Freda), those rules could be used to conclude thatvarious facts are true about Freda: amphibian(Freda), laysEggsInWater(Freda),~livesInDessert(Freda),andM;etc.andP;   et the program wouldandM;not &quot;know&quot; how to answer questions like: Does Freda lay eggs?andP;  Is Fredasometimes in water?andM;Humans can draw not only those direct conclusions fromlaysEggsInWater(Freda), but can also answer slightly more complex querieswhich require a modicum of &quot;outside&quot; knowledge: Does Freda live on the sun?andO;Was Freda born live or from an egg?andP;  Is Freda a person?andP;  Is Freda larger orsmaller than a bacterium?andP;  Is Freda larger or smaller than the Pacific Ocean?andO;Or even: How is Freda's egg-laying like Poe's story-writing?andM;Thus, much of the &quot;I&quot; in these &quot;AI&quot; programs is in the eye--and &quot;I&quot;--of thebeholder.andP;  Carefully selecting just the fragments of relevant knowledge leadsto adequate but brittle performance: when confronted by some unanticipatedsituation, the program is likely to reach the wrong conclusion.andP;  It is alltoo easy to find examples of such brittle behavior: a skin disease diagnosissystem is told about a rusty old car, and concludes it has measles; a carloan authorization system approves a loan from someone whose &quot;years at thesame job&quot; exceeds the applicant's age; a digitalis dosage system does notcomplain when someone accidentally types a patient's age and weight inreverse order (even though this 49-pound, 102-year-old patient was taken tothe hospital by his mother); and so on.andM;This, then, is the bottleneck of which we spoke earlier: brittle response tounexpected situations.andP;  It is a characterization of software today: it is thequality that separates it from human cognition.andP;  The programs' limitationsare both masked and exacerbated by the misleading sophistication of theirtemplates for English outputs, by the blind confidence their users place inthem, and by their being labelled with pretentious generalizations of theirfunctionality (e.g., a &quot;medical diagnosis expert system&quot; today does just anarrow slice of differential diagnosis.)andM;Overcoming BrittlenessandM;People are not brittle.andP;  Why?andP;  Because they have many possible ways toresolve a novel situation when it arises: asking someone for advice (this mayinclude reading some written material), referring to increasingly generalknowledge (eventually &quot;first principles&quot; or even &quot;common sense&quot;), comparingto a similar but unrelated situation.andP;  But each one of these paths toflexibility is closed to today's programs: they do not really understandnatural language very well, they do not have general knowledge from which todraw conclusions, and they do not have far-flung knowledge to use forcomparisons.andP;  Not only are programs vastly more narrow than we humans are,they are not equipped to dynamically grapple with a situation when it exceedstheir current limitations.andP;  As we stated earlier, even the so-called expertsystems, though they are the first attempt at iii), are only a &quot;half-serious&quot;attempt.andM;A serious attempt at iii) would entail building a vast knowledge base, onethat is 10 (4) to 10 (5) larger than today's typical expert system, whichwould contain general facts and heuristics and contain a wide sample ofspecific facts and heuristics for analogizing as well.andP;  This KB would bedistinguished by its breadth even more than by its size.andP;  Such a KB wouldhave to span human consensus reality knowledge: the facts and concepts thatyou and I know and which we each assume the other knows.andP;  Moreover, thiswould include beliefs, knowledge of others' (often grouped by culture, agegroup, or historical era) limited awareness of what we know, various ways ofrepresenting things, knowledge of which approximations (micro-theories) arereasonable in various contexts, and so on.andM;Late in 1984, we began the first serious attempt at iii), and the bulk ofthis article describes that effort.andP;  We have made significant progress sincethen, and anticipate a kind of crossover (from primarily manual knowledgeentry to primarily automatic entry via natural language understanding (NLU)later this decade.andP;  As the next article in this issue, &quot;Knowledge and NaturalLanguage Processing&quot; and [2] explain in detail, one cannot expect to shortcutthe building of the large KB today--let alone five years ago--by NLU, becauseopen-ended NLU itself requires such a KB--for semantic disambiguation of wordsenses, resolving anaphora, inducing the meaning of ellipses, and so on.andM;Interestingly, our work is spurring progress in i) and ii): in i), becausethe utility of various representation language features can best be judged byusing the language; in ii), because what is wanted is not the most efficientinference procedure overall, but rather those that are used most often, so itis good to perform activity ii) in the context of a large &quot;task-independent&quot;test-bed KB.andM;Overview of the Cyc ProjectandM;Although our project Cyc emphasizes iii), building an immense KB requiresthat we also cover i) and ii).andP;  Namely, the KB must be built in somerepresentation language, hence we have to include some of activity i).andP;  Wealso have to worry about some of ii) because the KB is going to be vastlysmaller than its deductive closure, (i.e., in order to answer most queries,it will have to do some sophisticated inference).andP;  The next threeparagraphs--and, in much more detail, the next three sections of thisarticle--discuss our approach to i), ii), and iii): our representationlanguage (CycL), our inference engine (actually many little ones), and ourontology.andM;Representation Language.andP;  We developed our representation languageincrementally as we progressed with task iii).andP;  Each time we encounteredsomething that needed saying but was awkward or impossible to represent, weaugmented the language to handle it.andP;  Every year or two we paused andsmoothed out the inevitable recent &quot;patchwork.&quot;andP;  The latest language has beenstable for 18 months; that is, its paradigm and &quot;core&quot; have remained stable,even though we have added many relatively minor extensions to it.andP;  Tosummarize it in a sentence, it is a frame-based language embedded in a moreexpressive predicate calculus framework along with features for representingdefaults, for reification (allowing one to talk about propositions in the KB)and for reflection (allowing one to talk about the act of working on someproblem.)andM;Inference Engine.andP;  The same &quot;incremental engineering approach&quot; was taken tobuilding the inference engine.andP;  As we identified frequently used classes ofinferences that could be used more efficiently, we introduced specialmechanisms for this purpose.andP;  Traditional computer science has identifiedmany problems having varying levels of complexity and has, devised specialdata structures and algorithms for solving them.andP;  AI on the other hand, haslargely opted for single, very general mechanisms (e.g., resolution) fordoing problem solving.andP;  We have adopted the former paradigm and are applyingit to cover the kinds of problems that a system such as Cyc tries to solve.andO;This approach is quite similar to that advocated in [4].andM;Ontology of the KB.andP;  As for the KB, we alternate bottom-up growth withtop-down design.andP;  The bulk of the effort is currently devoted to identifying,formalizing and entering &quot;microtheories&quot; of various topics (e.g., money,buying and shopping, containers, etc.)andP;  We follow a process that begins witha statement, in English, of the theory.andP;  On the way to our goal, anaxiomatization of the theory, we identify and make precise those Cyc conceptsnecessary to state the knowledge in axiomatic form.andP;  To test whether thetopic has been adequately covered, stories dealing with the topic arerepresented in Cyc, then questions any human ought to be able to answer afterreading the story are posed to Cyc.andM;There are currently between one and two million assertions in our KB, many ofwhich are general rules, classifications, constraints, and so on; only afraction (at present) are specific facts dealing with particular objects andevents (e.g., famous people and battles.)andM;More significantly, we feel we have found &quot;solutions&quot; for variousrepresentation thorns that we might have become caught on: time, space,belief, hypotheticals and counterfactuals, interval-based quantities,substances, composite tangible and intangible entities, etc.andP;  By &quot;solution&quot;we mean the following: a set of partial solutions which work adequately inthe moderately common cases, and which work very well in the very commoncases.andP;  For example, a significant amount of work on the problem ofrepresenting aspects of agents such as their beliefs, goals, etc., in AI andphilosophy, has focused on trying to reduce the total number of thesepropositional attitudes to the barest minimum and in trying to handle ratheresoteric problems such as the Prisoners Dilemma [28].andP;  We, on the other hand,have been quite promiscuous about inventing new propositional attitudes andhave concentrated on more mundane issues such as predicting what the driverof a car on an American road probably intends when he turns on his left turnsignal.andM;What do we hope to get from our efforts?andP;  Here are three possible levels ofsuccess, in decreasing order of optimism.andP;  It is interesting to note that weput the chance of the better result at less than 5 percent in 1984, but--dueto our clipping of representation thorns, and stabilizing of therepresentation language, inference engine suite, and high-level ontology--wenow place it as high as 60 percent:andM;* Good: While not directly built upon and widely used, the Cyc research doesprovide some insight into issues involved in task iii).andP;  Perhaps it gives usan indication as to whether the symbolic paradigm is flawed and, if so, how.andO;It also might yield a rich repertoire of &quot;how to represent it&quot; heuristics,and might at least motivate future research issues in tasks i) and ii).andM;* Better: Cyc's KB is used by the next generation of AI research programs,and its size and breadth help make them more than theoretical exercises.andP;  Noone doing research in symbolic AI in 1999 wants to be without a copy of Cyc,any more than today's researchers want to be without EVAL and ASSOC.andO;Eventually, it empowers the first full-fledged natural language understandingsystems, non-brittle expert systems, and machine learning systems.andM;* Best: Cyc, or something similar, serves as the foundation for the firsttrue artificial intelligent agent.andP;  Application programs routinely tie intoit, in effect letting it look over their shoulder.andP;  No one in the earlytwenty-first century even considers buying a machine without common sense,any more than anyone today even considers buying a PC that cannot runspreadsheets, word processing, and networking software.andM;CycL--The CycandM;RepresentationandM;LanguageandM;CycL is the language in which the Cyc KB is encoded.andP;  Let us first considersome of the issues that heavily influenced the design of CycL.andP;  As wementioned earlier, it is our aim that the Cyc KB be usable by many differentproblem solvers.andP;  This implies that the CycL should have a clear (andhopefully simple) semantics.andP;  We also want CycL to provide certaininferential capabilities and these should not be intolerably inefficient.andO;Since most of our commonsense knowledge is in the form of defaults, CycLshould provide some scheme for dealing with such knowledge.andP;  We would like tohave all the expressiveness of first-order predicate calculus with equality,and we would also like a means for handling propositional attitudes (such asbeliefs, goals, dreads, etc.) [26].andP;  And finally we would also like toprovide some facilities for operations such as reification, reflection, andso on.andP;  This, in short, is the &quot;wish list&quot; for CycL.andM;Epistemological Level and DefaultandM;ReasoningandM;Two of the &quot;wish-list&quot; entries seem to be at odds with each other: having aclean and simple semantics, yet providing speedy inference.andP;  To improveinferencing abilities, we want to include special-purpose representations andinference routines, procedural attachments, etc.andP;  But these make it harder toprovide a simple semantics.andP;  Also, while it is reasonable to expect thesemantics of CycL to remain unchanged, it is likely that new constructs aregoing to be incrementally added to improve CycL's inferencing.andP;  The additionof new special-purpose constructs is likely to prove bothersome to otherprograms that use Cyc--for instance, programs which were written before thenew constructs even existed and hence could not take advantage of them.andM;We therefore would like users of Cyc (either humans or application programs)to interact with the system at an epistemological level and not at aheuristic level.andP;  These terms, and the distinction between them, are used inthe sense as used by McCarthy and Hayes in [23].andP;  These observations lead tothe conclusion that the KB should be constructed at two levels, theEpistemological Level (EL) and the Heuristic Level (HL)--and this is exactlywhat we have done.andP;  The Cyc KB exists at these two levels and an externalprogram (or human user) can interact with CycL at either of these levels.andM;The Epistemological Level (EL) uses a language that is essentiallyfirst-order predicate calculus (with a slightly different syntax) withaugmentations for reification [20] &quot;i.e., having a name for propositions, andbeing able to make statements about other statements) and reflection [32](e.g., being able to refer to the facts supporting the system's beliefs inanother fact in axioms).andP;  The EL is meant for giving an account of the KB ina form that has a simple semantics and is easy to use to communicate.andM;The Heuristic Level (HL), by contrast, uses a variety of special-purposereporesentations and procedures for speedy inference.andP;  The HL is usedwhenever any inference needs to be done.andP;  It is best to think of the HL justas an optimization; i.e., to consider only the EL as &quot;real,&quot; as containingall the knowledge.andM;CycL has a facility called Tell-Ask (TA) for translating sentences from theEpistemoligical Level into the most appropriate representations in theJeuristic Level and vice versa.andP;  One can therefore type Epistemological Levelexpressions (i.e., in something like first-order predicate calculus) to TA,and they are converted into whichever Heuristic Level representation is mostefficient (inverse, transfers Through, automatic classification, inheritance,etc.).andM;The actual First-Order Predicate Calculus (FOPC)-like logic used by theEpistemological LEvel is called the &quot;Cyc constraint language&quot; (CL).andP;  Inaddition to the expressiveness provided by this, CycL also allows sentencesand function terms to be reified into objects.andP;  (1)  The Constraint Languagealso allows some amount of reflection of the problem solver into thelanguage.andP;  It also uses a number of modals (e.g., beliefs and desires) totalk about the propositional attitudes of agents.andM;Some of the assertions in Cyc's KB are monotonic (i.e., the addition of newfacts cannot cause them to be retracted).andP;  But most (over 90 percent) arenon-monotonic: they are currently held default beliefs which can quitepossibly turn out to be invalidated.andP;  Very little that we believe about theworld is certain and absolute; that is true not only for heuristics (andconclusions derived using them), but also for most common-sense &quot;facts&quot; aboutthe world.andP;  They often turn out to be simplifications (&quot;Lincoln was a goodPresident&quot;), approximations (&quot;The earth goes around the sun in an ellipse&quot;),or, more rarely, just plain wrong (e.g., over half of American high schoolstudents believe that if you drop a wrench on the moon, it will just hang inmid-air there!).andP;  The monotonic (absolutely true) assertions are usuallythose that are definitional (e.g., it is absolutely certain that tall peopleare people) or provable (which usually means mathematical facts, such as&quot;squares of odd numbers are odd&quot;).andM;Unlike many AI programs, most of whose default reasoning facilities are woveninto the logic they use, Cyc uses only minimal support from the logic fordoing its default reasoning, with most of the knowledge associated withdefault reasoning being represented as axioms in the KB [12].andM;The only non-monotonic constructs used are equivalent to the Closed WorldAssumption and the Unique Names Assumption.andP;  The Closed World Assumption isused only to provide the language with non-monotonicity, and the defaultreasoning abilities are designed using this and the notion of arguments.andP;  Thesyntactic structure of defaults is following that suggested in [22].andP;  Thus,the statement &quot;birds usually fly&quot; is represented as follows: (2)andM;[Mathematical Expression Omitted]andM;To derive conclusions from this, we use the concept of arguments, so we havean argumentation axiom (instead of the circumscription axiom.)andM;An argument for a proposition P is similar to a proof for P, but isnon-monotonic.andP;  For example, later information never invalidates a proof,once one is found, but might very well invalidate an argument.andP;  The essentialdifferences between a proof andan argument are that, unlike in proofs, thesentences in an argument can be assumptions [25] and that arguments arefirst-class objects which can be referred to in axioms.andP;  The assumptions thatcan be made are sentences of the form * [ab.sub.i](...).andM;We then write more axioms that allow us to conclude P (or * P), given a setof arguments for and against P--- i.e., axioms which conclude that someargument is valid, or conclude that one argument is stronger than another.andO;Here is the Argumentation Axiom; it says to believe in a proposition P:andM;i)  if there is an argument for it,andM;ii)  the argument is not known to be invalid, andandM;iii)  there is no preferred argument for * P (except perhaps some which areknown to be invalid): (3)andM;[Mathematical Expressions Omitted]andM;A closed-world assumption is made for the predicates argumentFor andinvalidArg.andP;  This axiom uses the truth-predicate True and in order to avoidthe possibility of paradoxes we allow the truth-predicate to be partial.andO;(i.e., (True('p) V True(' * p)) is not a theorem).andM;The salient aspect of this approach to doing default reasoning is that mostof the &quot;work&quot; is done using axioms in the language and not &quot;wired in&quot; to thelogic.andP;  The real core of the default reasoning is a set of additional axioms.andO;The axioms in one group specify when an argument is invalid: if one of theassumptions made by an argument is false, then the argument is invalid.andP;  Theaxioms in the other group specify when one argument is preferred to another:In the former group, if one of the assumptions made by an argument is false,then the argument in invalid.andP;  In the second group, causal arguments arepreferred over reductio ad absurdum arguments.andP;  This provides greaterflexibility and control, and makes it easier to fix things if inadequaciesare detected (i.e., adding/removing axioms from the KB is strongly preferableto changing the logic, especially when a massive KB already exists andassumes a certain logic).andM;This concludes the discussion of the Epistemological Level.andP;  A shortdescription of some of the techniques used at the Heuristic Level to speed upinference follows.andM;The Heuristic LEvel:andM;Inferencing in CycandM;The Heuristic Level (HL) is meant for doing inferencing.andP;  As opposed to theEpistemological LEvel, where we tried to avoid superfluous constructs, the HLincorporates a host of &quot;logically&quot; superfluous mechanisms for improvingefficiency.andM;Most of the novelty and power of Cyc stems from its rich, broad knowledgebase; so why all this treatment of reasoning?andP;  Even though most commonsensereasoning is shallow, &quot;shallow&quot; still means one or two deductions away fromwhat is already there in the KB.andP;  For instance, you have to make thefollowing decisions: what to cook for dinner tonight; whether a wrenchreleased on the moon will hang there or fall to the lunar surface; whysomeone just laughed; whether X is likely to already be acquainted with Y;etc.andP;  Most of the answerable queries are not preconceived.andP;  Their answers arenot worth pre-computing and caching because they are numerous and,individually, each very unlikely ever to be asked (e.g., &quot;Did Aristotle knowabout the Space Shuttle?&quot; &quot;Did Jefferson's right thumb have a thumbnail?&quot;).andO;Cyc can answer those questions correctly, giving &quot;right&quot; argumnts for itsanswers, and the ability to answer those questions is part of what it meansto have common sense...yet it would be wildly cost-inefficient to try tostore, let alone calculate, the answers to each such question ahead of time.andO;The number of potentially useful short deductions from our current KB is inthe trillions; so it is important to be able to quickly identify a smallsubset of sentences relevant to one's current problem, and it is important tobe able to efficiently reason using those sentences.andM;The functionality of the Heuristic Level is defined in terms of a FunctionalInterface which consists of the following six operations which the HL mustimplement.andM;a)  Tell: ([Sigma] x KB [arrow right] KB).andP;  &quot;Tell&quot; is used to assertstatements.andP;  Given a sentence [sigma] and a KB, after Tell ([sigma], KB) weget a new (modified) KB' in which [sigma] is an axiom.andP;  Regardless of otherarguments (multi-step &quot;proofs&quot;) of [sigma], KB' would contain a new argumentfor it, of the form &quot;Primitively, because the user told me so.&quot; [sigma] canbe any well-formed formula of the EL language.andM;b)  Unassert: ([Sigma] x KB [arrow right] KB).andP;  Given a sentence [sigma] anda KB, we get a KB' in which [sigma] is not an axiom.andP;  Nothing can be saidabout the truth-value of [sigma] in the resulting KB.andP;  For example, [sigma]might still be True (it still might be derivable from other axioms in KB'),it might be False ([Gamma] [sigma] might be derivable from axioms in KB'), orits truth-value might be unknown (neither [sigma] nor [Gamma] [sigma] aresupported by arguments in KB').andP;  Unassert is the direct &quot;undo&quot; of Assert.andO;Note that Tell([Gamma] [sigma], KB) is quite different from Unassert([sigma],KB); the Tell would result in a KB' in which [sigma] was false, as justifiedby an explicit new axiom [Gamma] [sigma].andM;c)  Deny: ([Sigma] x KB [arrow right] KB).andP;  Given a sentence [sigma] and aKB, after Deny~[sigma], KB) we get a KB' in which [sigma] is no longer true.andO;It is common for neither [sigma] nor [Gamma] [sigma] to be true in KB' (i.e.,andO;if there are no other arguments for [Gamma] [sigma]).andP;  In other words, thissquelches all positive arguments for [sigma], and does not affect negativearguments (arguments for [Gamma] [sigma]) in any way.andP;  Note that this is notthe same thing as Unassert([sigma], KB), in which case [sigma] might still betrue; and it is not the same as Tell([Gamma] [sigma], KB) in which case[sigma] would have to be false.andM;d) Justify: ([Sigma] x KB [right arrow] sentences).andP;  Justify is used toobtain the argument for a given proposition.andP;  If sentence [sigma] were truein KB, then Justify ([sigma], KB) would return a subset of the KB from which[sigma] can be derived.andP;  (Actually, Justify returns a somewhat morecomplicated value, which specifies the various pro and con arguments about[sigma], and how they combine to produce the &quot;net&quot; truth-value of [sigma] inKB.)andM;e) Ask: ([Sigma] x KB [right arrow] truth-value/bindings).andP;  &quot;Ask&quot; is used totest the truth value of a statement, and to find which free-variable bindingsmake an expression true.andP;  Given any constraint language (CL) expression[sigma] (which may contain free variables) and a KB, the value ofAsk([sigma], KB) is either the bindings for the free variables in [sigma], ora truth-value.andP;  An optional argument turns Ask into a generator; i.e., eachrepeated call yeilds a single distinct binding list.andM;f) Bundle: (sequence of Functional Interface statements).andP;  This is a facilitywhich performs a series of calls to the previous five FI functions as oneatomic macro operation.andP;  This is of great pragmatic benefit, in two ways:andM;i) The operations may violate some integrity constraints and satisfy themagain.andP;  For example, changing the domain of the predicate likes from Personto Animal requires one Assert and one Unassert.andP;  No matter in which orderthey are performed, after performing the first operation, there will be aviolation nto integrity constraint that says that each predicate hasprecisely one recorded domain.andM;ii) The bundling allows the HL to be &quot;smart&quot; about which assertions it has toundo.andP;  For example, changing an inheritance rule from &quot;Southerners speak witha drawl&quot; to &quot;Southerners over age 2 speak with a drawl&quot; will result in n/35retractions if they are Bundled together (assuming an average lifespan of 72years, a uniform population distribution, etc.), rather than 2*n, if they arenot.andM;The concept of a Functional Interface, with functions such as Tell and Ask,has existed in Computer Science and AI for some time [5].andP;  We have tailoredit for our purposes, and increased its pragmatic usefulness by adding somenew constructs (such as Bundle and justify) and by teasing apart old ones(such as Unassert(p, KB) versus Deny(p, KB) versus Tell(*p, KB)).andM;Default Reasoning ModulesandM;Most of the gain in speed of processing at the heuristic Level comes aboutbecause of the way we implement Ask.andP;  (Much of the complexity at theHeuristic Level is due to the need to do Deny properly.)andM;Since most of the reasoning done is related to defaults, we first describehow this is implemented.andP;  (4)  The structure of the heuristic Level is basedaround default reasoning and consists of these four modules:andM;* Argument Generator: Given a sentence, this module tries to generate anargument for it.andM;* Argument Comparator: Given a set of arguments for and against a sentence P,this module decides on a truth-value for P by comparing these statements.andP;  Itthen adds this sentece to the KB, with that &quot;net&quot; truth-value.andP;  Currenttruth-values include: monotonically true; true by default; unknown; false bydefault; and monotonically false.andM;* Conclusion Retractor: When the truth-value of a sentence x changes, thismodule ensures that truth-values of other sentences that depend on x are alsoupdated.andP;  Not surprisingly, the module for the generation of arguments is, inpractice, ver tightly integrated with this module.andM;* Contradiction Resolver: This module is responsible for detecting andresolving contradictions.andM;Though the epistemological Level has only two truth-values (true and false),the Heuristic Level uses 5 of them (true, default true, unknown, defaultfalse and false) to label sentences in the KB [11].andP;  &quot;True/false&quot; sentencesare those that are &quot;monotonically&quot; true (i.e., the addition of new factscannot cause them to be retracted).andP;  &quot;Default true/false&quot; sentences do nothave this property.andP;  &quot;Unknown&quot; is used for sentences for which there areunresolved conflicting arguments.andP;  Deductions that require making assumptionsare only default true (or false) while those that do not require anyassumptions are monotonically true.andM;Given a sentence P, Ask first tries to find arguments for it.andP;  If it can, itthen tries to find arguments against it.andP;  These are then checked for possibleinvalidity, compared, and the final truth-value is decided on this basis.andP;  Ifthere are unresolvable (incommensurable) arguments for and against P, then Pis labelled as Unknown.andM;Since the Heuristic Level has these five truth-values, the Tell-Asktranslator is able to covert axioms from the Epistemological Level intosentences at the Heuristic Level that do not contain any &quot;ab literals&quot;(assuming that no axiom has more than one negated ab literal).andP;  This makesthe default reasoning both easier to encode and faster.andM;A number of the axioms (i.e., assertions that have been manually entered intothe system) at the Epistemological Level are of the form ([~ab.sub.i(...)] *andO;andless;ground-formulaandgt;).andP;  These are called &quot;local defaults&quot; (and simply translateto the ground-formula with a truth-value of default true at the HeuristicLevel) and the Heuristic Level provides special support to handle theseefficiently.andM;It should be noted that since comparing two arguments could involve usingaxioms in the KB, the Argument Comparator (or any of the other modules) canrecursively use Ask or any of the other interface functions.andM;Speeding up the Argument-GeneratorandM;ModuleandM;The bulk of Cyc's time spent inferencing is used by the Argument-Generatormodule.andP;  a number of techniques have been introduced to make theArgument-Generator (and Conclusion-Retroactor) modules work more efficiently.andO;These techniques fall into three categories:andM;* highly specialized interference rules,andM;* domain-specific inference modlues, andandM;* dependency analysis of the KB.andM;Highly Specialized Inference RulesandM;There are a number of groups of axioms whose syntactic structure can becaptured using schemas that do not have any sentential variables.andP;  Each ofthese schemas is made into a rule of inference.andM;For instance, many rules we entered had the form (*x, y, z) s1(x, y) [and]s2(y, z) [right arrow] s1(x, z).andP;  For example, (*x, y, z) owns(x, y) [and]physicalParts(y, z) [right arrow] owns(x, z).andP;  If you own a car, and one ofits parts is a certain steering wheel, then you also own that steering wheel.andO;We introduced a new inference template, transfersThrough, so that one couldexpress that rule simply as transfersThrough(owns, physicalParts).andP;  There aremany other transfersThrough &quot;rules&quot; in Cyc, e.g., transfersThrough (lastName,father), so that lastName (MichaelDouglas, Douglas) and father(MichaelDouglas, KirkDouglas) imply lastName(KrkDouglas, Douglas).andP;  Anotherexample of the use of this special-purpose inference schema istransferThrough(causes, agentOf); for instance, if X caused something tohappen, while X was acting as an agent of Y, then we can consider Y to havecaused it as well.andM;Associated with each inference schema--such as transfersThrough orinherits--are specialized procedures for speeding up that sort ofinterferencing.andP;  For example, a certain amount of compilation can be donethat cuts down drastically on unification at runtime.andP;  Also, the stack usedby Lisp itself can be used instead of using binding lists.andP;  Many of thesesavings are similar to those obtained by Warren-Machine-like [31]compilations of Prolog programs.andP;  In particular, each schema has specializedprocedures for:andM;* Recognizing instances of the schema.andP;  For example, noticing when aconstraint language sentence can be transformed into an instance of thatschema.andP;  If the user Tells the system (*u, v, w) owns (u, v) [and]physicalParts(v, w) [right arrow] owns(u, w), that trivially matches thegeneral transferThrough(s1,s2) template (*x, y, z) s1(x, y) [and] s2(y,z)[right arrow] s1(x, z), so the Tell-Ask translator converts that intotransfersThrough(owns, physicalParts).andM;* Storing justifications.andP;  Each inference mechanism is responsible fordetecting whem an argument it proposed becomes invalid, and (at that time)retracting the argument.andP;  Truth Maintenance Systems perform two tasks:providing this kind of bookkeeping, and maintaining consistency.andP;  Thoughtypically tightly interwoven, in Cyc we see that these are kept clearlyseparated.andP;  The bookkeeping is inference mechanism-specific (the datastructure used to represent the argument could be dependent on the inferencemechanism that proposed it) while the consistency maintenance task (discussedin detail later, in the subsection on Denials) is inferencemechanism-independent.andM;* Applying the schema.andP;  For example, suppose we assert these three senteces:transfersThrough(owns, physicalParts) owns(Guha, toyota0093) andphysicalParts(toyota0093, WheelRR009382015)andM;Then a specialized procedure associated with transfersThrough would detectthe need to &quot;fire the rule&quot; (if it were forward-propagated, or if it werebackward-propagated and someone asked whether Guha owned WheelRR009382015).andM;We have also built a facility to help a user add new inference rule schemas[16].andP;  For example, one specifies a schema, and Cyc automatically generatesthe code needed to &quot;implement&quot; this schema as an inference rule--the types ofspecialized procedures itemized above.andP;  This facility can only handle schemasnot involving sentential variables.andM;Domain-Specific Inference ModulesandM;The first category of specialized mechanism was based purely on the syntacticstructure of the axioms, and had nothing to do with the domain with which theaxioms dealt.andM;There are times when one can exploit some special properties of a set ofdomain-specific axioms, and/or domain-specific use of a set of generalaxioms--notably, information about &quot;most frequently seen cases.&quot;andM;Some examples of such axiom clusters that Cyc currently optmizes in this wayare those related to temporal reasoning [1], quantity arithmetic [33],equality, etc.andM;It should be noted that while there may be nothing more than the programrepresenting these axioms at the Heuristic Level, these axioms do existdeclaratively, explicitly at the Epistemological Level.andM;Dependency Analysis of the KBandM;In the past, AI has developed a number of standalone modules (e.g., TruthMaintenance Systems [9] that can be used with any problem solver.)andP;  In orderto make them problem solver-independent, their operation was usually madeindependent of the contents of the KB the problem solver operated upon.andM;However, we have found that it is possible to obtain significant improvements(in efficiency) by using an analysis of the structure of the axioms in theKB.andM;For example, a dependency analysis of the axioms of the KB could reveal thecircumstances in which there could possibly be circular justifications andidentify the only sentences that may be involved in the circularjustification.andP;  Having this information can vastly reduce the time requiredto search for such circularities.andP;  (For example, it turns out, in Cyc's KB,that only a handful of the four-thousand kinds of slots can even possiblyparticipate in circular lines of reasoning and such &quot;garbage collectable&quot;chains are usually rather short; these two KB-specific properties make theproblem of detecting them computationally quite feasable, in practice, eventhough it requires a rather expensive procedure in theory.)andM;Though on the one hand these modules are now making strong assumptions aboutthe structure of the representation used by the problem solver, the resultantimprovements in efficiency are worth it.andM;Dealing with Multiple SpecializedandM;Inference EnginesandM;The two most critical issues that crop up in the presence of dozens of suchspecialized merchanisms are:andM;* When should a particular inference scheme be used? To determine whichmechanism to use when, we associate with each predicate the set of featuresthat may be used to deduce atomic formulae in which that predicate appears.andO;Cyc also has a general-purpose inference mechanism that (though inefficient)is capable of a much larger (but sitll incomplete) category of inferences.andO;This general inference engine is very similar to a unit preference resolutiontheorem prover.andM;* How does one integrate the operation of the different mechanisms? Eachinference mechanism is expected to provide a set functions (in addition toone for deducing some class of sentences) for providing the argumentjustifying an inference, providing a list of instances of the inference rule,etc.andP;  Given these facilities, integrating these inference features isstraightforward.andM;Each inference module can itself call any of the interface functions.andP;  (Ask,Deny, Justify, and Tell).andP;  For example, the mechanism for implementing thepreviously mentioned transferThrough schema calls Ask to verify the truth (orto find bindings satisfying) a particular sentence.andP;  When dealing withmechanisms other than domain-specific inference mechanism, a depth-firstiterative deepening procedure [27] is used for the search.andP;  Resource-limitedreasoning [3] is implemented by the indexical function resources-available,which specifies a cut-off depth, elapsed real time, or other resource boundsfor the search.andP;  (The usual cut-off depth used is about 25).andM;In addition, parts of these inference mechanisms are represented in Cyc, andthis reflection allows one to use an agenda to perform a best-first searchusing various heuristics to control the search strategy.andP;  The performance ofthe iterative deepening strategy has been good, however, that this meta-level[7] mechanism is rarely used.andM;Specifying Control Information ForandM;Individual AssertionsandM;A number of pieces of control information can be associated with eachassertion (sentence) P. Some of these include:andM;i)  Should the conclusions of the sentence P (the positive assertions, ifany) be propagated in the forward direction?andM;ii)  If backward-propagated, at what inference &quot;level of effort&quot; should thisrule P be run?andM;iii)  should the sentence P b treated as an integrity constraint?andM;Some of the motivation behind providing such annotations for axioms is todevelop a set of cliched meta-level (proof theoretic) sentences about whatactions were preferred, so that problem solvers could be written to exploitthese directly.andP;  That effort is still under way.andM;DenialsandM;The interface function Deny, though useful, is by far the most tricky one toimplement properly.andP;  As we remarked earlier, note that Deny ([Delta],KB) isnot the same (~[Delta], KB); the former will usually result in a KB in which[Delta] is unknown.andP;  For example, we might want to say that children ofteachers typically go to college.andP;  But we might want to Deny that forchildren of gym teachers.andP;  This is not to say that we would guess that theyvery likely do not go college, just that we do not want to bet one way or theother.andP;  Of course, there might be other agruments as to why those people (asa general rule) do or do not matriculate, and in any particular person's casethere might be other conclusive agruments for and/or against the assertionthat they attend college.andM;Though Deny can in principle be implemented by a combination of Tells andUnasserts, in practice we have found it useful to define a new operationcorresponding to the functionality described below.andM;If we write belief (Cyc, [Delta]) to say that [delta] is in the theorycorresponding to the KB, then Deny ([Delta] KB) is equivalent to asserting ~belief (Cyc, [Delta]).andP;  We can also specify the meaning of deny withoutresorting to belief as follows.andM;i)  If the sentece [Delta] had been asserted by Tell and is &quot;monotonicallytrue&quot; and there is no other way to derive it (i.e.andP;  it is an axiom and not atheorem), the Deny just deletes it fom the KB.andP;  So, in this case,Deny([delta], KB) reduces to Unassert([delta], KB).andM;ii)  If the assertion [delta] follows from others in the KB or is a &quot;localdefaults,&quot; and is labelled &quot;default true&quot; (or &quot;default false&quot;), then we getthe following two classes of denials.andM;-- Blanket Denial.andP;  This corresponds to introducing an axion that invalidatesany argument for [Delta] (i.e., agrumentFor ([Delta, a) * invalidArg (a)).andP;  Aless dogmatic version of this kind of denial is also available where onlythose arguments that are present at the time of the denial are asserted to beinvalid.andM;-- Constructive Denial.andP;  One or more of the assumptions (i.e., formulae ofthe form ~ [ab.sup.i](...)) is chosen and asserted to be false in order to&quot;defeat&quot; existing arguments for [Delta].andP;  Control over which assumption gets&quot;retracted&quot; can be exerted by using the predicate moreLikelyThan.andP;  IfmoreLikelyThan ('p1, 'p2) is true, then if a choice between p1 versus p2needs to be made, p2 is chosen as the likely one to retract.andM;iii)  If the assertion [Delta] follows from others and has been labelled&quot;monotonically true,&quot; then attempting to deny it causes an error to besignalled.andP;  It is then adjudicated by the asserter, who has the option ofretracting or reducing the truth-value (from monotonic to default true) ofvarious assertions from the KB (which led to [Delta] being asserted asmonotonically true), or (much more common if this is a &quot;top-level&quot; useroperation) simply abortin the attempt to Deny [Delta], at least for the timebeing.andM;We conclude the discussion of CycL and proceed to discuss the contents of theKB.andP;  Further details of the CycL language may be found in [8, 12-14, 16, 19].andM;The Cyc OntologyandM;Recall that the EL (Epistemological Level) is meant for communicating thecontents of Cyc independent of the &quot;inferencing hacks&quot; which are used forefficiency down at the HL (Heuristic Level).andP;  Hence, most of the discussionof the ontology of Cyc's KB in this article will be at the EL, not HL.andM;We begin by introducing some of the basic concepts and distinctions used, andlater proceed to &quot;representation issues&quot; such as time, events, agent,causality, etc.andP;  This discussion is meant only to give a flavor for the kindof things that are present in the Cyc Kb and is not a comprehensive overviewof what it encompasses.andM;Some Basic Concepts andandM;DistinctionsandM;The ontology of Cyc is organized around the concept of categoris.andP;  We shallalso refer to these as classes or collections.andP;  though we shall frequentlyuse set-theoretic notions to talk about collections, these collections aremore akin to what Quine termed Natural Kinds [29] than they are tomathematical sets.andP;  This shall become apparent later as we start ascribingvarious intentional properties to collections.andP;  The collections are organizedin a generalization/specialization heirarchy (not a tree since eachcollection may have more than one direct generalization).andP;  thegeneralizations and specializations of a collection (that is, its supersetsand subsets) will often be referred to as its genls and specs.andP;  Elements ormembers of a category are usually referred to as its instances.andM;Since this heirarchy is every important, we begin by discussing some of itsimportant nodes and why they are in certain unintuitive genls/specsrelations; we also discuss some of the partitions of categories (that is,dividing a category C into mutually disjoint subsets whose union is C).andM;The universal set is called Thing.andP;  One of its partitionings is into the twosets InternalMachineThing and RepresentedThing.andP;  Instances ofInternalMachineThing include the number '5,' the string &quot;Foo,&quot; et.--i.e.,andO;things for which the representation is provided by the Lisp substrate uponwhich CycL is written.andP;  Instances of RepresentedThing are things like Table,for which only a representation is provided by Cycl.andP;  This distinction is ofuse when deciding whether to use model attachments.andM;Another partition of Thing is into IndividualObject and Collection.andO;IndividualObjects are things like Fred, TheWhiteHouse,TheFourthOfJuly1990,--i.e., the non-sets.andP;  They can have parts, but notelements (instances).andP;  Instances of Collection include Thing (the set of allthings), Table (the set of all tables), dining (the set of all diningevents), and so on.andM;Predicates are all strongly typed and a single category from the Cychierarchy has to be specified as the type for each argument.andP;  This was aconscious design decision, and has tremendous heuristic power as the KB isbuilt.andP;  Namely, when a knowledge enterer has an urge to define a new kind ofslot (i.e., benary relation), he or she must either select or define thedomain (makesSenseFor) and range (entryIsA) of the slot.andP;  Usually, the slotis worth existing separately only if the domain is, and frequently gives theknowledge enterer a well-needed doublecheck on what he was about to do.andM;It should be noted that predicates such as age(x) and weight(x) cannotlegally be applied to collections (such as Table).andP;  To rephrase: since Tableis a set, a mathematical entity, it cannot have a weight or an age (it can ofcourse have many other slots such as cardinality), that is, the domain ofweight does not include collections such as Table.andP;  Of course we coulddiscuss weight (Table905)--the weight of an element of the set Table--butthat is quite different.andP;  Table is indeed a subset (spec) ofIndividualObject, it is just not an element of (istanceOf) IndividualObject.andM;In addition to collections of individuals, we also have collections ofcollections.andP;  For example, PersonType is a set whose elements include Person,ComputerScientist, Texan, etc., which themselves are collections whoseelements include Lenat, for example.andP;  The hierarchy folds into itself at thislevel and we do not have collections of collections of collections.andP;  (5)andM;It should be noted that unlike many frame systems, a distinction is madebetween the relations, instances (elements) and specs (subsets).andP;  So therelation between ComputerScientist and Fred (instances) is very differentfrom that between Person and ComputerScientist (specs).andM;The predicates themselves are first-class objects in the language and can beused as arguments to other predicates (this is a second-order like constructthat can be easily first orderized).andP;  Although some of our editing tools (andinternal data structures) gather together into &quot;frames&quot; the set of assertionsthat are binary predicates sharing a common first argument, that is merely aHeuristic Level (and user interface) distinction--there is nothing specialabout binary versus other-arity predicates at the Epistemological Level.andM;We are now ready to discuss some of the &quot;representation issues.&quot;andP;  First wediscuss the distinction between Substances and Individuals [18], and thenproceed to how we represent objects with temporal aspects to them.andM;Substances and Processes vs.andM;Individuals and EventsandM;If you take a piece of wood, and smash it into ten pieces, each piece isstill a (albeit smaller) piece of wood.andP;  But if you do the same for a table,each piece is not a (smaller) table.andP;  Substances are usually referred to inEnglish as mass nouns; some of them are obvious (sand, air, peanut butter)and some less so (time, walking).andP;  We view the concept PeanutButter as thecollection of all pieces of peanut butter.andM;Every individual is made of some substance or the other.andP;  If we do not have asingle type of substance of which that individual is composed, we can definea new one (Bertrand-RusselStuff?andP;  ugh!), use a more general substance(AnimalMatter), or even fall back on the most general kind of substance ofall, Substance.andM;Conversely, every piece of any substance--say this particular piece of peanutbutter over here--is an individual.andP;  This gives us some interesting relationsbetween substances and individuals.andM;Since every individual is a piece of some substance, Individual Object *Substance.andP;  On the other hand, any particular piece of any substance is anindividual and, since the category corresponding to a type of substance isnothing but the set of its pieces, Substance * IndividualObject.andM;So, rather surprisingly, the two sets are extensionally equivalent.andP;  We stillchoose to distinguish between them since they have different intensionaldescriptions.andP;  More specifically, one of the differences in their intensionaldescriptions is as follows.andP;  The different substances (such as plastic,peanut butter, air, etc.) are all instances of the collection SubstanceTypewhile the collections of individuals (Table, Person, Number) are instances ofObjectType.andP;  We shortly describe how this difference in intensionaldescription is used.andM;There are certain properties that are intrinsic in that if an individual hasthem, parts of individuals also have them (at least as a default), whilethere are other properties that are extrinsic (i.e., parts of individuals donot have this property even if the individual does.)andP;  The notion ofintrinsicness is closely related to that of substances in the following way.andO;Consider a particular table made entirely of wood--Table103.andP;  It inheritsvarious default properties from Wood, the kind of substance it is an instanceof (properties such as density, flash point, etc.) and it inherits otherproperties from Table, the kind of individual object it is an instance of(properties such as number of legs, cost, size, etc.)andP;  The former propertiesare intrinsic, the latter are extrinsic.andP;  This is no coincidence!andP;  An objectX (typically) inherits its intrinsic properties from whichever instances ofSubstanceType X is an instance of, and X inherits extrinsic properties fromwhichever instances of ObjectType it is an instance of.andM;So we now have a way of predicting, for any known predicate, whether or notit will be intrinsic: determine whether its domain (makesSenseFor) is aninstance of SubstanceType or ObjectType.andP;  This explains our earlier remarkabout how vital collections of collections are--we could actually dispensewith the concepts Substance and IndividualObject (since they arecoextensional), but we cannot do without SubstanceType and ObjectType.andM;Strictly speaking, it is always possible to carve up a substance so that theresulting parts are not instances of what the whole was an instance of.andP;  Forexample, one could take a glob of peanut butter and separate out all thepeanut chunks, and these alone do not form a glob of peanut butter.andP;  So thereis some restriction on how we may cut up a piece of some substance for thesubstancehood principle to apply.andP;  We associate a granule size with each kindof substance and the substancehood principle applies only to pieces largerthan the granule of that substance.andP;  This allows us to deal with strangekinds of substance like military hardware which is usually considered asubstance even though it consists of items like guns which are surely notsubstance-like.andM;Events and Persistent ObjectsandM;So far we have used the terms &quot;piece&quot; and &quot;cutting up&quot; in a very loosemanner.andP;  There are actually two senses in which these terms can beused--spatially and temporally--and we shall now examine them both.andP;  Thisexamination will lead to a discussion of more general issues concerningevents and objects that occur and exist over some time interval.andM;We can cut up something spatially (as we did with the piece of peanutbutter).andP;  We can also cut it up temporally.andP;  For instance, consider theprocess of walking: in Cyc's ontology.andP;  we have the collection Walking, whichis the set of all walking events.andP;  Consider one of its instances, aparticular event in which you walk to the corner mailbox and back home again.andO;Imagine a videotape of that event, and now consider some contiguousone-minute segment of the tape--say the third minute of it.andP;  If someonewatched just that minute, he or she would report that the minute was itself a(albeit shorter) walking event, that is, an instance of Walking.andM;In the last subsection, we noted that the class Wood had an interestingproperty: when a member of the class is physically carved into pieces eachpiece is still an instance of Wood.andP;  We then said that Wood was a type ofsubstance (an instance of Substance Type), and we could use such&quot;substance-like&quot; categorization to decide on intrinsicness of properties.andO;Here, we are seeing an analogous phenomenon: Walking, a class of events hasthe property that, when a number of the class is temporally carved intopieces, each piece is still an instance of Walking.andP;  We say that Walking is atype of temporal substance--what we will call a Process (that is, Walking isan instance of ProcessType).andP;  This turns out to be more than a superficialanalogy.andP;  Indeed, Walking is an instance of SubstanceType.andP;  We now divideSubstanceType into TangibleSubstanceType and ProcessType.andP;  Wood, for example,is an instance of TangibleSubstanceType.andM;Similarly, ObjectType is now divided into TangibleObjectType and EventType.andO;Even though Walking is a type of process, WalkingToTheMailboxAndBack is not.andO;If you imagine that third minute of the ten-minute WalkingToTheMailboxAndBackevent, it is still an instance of Walking, but a stranger watching just thatminute would not say that it was an instance of someone walking to a mailboxand back home--neither your home nor the mailbox might be anywhere visible onthe tape during that minute!andP;  The relationship here between Walking andWalkingToTheMailboxAndBack is indeed the same as the one between Wood andTable.andP;  Table is an instance of TangibleObjectType andWalkingToTheMailboxAndBack is an instance of EventType.andM;Earlier it was illustrated that, surprisingly, Substance and IndividualObjectwere coextensional; as a special case, it turns out that Process and Eventare coextensional.andP;  That is why ProcessType and EventType are actually moreuseful collections to have explicitly represented than Process and Event.andM;There are now two types of intrinsicness as well: a property can bespatiallyIntrinsic and/or temporallyIntrinsic.andP;  If you imagine the particularevent in which someone walked to the mailbox and back home, it is an instanceof Walking (from which it inherits default values for the average velocity,step-size, amount of attention required, etc.), and an instance ofWalkingToTheMailboxAndBack (from which it inherits default values fordestination, duration, etc.).andP;  Sure enough, that third minute of thevideotape would agree with the entire video on properties like averagevelocity, but would differ radically on properties such as duration.andM;Consider Table001--a particular table, an instance of the category Table.andP;  Itpersists for a &quot;lifetime,&quot; an interval of time before and after which it doesnot exist.andP;  Consider a temporal &quot;slice&quot; of Table001, such as the decade itwas owned by Fred.andP;  This too is an instance of Table.andP;  This is interestingsince it means that the category Table is an instance of ProcessType!andO;Actually there exist a number of categories in our ontology whose instancesare space-time chunks that have temporal aspects and which exhibitsufficiently persistent properties so that it makes sense to associate anotion of identity with these objects.andP;  The category of such things is calledSomethingExisting and this is an instance of ProcessType.andP;  Since all physicalobjects (which have any persistent identity) exhibit this property, bothTangibleSubstanceType and TangibleObjectType are specs of ProcessType!andO;Consequently, anything that is spatially substance-like is also temporallysubstance-like, though the converse is not true.andM;This is an interesting view of concepts such as Lenat or Table001.andP;  We viewthese objects as space-time chunks and we call the temporal pieces of these(e.g., LenatDuring1990, Table001WhileBeingEatenOn) subAbstractions of thelarger piece.andP;  SubAbstractions can of course have further subAbstractions.andO;The maximal subAbstraction (e.g., Lenat, Table001) is called an Entity.andO;Entities cannot have superAbstractions.andP;  Being space-time chunks thesesubAbstractions have temporal properties such as duration (the duration ofLenat is his lifespan), startingTime, endingTime, and so on.andP;  (6)andM;Not all objects that have temporal extents exhibit enough persistence towarrant according them a persistent identity.andP;  Consider Roger dining at arestaurant.andP;  We can consider a system consisting of Roger, the waitress, thetable, cutlery, food, etc., interesting enough to create an explicit objectfor this system.andP;  However, this object has no temporally persistentproperties and is of little interest after Roger walks out (except perhaps asan example in an article).andP;  Such objects are instances of SomethingOccurring,which is another important instance of ProcessType; they correspond toreifications of what usually goes by the name of actions, scripts, orprocesses.andP;  The parts of such an object are referred to as its actors (thoughthere are useful specializations (specSlots) of actors, such as performer,objectActedUpon, instrumentInAction, etc.).andP;  The various actors in an eventusually undergo some change either during or after its occurrence (i.e., thesubAbstractions of the actors during or immediately following the event aredifferent from the subAbstractions immediately preceding).andP;  It should benoted however that no ad hoc distinction is made about what kinds of eventscan cause changes in the properties of instances of SomethingExisting.andP;  Infact, since some of the properties of objects change simply by their existing(e.g., age), it could well be the case that the properties of somethingchange even though it was not an actor in any instance of SomethingOccurring.andM;Any instance of Event can have temporal properties (duration,endsAfterTheStartOf, etc.)andP;  We use two abstractions of time to specify thesetemporal properties: interval-based and set-based [1], [24].andM;Let us first discuss the interval-based abstraction of events.andP;  We can definea number of relations between events using the two primitives before andsimultaneousWith that can hold between the starting and/or ending times ofthese (possibly concave) intervals.andP;  For example, we define the binarytemporal relation startsBeforeStartOf by stating the following assertion toCyc: (*x,y) (startsBeforeStartOf(x,y) * Before(startingTime(x),startingTime(y)))andM;Why do we need a second abstraction of time?andP;  The interval-based abstractionof time makes it awkward to say things like &quot;people do not eat and sleep atthe same time&quot; since we are not dealing with a single convex interval.andP;  Insuch cases, it is easier to abstract &quot;the times when x is eating&quot; and &quot;thetimes when x is sleeping&quot; as sets of points.andP;  Then, based on this set-basedabstraction we use set theoretic relations such as intersects, disjoint,etc., to state axioms like the one above.andP;  In this case, the sentence wouldjust be an assertion that two intervals--viewed as a set of points--haveempty intersection.andM;It is interesting to note that by associating temporal extents with objectsas opposed to reifications of propositions, we get a certain addedexpressiveness.andP;  For example, it is easy to express statements of the form&quot;Fred when he was 35 liked his house as it had been 20 years earlier&quot; in thisformalism, while it is difficult to do so with formalisms that associate timewith propositions (or their reifications).andP;  There is, however a high costassociated with this.andP;  Given n entities and m intervals we can have up to n.msubAbstractions (O(n.m) objects) while using the other formalism we need onlyO(n+m) objects.andM;A vast majority of the statements we would like to make relate co-Temporalobjects, and we would like to exploit this.andP;  We do so by having a predicateholdsDuring.andP;  So instead of having to create two concepts never again needed,and asserting livesIn-(FredFrom1965To1975, House1From 1965To1975), we can nowjust assert holdsDuring(Fred, lives, House1, 1965-1975).andP;  It turns out to benotationally much simpler to write complex axioms (where specific instancesof SomethingExisting are replaced by variables) using the subAbstractionsformalism, but it is more efficient to do inference using the holdsDuringpredicate.andM;In addition to persistent objects such as Fred and nonpersistent objects suchas FredGoingToWendysForDinnerOnJuly4th1990, we also recognize changes inproperties of persistent objects as first-class events.andP;  If Fred was hungrybefore going to the restaurant and not hungry afterward, we can consider thischange as an object.andP;  Formally this corresponds to reifying a sentence thatspecifies he was hungry at some time and not hungry at some later time intoan object, and making this resultant object an event (since one can associatetemporal properties with it).andM;Temporal ProjectionandM;When one of the properties of an instance of SomethingExisting changes, it isnot likely to affect all (or even many) of its other properties [23].andP;  Forexample, when Guha gets a haircut, it does not affect his address,languages-Spoken, birthDate, etc.andP;  This is not surprising, since a useful setof properties is useful partly because they are largely independent.andM;Associated with each ground formula are intervals of persistence.andP;  So if weknew that a gun was loaded at time t0 and the persistence interval of thiswas I1, then, given any point in time between t0 and t0+I1, we can concludethat the gun was loaded at that time point.andP;  Usually we associate defaultperiods of persistence with classes of propositions by using axioms, whichare called Temporal Projection Axioms.andP;  These enable us to project (infer agood guess for) Fred's name and gender years in the future or past, his hairstyle months in the future or past, his mood seconds in the future or past,etc., based on the values of those attributes at any given time.andM;These temporal projections are only defaults.andP;  If there is evidence contraryto these projections based on particular actions that have taken place, thiscontrary evidence usually overrides these projections.andM;Associating specific finite periods of persistence with propositions is muchbetter than using a frame axiom [22] to allow for extended projection, butintroduces the following problem.andP;  If our knowledge that the gun was loadedat t0 was derived from a source other than temporal projection, we arewilling to say that up until time t0+I1 it is loaded.andP;  However, we do notwant to carry on and say that at time (t0+I1)+I1 it is still loaded.andP;  Thatis, we want to project only from a base time point where we had that &quot;other&quot;source of information (i.e., a justification other than temporal projection)about the fact in which we are interested.andP;  Notice how we escape from thisclassic problem by making use of the ability to refer to justifications forfacts (which we obtained using reflection) to state this dependence.andM;CausalityandM;Most treatments of causality (in AI) proceed by labelling some appropriatesubset of occurrences of material implication as causal.andP;  We do this by usinga relation causal whose argument is the reification of a sentence involving amaterial implication.andP;  For convenience, we shall refer to ((p * q) [and]causal'(p * q))) as (causes p q).andP;  Let us take a closer look at the axiomsthat specify the meaning of causes.andM;So suppose that we assert (causes p q).andP;  Then:andM;a) We have an inference rule that allows us to conclude that p implies(material implication) q from the above statement.andP;  Hence causes is astrictly stronger notion than material implication.andP;  That is, if p causes q,then p * q.andM;b) If p and q are ground sentences and true, they must refer to events (whichin Cyc is anything which can have temporal attributes).andP;  That is, p and qmust have at least one object constant that is an event.andP;  More importantly,every single event referred to in p must startBeforeTheEndingOf every eventin q.andM;c) Given any atomic ground sentence q that refers to an event, either qshould be &quot;basic&quot; or there should be some sentence p so that (causes p q) istrue.andP;  Intuitively, q being classified as basic corresponds to the notion ofit being &quot;unexplainable.&quot;andM;d) Given a statement of the form (causes p q), either this is basic or thereexists a sequence of sentences of the form (LogCause p a), (LogCause a b) ...andO;(causes m q), i.e., some &quot;mechanism&quot; that implements this causal relation.andM;Both c) and d) are extremely strong statements to make, which is why thenotion of &quot;basic sentences&quot; has been included.andP;  It would be nice to have astronger definition of causality that makes sentences such as (causes Falsep) false and we are working on this.andP;  No commitment is made as to whichoccurrences of implication are to be labelled as causal.andP;  The aim of theabove formalism is to provide a facility to state and experiment with variousheuristics for accomplishing that purpose.andM;Actions and ConcurrentandM;ProcessesandM;Each action (i.e., instance of SomethingOccurring) has associated with it aset of axioms specifying the preconditions for the action, the postconditionsof the action, and other axioms specifying the constraints on the actorsduring the event.andP;  Each action also may (and usually does) have a set ofsubEvents, the composition of which is the overall event.andP;  This decompositionof an event into subEvents (which are also actions) is identical to thedecomposition of an instance of SomethingExisting into its parts.andP;  In otherwords, the breaking down of a table into physical parts such as its legs,top, etc.andP;  is similar to the breaking down of having a meal at a restaurantinto ordering food, eating, paying the bill, etc.andM;The structure of a physical object is defined by the constraints on itsparts, and the structure of an event is defined by constraints on itssubEvents.andM;Just as there may be orthogonal ways of breaking down a physical object,there may be orthogonal ways of breaking down an action into subEvents.andM;Given a physical object and its parts, it is often possible to distinguishbetween different classes of parts.andP;  For example, the parts of most tablescan be classified into parts meant for providing support to the top, the topitself, parts for decoration, etc.andP;  We usually associate a predicate (whichis an instance of Part Slot) with each of these classes and use these torelate the parts to the overall object (rather than using a single predicatesuch as parts or physicalParts).andM;A similar approach is taken to relating the parts of an action to the action.andO;When dealing with actions there are two important categories of parts--twospecSlots of parts, namely actors and subEvents--and there are separatecategories of slots that are used to relate the actors to the particularaction (the ActorSlots) and to relate the subEvents to the particular event(the SubEventSlots).andP;  The actor slots define the &quot;roles&quot; played by thedifferent actors in the event (performer, victim, instrument...)andP;  Given anaction and a participant actor, there are three subAbstractions of the actorrelated to that action, namely, the subAbstraction of the actor just before,during and after the action.andP;  In practice we associate the entities of theactors with the action (through the ActorSlots) and then use three ternarypredicates (subAbsOfActorBefore, subAbsOfActorDuring, and SubAbsOfActorAfter)to specify the exact subAbstractions of the actors.andM;It should be noted that there are no &quot;primitive&quot; actions into which allactions are broken down.andP;  That is, the actions are not merely macrosintroduced for notational convenience, for use instead of more complexsequences of primitive actions.andP;  This approach is motivated by two reasons:we wish to be able to reason at different levels of abstraction and a prioriassigning of a set of actions as primitives goes against this; often onemight be able to provide only descriptions and not definitions of the morecomplex actions in terms of their sub-Events.andP;  In such cases, the morecomplex actions are not merely for notational convenience but are anepistemological necessity.andM;One of the problems that arises with predicting the effects of actions on theparticipating actors is the possibility of concurrent events [10, 23, 24].andP;  Asolution for this is obtained by collecting all overlapping events Ei(cutting up events if required) that affect a particular property into asingle event E and computing the net effect of E on the property from thesubEvents (suppressing the direct &quot;updating&quot; of the property by thesubEvents).andP;  The basic idea is to agglomerate the various concurrentprocesses that affect some property into a single process which has noconcurrent process that affects that property.andP;  The effects of this processare computed from those of the subEvents and the net change in the value ofthat property is that specified by this agglomeration process.andP;  It should benoted that the resulting agglomeration is necessarily a nonmonotonic processsince a closed-world assumption has to be made while collecting the set ofprocesses that affect our property.andM;When dealing with subAbstractions of reasonable durations, it becomes verydifficult to specify values for most temporally instrinsic numeric attributesbecause of the (often slight) changes in the value of the attribute over theperiod of the subAbstraction.andP;  To overcome this difficulty, we introduced anew class of terms corresponding to intervals in the quantity space (of theattribute).andP;  These intervals may be named (e.g., &quot;around 180 pounds&quot;) andexplicitly represented as Cyc units e.g., #%Around-180lbs).andP;  The intervalsmay be open (unbounded) in one direction.andP;  A calculus for performing simplemathematical operations with these intervals (provided by CycL) makes itrelatively easy to use both qualitative and quantitative specifications forattributes, switch between them, etc.andP;  [33].andP;  Another use for theseinterval-based quantity terms is to specify defaults for numeric attributes(e.g., height, weight, etc.) for categories which exhibit some but not toomuch variation in the value of these attributes (e.g., Fred's weight duringSeptember of 1990).andM;Interval-based quantity slots are also useful for dealing with quantities forwhich no acceptable measurable scale, or measuring instruments, have yet (orperhaps ever will) be defined: happiness, alertness, level of frustration,attractiveness, etc.andP;  Despite the lack of absolute units of measure, reified&quot;mileposts&quot; for these attributes' values can be defined, and partial ordersand even crude calculi developed.andM;Composite Objects andandM;AgentsandM;In addition to purely physical objects (such as tables and rocks) there existobjects like books and people with whom we would like to associate anintangible aspect such as a message or a mind (which also would have atemporal aspect).andM;Given such a composite tangible/intangible object, we can separate out thepurely tangible and the purely intangible parts, and represent both of themseparately and explicitly as well as representing the composite.andP;  The purelyintangible parts are instances of IntangibleObject; the purely physical partsare instances of TangibleObject; and the composition is an instance ofCompositeTangibleIntangibleObject.andM;The most important subset of CompositeTangibleObject is Agent--the set ofintelligent agents--and this subsection considers some aspects ofrepresenting agents.andP;  But first, consider why we want this distinctionbetween the physical and nonphysical aspects of agents.andP;  Considerrepresenting the Frankenstein monster at some point in time.andP;  We would liketo be able to say that his body was n years old, his mind was m years old andthe composition was k years old.andP;  Rather than introduce new predicates suchas ageOfMyMind, ageOfMyBody, amountOfTimeSinceMyMindAndBodyWereJoined,..., wewould much rather use the existing predicate age; besides being simpler andcleaner, this also lets us fully utilize the already-available axiomsinvolving age.andM;To do this, we need to be able to explicitly talk about the physical andmental extents of a composite.andP;  Having done this (via the predicatesphysicalExtent and mentalExtent) we associate weight not with the mental partof the Frankenstein monster nor with the composite part, but only with thephysical part; similarly, IQ is associated only with the mental part; and agemakes sense for all three aspects--and has a different value for all three.andM;This scheme gives the advantage of separating the physical aspects ofcomposites from their mental aspects and allows us to talk about aspects thatmight apply to both with different values (age, interestingness, likedBy,...)andO;However, in most cases, there is no predicate that can be used for both thephysical and mental extents that has different values and we would like tomake use of this regularity.andM;In other words, we do not mind having three separate concepts forFrankstein's monster--he was rather unusual, after all--but we should notneed to have three separate concepts for every composite if there is nothing&quot;conflicting&quot; among them.andP;  We accomplished this by adding the categoriesPartiallyTangible (a spec (subset) of SomethingExisting, and a genl(superset) of TangibleObject) and PartiallyIntangible (a spec ofSomethingExisting and a genl of IntangibleObject).andP;  SoCompositeTangibleIntangibleObject is now a spec of both of these newPartially...collections.andP;  Having done this, we can use a single unit, sayFred, to state both mental and physical properties of Fred.andP;  IQ, now makessense for PartiallyIntangibleObjects, weight makes sense forPartiallyTangibleObjects; and Fred is an instance of both those collectionsand hence can legally have both an IQ and a weight.andP;  If we happen to berepresenting an exception, like the Frankenstein monster, in which someproperty has a different value for the physical- or mental- extent, then wecan create the appropriate instances of TangibleObject and IntangibleObject,just as we did earlier.andM;As a default, we inherit the properties that talk about physical/mentalproperties to the physical/mental extents.andP;  This gives both theexpressiveness of the separation of physical and mental parts and theefficiency of not doing this when it is not required.andM;Since a full description of the various issues related to agenthood (thathave been/are being) considered in Cyc would require more space than isavailable here we will mention only a few of them.andP;  One of our recenttechnical reports [15] deals exclusively with this topic.andM;Agents can be collective (such as organizations and institutions) orindividual (such as people).andP;  Each Agent can have one or more propositionalattitudes toward any given proposition.andP;  The fundamental propositionalattitudes currently used are believes and desires.andP;  From these two, usingtime and other concepts, a variety of other modals are described and used(e.g., dreads, purposes, expects).andM;A primitive notion of awareness is incorporated as follows.andP;  Each agent has aset of terms and predicates of which he is aware.andP;  An agent may have anattitude only toward sentences that involve only terms of which he is aware.andO;This restriction is introduced to keep us from doing things like talkingabout Aristotle's beliefs about the Space Shuttle.andP;  We now consider someissues related to these propositional attitudes.andM;Attributing our own beliefs to other agents (with whom we might never havedirectly communicated) is something done quite frequently.andP;  Sometimes this isgood--(e.g., when the traffic light in front of you turns green, you assumethat the drivers on the cross street share your beliefs about what thatmeans!)--and sometimes it is bad (e.g., cross-cultural &quot;mirror-imaging&quot; hasled to innumerable political disasters.)andP;  There is a class of axioms calledthe belief projection axioms (analogous to temporal projection axioms) thatenable Cyc to efficiently do this sort of mirror-imaging, yet explicitlyrecord separate beliefs when they are known.andP;  The belief projection rulesthemselves are moderately interesting, since they describe what it means tobe a public figure, what it means to be commonsense knowledge, etc.andP;  CycLprovides special support to handle these efficiently at the Heuristic Level.andM;Agents can be in control of (the truth of) propositions.andP;  That means that thecontrolling agent can perform the requisite actions that determine theproposition's truth-value.andP;  For example, a robber holding a gun is in controlof whether the gun fires, and at whom.andP;  The truth-value chosen by thecontrolling agent is assumed to be based on his/her/its desires.andM;This notion of agents controlling propositions is sometimes an expedient wayof computing the truth-value of certain propositions.andP;  If there is an agentin control of a proposition P, and he or she desires P, then we can assumethat P is true (modulo limited resources, conflicting goals, etc.).andM;The concept of control provides us an abstraction layer that allows us toskip the details of the agent planning to make P true, executing that plan,monitoring it, repairing it, etc.andP;  Just knowing that you control the time yougo home from work, and that you want to sleep at home tonight, gives meenough information that I will call you first at home at midnight if I haveto reach you then; that is, I do not have to worry about the plan you made toge home, the details of the execution, etc., in order to believe that (bymidnight, at least) you would have arrived at home.andM;Agents may participate in Events (actually in instances ofSomethingOccurring) in one of two modes: voluntarily or involuntarily.andP;  If anagent participates in an event voluntarily, he usually has a purpose (usuallya propositional that is also one of his desires) that he believes will betrue as a result of that event.andP;  The concept of purpose allows us to (writeaxioms which will) decide when an agent will participate in (or pull out of)an event.andM;Agents can enter into Agreements with other agents; some of the parties to anagreement may be individual agents, and some may be collective.andP;  An agreementdefines a set of propositions that all the participants share (though theymay have quite different propositional attitudes toward the various clausesof the agreement!)andM;In addition, the agreement might also assign certain responsibilities(logically, these are also propositions) to specific participants.andO;Agreements usually also specify certain punitive and/or remedial actions tobe taken in the case of these responsibilities not being fulfilled.andP;  If theagent performing these &quot;punitive&quot; actions is a LegalSystem (such as aGovernment or GovernmentalAgency) then the agreement is a LegalAgreement.andM;We distinguish between agreements in which the event that &quot;enrolled&quot; aparticular agent was one in which he or she voluntarily participated and onesin which he did not participate voluntarily.andP;  For agreements an agentinvoluntarily participates in,the constraint that he or she shares the commonbeliefs of the agreement is slightly relaxed.andM;As a default, collective agents have one or more special types of agreementsassociated with them, such as their charter, articles of incorporation, etc.andO;Often an organization or institution will itself have (or at least act as ifit has) certain desires, dreads, purposes for its actions, authority, etc.,andO;that are not obtainable by a simple combination of those of the participants.andM;ConclusionandM;This article began by explaining the need for a large, general KB: toovercome the brittleness (in the face of unanticipated situations) thatlimits software today.andP;  The need for a Cyclike KB is critical not only inexpert system-like applications, but also for doing semantic processing fornatural language understanding, and for enabling realistic machine learningby far-flung analogizing.andM;We then focused on criteria for an adequate representation language, whichdrove us to the bifurcated architecture of having both an expressiveepistemological level (EL) and an efficient heuristic level (HL).andP;  One of theCyc project's most interesting accomplishments has been the construction ofthe Tell-Ask translator, which can convert back and forth between general EL(first-order predicate calculus-like) expressions and special-purpose HLtemplate instances.andM;Finally, we discussed some of the unexpected aspects of the Cyc KB'sorganization and contents, such as the relationships betweenIndividual-Object, Substance, Process, and Event.andP;  And we gave the flavor ofsome of our recent research by sketching our still very incomplete treatmentof Agents and Agreements.andM;Perhaps the most important theme from all these aspects of the project isthat of eschewing the &quot;single general solution&quot; dream, and rather assemblinga set of partial solutions that work most of the time, and work veryefficiently in the most common situations.andP;  We have seen that tenet apply torepresentation language design, knowledge entry methodology, control ofsearch during inferencing, truth maintenance, and throughout the contents ofthe KB.andP;  The emergent global behavior of the system should hopefully befairly &quot;use-neutral.&quot;andM;The reader may have noticed several aspects of the Cyc effort which we havenot touched on in this article.andP;  while interesting in their own right, theseare not our main topic for research, and in each case we have done what wefelt was necessary to maximize the rate of construction of Cyc.andP;  Here is alist of a few such intentional omissions from the article:andM;* The Knowledge Server: This subsystem accepts everyone's KB operations,serializes them, and, if constraint violations appear, adjudicates theresulution of the conflict.andP;  In cases of no conflict, it then broadcasts theoperations to everyone else.andP;  The connections today are generally thin-wire,though we expect this to change in the coming year.andM;* The User Interface: This collection of tools includes various textual andgraphical tools for browsing, querying, and editing the KB.andP;  Some of thegraphical tools are semantic-net-based; one is an Escher-esque recursivebirdseye view of a museum floor plan.andP;  Some of the editing tolls are idealfor making &quot;point mutations&quot; and corrections, some are oriented towardsketching some brand new area and gradually making the sketch more precise.andM;* The Machine-Learning Module: This subsystem roams over the KB, typically atnight, looking for unexpected symmetries and asymmetries.andP;  These in turnoften turn out to be bugs, usually crimes of omission of one sort or another.andO;In very rare cases today, but, more frequently we jope, in future years,these will turn out to be genuine little discoveries of useful but hithertounentered knowledge.andM;* Digitized Images: Yes, often it is much easier to just grab a picture of anobject and point to the part you mean, rather than trying to figure out whatits name is.andP;  Cyc contains such images (from the Visual Dictionary [6]), butexperienced knowledge enterers rarely use them.andM;* Other Nonpropositional Knowledge: Some Cyc researchers are building neuralnets that we can use at the very earliest (preheuristic) and very latest(reduction to instinct) stages of understanding of some task.andP;  One example ofthis development, training a net on examples of good and bad analogies, andthen letting it make &quot;hunches&quot; about potentially good new analogies, huncheswhich the rest of Cyc can investigate and flesh out symbolically.andM;* The Copy and Edit Mechanism: Most knowledge entry in Cyc involves findingsimilar knowledge and copying it, and modifying the copy.andP;  Increasingly overthe years, Cyc has helped in this process, and as a result knowledge entrycan be done more rapidly than we had originally estimated.andP;  This is goodsince the number of assertions before reaching the NLU crossover point alsoappears to be larger than our 1984 estimate.andP;  These two discrepancies are notunrelated: many of the extra assertions deal with overcoming ambiguities,with being precise about a cluster of closely related concepts, and thatmeans that Cyc can help the user copy a whole cluster or related &quot;thin&quot;concepts in approximately the time we expected it to take to copy one of ouroriginal &quot;fat&quot; concepts.andM;How are we to judge where we are going?andP;  How do we make sure that we do notgo through these 10 years of labor, only to learn in 1994 that theassumptions upon which we based our efforts were fundamentally mistaken allalong?andP;  We do this be getting others to actually use our system.andP;  In the past18 months, as the Cyc Representation Language and Ontology stabilized, webegan to encourage collaborations both with academic researchers and withindustrial researchers and developers: we held workshops and panel sessions;and we have begun once again (after a purposeful several-year hiatus to focussolely on research) to write books and technical reports and journalarticles, such as this one, to inform and interest the greater artificialintelligence and computer science communities.andM;Cyc is still too small to have more than an anecdotal chance of improving theperformance of application programs using it, but the early results arepromising.andP;  AT DEC, for example, John McDermott, DAvid Marques, RenataBushko, and others have built a Cyc-based computer-sizing application.andO;Serving as a pre-processing step for XCON [30], its job is to ask questionsabout a potential DEC customer and come up with a very rough computer sizing.andO;The trouble with having standard expert systems do this task is they tend toask too many questions, questions which can often be answered by commonsense, questions for which Cyc is able to guess answers.andP;  (For example, giventhat toy manufacturers have stringent government safety regulations, andadult clothing manufacturers do not, which is more likely to be the proper&quot;match&quot; or &quot;precedent&quot; for this new potential customer who is a manufacturerof children's clothing?andP;  Or: given that the basic business unit in a hotel is&quot;the room,&quot; and at a car rental agency is &quot;the car,&quot; use relatively deepunderstanding of what goes on at each kind of place to decide that for a newpotential customer which is a hospital the right business unit is the bed,not the room.)andM;Numerous other Cyc-based applications are under way at NCR, Bellcore, USWest, and Apple.andP;  Academic collaborations include coupling with largeengineering knowledge bases (with Ed Feigenbaum and Tom Gruber at Stanford),large data bases (with Stuart Russell and Mike Stonebraker at Berkeley),standardizing knowledge interchange formats (with Mike Genesereth atStanford), axiomatizing human emotions (with John McCarthy at Stanford),machine learning by analogy (with Devika Subramanian at Cornell), andqualitative physics reasoning in the service of understanding children'sstories (with Ken Forbus at Illinois).andP;  And of course one vital collaborationis with Elaine Rich and Jim Barnett at MCC, namely the natural languageunderstanding project which is described in [2].andP;  testing the system.andP;  Wealso thank Ed Feigenbaum, Pat Hayes, John McCarthy, John McDermott, andMarvin Minsky, who have in almost orthogonal ways helped us to think moreclearly about the material presented herein.andP;  We thank Bobby Inman and WoodyBledsoe for setting up MCC, the only place in the US where a high-riskhigh-labor long-term project like Cyc could be done; conversely, weappreciate our shareholders' sticking with us in the five first, riskiestyears.andP;  Finally, we wish to acknowledge our significant debt to the AIcommunity in general; Cyc is built upon a rich foundation of three decades ofCS and AI research results, only a small fraction of which we have explicitlycited in the References.andM;(1) The reification of a function term is different from the value of thatfunction term.andP;  For example, it might then be referred to in a propositionabout how costly its evaluation might be, which proofs depend on knowing thevalue, and other meta-level assertions.andM;(2) The &quot;isa&quot; predicate corresponds to the set-membership relation; it issometimes called ISA, is-a, AKO, element-of,.andP;  .  .  In Cyc's KB we happen tocall this instanceOF.andP;  Also, the &quot;ab1&quot; predicates are short for abnormal infashion i; so ab1 corresponds to being an exception in the sense of being abird and not being able to fly.andM;(3) Note that 'p, read &quot;quote p,&quot; refers to the sentence p, rather than toits truth-value.andP;  Normally, one is free to substitute &quot;equals for equals&quot; inmathematical or logical formulae, but think of the trouble you would get intowith &quot;Fred believes Mary's age is 39' if it turns out that Mary is 40.andP;  Wecertainly do not want to do the substitution and conclude &quot;Fred believes 40is 39.&quot;andP;  To prevent this sort of problem, assertions and formulae (such as&quot;Mary's age&quot;) can be quoted in this fashion.andM;(4) The argumentation axiom is just like any other axiom at theEpistemological Level.andP;  However, since it is used very often, at theHeuristic Level, there are some special procedures for incorporating it.andM;(5) We used to, but they were never much use.andP;  Collections of collections,however--such as PersonType and SubstanceType and EventType--have provenvital.andM;(6) This is superficially similar to the &quot;histories&quot; framework [17] but isdifferent in a very important way: there is no relation between theintersection of these histories and the frame problem.andM;ReferencesandM;[1] Allen, J. Maintaining knowledge about temporal intervals.andP;  IN Readings InKnowledge Representation, H. Levesque and R. Brachman, Eds., Morgan Kaufmann,Los Altos, CA, 1986.andM;[2] Barnett, J., Knight, K., Mani, I. and Rich, E. Knowledge and naturallanguage processing.andP;  Tech.andP;  Rep.andP;  ACT-NL-104-90, MCC, March 1990 (Alsoappears in this issue of CACM).andM;[3] Bobrow, D.G.andP;  and Winograd, T. An overview of krl, a knowledgerepresentation language.andP;  In Readings In Knowledge Representation, H.andO;Levesque and R. Brachman, Eds., Morgan Kaufmann, Los Altos, CA, 1986.andM;[4] Bledsoe, W.W.andP;  Non-resolution theorem proving.andP;  In Readings in ArtificialIntelligence, B.L.andP;  Webber and N.J.andP;  Nilsson, Eds., Morgan Kaufmann, LosAltos, CA, 1981.andM;[5] Brachman, R.J., Fikes, R.E.andP;  and Levesque, H.J.andP;  Krypton: A functionalapproach to knowledge representation.andP;  In Readings In KnowledgeRepresentation, H. Levesque and R. Brachman, Eds., Morgan Kaufmann, LosAltos, CA, 1986.andM;[6] Corbell, J.-C.andP;  The Visual Dictionary.andP;  Facts on File, New York, 1987.andM;[7] Davis, R. and Buchanan, B.G.andP;  Meta-lelvel knowledge: Overview andapplications.andP;  In Readings IN Knowledge Representation, H. Levesque and R.andO;Brachman, Eds., Morgan Kaufmann, Los Altos, CA, 1986.andM;[8] Derthick, M. An epistemological level interface for cyc.andP;  Tech.andP;  Rep.andO;ACT-CYC-084-90, MCC, February 1990.andM;[9] Doyle, J. A truth maintenance system.andP;  In Readings IN NonmonotonicReasoning, M. Ginsberg, Ed., Morgan Kaufmann, Los Altos, CA, 1987.andM;[10] Forbus, K. Qualitative physics: Past, present and future.andP;  In ExploringArtificial Intelligence, H. Shrobe, Ed., Morgan Kaufmann, Los ALtos, CA 1988.andM;[11] Ginsberg, M. Multivalued logic.andP;  In Readings In Nonmonotonic Reasoning,M. Ginsberg, Ed., Morgan Kaufmann, Los Altos, CA, 1987.andM;[12] Guha, R.V.andP;  The representation of defaults in cyc.andP;  Tech.andP;  Rep.andO;ACT-CYC-083-90, MCC, February 1990.andM;[13] Guha, R.V.andP;  and Lenat, D.B.andP;  Cycl: The cyc representation language, part2.andP;  Tech.andP;  Rep.andP;  ACT-CYC-452-89, MCC, December 1989.andM;[14] Guha, R.V.andP;  and Lenat, D.B.andP;  Cycl: The cyc representation language, part3.andP;  Tech.andP;  Rep.andP;  ACT-CYC-454-89, MCC, December 1989.andM;[15] Guha, R.V.andP;  and Lenat, D.B.andP;  The world according to cyc, part 2: Agentsand institutions.andP;  Tech.andP;  Rep.andP;  ACT-CYC-453-89, MCC, December 1989.andM;[16] Guha, R.V.andP;  and Lenat, D.B.andP;  Cycl: The cyc representation language, part4.andP;  Tech.andP;  Rep., MCC, April 1990.andM;[17] Hayes, P.J., Naive physics 1:Ontology for liquids.andP;  IN Formal Theoriesof the Common Sense World, J.R.andP;  Hobbs and R.C.andP;  Moore, Eds., Ablex, Norwood,N.J., 1985.andM;[18] HAyes, P.J.andP;  Some problems and non-problems in representation theory.andO;In Readings IN Knowledge Representation, H. Levesque and R. Brachman, Eds.,andO;Morgan Kaufmann, Los Altos, CA, 1986.andM;[19] Lenat, D.B.andP;  and Guha, R.V.andP;  Building Large Knowledge Bases.andO;Addison-Wesley, Reading, Mass., 1990.andM;[20] McCarthy, J. First order theories of individual concepts andpropositions.andP;  In Readings In Knowledge Representation, H. Levesque and R.andO;Brachman, Eds., Morgan Kaufmann, Los Altos, CA, 1986.andM;[21] McCarthy, J. Programs with common sense.andP;  IN Readings In KnowledgeRepresentation, H. Levesque and R. Brachman, Eds., Morgan Kaufmann, LosALtos, CA, 1986.andM;[22] McCarthy, J. Applications of circumscription to formalizing common senseknowledge.andP;  IN Readings In Nonmonotonic Reasoning, M. Ginsberg, Ed., MorganKaufmann, Los Altos, CA, 1987.andM;[23] McCarthy, J. and Hayes, P.J.andP;  Some philosophical problems from thestandpoint of artificial intelligence.andP;  In Readings In NonmonotonicReasoning, M. Ginsberg, Ed., Morgan Kaufmann, Los Altos, CA, 1987.andM;[24] McDermott, D. A temporal logic of reasoning about process and plans.andO;Cognitive Science, 6 (1982), 101-155.andM;[25] McDermott, D. and Doyle, J. Nonmonotonic logic.andP;  In Readings InNonmonotonic Reasoning, M. Ginsberg, Ed., Morgan Kaufmann, Los Altos, CA,1987.andM;[26] Moore, R.C.andP;  The role of logic in knowledge representation andcommonsense reasoning.andP;  IN Readings IN Knowledge Representation, H. Levesqueand R. Brachman, Eds., Morgan Kaufmann, Los Altos, CA, 1986.andM;[27] Pearl, J. and Korf, R. Search techniques.andP;  Annual Review of Comput.andO;Sci., (1987).andM;[28] Poundstone, W. Labyrinths of Reason.andP;  Doubleday, 1988.andM;[29] Quine, W.V.andP;  Natural kinds.andP;  In Ontological Relativity and other essays.andO;Columbia University Press, New York, 1969.andM;[30] Soloway, E., Bachant, J. and Jensen, K. assessing the maintainability ofxcon-in-rime: Coping with the problem of a very large rule-base.andP;  INProceedings of AAAI-87 (1987 pp.andP;  824-829.andM;[31] Warren, D.H.D.andP;  An abstract prolog instruction set.andP;  Tech.andP;  Rep.andP;  309,SRI, Artificial Intelligence Center, Computer science and Technology Center,October 1983.andM;[32] Weyhrauch, R.W.andP;  Prolegmena to a theory of mechanized formal reasoning.andO;In Readings IN Knowledge Representation, H. Levesque and R. Brachman, Eds.,andO;Morgan Kaufmann, Los Altos, CA, 1986.andM;[33] Williams, B. Minima: A symbolic approach to qualitative algebraicreasoning.andP;  In Proceedings of AAAI-88, 1988.andM;CR Categories and Subject Descriptors: C.5 [Computer Systems Organization]:Computer System Implementation; D.3.3 [Programming Languages]: LanguageConstructs--Control Structures, Data Types and Structures; F.4.1[Mathematical Logical and Formal Languages]: Mathematical Logic; H.2.8[INformation Systems]: Database Management--Database application; I.2.1[Artificial Intelligence]: Applications and Expert Systems--NAtural languageinterfaces; I.2.3 [Artificial Intelligence]: Deduction and TheoremProving--Deduction (e.g., natural, rule-based); I.2.4 [ArtificialIntelligence]: Knowledge Representations and Formalisms--Relation systems,representation languages, semantic networksandM;General Terms: Design, Human FactorsandM;Additional Key Words and Phrases: Cyc, knowledge basesandM;DOUGLAS B. LENAT is Principal Scientist at MCC and Consulting Professor ofComputer Science at Stanford University.andP;  His pioneering work in MachineLearning led him to chafe at the &quot;brittleness bottleneck,&quot; and in 1984 heestablished the Cyc project.andP;  He has authored more than 50 published papersand has written and edited several books, including Knowledge Based Systemsin Artificial Intelligence and Building Expert Systems.andM;R.V.andP;  GUHA is a mechanical engineer and computer scientist who is pursuing aPh.D.andP;  in Computer Science at Stanford University.andP;  He has authored severalpapers and technical reports, and (with coauthor Doug Lenat) a recent book:Building Large Knowledge Based systems: Representation and Inference in theCyc Project.andP;  Guha is interested in investigating the role that contexts playin everyday reasoning.andM;KAREN PITTMAN is a botanist who has spent the last three years addingknowledge to Cyc.andP;  Initially, she was involved in the construction of the UTComputer Science Department's Botany Knowledge Base.andP;  She has authored papersin the American Journal of Botany and in the Biotechnology and Ecology ofPollen.andM;DEXTER PRATT is a chemist and reformed entrepreneur (prior to joining MCC, hewas president of Red Shark Software).andP;  Before that, he was a long-timeemployee of Lisp Machine, Inc. (LMI), performing a variety of tasks includingprocessor design, software development, and technical management.andM;MARY SHEPHERD is a sociologist and engineer, and has worked on the Cycproject since its inception.andP;  She has authored articles on interface toolsfor browsing and editing large KBs.andP;  Prior to her involvement in Cyc, sheworked at Thinking Machines, Inc. (TMI) and was assistant to theVice-President for Information Technology at Harvard.andM;Authors' Present Address: All authors are members of the Cyc Projecttechnical staff at Microelectronics and Computer Technology Corporation(MCCe, 3500 W. Balcones Center Dr., Austin, Texas 78759.andP;  Their emailaddresses are ai.andP;  andless;last nameandgt; @mcc.com (e.g., ai LEnat@mcc.com).andO;</TEXT></DOC>