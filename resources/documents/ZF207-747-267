<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-747-267  </DOCNO><DOCID>07 747 267.andM;</DOCID><JOURNAL>Release 1.0  June 27 1989 v89 n6 p1(9)* Full Text COPYRIGHT EDventure Holdings 1989.andM;</JOURNAL><TITLE>Self-organizing systems. (overview of detailed examples ofself-organizing systems: includes related article about theimportance of self-organizing systems)andM;</TITLE><DESCRIPT>Topic:     Self-Organizing SystemsFuture of ComputingTheoryUnited States. Department of Energy.andM;</DESCRIPT><TEXT>SELF-ORGANIZING SYSTEMSandM;The attention of many software developers has shifted to multi-user systems.andO;These are not your multi-user systems of old, where a host controls amultitude of terminals, or even your new multi-user database, passivelyserving the ad hoc requests of several users, but distributed systems whereindividual users and applications act independently to produce results inconcert.andM;These systems are too complex and contain too many local interactions (bothinside and with the outside) to be centrally managed.andP;  Instead they must becoordinated and self-organizing, with access to distributed information -andunderneath it all, good plumbing.andP;  Self-organization is a property ofsystems.andP;  not of their components, but it results from the interactions ofthose components,andM;Self-organizing systems aren't new: Contention schemes such asmulti-processor scheduling algorithms and Ethernet are ubiquitous examples ofnon-hierarchical, coordinated systems.andM;Yet only a few commercial systems vendors have studied their theoreticalunderpinnings -- the field of self-organizing systems.andP;  This makes sense:Such systems self-organize whether developers intend them to or not.andP;  Traffichas been flowing (more or less) ever since the young hominid passed the oldone on a jungle path.andP;  The issue is not the existence of selforganizingsystems, but our ability to build better ones, from traffic grids and socialsafety nets to complex interacting network applications and groupware.andM;In proper self-organizing fashion, in this issue we explore some examples ofselforganizing computer systems and the necessary platforms first, and onlyafterwards examine the theories underlying their behavior.andP;  Since vendors'goal is to make the intricacies invisible to users and even to applicationdevelopers, most current implementations are embedded systems rather thanapplications.andP;  Yet long-run this paradigm (sorry, but that is the correctword) has profound implications for the design of large-scale unattendedsystems such as Reliable Water's desalination plant (page 4) and forgroupware.andP;  The fundamental prescription is that these systems should becollections of agents, not centrally controlled applications that directlymanage local activity, although they may well use a traditional databaseunderneath.andP;  In other words, authority is delegated to autonomousapplications (or agents) that negotiate or interact with each other.andP;  Thecentral system can manage the data and define the rules, but it does notdetermine the activity of the individual agents (just like a properlaissez-faire government; page 29).andP;  One benefit to developers is that theprograms they write need deal with only a subset of the whole system --although the effects, good or bad, propagate globally.andM;Yet another crackpot idea?andM;Like art, self-organizing behavior is hard to define precisely; it's easierto discuss its characteristics and specific implementations of it.andP;  Inessence, it results from the ability of interacting parts to create orderlysystems out of chaos, in a world where the theory of entropy says that thingsinevitably get more and more disorderly.andP;  (Self-organizing systems, ofcourse, take energy out of the environment to do their self-organizing.) Youseem to get more information and structure out than you put in; seeminglysimple equations or objects can produce complex, unpredictable patterns.andP;  Thebest way to predict them is by actually running a simulation.andM;Simulations will come in handy in predicting and determining how applicationsand modules will interact as we build both new and old modules intoever-larger interconnected (and thereby interacting) systems.andP;  Just asmarkets of multitudes of competing independent agents allocate resources(more or less) efficiently, so can self-organizing computer systems probablyrun a complex environment of computer systems more effectively than centralcontrol could.andP;  But that hardly means that any relatively stable state isoptimal -- far from it.andP;  The tweaking and external controls that help tonudge a system to optimality are the basic problem here -- and a perennialconcern of economists and policymakers as well as scientists.andP;  See ourdiscussion of markets (page 17 to 19) for more on this topic.andP;  Nor do allsystems of agents self-organize: Some stay inert, and others disintegrateinto chaos.andM;The principles in actionandM;Self-organization occurs with all kinds of objects: cells in a body, bees ina hive, people in a society, cars in traffic.andP;  The objects needn't be alike:It also applies to differentiated cells in a body, competition among species,relations between buyers and sellers or host and parasites.andP;  There are otherfamiliar strains here: Object-oriented programming.andP;  The free market system(a special love since our return from the Soviet Union).andP;  Agents and demons.andO;Evolution and ecology.andP;  Yield management (see Release 1.0, 88-2) -- which isairlines' attempt to participate in a market of independent customers withdifferent strategies, mostly levels of price- and time-sensitivity, insteadof treating them all as average.andP;  On the following pages we explore some moreexamples.andM;Of course, developers aren't all going to go off and grow software.andP;  Nor arewe going to use these ideas in rebuilding existing accounting applications ordatabases.andP;  (Large doesn't necessarily mean complex.) But they might be usedto allocate the computing resources to process these applications.andM;In terms of applications, computer-based self-organizing systems control onlytheir own &quot;environment&quot; -- the computers they reside on and representationsof the devices they control or monitor.andP;  So the obvious tasks to apply themto are network/resource management, as well as design (page 19), simulation,modeling and process control.andP;  For example.....andM;RELIABLE WATER COMPANYandM;What is a self-organizing system? The first large-scale, commercialselforganizing system we know of is the water-desalination plant recentlyunveiled by Reliable Water Company, RW-2.andP;  Reliable Water is a five-year-oldconcern co-founded by Ed Fredkin, former head of the MIT Computer Science Laband a scientist noted for offbeat theories that confound traditionalscientists by making sense.andM;RW-2 works without human intervention (except to turn it on).andP;  It is run ontwo 8-megabyte Mac IIs by REX, an integrated software system designed withthe G2 process-control expert system development tool from Gensym, alsocofounded by Fredkin.andP;  It operates with what Fredkin calls &quot;machineinstinct,&quot; and what ve would call a bunch of autonomous cooperating agents.andM;REX itself would be far too complex to program as a traditional expertsystem, with rules tied to specific pieces of equipment, let alone in thetraditional procedural way.andP;  Instead, most of the specific knowledge in RW-2sits in a knowledge base of passive object classes such as valves, pumps,filter membranes and the water itself.andP;  (RW-2 knows enough about valves tocalibrate a new one when it is added to the system and has already done so,says Fredkin.) These objects are hooked up to sensors monitoring the realthing, and supply their data to the software system.andP;  The system's layout ofpipes was entered as a diagram that the tool could interpret.andM;In addition, there are about 100 generic rules, or active agents (a numberthat will continue to grow as Reliable Water's engineers keep tinkering),which manipulate the data objects and actually run the plant and keep itsoperations within tolerance.andP;  The agents have individual goals that combineto make the plant deliver clean water while meeting a range of constraints:safety, efficiency, maintenance of the plant, etc.andP;  They have rules forworking with each other and for monitoring and controlling pressure,temperature, electrical currents, salinity and other parameters of theequipment and materials in the plant.andP;  Some care about current operatingconcerns; others consider the long-term impact of the short-term measurestaken to keep the plant operating despite small-scale equipment failures ormalfunctions.andP;  They also generate management reports and instructions forhuman maintenance engineers, and test the system after repairs.andP;  Whenreadings disagree, the agents can compare notes.andM;While G2 (written in LISP) doesn't use the word agent, it has somethingcalled &quot;focus,&quot; or collections of rules evoked when an unusual event happens,such as a power failure or leak.andP;  Agents performing other tasks continueroutine work while the focus agents decide what to do -- stop the plant anddetermine the cause of failure, fix the suspected item, test it, and soforth.andP;  call them cooperating expert systems.andP;  There is no single point offailure in the software; each agent should be covered by several others ifits task is not done properly.andP;  Says Fredkin: &quot;It encompasses everything.andP;  Ananimal in the jungle doesn't go out on a paved path; it's got to cope withwhatever it finds.&quot; This early commercial system, mind you, is of a kindwhere the worst failure would be the release of salty water into a watersupply; it's not about to blow up, deliver a first-strike attack or harmhumans in any serious, irrevocable way.andM;Nor was the system built overnight; in fact, it took five years to design,including extensive work on the reverse-osmosis process by which itdesalinates brine, and programming, To get many of the agents' rules andprocedures, says Fredkin, &quot;We had to live through the accidents.&quot; One clevertrick: Put a salt sensor in the floor drain; any salt loose in the system issure to show up there pretty quickly.andP;  Moreover, RW-2 has far more machinesensors than an equivalent human-run plant would need.andM;The ultimate promise of self-organizing systems is not to make complex taskssimple, but rather to automate non-routine, non-simple behavior.andP;  They do notreplace (or assist) a single expert, but rather model the behavior of a largegroup of mostly cooperating experts.andP;  By eliminating human factors such assleepiness, illness, competition (except regulated cost-minimizingnegotiation for resources), etc., self-organizing systems should operate moreeffectively and reliably than equivalent human systems.andM;Much of the work done by Reliable Water and Gensym at a pilot plant in theBritish Virgin Islands and a model in Massachusetts will be transferable toother kinds of systems, let alone clonable for an arbitrary number ofdesalination plants.andP;  (The company plans to field four more in the CaymanIslands and the Caribbean by December, at $350,000 to more than $1 millionapiece.) The logic in REX that knows about valves and pressures should beeasily transferable; so should many of its higher-level instincts/agents forkeeping equipment in good repair, avoiding damage to humans , etc.andP;  Each ofthese must obviously be customized, but much can be done locally.andP;  (A managercan manage anything, right? Only the workers need to know much about theparticular business they're carrying out.)andM;thINKer revisitedandM;We wrote about a similar system of cooperating expert agents, without theconceptual context, in April 1986.andP;  That system, to manage page layout andother production processes for newspapers, was never commercially fieldedbecause its vendor, Composition Systems Inc., was acquired and the projectshut down.andP;  However, its principals, Mike Stock and Marvin Berlin, started anew company, Artificial Intelligence Technologies, which sells expert-systemdevelopment tools akin to Gensym's.andP;  AIT is currently bidding on a couple ofcooperating-expert systems, including a factory-automation system for apharmaceutical company and a production system for a large publisher.andP;  &quot;Ourbiggest problem in the old days was connectivity and database,&quot; says Berlin.andO;AIT's Mercury system, however, has solved some of those problems with a tightSQL interface that lets it use distributed databases to manage informationaccess across environments, whereas many expert system tools keep track oftheir own data -- with difficulty.andM;NEW WINE IN OLD BOTTLES: FAMILIAR TERMS WITH NEW MEANINGSandM;(We'd hate to defend these in a court of law or worse, an academic symposium,but they should be useful in understanding the discussion that follows.)andM;adaptation -- change, generally in response to circumstances, by any means.andM;It's hard to program adaptation because the variety of circumstances is sogreat.andP;  (Also, if it's programmed, is it adaptation, or simply response?)andM;agent - -an autonomous application acting on behalf of another person orandM;thing, with delegated authority.andP;  The agent's goals are those of the entitythat created it.andP;  You could say that an agent is an active object with amission, but agents are abstractions that can be implemented in any way,whereas an object has a fairly formal definition.andM;application -- a generic, vague term for almost any kind of code that exandM;ecutes a defined set of instructions.andP;  Or just useful software.andM;class -- the generic form of objects (see across).andP;  Each object instance isandM;a member of a class from which it derives its behavior (and perhaps someclass data).andP;  Each object instance has its individual identity and data,which may come from a file or a database, or may be derived at runtime.andM;competition -- when two or more agents with separate, perhaps conflictingandM;goals attempt access to the same resources.andM;cooperation -- when two or more agents with at least one goal in common workandM;together to achieve it.andM;evolution -- adaptation by means of selection, a form of self-organization.andM;The individual components may or may not change; the system changes becauseof the replacement of its parts according to some criteria that cause thesystem gradually to change character in some way that furthers its survivaland growth.andM;expert system - -generally, a data-driven, rule-based application.andP;  It exandM;ecutes non-procedurally but it embodies explicit, unchanging rules.andP;  (Ofcourse, the rule could be to change its own code in such and such a way inresponse to certain conditions, in which case you might have aself-organizing system on your hands.) Because they need to be flexible (ifnot adaptable) in response to a variety of conditions, agents frequentlycontain expert systems.andP;  How many rules does it take to make an expert systeminstead of a rule-based code module? When does a procedural applicationcontain rules, and when does an expert system contain procedural modules?andO;It's a question of which one calls the shots.andM;genetic algorithms -- algorithms for simulating evolution.andP;  They direct proandM;grams composed of strings of subroutines to reproduce &quot;sexually,&quot; generallyby splicing code elements together, so that individuals of succeedinggenerations include code modules from both lines of ancestors.andP;  The geneticalgorithms also manage a selection process, so that the programs evolve tomeet criteria set by the genetic algorithms.andM;goal - -a specification for long-term success.andP;  Only people have goals inandM;the sense of mission or purpose; agents have explicit rules and constraintsand instructions.andP;  Self-organizing systems seem to have goals, but that's aphilosophical discussion....andM;markets -- self-organizing systems where the main means of interaction isandM;competition and trading.andP;  While trading generally encourages more efficiencythan competition without trading, markets suffer from the &quot;tragedy of thecommons,&quot; or local suboptimal solutions where everyone would be better off ifall agreed on some course of action, but where no one's individual interestis so served.andP;  Cooperation needed here!andM;objects -- The traditional way of explaining an object is to say it's encapandM;sulated (protected) data that includes procedures that are the only way ofmanipulating the data.andP;  But to the outside object-oriented world it looksmuch more like a program; it has behavior (executing code) that may have somedata (parameters) attached.andP;  An object has a protocol, which is the kinds ofmessages it knows how to respond to.andP;  The ideal agent has a broad range ofprotocols (or situations) it can handle, and the ideal self-organizing systemcan respond to anything.andP;  Active objects stand around in memory and interactwith other objects; they change things (and may do damage).andP;  Passive objectstend to do data collection and filtering, but they don't alter the data orchange the situations they encounter.andP;  In the Reliable Water system (page 4),for example, passive objects represent the physical system elements;rulebased active objects (agents) manipulate them.andP;  Even passive objects maysend messages to other objects, but in general their behavior doesn't haveside-effects.andP;  (Finally, there are what you might call &quot;dead&quot; objects, wheremarketeers use the word object to describe rich data types that their systemscan handle.)andM;Some people use &quot;instance&quot; to describe a particular object, and use class todescribe a generic object.andP;  This is clearer, but it smacks overly of jargonto some.andM;self-organizing system -- a system of independent, interacting parts thatandM;shows regular patterns of behavior and adaptation generated by the parts'interactions.andM;time - -an important aspect of all these systems.andP;  You can't adapt afterandM;you're dead.andP;  Time delays in dissemination of information and feedback haveimportant effects on the ability of systems to self-organize effectively.andM;transaction -- an atomic instance of (steps in) an application, with aandM;defined set of procedures or events to be accomplished and a means ofmaintaining integrity and closure (or rollback to the original state).andP;  Atransaction transforms the domain it concerns from one valid state at thebeginning to another valid state at the end -- hence the obsession withmanaging concurrency and conflict.andP;  Just as objects may contain otherobjects, so may parent transactions contain (or consist of) nested childtransactions.andM;MEMORY MANAGEMENT: BORLAND'S VROOMMandM;Another example on a smaller, less visible but far more mass-market scale isVROOMM, Borland's new Virtual Runtime Object-Oriented Memory Manager.andP;  Thissystem enables large applications such as Borland's new object-orientedversions of Reflex (shipping), Quattro and Paradox (forthcoming) to operatein 640K.andP;  Rather than extend memory (which requires users to purchaseadditional memory), VROOMM builds a self-organizing memory management systemthat uses available RAM better, discarding small code modules, or objects, ona dynamically determined basis.andP;  (The data encapsulated in these objects isthe code itself; any data they manipulated has been stored on disk or withthe application's data structure.) Each code object keeps track of its ownpersistence priority.andP;  The priority is based on factors such as vhen it waslast used, whether it was used to reach the current state of the system, andits interdependencies with other objects.andP;  For example, windows and menus aregenerally interdependent and loaded together, because menus are a kind ofwindow and require the window code for much of their behavior.andP;  As memoryfills up, the system kernel queries the objects to determine theirpersistence ranking, and sends the lowest-ranking object into the cache.andO;(When the cache fills, the lovest-ranking item is deleted.)andM;Most applications with memory management swap in or discard hugepre-determined overlays up to 64K in size, which take lots of time to reloadand contain much more code than the particular functions the user needs atany one point.andP;  By contrast, VROOMM lets the system load code in tiny,targeted increments.andP;  Performance degrades gracefully; as there's less spacein RAM for code, swapping gets more and more frequent, but still takes only asecond or two each time.andP;  Meanwhile, the application data can grow to take upalmost I all the space not required by the kernel.andP;  Obviously, such a systemcan work only if your code is divided into handy little object modules -- 2to 4K in this case, which required complete rewrites of Reflex and Quattro(Quattro was redone anyway to incorporate technology acquired with Surpass).andO;Paradox was already quite object-oriented under the covers and took to thenew scheme easily, says Paradox designer Richard Schwartz.andM;But it certainly wasn't easy, says Borland vp product management RobDickerson.andP;  Borland can be quite open about the general techniques used, hesays, because it took a lot of testing and debugging to develop the precisealgorithms that would work effectively and the development tools to use themin a general way in other Borland products and for resale with languageproducts.andP;  Exactly how much weight should you give to an element used fourcycles ago versus one used eight cycles ago? Which pieces of code should beloaded together? Defining the objects and the class collections (all therelated objects typically used for a particular task) is a key part of thejob, and one that's specific to each application.andP;  Borland originallyconsidered having the system retain information from session to session (tocreate &quot;personalized software&quot;), Dickerson says, &quot;but it turned out that thebiggest win was interdependencies.andP;  If a certain user rarely uses graphics,then it never loads the graphics-oriented modules, and they never show up.&quot;andM;It's hard to quantify the benefits from VROOMM, notes Dickerson, preciselybecause it moves you from a no-choice situation where the software simplydumps and reloads code overlays to one where performance degrades gracefullyin a granular trade-off as data takes over memory, and more and more smallchunks are removed in a sequence selected dynamically to minimize the numberthat need to be loaded back.andM;Borland intends to use VROOMM in OS/2 versions of its applications and offerits facilities in language toolkits as well.andP;  OS/2 doesn't give you morememory; it simply gives you access to more memory if you have (or buy) it.andO;As people start running several applications simultaneously in OS/2 withfinite amounts of physical RAM, memory management will continue to beimportant.andP;  The possibility of optimizing and sharing objects acrossapplications - -not a function of VROOMM but an extension of its approachthat will have to be coordinated with OS/2 -- is exciting,andM;MULTIPROCESSING: COROLLARY'S 386/smpandM;One frequent use of self-organizing coordination schemes is in busmanagement, multi-processor scheduling and other distributed-systems tasks.andO;OEM supplier Corollary is using such a scheme in its 386/smp, an add-inmultiprocessor system used by Zenith and other companies in their ownhigh-end UNIX systems.andP;  To applications and programmers they look like fast386 systems that run SCO Xenix, but inside, the 386/smp replaces SCO's UNIXkernel (while keeping all its utilities and drivers) with a new kernel thatsets up a self-organizing scheduling system among up to ten 386 processors.andO;&quot;There is no way for a central controller to know what's going on fastenough&quot; to allocate work efficiently, says Corollary president George White.andO;Formerly with Computer Automation, Western Digital and Texas Instruments,White founded the company in 1985.andP;  His goal, he says, is to resist thetemptation to put his computer into a box and to continue selling boards toother vendors.andP;  That way he can concentrate on performance rather thanpositioning, and use whatever schemes work underneath the hood without havingto explain them to end-users, as follows:andM;To maximize coordination and minimize overhead and private use of code anddata, the processors all share a global 64-megabyte memory on a high-speedbus (which doesn't work for geographically dispersed systems).andP;  Eachprocessor looks to the system run list for the next available task when itfinishes or suspends work.andP;  To minimize traffic across the bus, eachprocessor has its own 64K cache for the data it's working on, and has a biasto tasks it's done before so it doesn't need to load new code or data.andP;  Then,in a feature called coherent caching, each processor board contains an agentto watch the bus and intercept any calls for the data in its cache, so thatthe call can be diverted to that cache rather than get the old version fromthe main memory.andP;  The 386/smp includes one processor attached to an AT bus tohandle any AT peripherals the user may have.andP;  In addition, the multipleprocessors may have their own peripherals directly connected, and the systemcan be configured on installation so that any given processor favors tasksthat use its particular peripheral.andM;This sounds rather complex -- but that's the whole point.andP;  By observingsimple rules, the processor agents can carry out complex overall behaviorthat allocates the system resources efficiently.andM;EMERGENT TROJAN HORSE: SimCityandM;SimCity is fixing to be this year's hot game -- and perhaps the applicationthat illustrates (rather than explains) the principles of self-organizingsystems to the mass market.andP;  Positioned, and eminently enjoyable, as a game,it lets the user construct a city or play with any of seven model citiesincluded in the package.andP;  The user has a budget and has to cope with avariety of familiar challenges, as well as optional monsters andunpredictable disasters.andP;  The user can build industrial areas, raise or lowertaxes, hire police forces, replace roads with mass-transit systems -- andquery the system at any time for a citizens' poll on his performance.andP;  Butnothing he does is simple -- high taxes cause businesses and residents tomove out; economic growth puts pressure on resources; police protection costsmoney.andP;  Quite apart from random events the developer threw in (includingnuclear plant explosions although no nuclear power -- as opposed to weapons-- plant has ever exploded), the system is unpredictable because of all thesedependencies -- a/k/a/ object interactions.andM;Experience seems to be that players initially enjoy zapping their cities -andthen quickly discover that it's more fun trying to keep them alive.andP;  &quot;It'slike looking at an ant farm and poking it with a stick,&quot; says developer WillWright, 29, who spent three years developing the program to its current stateand has studied countless books and papers on urban planning.andP;  &quot;Pretty soonyou decide that's no fun.andP;  There's no challenge.andP;  You want to build a city;that's a challenge.&quot; The basic message is that cities are complex, livingthings and there's no simple way to score performance.andM;Wright asks, &quot;Why do you want me to tell you what the score is? But maybe youcould put in your goal when you start playing, and measure against that --city size, or the poll of residents...&quot;andM;In about 130K of C code, SimCity contains algorithms for 13 to 14 spatialarrays (maps) for data such as crime rates, land values, pollution andpopulation, as well as 300 or 400 other interacting variables; call themobjects.andP;  The system is especially complex because of this two-dimensionalaspect: You don't just have a crime rate, but a map of where the criminalshang out and how they're affected by the presence of police, parks and otherspatial elements.andP;  Many of these factors also have feedback loops: Crimedrives down land values and attracts further crime -- unless you do somethingabout it.andP;  Says Wright: &quot;We encode the behavior between the elements and thenwe just let it run and the system's behavior emerges.&quot;andM;All things considered, 130K for the simulation is a small amount of code -andinitial complexity.andP;  It's the behavior that's complex.andP;  Imagine trying tocode such a system procedurally or even with forward-chaining expertsystem*techniques.andP;  It takes almost twice as much additional code -- and as much CPUtime -- to manage the graphics and animation and other features.andM;Response to the game has generally been favorable even among professionalsand academics.andP;  &quot;Most of them want access to the algorithms so they can tweakit a little,&quot; says Wright.andP;  &quot;It would be great to have it used by people whoreally know what they're doing.andP;  We're trying to Trojan-horse the educationaspect, and it seems to be working.&quot;andM;TRAFFIC CONTROL: TEXAS INSTRUMENTS, ComMUTEandM;One of the obvious uses of simulated self-organizing systems is in trafficcontrol.andP;  The application is not using the systems to control the traffic,but using them to model and simulate the results of various local rules so asto design better traffic-flow systems.andP;  One such project, CoMMUTE (forComputationally Metabolic Utilitarian Transportation Ecosystem), is underwayat Texas Instruments' Dallas AI Lab, where two researchers are working to&quot;get over the bottlenecks of central management, explicit control and topdowndesign with emergent computation,&quot; says researcher Marek Lugowski.andM;He and colleague Duke Buster are building simulated vehicles (&quot;rho-dents,&quot;using the Greek letter for r) that crawl over grids to reach theirdestinations.andP;  Armed with about a page of LISP code (the environment takes alot more), they start with two coordinates each and modify those coordinatesto simulate travel.andP;  Their &quot;goal&quot; is to reach the destination coordinates,and they may not move to spaces occupied by other vehicles, which they can'tsee coming until they're in the next square in the grid.andP;  over time, theylearn to do this in a relatively efficient way.andP;  They work with some rulesabout avoiding occupied spaces and build an internal representation of thegrid -a map of their environment -- based on previous collisions.andP;  Theinformation in the map decays, so that it can be updated with more recentexperience and singular experiences wash out.andP;  In one simulation, with thedestinations lined up along an axis of the grid, the vehicles learn toapproach their destinations head-on in a way that minimizes collisions.andO;Better yet, they readjust within 10 to 30 iterations after the destinationsare shifted.andM;So far, ComMUTE is strictly experimental, but TI is funding it in the hopesthat something commercial may come of it.andP;  (That's how Speak'n'Spell gotstarted.) Lugovski, a four-year veteran of this area, has visions of airportswithout control towers, but TI will probably apply the approach first in suchmundane (and less risky) uses as directing forklifts in a warehouse.andP;  SaysLugovski: &quot;The problem with traditional AI as a solution is that it doesn'tscale up.andP;  Things get too complicated and vulnerable to flaws.&quot; Simulationsshow that simple rules such as the vehicles' work independently of the totalsystem's size.andP;  (The local ratio of rodents per grid area, however, has animpact on performance: You can't simply increase the number of rodentswithout giving them more room to run around in.) This makes intuitive sensetoo: Since all the vehicles know about and interact with is their localenvironment, the overall size of the system couldn't have any impact on theirperformance in avoiding collisions.andP;  But will they be as effective in gettingto their destinations on long trips?andM;SELF-ORGANIZING OPERATING SYSTEM: KEY LOGICandM;Last year ve wrote at length about Key Logic's KeyKOS, an object-orientedoperating system that provides extremely high security and efficientexecution by packaging all its functions -- including emulation oftraditional OSes such as UNIX and IBM's NVS -- as objects.andP;  After somefinancial and management commotion and a venture refinancing, the company hasregained its bearings.andP;  Although still in start-up mode after four years, itis now calling on commercial customers jointly with IBM under a ComplementaryMarketing Agreement.andP;  It has also licensed the software to a large softwarevendor that plans to use it as the foundation of a communications program forresale.andP;  For further details, see Release 1.0, 88-5.andM;SOME PLATFORMSandM;For now,most vendors are simply working on creating the kinds of multisystemenvironments and tools that will let multiple user and agent applicationsinteract, rather than building self-organizing systems per se.andO;(Multi-tasking is de rigueur, so all these agents can operate concurrently.)andO;The three major categories are databases of information about the componentsand state of the system (FileShare and Legato), cross-systems communications(Transarc and the Open Software Foundation's request for technology for adistributed computing environment) and programming tools that will help tobuild autonomous agents/transactions (Cooperative Solutions).andP;  Soft-Switchand Hewlett-Packard's NewWave environment will ultimately provide some of allthree.andP;  NewWave's Object Management Facility, a platform that will span (atleast) DOS, OS/2 and UNIX, has garnered some support from the ObjectManagement Group, a growing would-be standards group led by Hewlett-Packard(a key OSF founder).andM;Overall, the platform/activity or central/local dichotomy sounds much likethe division of labor between a database and the applications that surroundit; the added idea is that the applications interact with each other.andO;Distributed databases, because they have solved all these problems forthemselves, give you the ability to build cooperative applications acrossplatforms without worrying about these issues -- but only if you adhere tothe database tool's restrictions.andP;  It's easy to push data around, harder toexecute commands or send messages remotely.andM;WHO'S ON FIRST? SAROS FILESHARE AND LEGATO SYSTEMSandM;Saros and Legato Systems exemplify the differences between the OS12 and UNIXmindsets.andP;  Although they have similar goals in mind -- building a systeminformation substrate to manage system-resource objects and possiblyapplication objects -- they have come up with two entirely differentapproaches.andP;  Initially, Saros will be selling a cross-network file managerprimarily to network administrators for use by end-users in office-automationenvironments, whereas Legato will first sell a front-endless product to OEMsand programming teams who can appreciate the intricacies of its products.andO;Both of them will eventually operate in the shadow of -- or supportinterfaces to - -X.500, the forthcoming (don't hold your breath)international standard for directory services, a sort of global database thatwill enable users and applications to keep track of system resources acrosswide-area networks.andM;Saros FileShare is one of the first OS/2 applications to show up -- and anSQL Server application to boot.andP;  But in fact it's systems software that usesthe Sybase engine to accomplish the task of managing DOS and OS/2 filesacross a network.andP;  If you think of the world in the traditional form oflayers you have to wonder how systems software can sit on top of all theother layers, but the modular approach puts such facilities side by side.andM;FileShare was originally designed to be a general object manager by a highlytechnical crew of people mostly from Tandem and Microsoft.andP;  But its foundersdiscovered that their customer set was uneasy enough at the notion ofadopting OS/2 servers, and didn't want to hear about objects and such.andP;  Thecustomers had a real-world problem -- giving users access to files theyshould have access to, and keeping them away from files they shouldn't see.andO;FileShare allows users or applications to manage files by attributes --author, user, date, etc.andP;  -- as well as by as many key words as they care touse (and search).andP;  Because it relies on a database that manages the files (aswell as other objects, such as users, workgroups, etc.), user administratorscan perform set operations -- delete all files last used before 14 July 1988that do not include the key word &quot;IRS.&quot; Or transfer all files used by theWonderWidget workgroup to the archives; the project has been canceled.andO;Individual users can control their own private files, but the system managesgroup access to them in ways specified by the administrator.andM;FileShare thus lets almost any application function transparently as amulti-user application (aside from copyright issues) because FileShare takesover management of concurrent access to files and file-locking.andP;  In the shortterm, some vertical-market software vendors will be using it to manage filesfor their applications.andP;  As more and more application vendors supportFileShare (which isn't a big technical challenge), getting to FileShare filesfrom within an application will be almost as easy as it is now for DOS files,but FileShare does make the network visible in a way that network operatingsystems that let you use files off a server do not, The user has to find thefile and store it locally before gaining access to it.andM;FileShare's file-management services are extensive, giving users ways tocatalogue and selectively retrieve files, and allowing system administratorsto control access, back-ups, version management, archiving and other taskswith virtually all the power of SQL Server.andP;  At the user's option, a singlefile can be copied by multiple users and manipulated locally (with notice toother users that this is happening).andP;  When any user returns the file, the newcopy is kept as a version of the original, so you have, say, 3A, 3B, and 3C.andO;At any point, those three can be logically merged in FileShare: the user hasto do the work -- redlining and reconciling documents, say -- and thenFileShare creates a single new Version 4 from the result.andM;On beyond filesandM;Because it manages files, FileShare is the way dBASE used to be: An entirefile is off-limits when any part of it is restricted; in other words, youcan't lock records within a file, but just entire files.andP;  Of course, that'sthe province of a database manager, not a file manager anyway.andP;  Yet FileShareis really an object manager under its skin: With proper integration betweenan application and its underlying capabilities, you could just as easilymanage objects for an application and provide smaller-grained control,including locking records if they are so defined.andP;  (It's more likely to beused for database views or applications, notes president Wayne Carpenter;leave the records to the databases.) Other possible tasks include managingsystem resources such as printers, mailboxes or application modulesthemselves anywhere there's an SQL Server to help keep track of things.andM;For such extensions, the product will need to add application logic to dealwith the particular services and operating environments it's working in, butthe fundamental idea of managing system resources will stay the same.andP;  Ofcourse, it's a feature of OS/2 (and other advanced systems such as UNIX) thatapplications are composed of modules.andP;  Only a few of the modules need betask-specific; the rest are more general utilities that accomplish otherparts of the job; and yet other modules are specific to the system platform.andO;Typical of what we expect of many &quot;OS/2&quot; applications, such as Lotus Notes,FileShare is actually an OS/2 back-end linked to DOS front-ends.andP;  Overall, wethink FileShare will be successful if Saros can find a good way to sell andsupport it.andP;  It offers pc users (and their administrators) the same servicestaken for granted in other multi-user envirornments but not yet fullyaddressed by pc IAN and operating system vendors.andM;The UNIX approach: LegatoandM;FileShare operates on OS/2 servers only.andP;  Although it can operate acrossmultiple servers transparently (so that only the network administrator needsto know where things are physically, and then only at configuration time), itis limited for now to tightly linked OS/2 servers (despite its foundation onthe widely ported SQL Server) and has code specific to OS/2 and DOS filestructures and IAN security.andP;  Legato Systems, a 10-person VC-funded firmrecently started by a group of former Sun employees, addresses similarproblems for the higher-end, more performance-sensitive UNIX world.andM;Their goal is similar to FileShare's -- to provide an underlying facilitythat will enable users and applications to ignore the intricacies of networklayout and accessibility.andP;  Legato, however, is initially going afterprogrammers and developers rather than end-users, since that's where theaction is.andP;  Its first product is Prestoserve, a server performance-enhancerthat only a techie could love (or install).andM;Like FileShare, Legato's future products will use a database, but one modeledafter the hierarchical system used in X.500.andP;  Legato is interested in beingable to fit easily into the standards-sensitive UNIX world, while Saros isrelying on Microsoft and Sybase for standards for now (although it usesmostly SQL Server's transaction and integrity services, and manages a lot ofstorage directly for efficiency).andP;  Long-run, Legato co-founders RustySandberg and Bob Lyon expect they will be providing a kind of system resourcemanager that will work with rather than replace X.500.andP;  It will extend it byproviding tools for system resources to register themselves so thatapplications and users can find the most efficient resources that meetspecific criteria.andP;  In essence, it will provide a medium for publishingpersistent information - -such as the services available from a particularprinter or the applications available on a particular server -- as well as alanguage for real-time inquiries, such as &quot;Are you busy now?&quot; and &quot;Do youhave corporate stationery in one of your bins?&quot;andM;Although the underlying service is general, Legato intends initially to sellspecific versions of it for functions such as printing, communications and &quot;adecent back-up-and-restore service across heterogeneous cpus -- emphasis onrestore rather than backup,&quot; says Lyon.andP;  &quot;We want to turn everyone into anoperator just like they're an operator of the telephone, by making it alleasy and consistent.&quot; It's likely to be a lot easier to sell than objectmanagement.andM;Long-run, both these companies will probably be providing object managementfor self-organizing systems.andP;  In a world of many interacting objects/agents,it may be hard to find the right one to send a message to without theservices of some such global directory.andP;  Legato's language will be one meansof addressing objects that manage peripherals such as printers, fax machinesand new devices of the future.andP;  (Of course, in the far distant future X.500will probably advance to having an object-oriented database underneath.)andM;TOMORROW'S TRANSACTIONS: COOPERATIVE SOLUTIONS and SOFT-SWITCHandM;In the self-organizing object-oriented systems of the future, active agentswill be performing real work (rather than just searching information servicesfor interesting articles), and developers and users will want some way ofdefining and ensuring the integrity of the work they perform, i.e.andP;  a way todefine transactions.andP;  Although the system as a whole may easily adjust to thefailure of a transaction or two, the &quot;owner&quot; of the agent is unlikely to beas accommodating.andM;These agents can represent users trying to accomplish a high-level task, orsystem agents that manage resources, deliver mail or perform computations.andO;(See glossary, page 6.) Just as an object is an encapsulated piece of datawith some methods or behavior accessible externally, so is a transaction anencapsulation of a unit of work that transforms a domain from one valid stateto another.andM;The transaction's behavior is visible externally, and it may send messages toother objects and agents anywhere on the systems to accomplish its work, butit maintains integrity of action over time just as an object maintains theintegrity of its data.andP;  The transaction either commits or is rolled back.andO;Thus, transactions are atomic activity, with logic to check and enforceintegrity.andP;  No outside events -- except for those explicitly part of thetransaction -- are allowed to interfere with its behavior (just as objectsrespond only to messages they understand).andM;Time-stretched transactionsandM;But the traditional notion of a transaction sees it as an instantaneousevent: The state of the world outside is assumed to remain constant.andP;  In thissense, it's much like a batch job, notes Soft-Switch president Mike Zisman.andO;(Soft-Switch sells multi-platform E-mail tools and systems.) In fact,transactions can go on for days (also an issue for object-oriented databases;Release 1.0, 88-12); examples include delivery of mail, editing changes to adocument or design, multi-person approval cycles and other tasks that requireinput from several people (i.e.andP;  groupware).andP;  The trick will be to designtransactions that can accomplish their work successfully and with integrityin the face of a changing outside world and possibly conflictingtransactions.andP;  The simple approach would be to lock everything, but realityrequires more granularity so that the world can keep moving while manytransactions are going on concurrently.andM;E-mail is a combination of a front-end and a transaction-oriented back-endthat manages the location and transfer of high-level information.andP;  This kindof back-end capability will be vital for agents communicating asynchronously.andO;E-mail treats the transfer as an atomic transaction with facilities forerror-recovery, integrity, reporting, etc.andP;  In the case of Soft-Switch andsome others, it may also include data translation from one environment'sformat to another's.andP;  In the case of the Coordinator, it may include somecontent-based activity, monitoring the type of message and maintaining arecord of transaction types and open items.andP;  (Who promised a report to Juanbut hasn't delivered it yet? Whom did Alice delegate the customer's complaintto?) And there are nested transactions.andP;  Delegating a piece of work is atransaction, but the parent transaction -- completion of the work -- is stillunfinished.andP;  Another E-mail-style transaction application is the growing areaof EDI (electronic data interchange), with defined transactions for purchaseorders, invoices and the like.andM;In order to build agents, people will in fact be building transactions-atomic applications that accomplish a specific task and manage its integrity.andP;  One company addressing this issue is Cooperative Solutions, a startupwhose principals left Tandem last summer and started the 11-person firm thisJanuary after a long vacation.andP;  The company's aim is to enable users togenerate transactions for the new envirornment where &quot;applications may besmeared all over the network and have to adapt to resources -- database,agents, mail -- moving around too,&quot; says co-founder Kim Worsencroft.andP;  &quot;Andthey still have to be atomic.&quot; Initially these will be mostly databasebasedtransactions, but Cooperative Solutions will attempt to be databaseandenvironment-independent -- unlike most current development tools.andO;&quot;Object-oriented and transaction-oriented people come from different worlds,but we're trying to join the two,&quot; adds co-founder Dennis McEvoy.andM;(The name of Tandem crops up quite frequently; it is one of the firstcompanies to have truly understood the issues of cooperative processing,redundancy, transactions, etc.andP;  Indeed, one of the first independent-agentideas was designed by Tandem's Joel Bartlett into its Guardian OS in 1975-paranoid democracy.andP;  If a processor failed and another processor noticed,the second processor would send a message to the administrator and blackballthe failed processor.andP;  However, it wouldn't tell the other processors; itwould let them notice for themselves -- which they would, eventually.andP;  Thereason? What if part of a failing processor's behavior was to broadcast amessage that another, healthy processor was failing? This scheme ensured thatprocessors couldn't falsely denounce each other to the system.)andM;OPEN WORLD: OSF AND TRANSARCandM;The Open Software Foundation is well aware that selecting UNIX and a userinterface isn't enough; the world needs a &quot;Distributed Computing Environment&quot;to standardize upon.andP;  In fact, you might well argue that the distributedcomputing platform is more important than the local operating system.andP;  It'simportant only that local systems can communicate, rather than that softwarefrom one system be able to execute on another one.andP;  (See Release 1.0, 88-11.)andO;OSF's request for technology is seeking facilities for crosssystemcommunications, allowing applications and agents to interact freely,including remote procedure call services, naming and authentication services(part of X.500), presentation services (data translation betweenenvironments) and a distributed file system.andP;  These components will probablycome from several vendors and will be sewn together by OSF next year justlike the components of its Motif interface.andM;A possible contender for the OSF's blessing is a forthcoming product fromTransarc, a company recently funded by IBM among others and formed tocommercialize the technology underlying the Andrew File System long in use atCarnegie-Mellon.andP;  The AFS implementation is also likely to be adopted by NeXTand of course by IBM, especially if IBM puts its support behind the NextStepinterface/development environment.andP;  Transarc clearly has the technology forits first product, which will be a commercial version of AFS.andP;  Futureproducts will handle such tasks as implementing transactions over networks,with special attention to security and nested transactions, based on CMU'sCamelot, for CArnegie-Mellon Low-Overhead Transaction system.andM;SOME EXPERIMENTSandM;Large-scale self-organizing software systems are still pretty rare.andP;  With theexception of Reliable Water Company's REX (page 4), the only ones we know ofare research efforts.andP;  Two of the more prominent are the work of Danny Hillisat Thinking Machines, the company he founded, and Bernardo Huberman at XeroxPARC.andP;  Hillis is using the capabilities of the powerful Connection Machine hedesigned to model population dynamics and evolution and trends such as thespread of disease, while Huberman is more directly concerned with the use ofself-organizing market-style systems to manage computer resources -- or whathe terms &quot;the ecology of computation&quot; (the title of a book he recently editedon the topic).andM;What's the difference between a marketplace system and an evolutionary one?andO;One is probably simply the time scale; the other is that in evolution theagents are replaced over time, while in the market it's the goods or servicestraded and used by the agents that go in and out of existence depending ondemand for them (consider demand the criterion of survival in the market, butit's only the resources and market structure, not the agents, that evolve.andO;(Of course, most systems are hybrids over the long run.)andM;In the Hillis model, adaptation of individual elements is the focus, whereasin the Huberman approach the issue is the organization of the system and theallocation of resources.andP;  Interactions between the elements in Hillis's modelare simply competition for resources and high scores; in the Huberman model,agents negotiate each other in structured auctions for a variety ofresources.andP;  (Note: these are not different approaches to the same problem,but different problems and different approaches that are both part of thebroad field of self-organizing systems.)andM;BERNARDO AND THE MARKETSandM;Perhaps the most visible simulated market system is Spawn, the work ofHuberman and his colleagues at PARC.andP;  Huberman is a former physicist whoworked in chaos theory early, and has now moved on to self-organizingsystems.andP;  Spawn is a computational &quot;ecology,&quot; running mostly on networked Sunworkstations, which has attracted considerable press attention of late.andP;  Itenables PARC to make use of idle computer time through market allocation ofprocessor time -- and of course to study the effects and effectiveness of avariety of algorithms for doing so.andM;Huberman takes a rewarding physicist's approach, focusing on experiments andmeasurements, and he's getting interesting results.andP;  The system has been upjust a fev months and produced the results described here, but it's not ingeneral use: It's still easier to simulate than deal with the network'scryptic reporting interface and occasional failures.andP;  (Guess we need aselforganizing system to maintain as well as allocate resources.) The initialobservations are hardly surprising: It takes only a few agents competing forresources to establish &quot;rational&quot; prices: That is, time on a machine isproportional to its performance, so that price-performance is relativelyconstant.andP;  Prices rise in response to shortages or high demand.andP;  And soforth.andP;  The efficiency of allocation is close to optimal.andM;But more interesting effects emerge when you start looking at issues like useof resources when there's a delay in feedback: What happens when (as isnormally the case) you're dealing with delayed or imperfect information? Iftoo many agents use a single resource, its performance goes down, but theydon't find out until it's too late.andP;  (Sounds like Highway 101 to us!)andM;The situation here is that the decision is made on the price at one time, butthe actual price paid is higher or lower depending on actual use of theresource.andP;  What happens when you introduce agents who make predictions? As itturns out, it's good to have a couple of agents making predictions, but iftoo many do so, chaos reigns again (cf.andP;  October 17, 1987, when peoplepredicting a market collapse helped make it happen).andP;  A draft paper(&quot;Collective behavior of anticipatory agents,&quot; by J.andP;  0.andP;  Kephart, T.andP;  Hoggand Huberman) and the chart below explain it succinctly:andM;&quot;Initially, as analysts are introduced into a system of naive agents, theperformance of the naive agents improves because the oscillation amplitudecdeviation from the optimum! is reduced (&quot;trickle-down effect&quot;).andP;  The overallsystem performance improves as well.andP;  However, when the percentage ofanalysts increases beyond a certain point, the behavior becomes pathological,exhibiting complicated periodic or chaotic oscillations.andP;  The analysts startto perform even worse than the naive agents, and the overall systemperformance plummets.andP;  The cyclical analysts outsmart themselves, becausetheir presence in the system induces a qualitative change in the dynamicswhich they do not take into account themselves cin this particular model!.andO;This suggests that game theorists might be more successful...&quot;andM;Initial work shows that adaptive game theorists do do better, but that's onlybecause this market is relatively easy to predict....andM;Issues are availability of information, cross-impacts of behavior, theinability even of adaptive game theorists to predict prices correctly in anyreasonably complicated model, and the importance of diverse strategies.andP;  Forexample, if everyone avoids the Bay Bridge because the radio says there's atraffic jam, it might be in a single person's interest to take the BayBridge.andP;  But if everyone figures that out, then what? If everyone wears PCandM;Forum golf shirts, they lose their cachet.andP;  If Juan follows Alice's lead andbecomes a manager, who's left to do the work? Some resources become morevaluable if everyone uses them, like a popular movie (as long as you can getin) which is easier to talk about if others have seen it, while others becomeless valuable: &quot;It's so crowded no one goes there anymore.&quot;andM;But most troubling is the so-called &quot;tragedy of the commons,&quot; the fundamentalproblem we attempt to solve with government actions.andP;  This is the issue ofshared resources: Everyone is better off if everyone pays, but eachindividual agent is better off if he doesn't pay and mooches off the other.andO;In other words, how do we get global optimization when it's in contradictionwith local optimization.andP;  The same issues apply to long-term research in theface of stock-market pressures, competition among firms in the face ofexternal threats from other countries, the confusing interplay between safetynets and incentives in our welfare system and most current puzzles in publicpolicy.andP;  (To see some of them played out, try playing SimCity, page 10.)andM;There is much interesting discussion of market systems in the work of MarkMiller and Eric Drexler in Huberman's and Drexler's books cited on page 33.andO;Miller is currently chief architect at Xanadu, now part of Autodesk.andP;  He isworking there on building a back-end text database that will ultimately playhost to a variety of front-end agents that will not just search it but alsoannotate it, link cross-references and publish editorial assessments of itscontents.andP;  More on this next issue.andM;GENETIC ALGORITHMS: PROGRAMMING BY EVOLUTIONandM;Evolution is a means of adaptation: A population evolves as its members arereplaced by new and different ones; the individual elements don't necessarilyadapt.andP;  Evolution works by selection: Successful elements (and their traitsand behaviors) survive and reproduce.andP;  (Success may be determined by abilityto get food and sexual partners, or to earn a living, or to acquire aspecified level of currency or resource access in a computational system.)andO;Unsuccessful elements die out, taking their traits and behavior with them.andO;Over the long run, the successful elements and traits predominate.andM;There is a seeming difference between traditional evolutionary systems, whereindividual elements are created and die out according to their success inmeeting goals, and systems where the individual elements persist, while theirbehaviors or problem-solving techniques die out or flourish.andP;  But in fact,it's merely a matter of mechanisms and metaphors.andP;  In a market-based softwaresystem, certain algorithms and resources might get used frequently, andothers might &quot;die&quot; of neglect.andM;Will management then pour resources into making the widely used algorithmseven more efficient, or making popular application programs available to moreusers? At this point, evolution in the software industry is working mostly atthe macro level in this way, determining the marketplace success of operatingsystems, platforms, hardware architecture and applications.andP;  (Criteria forsuccess include things such as marketing and management stability as well asthe technical capabilities of the products.)andM;Market systems are exotic and scary enough to the traditional objectorientedprogrammer, who has to relinquish control of the executing application.andP;  Arelated but further-out notion is the idea of genetic algorithms, whichleaves even the design of the programs up to a self-organizing system.andM;Genetic algorithms are algorithms for building sequences of subroutines(analogous to genes) that reproduce and mate, resulting in ever moreefficient solutions for a given task (or for changing tasks, for thatmatter).andP;  This results in evolution, where the solutions change by replacingthemselves over time.andP;  The genetic algorithms are not the solution algorithmsthemselves, but the programs that manage the rules of reproduction, geneticrecombination and selection.andP;  In other words, they're the program running thesimulation.andM;Typically, the program treats the solution algorithms as strings of text(code subroutines) with designated breakpoints where splices can occur.andO;&quot;Children&quot; are created by joining spliced halves from two parents.andP;  Selectionis made by actually running the child and scoring its solution of the problem-- typically some kind of optimization problem.andP;  Most genetic algorithmsproduce succeeding generations of solution strings of the same general formand length, but relaxing those constraints with so-called &quot;messy algorithms&quot;tends to produce more rapid, effective evolution towards superiorperformance, says Dave Goldberg, an expert in the field at the University ofAlabama.andP;  &quot;We've taken our cue from nature, where evolution has carried usfrom a small number of genes per organism to many with good results.&quot;andM;Stuffed softvareandM;The implications for software development long-run are promising; GECorporate Research is using genetic algorithms in jet turbine design andreported promising results at the recent genetic algorithm conference --reportedly a 2 percent increase in efficiency.andP;  But genetic algorithms areunlikely to see much use outside the design lab for a while; few dp managersare going to trust algorithms of uncertain parentage.andP;  Emergent computationand genetic algorithms in particular merge the notions of design and runtime,since it's a permanently incremental approach where the system is always influx (or alive).andP;  But there's no reason that you can't use emergentprinciples for a period called &quot;design,&quot; and then remove the genetic capacityto create a runtime system (regardless of what the purists might think).andP;  Ifyou do it right, you then end up with inanimate but still executablesoftware.andM;EVOLUTION: DANNY DISCOVERS Spy AND PARASITESandM;Danny Hillis, founder of Thinking Machines, turns out to have built an idealmachine for running genetic algorithms.andP;  He has been using his own ConnectionMachine and his limited free time to build self-organizing evolutionarysimulations, modeling other people's ideas that ran too slowly elsewhere andalso coming up with a few of his own.andP;  First, he has built a system that canevolve a sorting algorithm that comes within one step (60 vs.andP;  61) of thebest humans can do for sorting a list.andP;  (The algorithms consist of 64sequenced instructions to compare and exchange a particular item in the listto be sorted.andP;  Each individual gets a random list to sort, and is scored onhow well it has sorted the list by the end of the 64 steps.) That's prettyimpressive.andP;  The whole thing took 100,000 generations, at about 10generations per second for this model.andM;There are different ways to score to determine survival, and to generatesuccessive generations, which both have a strong impact on the model.andP;  Scoreson the problem represent the environment, in the sense that it's what theindividuals are adapting to.andP;  The simplest method is to take an arbitrarypercentage of the population with the highest scores.andP;  Another is to assignarbitrary survival probabilities to specific traits, which is how populationbiologists generally do it.andM;The problem with either of these scoring methods, of course, is that they'restatic.andP;  They end up producing a population specialized for a particularenvironment.andP;  But a changing environment is closer to reality, andadaptability, rather than specialization, is key to survival over time.andO;(That's certainly the case with humans, which aren't particularly good atanything except intelligence, which equals learning, which equalsadaptability.)andM;Populations may get stuck in a local adaptation (specialization) that'scounterproductive in the long run.andP;  It turns out that parasites -- otherobjects that evolve more rapidly because their generations turn over faster-can counteract the tendency to inertia.andP;  Any time a particular type gets tooprevalent, it becomes an especially appealing host for parasites and isprevented from overrunning the population entirely, leaving enough diversityin the system for it to respond to new conditions.andP;  In other words, parasiteskeep populations from complacency, and may shake them out of suboptimalsolutions to further improvements.andM;There's also the question of just how to elicit and spread a diversity ofelements for the selection to work on.andP;  It turns out that exchange of geneticmatter is generally far more important than mutation in keeping a populationof complex things diverse.andP;  Mutations are less and less likely to bebeneficial as an individual gets complex, whereas sex allows variations thatwork to be passed along and spread throughout a population.andP;  Sex is a meansof what Hillis calls &quot;idea-sharing.&quot; Sexual reproduction is simulated byrecombining genes (represented as sections of the code strings) according tosome specification to generate a new generation.andP;  (Although the pairing ofany two individuals, or gene pools, is likely to result in a more &quot;average&quot;individual than the more extreme one, it also spreads its extremecharacteristics more broadly than would simple cloning, or asexualreproduction.)andM;Many variations may sit around in the population &quot;doing&quot; nothing, but whenconditions change somewhere there's likely to be a set of individuals bettersuited to the new condition.andP;  As they mate with less favored individuals,they may help the population survive.andP;  Or if they stick to themselves, thissmall group may flourish and grow larger as the rest of the populationflounders.andP;  Mating behavior -- random, pick your relatives or pick someonewith similar string patterns are common strategies -- is another importantcharacteristic of a model.andM;Gaps in the tape?&quot;andM;But most interesting are Hillis's theoretical insights extending the work ofothers in the field, as described in his unpublished paper &quot;Punctuatedequilibrium due to epistasis in simulated populations,&quot; which has traveledwidely on the samizdat circuit.andP;  (A fine example of the cross-disciplinarynature of this field).andP;  In essence, it offers explanation for the strangegaps in fossil records, which indicate that evolution is not a slow, steadyprocess, but rather a sequence of quick swings from one prevalent phenotype(trait or behavior) to another, or &quot;punctuated equilibrium.&quot; There's only ashort intermediate period as the majority of a population switches over.andM;The reason, as shown by Hillis's simulations, is that phenotypes aren't theresult of a single gene, but of a number of genes acting in concert.andP;  Earliersimulations which looked at genes and phenotypes as equivalent (which used asingle gene rather than several as a criterion for survival) missed thispoint.andP;  But simulations that use survival criteria based on the cooccurrenceof several genes (e.g., subroutines that work well together) mimic thereality of punctuated equilibrium.andP;  Those genes may be lurking aroundindividually in the population with little noticeable effect on survivalrates.andP;  Chance combinations of the favorable genes (with high survival rates)slowly raise their frequency in the overall population until they reach acritical mass -- and suddenly blossom.andP;  &quot;Any small increase in the frequencyof one ...andP;  will greatly enhance the selective values of the others, and viceversa,&quot; writes Hillis (with a great deal of supporting mathematics).andM;Theatre of the emergentandM;As biology, Hillis's simulations lack a representation of spatial migration --and no doubt other items too.andP;  But they can show some exciting patterns ofreality without modeling all its aspects.andM;As theater, they vary in what they show on the screen.andP;  The computer cancreate populations of an arbitrary number of elements (call them objects),execute their behavior and then, based on the results, decide whether theysurvive or not.andP;  You can display them as locations on the screen (turningpixels on or off), or with colors so you can see characteristics as colorssweeping over the screen and through a population.andP;  The results are dramatic.andO;As noted, if you have a static measure of success, you generally reach astable state fairly quickly -- although not necessarily at the optimal level.andO;This is an example of hill-climbing; once you've got to the top of the hill,you can't necessarily see another, higher hill elsewhere.andP;  It takes changeand diversity -- the equivalent of turning the terrain into a moving oceaninstead of static hills -- to make sure that the climbing continues.andP;  In reallife, of course, circumstances are always changing.andM;SOME PATTERNSandM;As you look at self-organizing systems, some interesting insights &quot;emerge.&quot;andM;* Although systems self-organize by themselves (by definition), there'sandM;still lots of work left for the designers of their components; minutevariations and nuances in the components can cause large, unpredictablevariations in the resulting systems.andP;  See page 25.andM;* Scale and the definition of system boundaries are vital but complexandM;questions.andP;  See page 26.andM;* As these systems get closer and closer to modeling and interacting withandM;humans, they will raise ethical and sociological questions.andP;  The very world&quot;agent&quot; sets off complicated emotional responses.andP;  See page 27.andM;* Diversity is valuable (and irrepressible).andP;  See page 30.andM;* &quot;Think globally; act locally!&quot; translates to providing global data acandM;cess, but letting applications make their own &quot;decisions.&quot; The essence ofself-organization is distributed control -- even with centralizedinformation.andP;  (TI's ComMUTE, for one, uses only local information; see page11.) The cost of maintaining central control rapidly overcomes its benefitsas systems scale up, while market-style allocation schemes become moreefficient (with exceptions).andP;  See pages 4 to 11.andM;* Self-organizing systems need reliable platforms for execution and comandM;munication.andP;  See pages 12 to 16.andM;* Careful attention must be paid to the quality and latency (timeliness)andM;of information.andP;  See pages 17 to 19.andM;* Systems can evolve, but only if inefficient components are allowed toandM;&quot;die&quot; (or terminate).andP;  See pages 17 to 22.andM;On the next few pages we try to describe self-organization and address someof these points not covered earlier.andM;As noted, self-organization (or emergent behavior) is a property of systemsand results from the interaction of their individual elements.andP;  The best wayto predict the pattern generated by their interaction is to simulate it.andO;This &quot;behavior&quot; is not explicit (then it could be defined precisely), but asystem's ability to maintain itself and to adapt to unforeseen events-everything from painless assimilation of a new computer into a network torepudiation of spurious messages from a marauding hacker.andM;On beyond neural netsandM;Self-organization, however, is different from mere flexibility oradaptability; it's more akin to intelligence.andP;  SATs to the contrary,intelligence is not how much you know.andP;  It's how quickly (or whether) you canlearn it.andP;  So in this sense emergent computing systems have the potential toexhibit far more intelligence than traditional expert systems, which merelyexecute rules rotely, or programmed recognition systems.andP;  Neural nets, bycontrast, are simple emergent systems which can learn to recognize patterns.'andO;Current computer based ones can't learn very much.andP;  A neural net is arelatively simple emergent system, because its nodes have very little visiblebehavior; they simply switch on or off.andP;  (Internally, the nodes adjust theweights of what may be extremely complex equations, and may produce extremelycomplex structures.) The emergent system that results is capable ofrecognizing faces or poor credit risks or (so some hope!) stock marketpatterns.andM;By contrast, a large object-oriented system consists of a lot of complexobjects, with a variety of goals that may not bear any visible relation tothe ostensible goal of the system they're part of.andP;  They pass complexmessages back and forth, whereas neural nets have fixed connections and nodesthat pass only binary signals or at best values to each other.andM;Will it take?andM;Of course, groups of objects don't always self-organize.andP;  There may not besufficient interaction, in which case the system will remain relativelystatic; each node will do its thing without instigating the sort of chainreaction that constitutes a self-organizing system.andP;  At the other extreme,there may be chaos, in both the old and the new senses of the world.andP;  Therecan be so much irregularity that no useful patterns emerge, or they may be soextreme as to be useless for our purposes.andM;But in the happy medium the interactions result in a relatively stable systemwith periodic oscillations around steady states or evolution from state tostate.andP;  Patterns emerge -- patterns that seem to hold far more informationthan the objects that created them did.andP;  How can millions of Chinese, forexample, suddenly join to foment revolution -- while millions of Russianslanguish inandM;sullen despair? This self-organized movement, unhappily,    turns outandM;to be part of an even largerandM;pattern of repression interspersed with easing.andP;  What's the differencebetveen smooth traffic flow and paralyzing gridlock? Between fast disk accessand overloaded thrashing?andM;Content countsandM;Can emergent computation actually build systems more complex than what youput into them? That's the hope.andM;What is the content of the agents that constitute them and generate suchcomplex interactions? Theoretically, the behavior of the individualcomponents should be easier to specify because they are (relatively) simplecompared to the whole.andP;  If you are building a system modeled along humaninteractions -- for office automation, say, or the water plant described onpage 4, you can start with the explicit interactions among people as yourmodel.andP;  Just as good expert systems don't mimic the brain but take a piece ofits behavior (the use of explicit rules) and model that, and neural netsmodel excitations of brain cells, these systems simply take some specificrules of behavior and model those to produce systems capable of handlingproblems of overwhelming complexity.andM;But you still have to build the logic of the local diagnostic expert systemor decision maker or data expert into your agent.andP;  And interactions amongpeople are frequently not explicit, after all (part of the reason for somepeople's discomfort with transaction-oriented groupware; Release 1.0, 88-6,and page 29).andP;  For example, what is the true meaning (to another computeragent, say) of the simple expression, &quot;Let's have lunch&quot;? How do you modelthe interaction it represents? The hope is that by modeling only explicitbehaviors, you may actually get systems that run more smoothly than humanones, But there will also be a lot missing.andM;The benefit of the model agents may be not just simplicity, but also theselection only of behaviors that are relevant and useful.andP;  You don't wantyour agents to have emotions and moods, necessarily, but you want them tohave socially useful goals and the behavior to achieve them.andP;  So you canmodel negotiating behavior, goals, etc., without having to model wholepeople.andP;  (But that means that your models, like those of &quot;model&quot; economies,may be of limited use in predicting actual behavior of a real system.)andM;Design for changingandM;How do you give a program/agent rules for changing itself? &quot;Most correct andvell-written programs will simply break if you make even a trivial change,&quot;says arch-programmer Bill Joy.andP;  That's why you need a lot of them in aself-organizing system, so that they can cover for each other.andP;  And we're not(exceptfor genetic algorithms) talking about random changes: You need a&quot;grammar&quot; for making changes, to maximize the proportion of beneficialchanges and minimize the harmful ones.andP;  (Most are probably immaterial.)andM;At the simplest level, you can have rules concerning data, which change theactions an agent takes but leave its overall behavior intact.andP;  At the highestlevel, a language like LISP, which treats the code itself as data, makes iteasy to write self-changing programs.andP;  (Of course, these programs arethemselves a set of interacting objects.) In the middle is a grey area, whereevent-triggered rules change the structure of the system in which the agentoperates, but the agent itself retains its original form.andP;  (In such a system,individual agents may die out from lack of use or resources, but they don'tchange.andP;  The result is evolution by replacement of components -thetraditional biological model.) In short, you can't define emergent behaviorby looking at the individual agents, but only at their interactions.andM;Levels and extents: Choose your -cosmandM;A basic issue in self-organizing systems is picking the level of abstraction:Are you looking at a whole system, or at components thereof? An applicationconsists of a set of functions, which consist of processes...andP;  and so forth.andO;Should programs themselves self-organize? Or only systems? Where should theactive objects fit in, and where the data or passive objects? From apragmatic point of view, if it's simpler to build something than to grow it,then that's what you should do.andP;  The goal of using emergent computation is togrow systems more complex than what you could build.andM;Aside from levels, how widely does it extend? Are people part of the system,or are they external forces who simply program the agents and set them inmotion? At some point, the system currency allocated to certain of theseresources may indicate to management that it's time to buy a fourth printer,or run a more cost-effective line between two workgroups.andP;  Is management partof the emergent system? In this context, yes.andP;  Management's behavior isaffected by interaction with its components, and management's behavior inturn affects the very nature of the system.andM;The spirit is emergent, but the flesh needs a platformandM;As indicated just above, the extent of a self-organizing system depends onyour perspective.andP;  The system platform can be an interacting part of aselforganizing system, or it can be the environment.andP;  Emergent softwaresystems, like any other software, are heir to traditional systemsrequirements.andP;  While emergent systems can be used to allocate systemresources, they themselves operate on top of traditional operating systemsand communication facilities -- their environment.andM;The environment may comprise a database, networking software, etc.andP;  Theself-organizing systems, applications or system-resource managers, are theflexible part that can usually override the imperfections and errors of theplatform.andP;  In a small, fixed system, errors are fatal, whereas in a larger,adaptive one they can be overcome.andP;  The emergent (you might call it living)system is error-tolerant; it overcomes small errors and repudiates big ones.andM;More and more of the typical computer system is becoming virtual hardware-that is, fixed or standard.andP;  The hardware used to be the only fixed part,and included the software, which was wired to perform particular tasks.andP;  Thenthe software became &quot;soft,&quot; and was able to give the same hardware a varietyof personalities.andP;  Eventually there was a separation between the systemsoftware and the applications, and the system software became virtually&quot;hard&quot; once again.andP;  In some cases, it is now burned into ROM (as with theMacintosh).andM;Now, the definition of system software itself is expanding, to include filemanagement, memory management, even database management.andP;  As these thingsbecome standardized, they are being treated as part of the hardware, or theplatform.andP;  The problem with this is that they lose their capacity to evolve.andO;They may respond, but they don't change themselves.andP;  (Without our necessarilybeing conscious of it, we are part of an evolutionary ecosystem where systemsand software are constantly evolving; we call it the market.)andM;Distributed and central controlandM;Self-organizing systems are truly object-oriented, as opposed to systemscalled object-oriented because they contain objects.andP;  In the latter, atraditional procedural application calls objects as it needs them: A databaseapplication tool, for example, may use graphical objects to build a screendesign, or a word-processing application may treat paragraphs and words asobjects.andP;  But generally either the users or the application logic manipulatesthe objects; they don't manipulate each other in cascading series ofinteractions.andP;  Of course, there are degrees of this: Do the objects containprocedural code, or does the procedural flow occasionally set off objectactivities? But in principle the distinction is clear: Only a system ofactive objects with distributed control exhibits true emergent behavior.andM;Take for example a system such as the MacroMind animation tools.andP;  Althoughthey create objects with their own behavior, the system is itself fairlyprocedural: MacroMind's Director stage-manages the objects; they do notinteract with each other, but rather each runs under the control of thecentral program.andP;  By contrast, with a simulation (as opposed to animation)program such as SimCity, the objects within the system interact with andaffect each other.andP;  Difficult as it is for programmers to give up control asthey design a system, it's much more difficult to accept that not only willthe objects run under their own control, but that the system will actuallyredesign (not just reconfigure) itself.andM;Agents and authorityandM;Reopening a vigorous discussion that took place at the November annualmeeting of Computer Professionals for Social Responsibility, a panel at therecent conference on Expert Communication (sponsored by the GraphicCommunications Association) addressed the nature and role of intelligentagents.andP;  The original discussion was kicked off by an airing of Apple'sKnowledge Navigator video, well-known by now to all but computer-industrytroglodytes.andM;Generally, many people find this tape off-putting for reasons ranging fromexcessive marketing zeal to sexism to incredibility.andP;  Our reaction is mostlyaversion to anthropomorphism: We like our computers to act like computers,and our friends to act like people.andP;  Computers' attempts to pass as peopleare either insulting to one's intelligence (if ineffective) or dangerouslydeceptive (because the illusion will inevitably break down).andM;What is an intelligent agent? We can't think of one other than a person suchas George Smiley.andP;  On the other hand, a plain old computer agent canautonomously carry out reliably any number of explicit rules andinstructions.andP;  Properly programmed, it can react in useful fashion to a largerange of individually unpredictable situations, carry out the goals of itscreator and adjust in specified ways to a variety of circumstances.andO;Collections of such agents may even &quot;learn.&quot; (Yes, a collection of agentsthus might constitute something close to an &quot;intelligent agent.&quot;) What's thedifference between an application and an agent? Probably the same as thedifference between a person and an intelligent agent.andP;  In other words, anagent is an application with a mission -- although the software agent'smission is not its own.andM;In self-organizing systems, there are lots of agents that seem to be workingon behalf of the system itself rather than for any user in particular, andthere are lots of agents interacting, rather than a few agents interactingonly with the system as environment.andM;Don't manipulate; delegate!andM;Any application can be set up as an agent, doing a user's bidding.andP;  Thedeeper connotation of agent is an autonomous, discrete application that willgo off and do something independently; it's the opposite of directmanipulation, where the user directs the application interactively.andP;  Instead,the user gives the application instructions -- whether with a language orthrough some kind of user-friendly fill-in form, prompted script or othertool -- and sends it off to work on its own.andP;  An agent can do its work once,periodically, or sit patiently in the background waiting for a triggeringevent.andP;  It can be as simple as an E-mail collector, or as complex as ajunkmail detector/filter or a sales manager's agent that gathers data from avariety of databases, generates a report and sends customized, personalizedEmail to the salespeople based on the contents of the report.andP;  (So what doesthe sales manager do? She can spend her time motivating the salespeople,calling on problem accounts and providing customer feedback to the productdevelopment group.)andM;A scenarioandM;In the future, this agent might negotiate with other agents to plan meetings,set sales objectives, or even bargain.andP;  (The instructions could be: &quot;Add 20percent to whatever each salesperson proposes as a sales quota, and tell himor her that's next year's quota.andP;  Then take the average of that and hercounteroffer as the final figure.andP;  If any salesperson refuses to confirm, setup a meeting (priority 3) and send me an exception message.&quot;)andM;Obviously, once a salesperson's agent figured out the salesmanager's agent'srules, the sales manager would have to refine her agent's rules -- bystarting with a floor offer of 110 percent of last year's sales, for example.andO;You can see how eventually the behavior of interacting agents -- especiallywhen customers get into the act -- could become quite intricate, asenvisioned by the team at PARC (page 17).andM;These agents have some conditional behavior, which could be expressed asifthen rules.andP;  Are they expert systems? As much as any other rule-orientedsystem.andP;  Because agents act for people, and are autonomous, they willgenerally include many data-driven actions rather than operate strictlyprocedurally.andP;  But that doesn't make them &quot;expert&quot; or &quot;intelligent.&quot; Itsimply makes them capable of acting within a specified range of likelyconditions.andP;  The last rule of any agent's instructions should run along thelines of &quot;If you encounter unforeseen conditions, get back to me.&quot;andM;...and groupwareandM;Groupware comes in two forms -- information-sharing systems, such asdatabases and bulletin boards, and more active, transaction-oriented systemssuch as the Coordinator and Coordination Technology's forthcoming product(see Release 1.0, 88-6).andP;  Many people are leery of the second form becausethey incorrectly assume it's authoritarian and rigid.andP;  In terms of thisdiscussion, they think it's filled with government agents.andP;  But in factgroupware is about user agents interacting with each other.andP;  A user, ofcourse, may be a representative of top management, but in general it'sold-fashioned hierarchical systems that have government agents, in the formof hard-coded rules and procedures not subject to coordination andnegotiation.andM;Systems and societies: Hicro- and macrocosmsandM;You can look at communities or even the entire population of the world ascomplex systems of individual people or communities.andP;  All these are relevantto some kinds of inquiry.andP;  We suspect that some of the world's trade problemsare due to the propensity of some countries to act like single companies, andof some large companies to take on the trappings of government bureaucracies.andM;While we were in the Soviet Union, we saw a system which was programmed andcontrolled by the state -- and which didn't work.andP;  A large system lacks theflexibility to respond to local information.andP;  You can build some of thatflexibility in, but the goal is to build in flexibility of a higher order -asystem that changes itself, not just its responses, in the face of newinformation.andM;By modeling these systems, we can hope to determine the optimal size of, say,business organizations: At what point does the overhead of internalcoordination so overwhelm things that little work gets accomplished?andM;IN PRAISE OF DIVERSITYandM;Diversity is the equivalentof change across a system's parts at a singlemoment, instead of across time, the usual medium of change.andM;Thinking about self-organizing systems highlights the dangers of the lack ofdiversity represented by standards.andP;  Although you can build upon and extendstandards, they enforce stasis and the end of progress in the specific areasthey define.andP;  (Although you can build on standards, sometimes it's worth itto start over.) Aside from retarding improvement in a fixed envirornment,lack of diversity also leaves us vulnerable to external change -- everythingfrom computer viruses to AIDS, global weather changes and the arrival of moreefficient competitors.andP;  From a global perspective, diversity -- the fact that&quot;we&quot; included both small and large, both warm-blooded and coldblooded,animals -- enabled us, the vertebrates, to survive in the face of whateverkilled off the dinosaurs.andP;  Diversity leads to adaptability, because it offersa range of solutions.andM;In recent days, the Internet virus attacked (with exceptions) only machinesrunning BSD 4.3 -- compelling testimony for why we don't want everyone usingthe same system.andP;  If you want to get worried, perhaps AIDS is the factor thatwill prove how similar all humans are.andP;  Mammals may survive, but thisparticular species may not.andP;  Similarly, the name UNIX may survive, but theparticular variants espoused by OSF or UNIX International may not.andP;  (And itmay keep the name but little else.) On the other hand, it's nice to have acouple to choose from, and OS/2 is spurring both of them along from outside.andM;Finally, change or no, you don't want each element of a system to have thesame goals and behavior: For example, it's fine to have newsletter writerscompeting to be better, but if everyone were a newsletter writer therewouldn't be much for them to write about, no matter how finely competitionhoned their skills.andP;  Likewise, in a software system, you want specializedmodules for specific tasks that can be called as needed.andP;  And you may wantmodules optimized for speed or for memory conservation, to be used as theavailability of resources warrants.andM;Diversity and SAAandM;From this perspective, IBM may be moving in the wrong direction with SAA.andO;Rather than let diversity flourish, it's attempting to obliterate thedifferences among its three broad product lines, with the result that none ofthem is optimized for any particular environment.andP;  And underlying it all,there's still the notion of the host controlling everything.andP;  IBM's notion ofcooperative processing is a PC talking to a mainframe, rather than twoconsenting PCs.andM;The real issue isn't to be able to run all software elements everywhere, asSAA would have it, but to allow all software elements to talk to one another.andO;That is, messages should travel freely, but they should be executeddifferently by different recipients.andP;  Objects with common protocols may havedifferent internal implementations, with no one the wiser.andM;The correct balance (for now) is probably a variety of operating environmentsconnected by a variety of communications protocols and even some facilitiessuch as object protocols.andP;  The Open Software Foundation, for example, iscurrently soliciting technology for a distributed computing environment (page16).andP;  This would not legislate the structure of the individual elements, andin fact could be the most useful part of the OSF suite, long after the localstuff -- UNIX or whatever sits at an individual desktop -is gone.andP;  While thecommunications stuff itself could also improve, in this context it's theenvironment rather than the self-organizing system itself.andM;Diversity in businessandM;The same principles can be applied to companies themselves.andP;  Competition anddiversity are good -- but at the right level: between companies not withinthem.andP;  This leads ineluctably to the conclusion that a company is frequentlybetter off funding a start-up than taking on an innovative, counter-cultureproject itself.andP;  This philosophy lies behind Lotus's recent decision to&quot;restructure&quot; its relationship with Lotus Notes -- a wonderful product thatLotus finds itself incapable of selling or supporting properly.andP;  The issueisn't the quality of the product or the size of Lotus's salesforce, butsimply the company's ability to twist its mindset to the service of a productso different from the one it was built upon.andP;  Lotus's heritage is numbers andindividual productivity; Notes is about text and communication andcollaboration.andM;Likewise, Cray Research's decision to split the company in two was astraightforward, clear-eyed recognition of the company's inability to supporttwo conflicting efforts managerially and emotionally.andP;  Finances were besidethe point.andM;This honest realism is refreshing in a world where everyone wonders how IBMcan support both its proprietary SAA and the &quot;open&quot; UNIX standard (and withinthe UNIX camp, OSF's Motif as well as NextStep).andP;  Elsewhere, you couldquestion the wisdom of Sun Microsystems' three product lines, andHewlett-Packard's ability to absorb the Apollo product line and culture.andO;Should Sun have bought TOPS? (On the other hand, Apple is doing fine with theApple II and the Mac -- perhaps because they do not overlap at all anymore.andO;But Apple was certainly smart to spin out Claris, for both external andinternal reasons.)andM;In fact, stockholders of IBM would probably be richer right now if IBM hadbeen split up by the Justice Department ten years ago.andP;  Meanwhile, formerATandamp;T stockholders are doing well with their investments in the regional Belloperating companies carved out of the old ATandamp;T, although the parent companyis still fighting the aftereffects of its size and inflexibility.andM;Among smaller companies, the most common malady is lack of focus, not lack offunds.andP;  All too often, going for market share or exploiting opportunitiesmeans a diversity of products for a variety of customers -- a great idea in amature market, but a dangerous dilution of effort where deep technologyrather than breadth of product line is the key to success.andP;  Many start-upsdie from internal competition for attention and resources long before theyget big enough to attract competition from outside.andP;  (No examples becausetheir names won't mean anything...)andM;By contrast, Cray Research's John Rollwagen and the new Cray Computer'sSeymour Cray decided the original company's two parts would be better off ifeach could be single-minded in pursuit of one system architecture.andP;  Thecountry benefits too.andP;  Now it has two supercomputer companies instead of one,plus the promise of a start-up founded by yet another Cray alumnus, SteveChen, and funded by IBM.andM;All this flies in the face of the current obsession with standards.andP;  In fact,the supercomputer race is far from over, and the last thing it needs ispremature standards that would bring innovation ancts progress to a halt, orhalf-hearted competition between two parts of a strife-torn company.andP;  If thegovernment doesn't know which effort to fund (or &quot;protect&quot;), so much thebetter.andP;  Let them fight it out in the marketplace.andP;  And let the governmenthelp them both by buying and using machines rather than with subsidies.andM;This applies, of course, to other markets besides supercomputers.andP;  The bestthing the government can do anywhere is encourage businesses to compete.andO;Although Cray welcomes help against Japanese trade barriers, it'sheartwarming to see how eager it is to foster competition at home.andP;  (There'sthat -cosm issue again.)andM;Why it mattersandM;An early sign of formal interest in the computer implications ofselforganizing systems was the conference on emergent computation sponsoredlast month by the Department of Energy at Los Alamos National Labs.andO;&quot;Emergent,&quot; a confusing word in this context, refers to the emergence ofcomplex, unpredictable patterns from the iterative interaction of seeminglysimple rules -- that is, self-organization.andM;&quot;Emergent computation&quot; can be used to simulate natural systems, or it canconstitute a working computer system itself.andP;  An exciting aspect of emergentcomputation is that it's cross-disciplinary, with contributions from hackers,physicists and neurosurgeons, to say nothing of demographers, statisticiansand pure mathematicians.andP;  Traditionally the province of physicists andbiologists, the concepts and biological metaphors of self-organizing systemsoffer useful models for the design and implementation of products andservices to exploit the growing market for multi-user, distributed systems.andM;Because self-organization generates complexity and is a property of systems,not of their components, examples of self-organization don't scale down well.andO;The best examples are things such as bee hives, ecosystems and theinteracting cells that constitute living animals -or smoothly running trafficsystems such as wide-area telephone networks, the rural highway system ormost Ethernet networks and other distributed systems.andM;Examples covered here include Borland's VROOMM (page 8), which letsinteracting code modules monitor their own priority for memory management,and Corollary's 386/smp (page 9), which has a self-management approach formultiple 386es.andP;  The product that is likely to make many of these conceptsclear to a mass market is SimCity (page 10), a city simulation for under $50on the Mac that illustrates the complex interactions and feedback loops offactors such as population, business, housing, crime, taxes and pollution.andO;It also illustrates that systems can &quot;work&quot; (self-organize and actcoherently) without working well.andM;The present is an enormously fertile time for these concepts, because we aremoving into a world of interconnected systems that need them, and we have thecomputing power (Connection Machines and such) to simulate them first.andP;  Thebasic question -- with many answers for many situations -- is: What simplelocal rules and behaviors generate the desired behavior in the larger,self-organizing system they constitute? While the best of these systems canhandle change and error and accomplish complex tasks more effectively than asystem that's programmed by hand, their parts still need to be programmed byhand.andP;  There's no magic!andM;This discussion is not so much a prescription for what you should do as forwhat you should think about -- a description of what is happening regardlessin a world of interconnected, interacting systems.andP;  It explores the issuesgoverning the behavior of large-scale systems -systems where the cost ofkeeping track of all the components overwhelms the benefits -- and whereinteraction occurs on a local basis.andO;</TEXT></DOC>