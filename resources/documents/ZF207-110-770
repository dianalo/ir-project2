<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-110-770  </DOCNO><DOCID>07 110 770.andM;</DOCID><JOURNAL>Computer Language  March 1989 v6 n3 p67(10)* Full Text COPYRIGHT Miller-Freeman 1989.andM;</JOURNAL><TITLE>Theory and practice. (floating-point arithmetic) (includes relatedarticles on compiler accuracy and on on floating-point limitationscompared to traditional calculation methods) (technical)</TITLE><AUTHOR>Ochs, Tom.andM;</AUTHOR><SUMMARY>The IEEE-754 standard for binary floating-point arithmetic hasspecific requirements for the compilation of floating-pointoperations, but a survey of compiler vendors reveals theinexactness and limits of their respective compiler softwarepackages.andP;  The IEEE standard requires: a single format of 32 bits(and an optional 64-bit format); routing of calculations byround-to-nearest or directed rounding; addition, subtraction,multiplication, division, square root, remainder,round-to-integer, convert-between-formats and compare operations;and specific error messages to signal exceptions.andP;  Exceptionalresults are: inexactness, invalid operation, overflow, division byzero, underflow, denormals, unnormals, NaN and infinity.andP;  Detailsof each of the required calculations are described.andM;</SUMMARY><DESCRIPT>Topic:     CompilersRoundoff ErrorFloating-Point ArithmeticSurveyError PropagationSoftware PublishersIEEEBinary-Coded Notation.andO;Feature:   illustrationtable.andO;Caption:   IEEE 754 conformance. (table)Format specifications. (table)andM;</DESCRIPT><TEXT>Theory and Practice Binary arithmetic has not been mastered but tamed.andP;  Eventamed it can still maul the unwary.andP;  If you are solving complicted,nonlinear, numerical systems such as fluid flow, plastic deformation,fracture mechanics, or weather systems and you take your arithmetic forgranted, this article may bring you bad news.andM;My work involves a lot of floating-point arithmetic, and I have alwaysdepended on the compiler to take care of the details of addition,subtraction, multiplication, and division.andP;  I have assumed that when thecompiler literature says &quot;supports the type REAL according to the IEEEstandard for double-precision floating-point numbers,&quot; I could depend onconsistent and accurate results in my calculations.andM;Imagine my surprise when I ran a program that plotted the quadrants of acomplex fractal in four colors and got different colors on two differentmachines.andP;  One of the machines had a coprocessor; the other did not.andP;  Thecompiler manufacturer swore its compiler followed the IEEE standardfaithfully and used the coprocessor if one was present, and emulated thecoprocessor otherwise.andP;  The difference in solutions led me to write thisarticle about the adherence of compilers and coprocessors to the IEEE-7541985 standard for binary floating-point arithmetic and the limitations ofthat standard.andM;Research for this article included surveying manufacturers of compilers,coprocessors, and even a supercomputer to determine the methods of used forfloating-point arithmetic.andP;  The responses to this survey ranged fromwell-informed, detailed information to a total lack of understanding of theconcept of floating-point arithmetic.andP;  Some manufacturers could not evenanswer detailed questions in-house since the person who wrote the kernelresides in Switzerland, England, or Germany, and the compiler literature doesnot address the gory details of floating-point arithmetic.andM;Table 1 summarizes the answers to my questions.andP;  Each field in the table isdescribed in the text.andP;  The responses were supplied by manufacturers and werenot tested in most cases.andP;  I urge users to test the features in which theyare interested.andP;  As I have discovered, the answers obtained from afloating-point package by the same vendor can change from version to version.andO;Caveat emptor.andM;IEEE 754andM;Many potential problems are addressed by the standard (see the sidebar&quot;Paranoia among the savages&quot;).andP;  The goal of the standard is to provide anumerical environment that will not surprise the user with inconsistentresults to a reasonably formulated program.andP;  The question of what constitutes&quot;reasonable&quot; dictates how important the details of the compiler arithmeticare to you.andP;  Contraty to popular belief, floating-point arithmetic oncomputers is not yeat an exact science.andP;  (For an excellent introduction, seeD. Knuth's The Art of Computer Programming.)andM;Many compiler manufacturers allow a choice of using a coprocessor or doingthe floating-point arithmetic in their software kernel.andP;  If theirfloating-point software routines behave as though a coprocessor were present,they are said to emulate the coprocessor.andP;  This is different from simplyadhering to the IEEE standard in that all of the control words and flags fromthe coprocessor must be simualted and responod the same way, whether acoprocessor is present or not.andP;  Also, it is not valid to assume each type ofcoprocessor will produce the same results.andP;  Internal differences between theIntel 80X87 and Weitek families will guarantee different answers to the samearithmetic.andM;Adherence to the standard will not ensure the same answers between compilersor between the compilers and a family of coprocessors.andP;  If a different systemgives a different answer, this does not imply that one is obviously wrong.andO;What is implied is that both answers are inexact; one is probably more exactthan the other.andP;  The standard helps establish limits on accuracy and ensuresa reasonable consistency in the answers.andM;FormatsandM;To establish a consistent internal representation in terms of bit patternsthat can be used to make software portable, the IEEE standard defines tworeal types.andP;  The types are a single format of 32 bits and a double format of64 bits.andP;  Each of these types defines an extended precision type forintermediate results, but only the extended type for the widest basic formatsupported is required.andP;  These extended formats hold intermediate results forincreased precision and the elimination of overflow and underflow inintermediate calculations.andP;  The formats are defined as three fields: sign,binary exponent, and significand (also known as the fractional part ormantissa).andP;  The sign bit is always one bit wide in the most significantposition.andP;  Table 2 shows the number of bits in the other fields.andM;To conform to the standard, a vendor must support the single format.andP;  Thedouble format is optional.andP;  A lot of latitude exists in the format of theextended types since only the minimum widths are specified.andM;Table 2 shows the precision of a number given, in decimal digits, determinedby the size of the significand.andP;  The range of the numbers is determined bythe exponent.andP;  The exponents are presented in a biased (or excess) binaryform in which a number is added to the exponent to make it a positiveinteger.andP;  The significand is normalized, forcing it to have a value between1.0 and 2.0.andP;  The form of the representation is X = 2.sup.(a-c)*.f.sub.b.,andO;where X is the binary floating-point number, a is the binary exponent, c isthe bias value, and f.sub.b is the normalized binary significand.andM;In single- and double-precision representation, the first bit to the left ofthe binary point is assumed, not explicitly set.andP;  Zero is considered a uniquerepresentation signaled by a zero exponent with all zeros in the significand.andM;In addition to these standard formats, exceptional cases are defined in whichthe bits are arranged to signal the occurrence of a special result.andP;  Examplesof these exceptional cases are infinites, NaN (Not a Number), and denormals.andO;These exceptions will be explained later.andM;RoundingandM;All calculations resulting in a number that cannot be exactly represented inthe format of the destination variable must be shortened.andP;  The IEEE standardstates that the value be rounded by either round-to-nearest or directedrounding.andP;  Round-to-nearest uses the banker's algorithm to decide what to dowith the rounding when the two nearest representable values are the samedistance apart.andP;  In this case, rounding is toward the value with theleast-significant bit zero.andP;  Round-to-nearest is specified in the standard asthe default mode, but the user should control the rounding method.andM;The directed-rounding mode has three user-selectable methods.andP;  Thedirected-rounding methods are rounded toward positive infinity, negativeinfinity, or zero.andP;  One reason for directed rounding is that in sensitivemathematical computations it is difficult to identify the effects of errorpropagation.andP;  If a computation is performed with the rounding directed towardpositive infinity, then with rounding directed toward negative infinity, anda third time with round-to-nearest, the user can get an idea of the effect ofchanges in the last bit of precision.andP;  Further calculations can then becarried out with a reasonable estimate of the envelope of the computation.andM;OperationsandM;The operatons of addition, subtraction, multiplication, division, squareroot, remainder, round-to-integer, convert-between formats, and compare arerequired by the standard.andP;  All of these operations are carried out as if theintermediate result were correct to infinite precision and then coerced,using the active rounding method, into the format of the destination.andM;Examining the arithmetic operation of multiplication shows how theintermediate result can be considered to be of infinite precision.andP;  In themultiplication of two binary fractions, the multiplication is carried outjust as you were taught to carry out long multiplication in grade school.andM;Multiplying the binary representation of 1.3125 by 0.1875 we have:andM;As you can see, twice as many digits are necessary to exactly represent theproducts as the multipliers in either representation.andP;  Since we have fixedthe size of the intermediates at less than twice the number of the bits inthe significand, it is necessary to carry out the rounding process in theintermediates as the multiplication is being carried out.andM;In the preceding example, we would start rounding at each multiplication,carrying bits forward as the calculation progresses.andP;  Using theround-to-nearest algorithm, and considering the destination register to allowfour bits to the right of the binary point, the binary representation wouldround to 0.0100, or 0.2500 decimal.andP;  If we truncate the answer at 0.0011instead, we get the result 0.1875, which was our original multiplier and isnot close to the correct answer.andM;As you can see from this example, rounding is an important feature.andP;  It isalso important to carry all of the precision of the multiplication.andP;  The sameholds for the other arithmetic operations.andP;  In the case of division, it isnot possible to know ahead of time how many bits are necessary to carry outthe arithmetic to infinite precision.andP;  Instead, the operations are carriedout until the extended precision intermediate is filled.andP;  Rounding is thencarried out when it is coerced into the destination.andP;  (Other divisionmethods, such as using a Newton-Raphson approximation algorithm, exist toestimate the reciprocal of the divisor and then multiply by it.andP;  This is afast method used by the Weitek coprocessor.)andM;In the Intel 80x87 family of coprocessors, the internal stacks are in 80-bit,extended-precision format.andP;  Some compilers take advantage of this 80-bitstack by maintaining intermediate results on the coprocessor stack, whichboth speeds up operations and enhances accuracy.andP;  The Weitek coprocessor hasa 64-bit internal stack with no extended precision, which is not incompliance with the standard.andP;  The compilers that can use the Weitek can alsomaintain variables on the internal stack to gain speed, but the results willbe rounded to the 64-bit format at each operation.andM;For arithmetic, the size of the extended-precision intermediates can affectthe results of the operations.andP;  Since only the minimum size is specified,different implementations that meet the standard can use different-sizedextended intermediates and can therefore provide different answers toarithmetic computations.andP;  In systems that do not use the extendedintermediates, differing results to multiple calculations are also expected.andM;It is difficult to determine how these differing results will affect aspecific calculation since we are discussing differences on the order of onepart in 10.sup.-19 or less in the intermediates.andP;  It is difficult to even seethese differences since printing and display routines for floating-pointnumbers will often write the same number for two numbers that differ by onlyone bit.andP;  It is more reliable to compare numbers bit by bit.andM;The implementation details of arithmetic will most certainly differ for allcompilers.andP;  The results will be similar in that any discrepancies will be onthe order of one bit.andP;  There is always a trade-off between precision, range,and speed that will prevent absolute standardization.andM;ExceptionsandM;Arithmetic operations always have the possibility of a well-designedalgorithm failing for a range of arguments.andP;  If that occurs, it is best forthe system to let you know, as gently as possible, exactly what went wrong.andO;The IEEE standard allows for the passing of error messages in the form offlags, status bits, or interrupts to signal exceptions, unlike a number ofsystems that quietly freeze your computer and require a hardware reboot.andP;  Ina true coprocessor emulator, many systems have a program interruption as thedefault condition but allow overriding of the interrupt through auser-written interrupt handler or maskable control word.andM;In Table 1, if the result of an exception was an automatic programtermination, the system was considered to fail in meeting the standard.andO;Also, if all numeric exceptions raised the same error flag with no way ofdifferentiating the cause of the error, the compiler was not considered incompliance.andM;The following are common exceptional results:andM;Ineact: If the result of a calculations is not exactly expressible in thedestination variable space, a rounding or truncation method is used to coercethe result into the space available.andP;  In this case, the inexact exceptionshould be signaled.andM;Invalid operation: The invalid operation exception is signaled in a varietyof circumstances:andM;* Any operations on a NaNandM;* Addition or subtraction of infinitesandM;* Multiplication of infinity by zeroandM;* Division of zero by zero or infinity by infinityandM;* Remainder X Rem Y, where y is zero or X is infinityandM;* Square root of a negative number (remember, we are discussing realarithmetic)andM;* Conversion of format when the result will not be reliableandM;* Comparison of unordered arguments.andM;Overflow: An overflow exception occurs when the absolute value of the resultis larger than the largest number expressible in the destination format.andP;  Inextended intermediates, an intermediate result can exceed the magnitude ofthe destination format but is reduced in subsequent calculations to amagnitude that will fit.andP;  If the compiler uses the extended format forstorage of the intermediate results, a valid answer may be obtained whereoverflow would otherwise be expected.andP;  This is one reason the extendedformats are defined.andM;Division by zero: If a finite number is divided by zero, the result should beset to either positive or negative infinity and the exception signaled.andP;  Thisdiffers from overflow, which can be the result of a valid operation with alarge but finite result.andP;  Division by zero is defined to have an infiniteresult (except in the case of zero divided by zero, which is signaled as aninvalid operation).andP;  If the zero has a sign, the sign of the result is notdefined in the standard.andP;  A reasonable way to determine the sign of theresult is to exclusive-or the signs with positive considered true.andM;Underflow: This exception occurs when the result is tiny and nonzero andmight cause other exceptions, such as divide by zero.andP;  The other result ofthis type of exception can be loss of accuracy due to the inadequacy of therepresentation.andP;  These tiny numbers can occur in intermediates or in thefinal results, as can overflow exceptions.andP;  The implementor can determine howand when to signal this exception (for example, before or after rounding).andO;This latitude in the specification allows individual compilers to varyconsiderably on the handling of underflow.andP;  As we will see when we examinedenormals, both gradual and instantaneous underflow can occur.andP;  Both havetheir own sets of problems.andM;Denormals: Zero is a special number signaled by all zeros in both theexponent and significand fields.andP;  For double precision, because of the bias,a 1,023 in the exponent field (not zeros) and all zeros in the significand(with an implied normalized leading bit) represent the smallest normalizednumber.andP;  The implied leading signifcand bit means that 53 bits of precision(or about 15 decimal digits) cannot be represented.andP;  This contributes togranularity (discussed in the sidebar &quot;Why reals aren't real&quot;).andM;To represent these small numbers near zero, a denormalized number is definedwith zero in the exponent field and a nonnormalized significand.andP;  This meansnumbers smaller than the smallest normalized number can be represented withan attendant loss of precision.andP;  This loss of precision can be severe if thetiny number is close to the limit of the resolution of the bits in thesignificand.andP;  The availability of denormals leads to gradual underflow sincethe numbers close to zero are now coerced into a denormal rather than beingrounded to zero.andP;  This reduces the gap between zero and its next nearestneighbor by a factor of 10andless;15andgt; for double precision.andP;  The Weiteck coprocessorallows denormals but also has a fast mode that allows the user to default alldenormals to zero for faster operation.andM;Unnormals: The result of operations between a denormal and normalized numberwas defined as an unnormal in earlier drafts of the standard.andP;  Althoughunnormals are no longer part of the standard, some compilers and coprocessorsproduced before the new standard still flag this exception as a uniqueoccurrence.andP;  Since the denormal exception was raised when the denormal wasfirst produced, the user can note that further operations with that variablewill have a possible loss of precision.andM;NaN: NaN is a reserved representation that is implementation specific.andP;  Theserepresentations come in two types: signaling and quiet.andP;  Signaling NaNs raisethe invalid operation exception as defined, or signal operations that are notpart of the standard.andP;  Quiet NaNs can be used for diagnostics or otheroperations where a unique result must be propagated through the pendingoperations.andP;  I have not seen these NaNs in general use other than to signaluninitialized variables.andP;  Sign bits are not interpreted for NaNs.andM;Infinity: The standard considers infinity arithmetic to be the limiting caseof real arithmetic with arbitrarily large operands.andP;  Arithmetic on infinityis always exact, yielding either another infinity, zero, or an invalidoperation.andP;  Infinity is created from any legal overflow or division by zero.andO;Many compilers do not allow the user to perform infinite arithmetic.andM;Who cares?andM;How much of a problem is it for the users of compilers who depend on the realkernel to deliver correct and consistent answers?andP;  The answer depends on thesensitivity of the algorithm being used and the number of iterations.andP;  Ingeneral, this standard will give very precise results.andP;  For example, in therealm of business applications, it is possible to add one penny to thenational debt and get an accurate result since the national debt is currentlyaround 2andless;*andgt;10andless;14andgt; pennies and the limit of reliable resolution for thisstandard in double precision is about one part in 10andless;15andgt;.andP;  On the other hand,if you are solving a nonlinear equation iteratively, an answer that isoccacionally different by one bit in the iterations will quickly diverge.andO;Even the evaluation of a function in a sensitive range can cause dramaticloss of accuracy.andP;  Subtraction of two numbers that are very close togetherwill result in a number close to zero with the attendant loss of precision.andM;In supercomputer that operate at 10andless;10andgt; floating-point operations persecond,an unstable answer can diverge rapidly or converge to the wrong value.andP;  TheETA-10 super-computer is interesting in that its standard 64-bitrepresentation of floating-point numbers differs significantly from the IEEEstandard and has only 48 bits in the significand.andM;The trade-off of precision of speed occurs in many implementations.andP;  It isimportant to be aware of trade-offs and exceptions by the hardware orsoftware.andP;  It should be unacceptable for a system to have a catastrophicunderflow and not signal the user.andP;  Such an underflow results in the loss ofall bits of precision since the number is normally set to zero.andM;Exceptions should always be signaled so the user has the option of handlingthem in some consistent way.andP;  Aborting the program is not an elegant way forthe manufacturer of a modern language to signal what could be a recoverableerror.andM;At best, we should expect consistency in the answers obtained by usinglanguages adhering to the IEEE-754 standard.andP;  As can be seen from Table 1,areas of general conformance, such as format, exist.andP;  On theother hand, areasof general nonconformance, such as exception handling, also exist.andP;  It isimportant for a user to be aware of the options available and to use cautionin all computations.andO;</TEXT></DOC>