<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-289-064  </DOCNO><DOCID>08 289 064.andM;</DOCID><JOURNAL>Dr. Dobb's Journal  April 1990 v15 n4 p38(5)* Full Text COPYRIGHT Mandamp;T Publishing 1990.andM;</JOURNAL><TITLE>Untangling neural nets: when is one model better than another?andO;(neural network models)</TITLE><AUTHOR>Lawrence, Jeannette 'Jet'.andM;</AUTHOR><SUMMARY>Neural networks are computers formed of simulated neuronsconnected together in much the same way as the cells of the humanbrain.andP;  A neural network can generalize and associate withoutrules and is suited to solving problems which humans do well, suchas association, pattern recognition, and evaluation.andP;  Other neuralnetwork applications include problems that do not require perfectanswers, such as real-time robotics, predicting behavior, andanalyzing large quantities of data.andP;  A neural network is composedof nodes that each receive output signals from many other nodesover connections analogous to synapses.andP;  The two main neuralnetwork topologies are feedback and feed-forward.andP;  Feedback modelsmay be either constructed or trained, while feed-forward modelsrely on machine learning.andP;  Learning algorithms may be supervisedor unsupervised.andP;  The size of a network, along with problemcomplexity, limits its capabilities.andM;</SUMMARY><DESCRIPT>Topic:     Neural NetworksSoftware DesignSystem DesignArtificial IntelligenceComputer LearningPattern Recognition.andO;Feature:   illustrationchart.andO;Caption:   The formal model of a neural-network processing element. (chart)A taxonomy of neural-network types. (chart)The topology of a Hopfield neural network. (chart)andM;</DESCRIPT><TEXT>Untangling Neural NetsandM;Neural networks, which are formed by simulated neurons connected togethermuch the same way the brain's neurons are, are able to associate andgeneralize without rules.andP;  They have been used to classify undersea sonarreturns, speech, and handwriting, predict financial trends, evaluatepersonnel data, control robot arms, model cognitive phenomena, and much more.andM;The kinds of problems best solved by neural networks are also those thatpeople do wel: Association, evaluation, and pattern recognition.andP;  Neuralnetworks also handle problems that are difficult to compute and do notrequire perfect answers--just quick, good answers.andP;  This is especially truein real-time robotics or industrial controller applications.andM;Other appropriate applications are predicting behavior and analyzing largeamounts of data, such as in stock market forecasting and consumer loananalysis.andP;  New applications under development include simple vision systems,weather forecasting, assistance in medical diagnosis, and estimation of theworth of insurance claims.andM;A neural network is not always the best solution for certain problems.andP;  Theyare poor at precise calculations and serial processing, nor are they able topredict or recognize anything that does not inherently contain some sort ofpattern.andP;  This is why, for example, a neural net cannot predict the lottery,because a lottery is by definition a random process.andM;It is unlikely that a neural network could be built that has the capacity tothink as well as a person does for two reasons: Neural networks are terribleat deduction (logical thinking), and the human brain is too massively complexto simulate completely.andP;  A human brain contains about 100 billion neurons,each of which connects to about 10,000 other neurons.andM;A brief look at the general structure and operation of neural networks willhelp explain the limits of neural networks abilities.andP;  There are many typesof neural networks, but all have three things in common: Distributedprocessing elements (neurons), the connections between them (networktopology), and the learning rule.andP;  These three aspects together constitutethe neural-network paradigm.andM;The Formal Model of a NeuronandM;Artificial neurons are also known as processing elements, neurodes, units, orcells.andP;  Figure 1 shows the canonical model of a neuron.andP;  Each neuron receivesthe output signals from many other neurons.andP;  The point where two neuronscommunicate is called a &quot;connection.&quot;andP;  This neural connection is analogous toa biological synapse in the mammalian brain.andP;  A neuron calculates its outputby finding the weighted sum of its inputs.andP;  The strength of a particularconnection, called its weight, is noted [w.sub.ij], where i is the receivingneuron and j is the sending neuron.andM;At any point in time (t), the activation function, adds up the weightedinputs to produce an activation value [a.sub.i](t).andP;  In most models, inputsignals can either be excitatory or inhibitory, that is, they either tend tomake the neuron fire or tend to suppress its firing.andP;  This value is passedthrough an output (or transfer) function [f.sub.i], which produces the actualoutput for that neuron for that time, [o.sub.i](t).andM;After summation, the net input of the neuron is combined with the previousstate of the neuron to produce a new activation value.andP;  In the simplestmodels, the activation function is the weighted sum of the neuron's inputs;the previous state is not taken into account.andP;  In more complicated models,the activation function also uses the previous output of the neuron, so thatthe neuron can self-excite.andP;  These activation functions slowly decay overtime; an excited state slowly returns to an inactive level.andP;  Sometimes theactivation function is stochastic, that is, it includes a random noisefactor.andM;The transfer function of a neuron defines how the activation value is output.andO;The earliest models used a linear transfer function.andP;  However, certainproblems are not entirely reducible by purely linear methods.andP;  The thresholdtransfer function is the simplest of the non-linear models.andP;  This function isan all-or-nothing function: if the input is greater than some fixed amount(the threshold), the neuron will output a 1; if the value is below thethreshold, the neuron will output a 0.andM;Sometimes the transfer function is a saturation type of function: Moreexcitation above some maximum firing level has no further effect.andP;  Aparticularly useful transfer function is called the &quot;sigmoid function,&quot; whichhas a high-and a low-saturation limit and a proportionality range in between.andO;This function is 0 when the activation value is a large negative number.andP;  Thesigmoid function is 1 when the activation value is a large positive numberand makes a smooth transition in between.andM;The behavior of the network depends heavily on the way the neurons areconnected.andP;  In most models, the individual neurons are grouped into layers sothat the output from each neuron in one layer is fully interconnected withthe inputs of all the neurons in the next layer.andP;  A network may includeinhibitory connections from one neuron to the rest of the neurons in the samelayer called &quot;lateral inhibition.&quot;andP;  Sometimes a network has such stronglateral inhibition that only one neuron in a layer, usually the output layer,can be activated at a time.andP;  This effect of minimizing the number of activeneurons is known as &quot;competition.&quot;andP;  In a feedforward network, neurons in agiven layer do not take inputs from subsequent layers or from layers prior tothe immediately previous layer.andP;  Also, the neurons in a feed-forward networkusually do not connect to each other.andP;  The back propagation network typicallyhas three feed-forward layers: Input, hidden, and output.andP;  Feedback modelsadditionally include connections from the outputs of one layer to the inputsof the same or a previous layer.andM;A neural network learns by adapting to changes in the input.andP;  This isaccomplished through changes in the weights as the network gains experience.andO;The learning rule is the very heart of a neural network; it determines howthe weights are adjusted as the neural network gains experience.andP;  Of thenumerous learning rules in use, the most well-known are Hebb's Rule and theDelta Rule.andP;  Nearly all other rules are variations of these two.andM;More than 30 years ago, Donald O. Hebb theorized that biological associativememory lies in the synaptic connections between nerve cells, and that theprocess of learning and memory storage involved changes in the strength withwhich nerve signals are transmitted across individuals synapses.andP;  Hebb's Rulestates that pairs of neurons that are active simultaneously become strongerby synaptic (weight) changes.andP;  The result is a reinforcement of thosepathways in the brain.andP;  Hebb's Rule states [Delta][w.sub.ij] =[va.sub.i.O.sub.j] where v is the learning rate that specifies a scalingfactor for changes during training.andM;The Delta Rule, a supervised learning algorithm, additionally states that ifthere is a difference between the actual output pattern and the desiredoutput pattern during training, then the weights are adjusted to reduce thedifference.andP;  The Delta Rule states [Delta][w.sub.ij] = v([t.sub.i] -[a.sub.i])[o.sub.j], where [t.sub.i] is the treaining (desired output)pattern.andP;  The back-propagation rule is a generalization of the Delta Rule fora network with hidden neurons.andM;The best learning rule to use with linear neurons is the Delta Rule.andP;  Thisallows arbitrary associations to be learned, provided that the inputs are alllinearly independent.andP;  Other learning rules (such as Hebb's) require that theinputs also be orthogonal.andM;The Two Major TopologiesandM;Neural networks can be arbitrarily categorized by topology, neuron model, andtraining algorithm.andP;  (Figure 2 shows one method of classifying neuralnetworks.)andP;  There are two main subdivisions of neural network models:Feedforward and feedback topologies.andM;Feedback models can be constructed or trained.andP;  In a constructed model theweight matrix is created by taking the outer product of every input patternvector with itself or with an associated input, and adding up all the outerproducts.andP;  After construction, a partial or inaccurate input pattern can bepresented to the network, and after a time the network should converge sothat one of the original input patterns is the result.andP;  Hopfield and BAM aretwo well-known constructed feedback models.andM;The Hopfield network is a self-organizing, associative memory.andP;  It is thecanonical feedback network.andP;  It is composed of a single layer of neurons thatact as both output and input.andP;  The neurons are symmetrically connected([w.sub.ij] = [w.sub.ji]).andP;  (See Figure 3.)andP;  Hopfield networks are made ofnonlinear neurons capable of assuming two output values: -1 (off) and +1(on).andP;  The linear synaptic weights provide global communication ofinformation.andP;  In spite of its apparent simplicity, a Hopfield network hasconsiderable computational power.andM;The weight matrix is created by taking the outer product of each inputpattern vector with itself, and adding up all the outer products.andP;  Afterconstruction, a pattern is given to the network.andP;  A process ofreaction-stimulation-reaction between neurons occurs until the networksettles down into a fixed pattern called a &quot;stable state.&quot;andP;  Thus, the networkresult comes as a direct response to input.andM;The energy required by a device to reach a stable state can be plotted inthree dimensions as a curved surface.andP;  In this representation, the stablestates of the system (the energy minimums) appear as valleys.andP;  A neuralnetwork, which is used to find &quot;good enough&quot; solutions to optimizationproblems, may have many possible energy minimums or valleys.andP;  Depending uponthe initial state of the network, any of the deepest valleys may end up asthe answer.andP;  Inputing incomplete information to an associative memory networkcauses the network to follow paths to a nearby energy minimum where thecomplete information is stored.andM;Hopfield networks can recognize patterns by matching new inputs with theclosest previously stored patterns.andP;  Hopfield networks are especially goodfor finding the best answer out of many possibilities.andP;  They are also good atrecalling all of a stored piece of information when given partial data.andO;Hopfield networks are often used in applications requiring some form ofcontent addressable memory.andM;While the Hopfield model is able to associate on a large scale, it does notlearn; the weights must be set in advance.andP;  A serious limitation of theHopfield model is that the maximum number of memories M, which can be storedwhile still retaining perfect recall is [M less than or equal to N/(4 log N)]where N is the number of neurons.andP;  If more memories are stored, then thestable states begin to differ significantly from the stored information andeventually all will be forgotten.andP;  If an error rate of 5 percent istolerable, then the capacity is about 14 percent of N.andP;  The hardwareefficiency is also poor.andP;  A variation has been proposed, called the &quot;Unary orHamming&quot; network, which uses inhibitory lateral connections in the internalneurons.andP;  It is claimed that this model has a capacity of M andgt;andgt; N with noerrors in the final state.andM;Bart Kosko brought the Hopfield network to its logical conclusion with theBAM.andP;  The BAM (bidirectional associative memory) is a generalization of theHopfield network.andP;  Instead of creating the weight matrix with the dot productof a pattern with itself (auto-association), pairs of patterns are used (pairassociation).andP;  After construction of the weight matrix, either pattern can beapplied as input to elicit as output the other pattern in the pair.andM;A trained feedback model is much more complicated because adjustment of theweights affects the signals as they move forward as well as backward,Adaptive Resonance Theory (ART) model is a complex trained feedback paradigmdeveloped by Stephen Grossberg and Gail Carpenter of the Center for AdaptiveSystems at Boston University.andP;  ART is considered by some to be very powerful,but the number of patterns that can be stored is limited to exactly thenumber of nodes in the storage layer.andP;  No production applications have beenpublished to date; ART is presently considered a research tool.andM;Feed-Forward TopologiesandM;The second division of neural networks is the feed-forward category.andP;  Theearliest neural network models were linear feed-forward.andP;  In 1972, twosimultaneous papers independently proposed the same model for an associativememory, the linear associator.andP;  J.A.andP;  Anderson, a neurophysiologist, andTeuvo Kohonen, an electrical engineer, were not aware of each other's work.andM;The linear associator uses the simple Hebb's Rule.andP;  The only case whereassociation is perfect when simple Hebbian learning is used is when the inputpatterns are orthogonal.andP;  This puts an upper limit on the number of patternsthat can be stored.andP;  The system will work very well for random patterns ifthe maximum number of patterns to be stored is 10 - 20 percent of the numberof neurons.andP;  If the input patterns are not orthogonal, there will beinterference among them; fewer patterns can be stored and correctlyretrieved.andP;  One of the predictions of the linear associator is interferencebetween nonorthogonal patterns.andP;  Much of Kohonen's book, Self-Organizationand Associative Memory (Springer-Verlag, 1984) is concerned with correctingthe errors caused by interference.andM;The nonlinear feed-forward models are the most commonly used today.andO;Feed-forward networks, for historical reasons, are less often considered tobe associative memories than the feedback networks, even though they canprovide exactly the same functionality.andP;  It can be shown mathematically thatany feedback network has an equivalent feed-forward network that performs thesame task.andM;Types of Learning AlgorithmsandM;The are two main types of training algorithms: Supervised and unsupervised.andO;Supervised learning is the most elementary form of adaptation.andP;  It requiresan a priori knowledge of what the result should be.andP;  during training, thenetwork's output is compared to the ideal response, and any error is used tocorrect the network.andP;  Learning occurs as a result of changes to the weightsto reduce the errors as the network gains experience.andP;  For one-layer networksthis is easily accomplished by monitoring each neuron individually.andP;  Inmulti-layer networks, supervised learning is more difficult due to thecorrection of the hidden layers.andP;  Unsupervised learning differs in that itdoes not have specific corrections made by comparison to ideal results.andO;Supervised and unsupervised learning are methods which are used exclusivelyof each other.andM;The supervised back propagation model is the most commonly implementedparadigm today because it is the best general-purpose model and probably thebest at generalization.andP;  (This model ise used by the &quot;BrainMaker&quot; softwarefrom California Scientific Software.)andP;  Back propagation is a multi-layerfeed-forward network that uses the Generalized Delta Rule.andM;By 1985, back propagation had been simultaneously discovered by three groupsof people: D.E.andP;  Rumelhart, G.E.andP;  Hinton, R.J.andP;  Williams; Y. Le Cun; and D.andO;Parker.andP;  Back propagation is the canonical feed-forward network where anerror signal is fed back through the network, altering weights as it goes, inorder to prevent the same error from happening again.andP;  (See Figure 4.)andM;The error on an output neuron, i, for a particular pattern, p, is defined as[e.sub.pi] = ([T.sub.pi] - [O.sub.pi]) where T is the training (desired)pattern and O is the actual output.andP;  The total error on pattern p, [E.sub.p],is the sum of the errors on all the output neurons for pattern p.andP;  The totalerror, E, for all patterns is the sum of the errors on each pattern over allp.andP;  The simplest method for finding the minimum of E is known as &quot;gradientdescent.c  It involves moving a small step down the local gradient of thescalar field.andP;  This is directly analogous to a skier always moving down hillthrough the mountains until he hits the bottom.andM;Back propagation is useful because it provides a mathematical explanation forthe dynamics of the learning process.andP;  It is also very consistent andreliable in the kinds of applications that can currently be built.andP;  Thebiggest limitation is the size of the network.andP;  The back propagation network&quot;NetTalk&quot; uses about 325 neurons and 20,000 connections.andP;  A useful visualrecognition system probably requires at least 125,000 connections.andP;  Currentlyavailable commercial systems provide anywhere from a few neurons andconnections to 1 million neurons and 1.5 million connections, for anywherefrom $200 to $25,000.andM;A popular unsupervised feed-forward model is the Kohonen model.andP;  The basicsystem is a one- or two-dimensional array of threshold-type logic units withshort-range lateral connections between neighboring neurons.andP;  The systemmodifies itself so that nearby neurons respond similarly.andP;  The neuronscompete in a modified winner-take-all manner.andP;  The neuron whose weight vectorgenerates the largest dot product with the input vector is the winner and ispermitted to output.andP;  In this model not only the weights of the winner butalso those of its nearest neighbors (in the physical sense) are adjusted.andM;One of the problems with Kohonen learning is that there is a possibility thata neuron will never &quot;win,&quot; or that one will almost always &quot;win.&quot;andP;  The weightvectors get stuck in isolated regions.andP;  One way to prevent the weight vectorsfrom getting stuck is to start off with all the weight vectors equal.andP;  Thenetwork is first fed fractional amounts of the patterns.andP;  The inputs are thenslowly built up to the full input patterns.andP;  This method, called &quot;convexcombination,&quot; works well but it slows down learning.andP;  Another preventativemethod is to add noise to the data, which makes the probability densityfunction positive everywhere.andP;  The probability density function is areal-valued function that gives the probability that a random variable hasvalues in the set.andP;  This method works, but it is even slower than convexcombination.andP;  Another approach is to give the neurons a &quot;conscience&quot;; if theneurons realize that they are winning a lot, they will step out of thecompetition for a while.andM;A special case of the feed-forward model is the Neocognition.andP;  The originalmodel was unsupervised, but a more recent model (1983) uses a teacher.andP;  Themulti-layer (seven- or nine-layer) system assumes that the builder of thenetwork knows roughly what kind of result is wanted.andP;  All the neurons are ofanalog type; the inputs and outputs take nonnegative values proportional tothe instantaneous firing frequencies of actual biological neurons.andP;  In theoriginal model, only the maximum-output neurons have their input connectionsreinforced.andP;  It uses a variation of the Hebbian Rule.andP;  After learning iscompleted, the final Neocognitron system is capable of recognizinghandwritten numerals presented in any visual field location, even withconsiderable distortion.andP;  Drawbacks of the Neocognitron are that it is highlyspecialized and requires a large number of neurons and connections.andM;ConclusionandM;Neural networks are capable of some impressive things but they are alsolimited, primarily by the size of the network and the complexity of theproblem.andP;  They are especially good at association and generalization, butpoor at precise computations and logic.andP;  Some models are able to generalizebetter than others, some are good at association.andM;With more than 40 functioning models to choose from, it is important to knowwhich models have had the most success and to understand their similaritiesand differences.andP;  Currently, back propagation is the most popular model.andO;Several others are discussed in detail in this issue, each has it own merits.andM;Jeannette (Jet) Lawrence is technical publications manager at CaliforniaScientific Software, and the author of their 1989 publication Introduction toNeural Networks.andP;  She can be contacted at 160 E. Montecito #E, Sierra Madre,CA 91024.andO;</TEXT></DOC>