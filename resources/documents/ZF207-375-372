<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-375-372  </DOCNO><DOCID>07 375 372.andM;</DOCID><JOURNAL>AI Expert  July 1989 v4 n7 p56(7)* Full Text COPYRIGHT Miller-Freeman 1989.andM;</JOURNAL><TITLE>Selecting an uncertainty management system. (technical)</TITLE><AUTHOR>Rothman, Peter.andM;</AUTHOR><SUMMARY>Most expert-system application domains involve uncertainty.andO;Rule-based expert systems employ uncertainty-management systems(UMSs), which are sets of algorithms for managing uncertainknowledge.andP;  Four common UMSs are Bayesian inference, certaintyfactors, Dempster-Shafer reasoning, and fuzzy logic.andP;  Bayesianinference employs probability ratios to create inference networksusing the 'odds' form of Bayes' rule.andP;  Certainty factors useheuristic measures of belief and disbelief in a given hypothesis.andO;Dempster-Shafer evidential reasoning applies a mathematical theorywhich modifies probability theory by reflecting the unknown valueof a variable.andP;  Fuzzy logic arises from fuzzy set theory, anextension of set theory in which the set-membership function mayassume values between zero and one.andP;  Commercially available expertsystem development tools are evaluated for their UMS features.andM;</SUMMARY><DESCRIPT>Topic:     Fuzzy SetsUncertaintyExpert SystemsRule-Based SystemsData Management.andO;Feature:   illustrationgraph.andO;Caption:   A fuzzy set. (graph)The divergence of two aircraft trajectories due to SIC. (graph)andM;</DESCRIPT><TEXT>SELECTING an Uncertainty Management SYSTEMandM;Most expert system application domains involve uncertainty.andP;  Rule-basedexpert systems require a mechanism for managing and reasoning with uncertainknowledge.andP;  These mechanisms are known as Uncertainty Management Systems(UMSs).andP;  This article presents some issues in managing uncertainty andselecting an appropriate UMS for a given application.andP;  Four popular UMSs aredescribed and those that are commercially available in expert system toolsare presented.andM;Virtually all knowledge outside of pure mathematics involves some level ofuncertainty.andP;  Uncertainty arises from the environment; some sources includelimited measurement accuracy, fuzziness, lack of knowledge or observability,and sensitivity to initial conditions (SIC).andP;  The term &quot;uncertainty&quot; is oftenequated with the concept of randomness.andP;  Randomness refers to uncertaintyarising from the observation of random processes.andP;  The occurrence of randomevents cannot be predicted except statistically.andP;  Some examples of randomprocesses are the decay of radioactive materials, electronic componentsfailure, thermal noise, or flipping a coin.andM;The form of uncertainty most commonly encountered in applications occurs whenmeasurement devices with limited accuracy are used to observe quantitativeparameters of a physical system.andP;  Since these measurement devices havelimited accuracy and resolution, some degree of uncertainty is inherent inthese measurements.andP;  Consider the measurement of body temperature with athermometer (Figure 1).andP;  If the thermometer has markings every Celsiusdegree, any measurement will have a maximum accuracy of one degree.andP;  Forexample, if we measure a person's temperature as 37,[deg.] all we really knowis that the temperature is between 36.5[deg.] and 37.5.[deg.]  The limitedmeasurement accuracy creates uncertainty in the measured temperature.andO;Uncertainty due to limited measurement accuracy is commonly modeled as arandom error.andM;Another form of uncertainty is fuzziness.andP;  Fuzziness refers to the inherentvagueness of specific classifications or descriptions.andP;  Most knowledgeacquired from human experts is fuzzy.andP;  Fuzziness may seem similar torandomness, but it differs greatly.andP;  Fuzzy uncertainty is not necessarilycaused by any random process; rather, the uncertainty arises from thefuzziness of the knowledge itself.andP;  Thus, uncertainty due to fuzziness refersto a degree of belonging; uncertainty due to randomness refers to theprobability of a random experiment's outcome.andM;As an example of fuzzy knowledge consider the concepts of &quot;tall&quot; and &quot;short.&quot;andO;Clearly, someone more than seven feet high is tall and someone less than fourfeet high is short.andP;  However, most people fall somewhere in between theseextremes (Figure 2).andP;  Imagine that we surveyed people to determine what theyconsidered the relative tallness and shortness of various heights.andO;Tabulating the survey results, we might arrive at curves such as thosedepicted in Figure 3.andM;Ignorance of one or more parameters of a physical system often causesuncertainty in other parameters.andP;  For example, ignorance of a vehicle'sacceleration causes uncertainty in its velocity.andP;  Furthermore, informationabout a system may be completely unobservable, creating a lower bound on thetotal uncertainty in other system parameters.andP;  Additionally, certainfundamental uncertainty relationships such as the Heisenberg uncertaintyprinciple and the Gabor spatial/spectral uncertainty relationship place alower bound on the uncertainty in coupled systems of parameters (for example,the position and momentum or spatial and spectral distributions).andM;A less recognized cause of uncertainty is SIC.andP;  SIC refers to a systemsevolution's sensitive dependence on its initial state.andP;  A purelydeterministic phenomenon, SIC does not imply any form of random behavior inthe system.andP;  SIc's net effect is that specific temporal predictions of thefuture system state cannot be made over significant time intervals.andP;  SIC isoften encountered in conjunction with other sources of uncertainty such aslimited-measurement accuracy and ignorance or inobservability.andP;  Figure 4depicts a simple system exhibiting SIC.andP;  Two aircraft maneuver according tothe same deterministic acceleration law.andP;  Although their initial positionsand velocities are identical and their initial accelerations differ by onlyone part in one million, the aircrafts' trajectories diverge significantlyrelatively soon.andM;Uncertainty arises in almost all domains that apply expert systems and AItechnology.andP;  Some domains in which reasoning with uncertain knowledge playsan important role are medical diagnosis, natural-language understanding,production planning, decision-support and defense systems, economic andweather forecasting, sensor-data fusion, gambling, and criminalidentification.andP;  depending on the application, the expert system developerwill confront several types of interacting uncertainty.andP;  In medicaldiagnosis, the expert system developer must cope with randomness, limitedmeasurement accuracy, fuzziness, ignorance, and lack of observability.andP;  Inthe sensor-data fusion problem, uncertainty arises primarily because oflimited measurement accuracy, but developers also encounter fuzziness,randomness, lack of observability, and SIC.andP;  Most nontrivial applicationdomains involve multiple interacting sources of uncertainty.andM;UMSsandM;A UMS is a set of mathematical algorithms or software tools for managinguncertain knowledge.andP;  A UMS provides the ability to store, generate, andreason with uncertain and imprecise knowledge.andP;  Many uncertainty managementsystems have been proposed; entire journals are devoted to the subject.andP;  Fourwell-known UMSs are Bayesian inference, certainty factors, Dempster-Shaferevidential reasoning, and fuzzy logic.andM;Bayesian inference is based on the use of Bayes' rule from elementaryprobability theory.andP;  Probability theory describes, in a highly rigorousmathematical framework, observations of random experiments.andP;  According toLaplace's original formulation, probabilities can be viewed as a ratio of thenumber of outcomes of a particular class over the total number of possibleoutcomes.andP;  For example, the probability of drawing any card at random from adeck of 52 playing cards is one in 52.andP;  The probability of an outcome X isdenoted P(X).andP;  The probability that an outcome X does not occur is denotedP(X) and is equal to 1 - P(X).andP;  The conditional probability describes theprobability of an outcome X, given that we have observed some evidence E, andis denoted P(X!E).andP;  If two jacks have been drawn from a deck of cards, theprobability of drawing a third jack is two in 50 or 4%.andP;  An event is a set ofpossible outcomes, and a hypothesis is special type of event.andP;  Theprobability of an event is the sum of the probabilities of all the disjointoutcomes that comprise it.andM;UMSs implemented in probabilistic framework commonly use probabilisticinference networks (PINs).andP;  Reasoning and propagation of uncertainty in PINsare based on the odds form of Bayes' rule.andP;  Paul Morawski has exploredprobabilistic inference networks further.andM;A Bayesian UMS's operation is best understood by considering an example.andO;Imagine that two sensors (such as the radar and electronic support measures)aboard an aircraft carrier attempt to determine whether an incoming aircraftis friend, foe, or neutral.andP;  The radar reports the evidence P(Friend) = 0.5.andO;The electronic support measures (ESM) report the information P(Foe) = 0.7.andO;IF the radar and ESM system provide accurate estimates of their confidence80% and 95% of the time respectively, the likelihood ratios are: radar[lambda] = .5/.2 = 2.50 ESM [lambda] = .3/.05 = 6.00andM;The values of [lambda]' are: radar [lambda]' = (1-.5)/(1-.2) = 0.63 ESM[lambda]' = (1-.3)/(1-.05) = 0.74andM;The likelihood ratios for hypothesis that the aircraft is a friend are givenby: [lambda] = 2.50 * 6.00 = 15.00 [lambda]' = 0.63 * 0.74 = 0.47andM;Assuming prior odds of the target being a friend were 1.00, the odds of thetarget being a friend after the evidence from the sensors has been providedare expressed 0(Friend) = 1.00 * 15.00 = 15.00.andP;  Similarly, the odds that thetarget is a foe after the evidence from the sensors is received are expressed0(Foe) = 1.00 * 0.47 = 0.47.andP;  Based on this, we conclude that the aircraft isslightly more likely to be hostile than friendly, since P(Friend) = 0.93 andP(Foe) = 0.94.andM;Implementing a Bayesian UMS is complicated by problems that limit theusefulness of Bayesian techniques.andP;  First, implementing a Bayesian PINrequires knowledge of all the a priori probabilities.andP;  Worse, theseprobabilities are often inconsistent when elicited from human experts.andO;Specifically, the probability of a hypothesis H in the absence of any otherevidence E' should be the prior probability P(H\E); this is often not thecase.andP;  As a result, updating a node with evidence in support of a hypothesismay actually lower the a posteriori probability of H.andM;Another complication is the difficulty of obtaining all the a prioriconditional and joint probabilities required by Bayesian UMSs, especiallywhen these probabilities are time-varying.andP;  Also, the complex interactionsbetween the various probabilities in the PIN may make modification of theknowledge base unwiedly, since the sum of the probabilities must remainconstant.andP;  Bayesian reasoning assumes that all possible outcomes aredisjoint, an oft-violated assumption.andP;  For example, a person may suffer frommore than one disease or a machine may suffer multiple component failures.andM;Thus, several alternative UMSs were developed.andP;  Buchanan and Shortliffedeveloped certainty factors as an alternative in the medical diagnosis systemMYCIN.andP;  (E.andP;  Rich has written well about reasoning with certainty factors.)andO;Certainty factors are based on heuristic measures of belief and disbelief inhypotheses and are not strictly based on probabilistic models.andM;In MYCIN, the measure of belief in a hypothesis H given evidence E is theratio of increase in the hypothesis's probability (given the evidence fromits a priori probability) over the probability that the hypothesis is false.andO;If the evidence does not support the hypothesis, the measure of belief in thehypothesis is zero.andP;  Similarly, the measure of disbelief in a hypothesis Hgiven evidence E is the ratio of the decrease in the probability of H overthe a priori probability of H.andP;  The certainty factor of H given E is definedas the difference between the measure of belief and the measure of disbelief.andO;Positive certainty factors indicate that most of the evidence supports thehypothesis; negative certainty factors indicate that most of the evidenceconflicts with the hypothesis.andP;  Positive or negative certainty factors nearzero are usually considered indecisive.andM;Returning to the example of the aircraft identification from uncertain sensordata, suppose the radar and ESM systems report P(Friend) = 0.5 and P(Foe) =0.7.andP;  We can use this information to compute the measures of belief anddisbelief as to whether the incoming aircraft is a friend or foe.andP;  Assumingthe a priori probability of the hypotheses that the aircraft is friend/foe is50%, we have: MB(Friend,radar) = 0.0 MD(Friend,radar) = 0.0 MB(Foe,ESM) =0.2/(1-.5)=0.40 MD(Foe,ESM) = 0.0 CF(Friend) = 0.0 CF(Foe) = 0.40andM;Based on these results, we would conclude that the aircraft is hostile.andM;Although the MYCIN certainty factor model is computationally simple andperforms adequately for many applications, it suffers from several problems.andO;J. Barclay Adams has shown that certainty factors are isomorphic to a subsetof probability theory under an appropriate set of assumptions.andP;  Also, the adhoc nature of the certainty-factor model and its questionable relationship tohuman reasoning may be an issue.andP;  Further, very weak evidence favoring aconclusion would be accepted in the absence of any conflicting evidence.andO;Buchanan and Shortliffe used a threshold of .2 on the certainty factors toprevent this.andP;  Finally, a single negative assertion with a high measure ofdisbelief can overwhelm several weaker measures of belief, which can producecounterintuitive behavior in some circumstances.andM;Because of these difficulties with Bayesian- and certainty-factor-based UMSs,gordon and Shortliffe have proposed using the Dempster-Shafer calculusinstead of certainty factors in MYCIN.andP;  Dempster-Shafer evidential reasoningis a mathematical theory of evidence first published by Glenn Shafer in 1976.andO;The fundamental difference between the Dempster-Shafer calculus and theprobabilistic approach is the relaxation of the probability theory constraintthat P(X) + P(X) = 1.andP;  Dempster-Shafer evidential reasoning reflects theunknown value of a variable and is based on the concept of a basicprobability assignment.andP;  The basic probability assignment associates aprobability or mass with every possible variable value.andP;  As in probabilitytheory, the sum of the basic probabilities over all possible variable valuesmust equal one.andP;  But in the Dempster-Shafer calculus, reasoning is done withmeasures of belief rather than these basic probabilities.andP;  Measures of beliefare combined according to Dempster's rule of combination.andP;  Dempster-Shafterreasoning can be applied to the aircraft identification example.andP;  The radarreports the basic probability assignment: Friend  T .5  .5andM;The electronic support measures report the assignment: Foe  T .7 .3 where Trepresents the disjunction of all possible target types.andM;The combined probability assignment, including the evidence from bothsensors, is:andM;Assume also that the target is flying in a commercial aviation corridor, andthat we can therefore conclude: Neutral  T .4  .6andM;This then gives the combined probability assignment: Friend  .136 Foe  .318Neutral  .09 Friend or Foe  .318 T  .136 since the measure of conflict k isgiven by k = .06 + .14 + .14 = .34.andP;  Given this evidence, our belief that thetarget is not hostile is B(Not Hostile) = .136 + .09 + .136 = .362.andP;  Ourbelief that the aircraft is hostile is B(Hostile) = .318 + .318 = .636.andP;  Onthe other hand, the plausibility that the target is not hostile is given byPL(Not Hostile) = .682.andM;Here the plausibility of the assertion that the aircraft is not hostile isgreater than our belief in the assertion that the aircraft is hostile.andP;  Thisindicates that it would be inappropriate to take action based on theconclusion that the aircraft is hostile without more evidence.andP;  Althoughschemes can be devised to implement a system similar to this in both Bayesianreasoning and MYCIN certainty factors, Dempster-Shafer reasoning provides amechanism for reasoning about plausibility and belief separately.andP;  Thiscapability enables the UMS to perform more robustly in complex problemdomains.andM;Our final UMS is fuzzy logic.andP;  Fuzzy logic and fuzzy set theory wereintroduced by L. Zadeh as a natural extension of conventional set theory.andO;(Other sources are available on fuzzy set theory, but Zadeh's is superior.)andO;In conventional set theory, a potential element of a set is considered eitherto be contained in the set or not contained in the set.andP;  The characteristic,or membership, function of a conventional &quot;crisp&quot; set can therefore onlyassume the values zero or one.andP;  Conversely, in fuzzy set theory, themembership function may assume any value in the interval between zero andone.andP;  Both conventional and fuzzy set theories develop logics that can beapplied to universal reasoning.andP;  Conventional set theory gives rise toBoolean logic, in which statements are true or false; fuzzy set theory givesrise to fuzzy logic, in which statements can assume a continuum of truthvalues.andM;Unlike probability theory, fuzzy logic does not constrain the total of allmembership values to be one.andP;  Reasoning in fuzzy logic is performed by themathematical functions max and min.andP;  Let's assume we have three friends, Bob,John, and Sally.andP;  Bob is 5'10&quot; and has jet-black hair and a full beard.andP;  Johnis 6'2&quot;, very blond, and often forgets to shave.andP;  Sally is 5'5&quot; and has sandyblond hair and no beard.andP;  We want to know which of our friends are tall andblond, blond and bearded, etc.andP;  We can find out by computing the fuzzyvalues:andM;Fuzzy logic also admits other operators on fuzzy sets.andP;  For example, we mightlike to find people who are very tall or not very tall.andP;  Using thedefinitions: very tall = CON(Tall) not very tall = 1 - CON(tall) we findthat:andM;This example illustrates how easily fuzzy values can be translated intolinguistic variables.andP;  This property makes fuzzy logic very useful fornatural-language processing and constructing intelligent interfaces.andM;The role of fuzzy set theory and its relation to probability theory has beendebated.andP;  Dr. Bart Kosko of the University of Southern California (LosAngeles, Calif.) has shown that while Boolean logic restricts truth values tothe corners of an n-dimensional hypercube (Figure 5), fuzzy theory allowstruth values to assume the value of any point within the hypercube.andP;  Since inprobability theory the sum of the probabilities must equal one, a logic basedon probability theory would constrain truth values to the n-dimensionalsimplex (the diagonal triangle contained within the cube).andP;  Without enteringthe probability-vs.-fuzzy-theory debate, it seems that this geometricargument at least intuitively demonstrates the differences between Boolean,probabilistic, and fuzzy logics.andM;SELECTING A UMSandM;Each UMS described above is based on a different mathematical formalism, andeach assumes a dissimilar model of uncertainty.andP;  The selection of theappropriate UMS for developing a particular application is often key to theproject's success.andP;  Using the wrong UMS may compromise the system'sperformance, effectiveness, robustness, and reliability.andP;  But developing apowerful UMS in-house may be expensive and will have financial and schedulingimpacts.andM;Selecting an appropriate UMS will depend to some extent on the kinds ofuncertainty encountered in the application.andP;  Each UMS described here isappropriate for handling some kinds of uncertainty but may be inappropriatefor others.andP;  Table 1 summarizes the appropriateness of each UMS with respectto the four sources of uncertainty.andM;Many commercially available expert system development tools provide UMSs toenable the system developer to construct applications that handle uncertainor imprecise knowledge.andP;  The most common commercially available UMSs arethose based on Bayesian reasoning, MYCIN certainty factors, and fuzzy logic.andO;Several of the tools provide variants of these four systems or systemscompletely different from these UMSs.andP;  Some tools allow the user to utilizedifferent UMSs on a rule-by-rule basis; others must use a single UMSthroughout a knowledge base.andP;  Table 2 offers a comparative list of some ofthese tools.andM;Uncertainty and randomness have long been considered equivalent.andP;  Recently,other sources of uncertainty have been recognized.andP;  As we have seen,uncertainty can develop even in completely deterministic systems.andP;  Thedistinctions between the types of uncertainty that arise even in the simplestphysical systems are often subtle and difficult to detect.andP;  Moreover, in mostreal-world application domains, uncertainty develops because of interactionsbetween several of these factors.andP;  For example, measurement uncertainty andSIC might combine to generate the uncertainty in the estimated position ofthe two aircraft (Figure 4).andM;In surveying the UMSs available with commercial expert system developmenttools, it becomes apparent that many application developers avoid usinguncertainty in expert systems, for several reasons.andP;  The mathematical detailsof UMSs may be intimidating, particularly to nontechnical users.andP;  Someproblem domains do not require uncertainty management (for example,database-driven systems in which knowledge is either contained or notcontained in the database).andP;  Finally, confusion rages between reasoning withuncertain knowledge and providing uncertain conclusions.andP;  A system thatreasons with uncertain knowledge can provide definitive results.andP;  Moreover, asystem that ignores basic uncertainties in the domain knowledge may falselyprovide completely &quot;certain&quot; recommendations that may have very brittleperformance.andM;When selecting a UMS, the types and sources of uncertainty in the problemdomain must be identified.andP;  The available computational resources and thoserequired by the system under consideration must be compared.andP;  Themathematical rigor and similarity to human reasoning of the various UMSs mustbe evaluated within the context of the project requirements.andP;  Finally, theavailability and purchase cost or development of the various systems underconsideration must be assessed.andO;</TEXT></DOC>