<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF109-558-903  </DOCNO><DOCID>09 558 903.andM;</DOCID><JOURNAL>EXE  Oct 1990 v5 n5 p62(4)* Full Text COPYRIGHT Process Communications Ltd. (England) 1990.andM;</JOURNAL><TITLE>Not enough time in the universe. (problems incapable of beingsolved no matter how large the computer resources available)</TITLE><AUTHOR>Ince, Darrell.andM;</AUTHOR><SUMMARY>Fast probabilistic algorithms can solve NP-complete computationalproblems, a class of complex problems that cannot be otherwisesolved with any amount of computing resources.andP;  Algorithmiccomplexity is a branch of computing which develops algebraicdescriptions of program run-time or memory performance.andP;  Thedescriptions indicate the complexity of computational problems.andO;The most famous example of an NP-complete computational problem isthe travelling salesman problem.andP;  Finding an efficient exactsolution to any collection of NP-complete problems indicates thatall such problems could be solved and would be worth a Nobelprize.andP;  Probabilistic algorithms rapidly determine theoverwhelmingly probable answer but do not guarantee the same,correct result each time.andP;  The algorithms are also used toimplement fingerprinting functions for the rapid comparison ofcharacter strings or DNA strands.andM;</SUMMARY><DESCRIPT>Topic:     Algorithm ComplexityNP-Complete ProblemsSolvabilityApplicationsMethodsProblem SolvingScientific Research.andO;Feature:   illustrationgraphchart.andO;Caption:   The growth of an NP-complete problem. (graph)The travelling salesman problem. (chart)Desirable and realistic growth of travelling salesman problem.andO;(graph)andM;</DESCRIPT><TEXT>Not enough Time in the Universe There is a tendency to think of computers asomnipotent: that no matter what problem we give them, they will be capable ofa solution.andP;  However, in the last few years, we have seen this assumptioncompletely overturned.andP;  Research scientists have discovered problems that areincapable of being efficiently solved: that no matter how big a computer youemploy, even small instances of a problem will defeat it.andP;  Such problems arecalled NP-complete.andM;Before examining the nature of NP completeness, it is worth looking at abranch of computing known as algorithmic complexity.andP;  Researchers working inthis field are trying to develop techniques which lead to the derivation ofsome algebraic description of the run-time or memory performance of aprogram.andP;  They have devised a notation, known as the 'O notation', whichdescribes the run-time behaviour of a program.andM;For example, if the run-time of a program rises linearly with the amount ofdata that it processes then its algorithmic complexity is written as O(n).andO;This means that if a program runs in m seconds with a items of data, it willrun in 2m seconds with 2a items of data.andP;  This is reasonably respectablebehaviour.andP;  It is certainly better than a program which has a complexity ofO([n.sup.2]), where the increase in run-time varies as the square of the sizeof the problem.andM;An example of a very primitive way of determining algorithmic complexity isas follows.andP;  Consider the Pascal fragment shown below, which just initialisesa two-dimensional array to zero:andM;for i:= 1 to n do for j:=1 to n do a[i,j] := 0;andM;The second for statement is executed n times, so clearly the assignmentstatement is executed [n.sup.2] times.andP;  This gives the algorithmic complexityof this simple array assignment as O([n.sup.2]).andP;  This is a rather trivialexample, but it does give the flavour of the sort of analysis thatresearchers carry out.andP;  For a meaningful program, however, the mathematicscan be quite horrendous.andM;American researchers have been at the forefront in complexity research.andP;  Theyhave provided a number of mathematical tools which enable a softwaredeveloper to characterise the run-time of a program in algebraic terms.andO;During the 1970s, one young researcher, Steven Cooke, made an extraordinarydiscovery.andP;  He round that there were a number of problems whose increase inrun-time as a function of the amount of data processed was such that theirgrowth was exponential.andP;  A small instance of a problem could be solved in afew seconds, the next bigger instance in an hour or two and the next instancein a few days even using a supercomputer.andP;  He showed that there were someproblems which could not be solved with realistic examples within the knownfuture life of the universe.andP;  The explosive growth in such problems is shownin Figure 1.andM;A problem such as this has a complexity of O(exp n).andP;  At first, in the early1970s, there was the temptation to dismiss the work on NP-complete problemsas something of an academic plaything.andP;  However, very rapidly, with thegrowth of computing power and the ambition of the computing industry to takeon larger and larger challenges, a number of problems were discovered to beNP-complete.andP;  These problems came from diverse application areas includingVLSI fabrication, operations research, molecular biology and networkscheduling.andM;A typical NP-complete problem occurs in delivery systems.andP;  You are given awhole series of containers of varying sizes; the aim is to pack a lorry orvan with these containers such that the minimum amount of space is empty.andM;Travelling SalesmanandM;Probably the most famous NP-complete problem is the travelling salesmanproblem.andP;  Figure 2 shows a network of cities {a,b,c,d,e,f} with a number ofroads joining them.andP;  Each road has an associated mileage, and the aim is tofind a tour of all the cities, such that the mileage is minimised.andM;Small instances of the travelling salesman problem can be solved in seconds.andO;Larger (more practical) instances, involving 50 cities and hundreds ofroutes, require years of computation.andP;  This is a tragedy, as variants of thisproblem occur in many areas, such as the design of fluid transmissionsystems, delivery scheduling and VLSI design.andM;One of the most interesting features of NP-complete problems is that they arebased on what might seem a shaky edifice.andP;  They possess this feature: if youcan write an efficient program which solves one of the large collections ofcurrently known NP-complete problems, then all the problems are capable of anefficient solution.andP;  Certainly, if anybody managed to find an efficientprogram then it would be worth a Nobel prize.andM;Let me warn you, however, that the chances of finding an efficient programare incredibly small.andP;  Very talented researchers all over the world have beenattempting to do it for hundreds of problems, and nothing has yet emerged.andO;Many of these researchers have intellects the size of the known universe, buthave yet to come anywhere near finding an efficient algorithm for anNP-complete problem.andM;Win a Nobel PrizeandM;If you are interested in winning a Nobel prize, the following step-by-stepdescription tells you what you need do.andM;* Find a convenient NP-complete solution.andP;  The travelling salesman problemswould do.andP;  It's reasonably easy to program and also has major applications inoperations research.andM;* Develop an algorithm that you think will solve the problem in an efficienttime.andP;  Write a program which implements the algorithm.andM;* Write a brute-force program that solves the problem.andM;* Run both the 'efficient' program and the brute force program using anincreasingly large data set.andM;* Time each run.andP;  A stop watch would do for this.andM;* Plot each time against the size of the data set.andM;* If the graph for your algorithm looks like (a) in Figure 3 below, thencongratulations, it's time to ring up the Nobel prize committee.andO;Unfortunately, your graph will almost invariably look like (b).andM;This process can be started on a common-or-garden microcomputer.andP;  Usually,the graph will quickly tell you whether your efficient program is reallyefficient.andP;  If the curve for your program is still rising slowly when thesize of the data set blows the micro, transfer your program to a mainframe.andO;Examine its behaviour again.andP;  If the graph for the efficient program onlyrises comparatively slowly, then there is a high probability that you havecracked one of the great unsolved problems in computer science.andM;When researchers started work on algorithmic complexity, the main chargelevelled against it was that it was hopelessly theoretical, with no possibleapplication in computing.andP;  Even 20 years ago, there seemed to be ratherPhilistine approach to 'blue skies' research, although this attitude hasstrengthened recently.andP;  However, it did not take long for computer scientiststo discover useful applications of NP-complete problems.andP;  Probably the bestknown is in cryptography.andM;Cryptography is the study of secret codes: their invention, transmission anddecoding.andP;  Since the massive increase in electronic communication over thelast two decades, interest in cryptography has blossomed.andP;  Most of theresearch in this area is being carried out, in secret, by security agencies,banks and computer manufacturers.andM;Someone who needs secure communication must take his message and apply sometransformation to it.andP;  For simplicity's sake, let us assume that the messageconsists of two digit numbers, and the transformation t - not a very secureone - is that of adding an integer x to each number sent.andP;  The message is nowdelivered via some communication line.andP;  A sender then decodes the message byapplying an inverse transformation q.andP;  In my example, the inverse is tosubtract x from each number.andP;  The integer x, the key, will have been sentseparately to the receiver, enabling him to decode the message.andP;  Forcommunication to take place, the transformations must have the property thatwhen they are applied consecutively to a message the message remainsunaltered.andP;  Thus, in my example, adding an integer x to an integer and thensubtracting x gives the original integer.andM;This is one of the main planks of cryptography.andP;  However, the problem withthe technique I have described is that it is easy to crack the code withoutthe key.andP;  If the integers are the internal codes of characters in a naturallanguage text, the message can be easily broken by recourse to standardtables which give the frequency of letters in a natural language text.andO;Sophisticated methods now exist which can break such codes.andM;Rivest, Shamir and Adleman, three American researchers, devised acryptography scheme which, if an intruder wished to crack a code withoutknowing the key, would require them to solve an NP-complete problem.andP;  Inpractice, the problem normally used for this purpose is the factorisation ofa very large number (containing more than 200 digits).andP;  So far, all attemptsat devising methods to crack these codes have failed.andP;  Either the newalgorithm turned out to be flawed or, if it worked, then it relied on thefactorisation of a very large number...a problem that has been already shownto be grossly NP-complete.andM;Tinpot brainsandM;I find the existence of NP-complete problems quite reassuring.andP;  Too often webelieve that the computer is omnipotent, and can solve any problem that isgiven to it.andP;  This is often the basis for much of the optimism aboutartificial intelligence, and the predicted transfer of many of the tasks thatwe are good at to computers.andP;  The existence of NP-complete problems gives usmuch hope that human flexibility and built-in heuristics will enable us tooutwit any computer in complex tasks.andM;It would be tempting to finish this article on such this upbeat note.andO;However, there is a new strand of research which is attempting to beatNP-completeness.andP;  Researchers in this area have developed 'algorithms' whichgive rise to efficient programs for NP-complete problems.andP;  Now this mayconfuse you because, earlier on, I stated that it was highly unlikely thatsuch algorithms exist.andP;  However, the researchers have over-turned the idea ofan algorithm in their search for efficiency.andM;Look up the definition of an algorithm in any computer science book, and whatyou will find is a variant of this statement: 'an algorithm is a step-by-stepprocedure for solving a problem which is guaranteed to give the samesolution, for the same data, each time that it is executed'.andP;  Researchershave developed a new type of algorithm called a probablistic algorithm.andP;  Themain feature of such an algorithm is that it will be fast, exceptionally fasteven when applied to an NP-complete problem, but that in contrast to aconventional algorithm, it cannot be guaranteed to deliver the same, correctresult each time that it is executed.andM;This doesn't seem to be very helpful.andP;  However, probablistic algorithms havebeen devised where the probability of delivering an incorrect answer,although finite, is very low indeed.andP;  If the probability of getting anincorrect result is lower than an incorrect result being delivered due to acircuit malfunction in the computer used to execute the algorithm, then youcan see that the technique can be most useful.andM;Here is an example.andP;  Consider the problem of selecting one integer from a setof 1,000,000 (randomly ordered) integers, such that the chosen item lies inthe top half of the set in terms of size.andP;  To do this conventionally, wemight develop a program to find the maximum integer from the set.andP;  Thisguarantees the result, but requires that we thrash through the whole lot,performing something like 999,999 (1,000,000-1) comparisons.andP;  An obviousrefinement is to stop the maximum program when it has examined over half theintegers; this requires 500,000 (1,000,000/2) comparisons, and seems to bethe optimum solution, if we insist that a correct result is always given.andM;A probablistic algorithm to solve this problem would select k numbers fromthe set and then find the maximum of these knumbers.andP;  If k is 20 then theprobability of giving a correct answer is .9999999.andP;  If k is set at 100, theprobability of things going wrong is negligible - much lower than theprobability of the computer breaking down, an earthquake happening or youhaving a heart attack during the execution of the program.andP;  So we have analgorithm which requires only 100 operations, compared with 500,000operations for a conventional algorithm, and which almost invariably deliversthe correct result.andM;Domestic applianceandM;Probablistic algorithms are not only used for solving NP-complete problems.andO;They are often employed in conventional software development.andP;  One of themost common examples is the concept known as fingerprinting.andP;  Consider asearch of a large database of employee records, where each record consists ofan employee's name and details.andP;  Programs accessing such a database willspend a lot of time comparing strings of characters to find a name match.andO;Such comparisons can be quite time-consuming if the strings are very large:each character of one string has to be compared with a character of anotherstring.andP;  To speed up the comparison, each name string is associated with aspecial integer, calculated when the string is entered in the database, andstored with it in the record.andM;A fingerprinting subroutine is used to calculate the integer, the onlyproviso being that such a subroutine guarantees that two different characterstrings are most unlikely to generate the same integer.andP;  A possiblefingerprinting function might work like this: add up the internal codes of astring, and then form the remainder when the sum is divided by another(large) integer, where the divisor is smaller than the word size of themachine being used.andP;  To use the database first search for a record by its'fingerprint' key - which can be done much faster than string comparisons.andO;When an integer match is found, you must then perform a full stringcomparison, character by character, to check that the strings are equal.andM;Genetic EngineeringandM;Fingerprinting is currently one of the hot techniques in genetic engineeringcomputing.andP;  Genetic engineering scientists are currently trying to unravelthe genetic code: the sequence of chemicals contained in the DNA moleculewhich determine whether we are going to be tall, have blue eyes or besusceptible to cancer.andP;  In order to do this, they have to compare longstrands of DNA, stored on a computer as billions of characters.andP;  Acomputationally very exhausting problem.andP;  One of the most promisingtechniques for bringing the run-time of their programs down to the pointwhere they may be guaranteed success, is the use of probablistic algorithmsand, in particular, fingerprinting.andM;Algorithmic complexity and probablistic algorithms form one of the mostexciting research areas in computing.andP;  Unfortunately, most current researchis being done in secret.andP;  This not only occurs in cryptography, but also incomputational genetic engineering, where the financial gains of, say,engineering a new strain of vegetable can be massive.andM;However, research into algorithmic complexity and probablistic algorithms hasthe attractive property that it is an area where the amateur, with amicrocomputer, can participate, and where the disadvantage of being anamateur, and having limited computing equipment (even a humble PC) is muchless than in most other areas of computing research.andM;Darrell Ince is a Professor of Computing Science at the Open University.andO;Until recently, he was acting head of the computing department.andO;</TEXT></DOC>