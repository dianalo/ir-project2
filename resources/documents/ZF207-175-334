<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-175-334  </DOCNO><DOCID>07 175 334.andM;</DOCID><JOURNAL>Communications of the ACM  April 1989 v32 n4 p426(10)* Full Text COPYRIGHT Assn. for Computing Machinery, Inc. 1989.andM;</JOURNAL><TITLE>Volume rendering. (technical)</TITLE><AUTHOR>Frenkel, Karen A.andM;</AUTHOR><SUMMARY>New devices and techniques make volume rendering more feasible nowthan ever before.andP;  Computer graphics provide a general means ofvisualization that is effective for two types of data: real(measured) and numerical (calculated).andP;  The technique of volumerendering provides physicians with more data, therefore changingthe course of treatment.andP;  Three-dimensional rendering of computedtomography (CT) scan data is used by surgeons to plan operations.andO;CT is also known as computerized axial tomography.andP;  Widespreadacceptance of the technology has been hindered by vendors thathave kept their data formats proprietary.andP;  The next quantum leapin volume rendering will come with the real time production ofvery high quality images.andP;  The challenge is to provide the controlof traditional rendering for volume rendering.andP;  An ancillarybenefit is the use of the technology to convey scientificprinciples to non-scientific people.andM;</SUMMARY><DESCRIPT>Topic:     TomographyThree-Dimensional GraphicsScanning.andO;Feature:   illustrationphotograph.andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>VOLUME RENDERING A young man in his late twenties suffered a crushed pelvisin an auto accident.andP;  His orthopedists said that the fracture was toocomplicated to operate on and elected to treat him conservatively; he wouldbe in traction for a few months.andP;  The doctors were certain that the young manwould be permanently crippled.andM;Luckily, the man's father, also a physician, knew of research in 3-Drendering of computed tomography (CT) scan data.andP;  He sent his son's CT scanstudies to the researchers, a radiologist, an orthopedic surgeon, and acomputer graphics expert, who studied the volumetric rendering of the pelvisthat was created with specially designed hardware and software.andP;  Able to seeit from all angles, they determined the extent of the fracture and thelocations of several key fragments.andP;  The pelvis was operable and the nextday, the surgeon set the fragments.andP;  Three months later the patient returnedfor a check up and demonstrated full-range hip motion.andM;This case coupled great medicine and great computer science.andP;  The techniqueof volume rendering changed the course of treatment by providing thephysicians with more data.andP;  This data ultimately gave them the confidence tooperate and thereby improved the patient's quality of life.andP;  While volumerendering helped manage the medical complexities, this case also representsdepartures from tradition for both disciplines.andM;In the medical realm, radiologist Elliot K. Fishman, Director of ComputedBody Tomography at Johns Hopkins University, has been pioneering volumerenderings of CT (also known as computerized axial tomography) data for threeyears.andP;  But not all radiologists, whose fundamental training involvesinterpreting two-dimensional data into three dimensions, have embraced thisnew technique.andP;  Many are concerned that computer-generated artifacts andpseudo-color can lead to misdiagnoses.andP;  Widespread use and acceptance ofvolume rendering has also been hindered by competing scanner vendors who havekept their data formats proprietary.andP;  This has forced those on the computergraphics end to reverse engineer tapes of data to uncover the formats.andP;  Onthe other hand, surgeons can benefit from the precision that volume renderedCT and magnetic resonance imaging (MRI) can yield.andM;On the computer graphics side, Bob Drebin and his colleagues at Pixar havedeparted from tradition by abandoning surface rendering, which has itsfoundations in geometry based modeling.andP;  They maintain that volumetric datashould not be skimmed to yield only surface renderings.andP;  They have developednew algorithms that take full advantage of 3-D arrays of data, rather thanjust using the surface data found in such arrays.andP;  Their approach alsoreflects the early computer graphics dilemma over slowly generated,photorealistic graphics versus fast, less detailed image processing.andM;With the imaging and graphics application market expected to reach $1.6billion by 1990, according to Dataquest, several graphics and medical imagingvendors are merging or teaming up on large projects.andP;  In 1987, SunMicrosystems, Inc. bought Trancept Systems, Inc. to form a graphicsaccelerator division in Research Triangle Park, North Carolina, where theTAAC-1 add-on for Suns was developed.andP;  Also that year, Philips MedicalSystems, Inc., in Shelton, Connecticut, formed a partnership with Cemax, Inc.andO;in Santa Clara, California, and Island Graphics and Pixar, both in SanRafael, California, to launch Project Pegasus.andP;  Fifteen medical centers(including Johns Hopkins) are exploring different challenges in medicalimaging, evaluating equipment, and helping Philips develop hardware andsoftware.andP;  Another project, named for the Renaissance artist Leonardo daVinci, is a database of the entire human body on a Cyber 910.andP;  A joint effortof Control Data and the University of Illinois, Chicago, the projectintegrates the activities of medical illustrators, anatomists, radiologists,and biomedical engineers.andP;  Some researchers, like Craig Upson of StellarComputer, Inc., in Newton, Massachussetts, say that volume rendering is doingfor computer graphics in the late 1980s what the introduction of perspectivedid for drawing and painting during the Renaissance.andM;Why is volume rendering more feasible now then ever before?andP;  In volumerendering, computer graphics has found a general means of visualization thatis effective for two types of data--real (measured) and numerical(calculated).andP;  Huge amounts of data, collected a variety of ways, can beprocessed by miniaturized chips with immense, and often parallel processing,power.andP;  Besides CT and MRI data, 3-D measurements are now taken with the helpof solid state cameras and lasers, and improved microscopes.andP;  One new device,the very high resolution, confocal microscope, is expected to vastly expandcell biology experimentation.andM;Neurobiologist Vincent Argiro of Maharishi International University inFairfield, Iowa, who has used confocal data to volume render neurons, says,&quot;Volume rendering is one of the most direct, straightforward ways of doingthree-dimensional image processing.andP;  It's computer graphics on the one hand,but it's image processing on the other.andP;  You're dealing with real data aboutreal structures.andP;  These are not synthesized pictures that just come out of amathematical equation.&quot;andP;  Further, he sees volume rendering of any kind ofdata as a catholic approach to understanding a huge range of phenomena innature.andP;  Far from belittling numerically based volumetric simulationsgenerated on supercomputers, he adds, &quot;It's intriguing that you have onemethod that can be used to display a three-dimensional relationship amongeither real data from the real world--from a huge variety of measurementmethods that span a range of 20 orders of magnitude--that can also just aseasily be applied to the simulation of phenomena generated on supercomputersby purely numerical methods.andP;  So it's a unifying approach to looking at theworld.&quot;andM;In fact, researchers are volume rendering right up the scale, from moleculesand their electron clouds measured in nanometers, to the distribution ofgasses throughout the galaxy, measured in light years.andP;  Other applicationsinclude nondestructive testing and failure analysis of manufactured goods.andM;Interest in volume rendering among broad groups of researchers is growing.andO;The volume imaging group that met at SIGGRAPH '88 had quadrupled to about 100from the year before.andP;  Upon opening the meeting, Chairman Nick England of SunMicrosystems declared, &quot;I'm going to teach radiologists to love voxels,&quot; andthen polled the group to find out who they were.andP;  The group was equallydivided between those studying real world and simulated data, as it was fordynamic and static, monochrome and color, and continuous and discontinuous.andO;Between 10 and 20 were comparing multiple volumes and using stereo to helpsee an image more clearly.andP;  The smallest data set being massaged was 10 X 10X 30 and the largest was 10,000 X 10,000 X 4,000 voxels.andP;  Voxel comes fromvolumetric element.andM;THE MATERIAL MIXTURE MODELandM;The geometry-based model that Drebin discarded calls for describing an objectin terms of lines, polygons, patches, and other abstract geometrical conceptsthat are then converted into pixels.andP;  But few objects in nature lendthemselves to such descriptors.andP;  Alvy Ray Smith, Pixar's Executive VicePresident, points out that &quot;Ninety percent of the data [in scientificvisualization] does not come from geometric sources--geometrically describedobjects--in the first place.&quot;andP;  Instead, Drebin, Loren Carpenter, and PatHanrahan developed the &quot;material mixture&quot; model, whereby materials arerepresented as adjacent to each other and/or mixing with each other.andM;The quest for the algorithm that finally helped Fishman visualize thefractured pelvis actually began with another set of broken bones.andP;  In 1984,when Drebin came as a programmer to what is now Pixar, it was still adivision of Lucasfilm Ltd., handling special effects and the Pixar processorwas still in the design phase.andP;  Just as the company was beginning to marketthe Pixar Image Computer outside the film industry, Drebin broke his arm.andO;With his arm in a sling, he was unable to program, so he joined the team thatwas identifying potential markets for the machine.andP;  They landed at Siemens,where the medical imaging group was dissatisfied with its 3-D imagingresults.andP;  Siemens' researchers gave Pixar a tape that originated withFishman.andP;  The images were unsatisfactory, Drebin felt, because the users weretrying to fit the data into available systems.andP;  &quot;The problem seemed to bethat people were trying to extract a geometric model from their data so thatthey could use a traditional rendered,&quot; he says.andP;  But the geometric model&quot;didn't do justice to the subtlety of the image data.&quot;andP;  For example, theresolution of 48 CT slices was too low to reveal details of porous bone.andO;&quot;The way it was sampled, the porous bone appeared fuzzy,&quot; Drebin explains,&quot;It was not a very distinct, sharp region.andP;  So it's difficult to extractgeometry and it's not always possible.&quot;andM;Until now, most techniques for visualizing volumes have relied on displayingsurfaces by reducing volume arrays to the boundaries between materials.andO;Instead of working with pixels, arrays of voxels are created.andP;  Someresearchers have manually traced two-dimensional contours from individualslices and then used graphics systems to connect them and form trianglestrips or surface patches, but problems arise if the distance between thesections is large relative to the size of the voxels.andP;  Other surfacetechniques output polygons at every voxel; each voxel might be treated as acube whose faces are output as square polygons, or values at each vertex areused and estimates made of where a surface cuts through the cube.andM;Because these techniques extract surface information from 3-D arrays, theyare an indirect way of visualizing volumes.andP;  They assume that a thin surface,suspended in air, accurately represents the original volume, but often dataare taken from volumes containing fluids and tissues that interface and formlocal mixes.andP;  They absorb and emit light differently, information which islost if the data are reduced to shell-like surfaces.andP;  &quot;We have athree-dimensional data set and we'd like to see into that three-dimensionaldata set,&quot; says Drebin, &quot;So let's treat it as a three-dimensional image.&quot;andP;  Topreserve the continuity of the 3-D data and see the exterior, interior, andlocal variations in that interior, Drebin developed a display processconsisting of three steps: classification, modeling, and rendering.andO;Classification assigns percentages of materials contained in each voxel.andP;  Theresult is not an all-or-none decision, but a best estimate of how much of amaterial is present in a voxel.andP;  The information from this probabilisticclassifier is stored fractionally, not in binary, because binaryrepresentation disrupts the continuity of the data.andM;In the modeling and rendering steps, the material mixture model isrepresented by assigned colors and opacity.andP;  Boundaries occur when there is alocal change betweeen densities, so in a sense, surfaces can be extracted.andO;The change in densities, or gradient, is used to estimate the surfacestrength, or amount of surface present.andP;  Later, that information is used forshading.andP;  Perspective on an image is provided by lighting a model in such away that light can be reflected, absorbed, and emitted.andM;Because volumetric renderings are done for color images, red, green, and bluedata can be computed by three channels in parallel.andP;  When rotating a volume,for example, operations for each set are done simultaneously.andP;  A fourthparallel channel, the alpha channel, handles opacity, compositing, overlays,anti-aliasing, and matting.andP;  Originally developed for creating specialeffects, matting is the technique responsible for space ships zooming pastcelestial bodies, as seen in Star Wars.andP;  In this application, it enables aviewer to peel away layers by performing cut-aways, or to remove regions ifthe data is unreliable or uninteresting.andM;A DIAGNOSTIC TOOL?andM;In case of artifacts, Drebin says working with percentages of materials in amixture allows noise to appear as noise in an image, whereas geometricmodeling does not allow noise to be directly modeled.andP;  Since it isidentifiable, he says it is a big step toward getting rid of most artifacts.andO;Others are not as optimistic about false details.andP;  Henry Rusinik, who workson the Pegasus Project site at New York University Medical Center, says, &quot;Wedon't claim to be able to do a diagnosis yet.andP;  False positives are veryimportant if you want to claim whether or not a person is sick.andP;  I don't knowof anybody who can claim that 3-D is better than 2-D for diagnosis.andP;  .  .  . andO;Eventually it will be, but not in the next 10 years.&quot;andM;Looking back on the successful treatment of the man with a crushed pelvis,Drebin remembers a videotape made two months after surgery.andP;  &quot;It's amazing tosee this man, with all the pins they put in, walking on a platform without alimp and doing deep knee bends.&quot;andP;  He says orthopedic surgeons at JohnsHopkins now regularly ask for &quot;a Pixar&quot; to be done.andP;  Over 2,000 studies havebeen performed so far.andP;  Also interested in chemotherapy for cancer patients,particularly radiation dose planning, Drebin explored how particles wouldscatter in a child's brain.andP;  Planning is now done on CT scans displayed on atwo-dimensional plane.andP;  Matte algebra and choosing the right translucence andsurface characteristics help elucidate the fuzzy radiation.andP;  That couldimprove targeting a tumor, for example, and protect healthy tissue.andM;NEURONS AND A NEW DATA SOURCEandM;Argiro started building graphics tools to help satisfy his curiosity abouthow the brain functions at the cellular level.andP;  He wanted to see how liveneurons take on the special structural and functional properties that allowthem to participate in the &quot;extraordinary network that gives rise to ourawareness, our capacity to learn and create and so forth.&quot;andP;  And then hewanted to &quot;build beautiful, three-dimensional pictures of neurons blindinglyfast.&quot;andP;  Recognizing how ambitious such an undertaking is, he says, &quot;It's oneof the most difficult problems in science.andP;  The brain is the moststructurally complicated object in the universe and it's the most complicatedvolume that one could ever volume render.&quot;andM;A participant in silicon Graphics Inc.'s Geometry Developers Group, Argiro'scompany, Vital Images, Inc., is developing software for SGI's machines,including the most advanced model, the Iris 4D-120 GTX.andP;  His work is fundedfor three years for half a million dollars by the National ScieneceFoundation and Iowa State Department of Economics, which wants to see its&quot;Silicon Cornfields&quot; grow.andM;Argiro had been developing a techniques for surface rendering living cells'&quot;foot prints&quot; in tissue culture under an interference reflection microscope.andO;Colleagues attempting to recover three-dimensional geometry were, and stillare, manually tracing slices and then building pictures.andP;  For the most part,Argiro has eschewed the two primary data sources, CT and MRI, in favor ofconfocal data.andP;  In CT, there is a straightforward relationship between tissuedensity and the brightness of the image.andP;  Although most agree that MRI willreplace CT, for volume rendering it pesents difficulties.andP;  MRI data yieldsmuch higher spatial resolution and very subtle contrasts particularly in softtissue, but the relationship between the signals and the underlying nature ofthe material is not simple, and that is an active research topic now.andM;Argiro saw the first commercial laser scan confocal microscope, the Phoibus1000 made by the Swedish company Sarastro A.B.andP;  (U.S.andP;  patent number4,631,581), at a 1987 neuroscience meeting.andP;  It was hooked up to a Compaq 386and the picture quality was &quot;very elementary.&quot;andP;  It took half an hour to buildone picture on a five-MIP machine, but it increased resolution in thehorizontal plane, and more important, greatly increased resolution in thevertical plane.andP;  &quot;The depth of field of the microscope is very, very small,&quot;he explains, &quot;so it's possible to take a half-a-millimeter-deep slice throughan intact volume of living tissue without actually having to disturb thestructure of the tissue.&quot;andP;  The laser is focused onto the specimen plane andscans across that plane.andP;  Instead of acquiring the image as a plane image inparallel, as in a normal optical microscope, the image is built up point bypoint, like a television or a raster.andP;  Light coming back from the sample isacquired by a photo multiplier, digitized, and then a number is recorded foreach point in the image.andP;  This information builds up in the frame buffer.andO;Then, to section finely in the vertical dimension, a stepper motor on thefocus control takes a series of 2-D sections, optically slicing up a volumeof tissue.andP;  The resolution is 0.25 microns in the x and y plane and 0.75microns in the vertical plane.andP;  The Phoibus 1000 can scan 1024 X 1024 X 512voxels.andP;  The maximum capability could have half a gigabyte of data generatedfrom one experiment.andP;  &quot;Unless you can render several hundreds of thousands ofvoxels per second, you're not going to get near one or a few seconds ofrendering time, and physicians can't wait more than five minutes to build apicture,&quot; says Argiro.andP;  On the SGI GT Series some pictures can be rendered on0.5 seconds.andP;  So far the highest rate has been 240,000 voxels per second onMRI data of a human head.andP;  &quot;No one else has gotten anywhere near that,&quot; saysArgiro, &quot;It has raised a lot of eyebrows.&quot;andM;FINE-TUNING MICROCODEandM;Besides making volume rendering an interactive rather than a batch process,the challenge has been to determine what tasks could be done using SGI'sexisting architecture, and to fine-tune existing algorithms.andP;  To makealgorithms faster, Argiro focused on two areas.andP;  First, he looked at how toorganize a volume dtabase so that it could be traversed very rapidly, anduseful information retrieved very quickly.andP;  Memory access time in a rawvolume database of 10 megabytes, which is the size of the neuron set, meansthe loop in a program takes a substantial amount of time all by itself.andO;Second, he developed a shading or contrasting method that be believes isunique.andM;Of the microcode, Argiro says, &quot;We found that, inadvertently and fortunately,SGI had put most of the operations for voxel rendering into their microcode.&quot;andO;For example, because volume rendering is compositing, you have to sumcontributions from different planes that would be in effect in front of orbehind the viewing screen.andP;  That means compressing them into a flat picture,an arithmetic operation done at the last minute before going into the framebuffer.andP;  Consequently, there must be a very fast adder/multiplier (in SGI'smachine it's called a &quot;blend function&quot;) right at the frame buffer.andP;  Anotheradvantageous function is the complex lighting model, which allows you to setup complex lighting equation that takes into account up to eight infinite orpoint light sources.andP;  In addition, material properties can be assigned tocharacterize the object in question and then executed on the fly at a veryhigh rate.andP;  In principle that could be done up to 400,000 voxels per second.andM;The voxel rate is not limited by the graphics hardware, however.andP;  Argiroexplains,andM;It's actually limited by the CPU and how fast one can traverse a huge volumedatabase and then stuff the information into the graphics hardware.andP;  Ifyou're talking about rendering half a million voxels per second, you have twomicroseconds to do everything for that voxel.andP;  Now, two microseconds, even ona very fast, current generation RISC CPU is still only about 20 machinecycles, which means even on a very efficient processor like the MIPS that SGIuses, you've got 15 to 18 machine instructions to turn that voxel around.andP;  Ifyou see C, you've got about four or five lines of code to handle that voxel.andO;And then you've got to be doing the next one.andP;  That's how tight yourprograms's inner loop has to be.andP;  And so that's where the performance tuninghas gotten very involved.andP;  There just isn't a whole lot of time if you wantto keep that rate that high.andP;  So we've sat many long hours staring at verysmall pieces of code, figuring out how to make them absolutely as fast aspossible, coming up with data structures, coming up with approximationmethods, and so forth, that give us a very heuristically pleasing image onscreen, but still do it as blindingly fast as possible.andM;Argiro hopes to break the one million voxel barrier by adding microcode tothe geometry pipeline.andP;  Theoretical calculations on dataflows on a number ofoperations that can be done per voxel, may hit rates as much as 5 millionvoxels per second on the existing architecture.andP;  But he admits that hisalgorithm does not work equally well on all databases.andP;  They work best oninherently high resolution, dense, data (256 X 256 X X slices and up), which would include most volume data.andP;  People have used it on very sparse or verylow resolution data, (50 X 50 X 50), or just a few thousand voxels, but thatrequires interpolation to generate intermediate values, which the algorithmis not intended to do.andM;DISCOVERIES COMPARABLE TO THE DOUBLEandM;HELIX?andM;During the past 15 to 20 years, neurobiologists have spent hundreds ofthousands of dollars on histological and primitive computer graphics methodsthat would take weeks to recover the geometry of one neuron.andP;  The work hasbeen as painstaking as it must have been for Watson and Crick to analyzeX-ray crystallography data without the the aid of computer graphics.andP;  ForArgiro, the confocal microscope has opened up hundreds of experiments andwill help answer questions that are &quot;just dying to be answered.&quot;andP;  He expectsa huge flurry of cell biology papers because research that was previouslyimpractical now is.andP;  Does he expect a discovery in neurobiology that isanalogous to the double helix?andP;  &quot;It hasn't happened yet, but it could.andP;  Thereare many, many cases in science where opening up a new experimental windowopens up possibilities for people's imaginations and then--boom--somethingcomes out the mist.andP;  The rate of understanding three-dimensionalrelationships in biological tissue can accelerate dramatically.andP;  That's beenvery exciting to me.&quot;andM;MACROMOLECULES: FROM DNA TO THE POLIOandM;VIRUSandM;Working at the macromolecular level is Arthur Olson of the Scripps ClinicMolecular Biology Department in La Jolla, California.andP;  Trained as an X-raycrystallographer, he is now a molecular modeler, exploring how scientistsinteract with molecular models that they build based on data derived eitherfrom experimentation or computation.andP;  Interactivity goes hand in hand withinterpretability, says Olson, so his team explores the best ways to representa molecule's properties or characteristics.andP;  The goal is to make the processof examination and understanding as clear as possible.andM;Volume rendering macromolecules like proteins involves several hundred toseveral thousand atoms.andP;  Viruses, the next level of organization, havehundreds of proteins.andP;  The first step is to understand how molecules fold andtake on their particular shapes.andP;  The next step is to determine how theyinteract with one another to produce larger assemblies that then go on andperform particular functions.andP;  The positions, charges, and other chemicalcharacteristics of those atoms play a role in how these molecules function.andM;Marvelling at the complexity in nature, Olson says,andM;The striking thing to think about is that, on the one hand, these arechemicals; they're just assemblies of atoms.andP;  But on the other hand, thesearen't things that were just thrown together in a test tube; this is anassembly of large numbers of atoms that have evolved over billions of years,to perform particular functions.andP;  So that their design is incrediblysophisticated, incredibly intricate.andP;  In order to have a hope ofunderstanding the relationship between the placement of all these atoms andthe biological function at the other end, we have to be able to visualize thewhole, and understand it in terms of all the parts, because certainly thewhole is much, much greater than the sum of all of the parts.andM;Rather than choose between surface and volume rendering, Olson combines thetwo so that there are &quot;landmarks,&quot; which are necessary for understanding andinterpreting the many twists and folds of these very complex structures.andO;Volumetric information is mapped onto, or rendered in the context of, ageometrical model, like a molecular skeleton or surface.andP;  The model is basedon some data, and then the model itself is the basis for the synthetic imageof the molecule.andP;  Unlike those working strictly on data interpretation, Olsonis looking at it from the model analysis end.andP;  The model and volumetric databoth are rendered in the same frame--the program takes two different types ofinformation and integrates it into a single view.andP;  Their algorithm is in theframe buffer, is written in FORTRAN, and runs on the Convex C1 computer.andO;Generally, it calculates and renders images that are 500 pixels squared at 24bytes per pixel for four color separations in 20 to 40 minutes.andP;  Olson wouldlike to get simulations of optical interaction due to chemical properties inreal time, but &quot;that's asking a lot,&quot; he says.andP;  &quot;We work at both ends of theproblem.&quot;andP;  In this area, intelligibility of images and picture quality havebeen the priorities and they have not been sacrificed for faster computation.andM;One unanticipated discovery that was extremely useful for understanding theself-assembly of a virus particle resulted from volume rendering the poliovirus.andP;  Inside the molecule one would expect to find an even, relativelyneutral inner surface because the phosphate groups on the nucleic acids havea lot of negative charges.andP;  In turn, one would expect the protein code tohave a lot of positive charges around it.andP;  But when Olson and post-doctoralfellow David Goodsell did the calculation, it showed a large lobe of negativedensity.andP;  This helped them see the complementarity between one side of anassembly unit and its mate.andP;  &quot;So not only are the shapes complementary butyou can easily see from these renderings that the electrostatic fields arecomplementary,&quot; Olson explains &quot;Often you see things you weren't looking for.andO;It's when you don't know what questions to ask that graphics takes onimportance.&quot;andM;Are artifacts a problem at this scale?andP;  Since no life threatening situationscan arise, the stakes are of course not as high as in medicine.andP;  Further,these macromolecular researchers are not looking at individual cases, but atthe generic case.andP;  And the properties they are looking at are calculatedbased upon a grid for descretizing and sampling points in space.andP;  Forexample, to calculate the electrostatic potential at a point, the charges inspace are summed vis-a-vis a test charge at a particular point.andP;  Then theymove the point a discrete amount in space, and do the calculation again.andO;Upon volume rendering, they cast a ray of light through that grid, andperform interpolations based upon those values computed at that grid.andP;  Theresearchers define that grid, but in medical imaging, the scanning equipmentdictates the grid and therefore the sampling of measurements.andP;  &quot;They don'thave much of a choice,&quot; explains Olson, &quot;If we feel that we're gettingartifactual results, we can adjust the grid and make it smaller.&quot;andM;Whereas for Argiro, volume rendering unifies inquiry across scales, Olsonsees it as a unified paradigm for different types of data within themacromolecular level.andP;  &quot;We can use the same algorithm to show contactsurface, electron density, electrostatic potential, and any calculated orobserved properties in three dimensions,&quot; says Olson.andP;  &quot;So it has thepotential of unifying a lot of different types of analysis for us.&quot;andM;OBJECT-ORIENTED GRAPHICSandM;Recognizing the need for scientists to do both geometric and nongeometricmodeling, and to help them reuse their code, several companies are creatingobject-oriented programming (OOP) graphics tools and libraries.andP;  Among theseare Apollo Computer, Inc. in Chelmsford, Massachusetts, Ardent ComputerCorporation, in Sunnyvale, California, and Stellar Computer, Inc. in Newton,Massachusetts.andP;  These companies also see OOPs as a way of distributinggraphics and providing data abstraction to help process, and determine wherebest to process, the torrents of data volume rendering involves.andM;At Apollo, OOPs has grown out of a desire to improve the efficiency ofdistributed processing done at workstations linked by networks.andP;  In such&quot;network computing,&quot; as Al Lopez, Apollo's Director of Graphics and UserEnvironment R andamp; D, calls it, data exists at many locations on the network andthe problem of getting the processing out to the data must be addressed.andO;&quot;How do you process it?&quot; he asks, &quot;Do you move the data around the network ordo you position it strategically next to the computing resource that's goingto be processing the data?andP;  Then, how do you get the computing, or that partof the application that is going to operate on the data, out to thatresource?&quot;andP;  Because scientists want to control or steer components of theapplication, they no longer want a batch process.andP;  There is a demand forinteractive, low-end systems on high bandwidths, but it is not enough tosimply move and process data faster, says Lopez.andP;  Interactive, distributedapplications must be supported in such a way that the network is transparentto users and that they are immune to changes in the network.andP;  The nextgeneration of graphics environments will be object-oriented and coupled withobject-oriented network computing systems, like Apollo's Network ComputerSystem, he says.andP;  To such a graphics interface you would be able to say,&quot;Rotate yourself 30 degrees&quot; and not care about whether it's a bit-mappedimage or some geometry.andP;  In addition, OOPs would provide extensibility sothat users would not have to wait for a new release from a vendor.andP;  And itwould also provide distributed access to shared objects anywhere on thenetwork.andP;  Says Lopez, &quot;If you say to an object, 'Ray trace yourself,' [youshould] have the method for that object to use the distributed computingenvironment to spawn out copies of the ray tracer on multiple nodes inparallel.&quot;andM;One object-oriented graphics application interface is Ardent's Dore (DynamicObject-Oriented Environment), which was written to accommodate the Ardentmini-supercomputer's closely coupled computational and graphics dataarchitecture.andP;  To satisfy that kind of abstraction, it is built at the macrolevel, so that primitives, attributes, views, and devices are objects.andP;  Theuser does not have to understand rendering, know where the processing isoccurring, what decomposition of geometry is being performed at a lowerlevel, or what attribute assignment mechanisms are in use.andP;  Instead of sayinghow to render an image, Dore directs different renderers, like Pixar'sRenderMan, to obtain the best output for the devices being used.andP;  Dore isalso extensible, so you can, as Ardent did, take a photograph of YosemiteValley, map it onto a three-dimensional height field, make a mesh oftriangles, color them and then rotate them in real time.andP;  Then you could addthose primitives to Dore and reuse them.andP;  Programmed in Standard C, Dore isportable to other systems.andM;LINKING CAD AND VOLUMETRIC DATBASESandM;In the nondestructive testing field, engineers are saving money by usingvolumetric data to analyze and inspect parts and to compare them to theidealized versions that they designed.andP;  Donald Jones, Director of EngineeringAnimation and Visualization at Failure Analysis Associates, Inc. in PaloAlto, California, has used CT, MRI, and ultrasonic data to check dimensions,and eddy current data to measure conductivity.andP;  In the past, Jones was ableto look at only a subset of data after preprocessing, like polygons that thenhad to be interpolated; now he can look at all the raw data.andP;  Occasionally,preprocessing causes inspectors to miss minor defects, but with volumerendering, &quot;they don't have to throw [any data] away.&quot;andP;  Since industrial CTcan take far more slices than can be taken from humans (who cannot be exposedto the radiation as long), the resolution is considerably finer: 5 mil (1 mil= 0.001 inch; or 1 pixel is about equal to 5 mil) compared to between 40 miland 50 mil for humans.andP;  Jones, a Pixar user, performs both surface extractionand assigns transparency to voxels because sometimes they are interested inthe form and shape inside a container.andP;  Putty inside a part will have its ownform, for example.andP;  Since different types of materials adhere differently tosurfaces, that has to be taken into account if the material and the part areprocessed together.andM;Jones emphasizes the interface between his inspection and CAD databases.andO;&quot;Now that we can reconstruct, three-dimensionally that actual part, not anidealized part, we can take the CAD database that the designer has used, andlook at that data to cross check whether our part is dimensionally tolerant.&quot;andO;Explains Jones, &quot;We take an existing finite element model and look at our CTand then warp or scale the finite element model to match the CT model.andP;  Nowwe have an exact model and can run an analysis on that and see if it willfail, based on the mathematical geometric properties of that particularpart.&quot;andP;  If it is far off, they reject it.andP;  But if it is just out oftolerance, they can store it and wait until an accompanying part appears withcompatible tolerances.andP;  This can lead to tremendous savings.andP;  Says Jones,&quot;These parts are not cheap.andP;  They're the cost of a couple of Californiahouses--$300,000 each.andP;  You don't want to just throw them away if you don'thave to.&quot; Eventually, Jones hopes to automate his inspection system withneural networks that will look at patterns of defects and decide what to dowith defective parts.andM;MOTION AND PHOTOREALISM VERSUS FASTandM;IMAGE PROCESSINGandM;Volumetric images offer the most information when they are seen moving on thescreen.andP;  Argiro says rotating an image on the screen is essential to theperception value of the computer graphics.andP;  &quot;A lot of the brain deals withperception of motion,c says Argiro, &quot;and if you have a static picture on thescreen there's a whole part of the brain that just goes to sleep.andP;  As soon assomething moves on the screen a whole part of the brain wakes up.&quot;andP;  Accordingto Argiro, interacting with a moving image is &quot;SGI's angle.&quot;andP;  &quot;Let's make[the visualization tool] interactive, and then we'll tune the quality andphotorealism up.&quot;andP;  As the technology advances, he says, SGI will &quot;make thepictures prettier and prettier and prettier, but without sacrificinginter-activity.andP;  [The technology will get to] the point where one could makephotorealistic pictures in real time, but one still wants the real timeresponse.&quot;andM;At Pixar, the philosophy is different.andP;  On the photorealism/fast imageprocessing spectrum, Drebin himself leans toward photorealism, but says Pixarfalls somewhere in the middle.andP;  &quot;If you can approach realism, then you canback off again,&quot; he says, preferring to provide a superset of informationfirst.andP;  &quot;Then you have much more control over the abstract way ofrepresenting information.andP;  That's one way we differ significantly from otherapproaches.&quot;andM;Although Drebin agrees that the next quantum leap in volume rendering willcome when very high quality images are produced in real time, much is stillnot understood: &quot;We're getting a lot closer to understanding why images comeout the way they do, but because you don't know the data you're workign with,it sometimes is harder to control than when you're working with a geometricmodel where you chose where the type of light, your depth of field, thesurface color, and the surface texture.andP;  With volume rendering you don'tquite have that control yet.andP;  One of the big challenges is to get volumerendering to the point where you have all the controls you have intraditional rendering, so that you can predictably say, 'I want the bone tohave this surface characteristic, with the proper reflections, the properroughness.'andP;  One [end of the spectrum] is getting closer to traditionalrendering, or getting closer to realism.andP;  And the other side is just makingthe environment in which it is possible to process that data much faster.&quot;andM;Olson believes that photorealism and merely interpretable images willconverge.andP;  &quot;You need data from both ends,&quot; he says.andP;  &quot;Different types ofpeople are oriented towards different things.andP;  I'm visually oriented.andP;  A lotof people say 'Why bother taking pictures when really the constructs are inyour mind?'andP;  But, to me and to a lot of other people, things become much morereal and concrete when you can have a view, a vision, of what they are.andP;  I'mnot saying it's necessary for every scientist to look at things in this way,but I know it's necessary for a lot of scientists.&quot;andP;  And a &quot;spin-off&quot; benefitis that it helps convey scientific principles to others: &quot;It's important interms of communicating some of the science to other people.&quot;andM;CR Categories and Subject Descriptors: I.3.5 [Computer Graphics]:Computational Geometry and Object Modeling--geometric algorithms, languages,and systems; J.3 [Computer Applications]: Life and Medical Sciences--MedicalInformation SystemsandM;General Terms: Algorithms, Design, PerformanceandM;Additional Key Words and Phrases:  Computed axial tomography, failureanalysis, magnetic resonance imaging, neurobiology, nondestructive testing,radiology, tomography, volume rendering, voxelsandM;Permission to copy without fee all or part of this material is grantedprovided that the copies are not made or distributed for direct commercialadvantage, the ACM copyright notice and the title of the publication and itsdate appear, and notice is given that copying is by permission of theAssociation for Computing Machinery.andP;  to copy otherwise, or to republish,requires a fee and/or specific permission.andO;</TEXT></DOC>