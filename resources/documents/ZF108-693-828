<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-693-828  </DOCNO><DOCID>08 693 828.andM;</DOCID><JOURNAL>AI Expert  August 1990 v5 n8 p56(9)* Full Text COPYRIGHT Miller Freeman Publications 1990.andM;</JOURNAL><TITLE>AI and the military: time for a standard. (includes relatedarticle on new Department of Defense standards)</TITLE><AUTHOR>Rock, Denny; Azarewicz, Jerome; Klobuchar, Rick; Oshin, Jennifer.andM;</AUTHOR><SUMMARY>Software standards have come about in the Department of Defense asa way to confront unsound developer practices, poor projectmanagement and documentation and other deficiencies, and it isjust a matter of time before these standards will be implementedin artificial intelligence (AI) components in defense systems.andO;The latest standard is DOD-STD-2167A.andP;  In AI work, highreliability and robustness must be assured, or the components willnot be trusted in mission-critical applications.andP;  The PlanRecognition Project at the Naval Air Development Center inWarminster, PA, and the Minefield Planner Expert System project ofthe Undersea Warfare Dept at the Naval Surface Warfare Center atWhite Oak, MD are both involved with AI projects.andM;</SUMMARY><DESCRIPT>Topic:     Artificial IntelligenceStandardsData SecurityProject ManagementMilitaryUnited States. Department of Defense.andM;</DESCRIPT><TEXT>Enforcing standards for AI projects will gradually increase customerconfidence in their systemsandM;Software development and documentation standards for the U.S.andP;  Dept.andP;  ofDefense (DOD-STD) have evolved over the last decade to confront poor projectmanagement and documentation, milestone schedule failures, and unsounddeveloper practices.andP;  The latest standard is DOD-STD-2167A,(1) a major 1988upgrade to DOD-STD-2167, the initial standard all service agencies haveagreed upon (see sidebar).andP;  Although the FAA and other agencies have theirown software standards, DOD ones predominate.andM;The federal government is currently granting few exceptions to the standardsfor conventional, non-AI software and few waivers to the use of Ada.andP;  As moreAI finds its way into DOD software contracts and the competition for thesecontracts increases, it's only a matter of time before these standardsdescend upon the development of AI components in defense systems.andM;Ongoing AI work in the DOD spans basic research-which some AI engineers thinkwould be restricted by the imposition of standards-through embeddedsystems.(2) Some AI work begins as research and later migrates to deploymentwith the standards either neglected or used in a variety of ways.andM;The AI work earmarked for deployment in larger, embedded systems must carryassurances of high reliability and robustness.andP;  The components will not betrusted by military operational personnel in mission-critical applicationsuntil AI can be trusted with a high level of confidence not to makecatastrophic errors.andP;  For these embedded systems, DOD-STD can be tailored toaccommodate the unique development issues of AI components.andM;This article contains case studies as examples of the various uses ofDOD-STD.andP;  Our experiences reflect these various viewpoints from threeaspects: government-employed engineers in AI laboratories, prime contractors,and independent verification and validation (IVandamp;V) agents.andM;We'll also suggest ways to address the requirements within DOD-STD whilesafeguarding traditional AI approaches to development.andP;  These  suggestionscould increase the role of AI in government projects without asking projectmanagers to compromise the security of their projects.andP;  Consequently, thisinformation can effectively promote the use of AI technology within thegovernment arena.andM;NAVY AI LABandM;The Plan Recognition Project (PLANREC) at the Naval Air Development Center(NADC) in Warminster, Pa., has been ongoing for more than five years.andP;  Theproject is sponsored by the Offices of Naval Research and Naval Technology,and independent research and development funded by NADC.andM;The first personnel hired for PLANREC had no AI experience.andP;  In the course offive years, this project progressed in DOD funding sources from a  6.1&quot;effort-basic research, high-risk/high-payoff-to a  6.3&quot; effort, meaningadvanced development.andP;  The system is presently being installed in the FleetCommand Center at Commander-in-Chief Pacific Fleet (CINCPACFLT), PearlHarbor, Hawaii, in support of the Fleet Command Center Battle ManagementProgram.andM;The problem is that fielding PLANREC at CINCPACFLT was not in the originalplans.andP;  PLANREC was originally conceived as a system to improve the responseof the crew of an E-2C, a Navy airborne early warning (AEW) platform, toincoming airborne threats.andP;  The goal was to improve the crew's ability toeffectively vector combat air patrols for intercepting airborne threats.andM;The responsibilities of the E-2C crew are multifaceted and thought to bereadily accomplished when the number of threats is none or small; however, inthe projected war of the future, the number of threats combined with dronesand feints is expected to overwhelm the E-2C's crew.andP;  Furthermore, the nextrelease of the Navy AEW platform will be able to track many more threatssimultaneously and threatens to overwhelm the human operator.andM;PLANREC was proposed as a plan-recognition system that could recognize andrank the threats in order of potential threat.andP;  The application of a similarplan-recognition system was initially considered for the cockpit of advancedcombat aircraft, the Combat Information Center of U.S.andP;  aircraft carriers,and other surface combatants.andP;  Thus, PLANREC was initiated as a system toassist  the decision maker in determining the intentions of the mostthreatening enemy aircraft and recommend a response to the E-2C crew.andM;Since the concept of a plan-recognition system at the time was relativelynew, the work was considered at the 6.1 level.andP;  PLANREC prototypes progressedfrom single-agent/single-hypotheses systems in an airborne threat contextthrough a multiple-agent/multiple-hypotheses in a subsurface (submarine)threat context.(3)andM;PLANREC's objective was concept feasibility and to push the state of the artof plan-recognition research.andP;  Since the prototypes were not intended to befielded in the CINCPACFLT, they functioned merely as proof of concept andweren't expected to be completely reliable.andP;  Furthermore, since the lifecycle of a prototype lasts from a few days to a year, maintaining theprototype system for any extended period of time was unnecessary.andM;In the summer of 1988, PLANREC was demonstrated to a group of CINCPACFLTpersonnel, and it was determined that various components of the PLANRECsystem were desirable for the testbed facility at CINCPACFLT.andP;  This decisionalso influenced the direction of the project from airborne only to includeantisubmarine warfare.andP;  Suddenly, it became imperative that PLANREC be adeployable system-the engineers had a lot of catching up to do.andM;Because PLANREC was not originally intended to integrate into CINCPACFLT, theuse of DOD-STD wasn't questioned or enforced.andP;  The substance of 2167A'ssoftware requirements specifications, software-design documents, softwaretest plans, and so on, were only addressed informally in team meetings, andmore formally in monthly status meetings with the division manager andsemiannual reports to sponsors.andM;While PLANREC was at NADC, issues such as reliability and maintainabilitywere rarely broached.andP;  At CINCPACFLT the demands increased to includefunctional descriptions, test plans, system verification and validation,users guides, NADC personnel to install and maintain the system, and so on.andM;Therefore, basic research had to be stopped to catch up with systemmodification and neglected documentation.andP;  Despite these measures, thePLANREC system as installed at CINCPACFLT still doesn't conform to 2167A.andM;The history of PLANREC and other AI systems that progressed from research tooperational deployment suggest that sometimes 2167A is more or lessapplicable.andP;  Although it explicitly states that the standard &quot;is not intendedto specify or discourage the use of any particular software-developmentmethod ...andP;  (for example, rapid prototyping),&quot; its existence is antitheticalto the whole notion of rapid prototyping.andP;  In retrospect, it seems thatfollowing the specifications in 2167/2167A during the early rapid-prototypingphases of PLANREC could have significantly impeded progress.andP;  It would havebenefited the project only if there had been more time and funding and if thetechnology had been more mature.andM;In a research and development environment, the documentation should emphasizewhy the project takes different directions, why one implementation strategywas chosen over another, and why one approach failed and another wassuccessful.andP;  The goal is maximum flexibility in resolving the research issuesof knowledge representation, inference engine validation, knowledgeconsistency, and so on.andM;On the other hand, the experience on current work to transit PLANREC toCINCPACFLT suggests that 2167A is most applicable when the softwaretechnology is more mature, must be reliable, the end product is to be used bysomeone other than the developer, and the system will have to be maintainedthroughout the life cycle.andM;TAILORING 2167 FOR MINEPLANandM;The Minefield Planner Expert System (MINEPLAN) is an intelligent tacticaldecision-aid project of the Undersea Warfare Dept.andP;  at the Naval SurfaceWarfare Center at White Oak, Md.andP;  (NSWC/WO).andP;  MINEPLAN commenced in May 1983with a concept briefing to the Navy's Mine Development Conference; prototypework began in Feb. 1986.andP;  Since that time, MINEPLAN has progressed throughconcept development, system design, knowledge engineering, rapid prototyping,documentation development, and preliminary implementation planning.andM;A series of five increasingly complex proof-of-concept demonstrations wereconducted.andP;  The minefield planning process modeled in MINEPLAN was derivedfrom various naval-warfare publications.andP;  The developers of MINEPLAN realizedthat these publications were a valuable repository of documented expert-levelknowledge that could be readily implemented into an expert system.andM;NSWC/WO is currently in transition planning to the operational environment atthe Navy's Mine Warfare Command in Charleston, S.C.andP;  The transition effortwill include full-scale development of the final MINEPLAN capabilities.andM;An important part of the original MINEPLAN concept was to invoke DOD-STD-2167procedures.andP;  At the time, employing DOD-STD in a rapid prototypingenvironment was a novel idea-configuration management of decision rules,inference engines,  and  objects  (with  embedded attributes, methods, andinheritances) was unheard of.andP;  The engineers were aware from the beginningthat the various DIDs in 2167 would have to be tailored to accommodate thehybrid, object-oriented, rule-based approach.andM;Minefield planning is a time-consuming and iterative process.andP;  The task isdata- and knowledge-intensive, requiring consideration of mine actuation anddamage data, enemy target factors, potential mine countermeasures, aircraftdelivery factors, and so on.andP;  A large search space of candidate &quot;solutions&quot;exists that requires analysis of factors such as placement of the minefield,number and type of mines, settings (sensitivities, ship counts, and delayarms), logistics and deliverability factors, sensor coupling to theenvironment, and integration of mine warfare into the total operation.andO;Minefield planning is performed by a small staff of dedicated planners atCOMINEWARCOM composed of highly trained naval officers with fleet operationalexperience.andP;  They run various minefield planning math models and interpretthe results in the context of larger naval operations.andP;  Expert-level judgmentis required both in entering the data and assessing the results.andO;Unfortunately, minefield  planners rotate often with the impact that muchminefield planning knowledge is perishable and must be relearned by the nextgeneration of planners.andM;The MINEPLAN development effort started as a 6.2 exploratory initiative withthe goal of evaluating the potential application of AI technology to theminefield planning process.andP;  That process was subject to interpretation byindividual planners; among minefield planning experts, a difference ofopinion frequently exists as to the most effective plan.andP;  MINEPLAN has beenhighly useful in helping to baseline the planning process.andM;The allocation of resources for MINEPLAN was planned in advance of rapidprototyping.andP;  The first year under contract was spent developing a projectedsoftware-development plan (SDP), operational-concept document (OCD), andinitial system specification (SS) according to DOD-STD-2167 guidelines.andP;  Thisstudy period was highly valuable in fleshing out the MINEPLAN concept andcharting a direction for prototyping, testing, and transition.andM;The SDP identified the computer software configuration items  (CSCI)-thecomputer program to be developed in the demonstration phase.andP;  Each CSCI wasanalyzed relative to its schedule for completion, complexity, and integrationrequirements with the MINEPLAN system executive.andP;  For each CSCI, resourcerequirements were estimated in the SDP.andP;  These estimates were listed by laborcategory, travel, hardware and software requirements, and other directcharges.andP;  NSWC used the estimates of resource requirements, resourceallocation, and schedule of CSCI demonstrations as the basis for issuance ofindividual task orders.andP;  Estimates of labor were particularly importantduring the prototyping because the original contract was a time-and-materialscontract.andM;The tailored 2167 development and testing approach called for a series ofincreasingly sophisticated, proof-of-concept demonstrations in the secondyear.andP;  Each demonstration involved a different CSCI.andP;  This approach mitigatedrisk, because NSWC was able to chart progress in a structured and modularway.andP;  Every demonstration occurred within 10 days of its scheduled time.andM;Since May 1983, the MINEPLAN work has taught valuable lessons about workingwith the DOD-STD:andM;* DOD-STD-2167/2167A ignores software-configuration management of objects andrules in expert systems.andM;* DOD-STD-2167/2167A provides little guidance relative to development ofobject-oriented and rule-based expert systems.andP;  It is exceptionally difficultto describe, document, and baseline such characteristics using a hybrid-toolapproach because the objects embed functionality, several thousand objectsmay need to be represented, rules contain tactics, and objects communicatewith each other in a message-passing sense.andM;* DOD-STD-2167/2167A can be applied to expert-system development projects;however, it should be tailored and flexible in interpretation.andM;* DOD-STD-2167A needs to be updated to consider formal methods of IVandamp;V andtesting of expert systems.andP;  A collection of rules that looks &quot;good&quot; in astatic sense may not work in a dynamic environment.andP;  Currently, no formalmethodology proves that a rulebased expert system can process data in realtime if the rules are permitted to alter the data in a chaining sense.andM;* DOD-STD-XXXX, a future 2167A revision, should include discussion of thetransition from a rapid prototyping environment to a development/deliveryone.andM;CONTRACTING AI WORKandM;DOD standards are intended to provide guidelines for the government inprocuring a quality software product that is both reliable and maintainableby someone other than the developing contractor.andP;  When writing AI contractspecifications, the contracting agency is responsible for defining the issuesand acceptable approach in the request for proposal (RFP).andP;  This documentmust stipulate the expectations of the DOD-STD.andM;As an example, the 1986 Statement of Work for the Joint InteroperabilityEvaluation System project included the demand for adherence to DOD-STD butcontinually referred to &quot;expert system techniques&quot; and not merely expertsystems.andP;  This seemingly innocent error lead to confusion in projectrequirements.andM;One tactic is to delimit in the RFP the environment for the AI work; therange of potential AI tools and platforms could be specified.andP;  Any memoryallocation or processing requirements should be acknowledged.andP;  In some cases,the RFP may insist on the use of commercial off-the-shelf tools.andP;  A goal isto avoid the scenario of a contractor using valuable time and resources toreinvent some new AI toolset or to go on a &quot;fishing trip&quot; within thetechnology (their engineers learn AI technology for the first time).andP;  Inother cases, the scope of consulting-type requirements or knowledgeengineering, which is far less product-oriented and less quantifiable, can bebounded.andM;Another approach is to mete out the work.andP;  The initial work is a veryshort-term feasibility study that would suggest the necessary follow-on work,as is the case with small business initiative research (SBIR) contracts.andO;Once the contract has been awarded, task orders are placed against thecontract and requirements for detailed documentation are written as strictlyor as loosely as necessary.andP;  The following case is an example of such anapproach.andM;CUTTING THROUGH RED TAPEandM;In Sept. 1988, Carnegie Group Inc. won, through the competitive biddingprocess, an AI technical support contract with the Human EngineeringLaboratory (HEL) of the U.S.andP;  Army's Laboratory Command.andP;  The contract is atask-order agreement providing for technology transfer and applicationdevelopment in areas such as logistics planning and diagnostics/maintenance,and lets HEL issue task orders to Carnegie for specific projects within thescope of the contract.andM;Task-order contracts of this kind are beneficial to the government becausethey let federal agencies comply with the policy of competitive bids for alloutside-company work while reducing the time required to process specifictask assignments.andP;  Within the specified contract timeframe, the contracteecan be awarded task-order assignments without having to go through thecompetitive bid process for each job.andP;  This approach saves time and money forboth the government and the companies involved.andM;The contract Carnegie won called for proposals to be submitted by companieswith a knowledge of, and proven experience in, applying AI to areas includingdesign, configuration, diagnostics, user-interface development, scheduling,and logistics.andP;  By winning the contract, Carnegie was given the opportunityto work on a number of task orders calling for the development of AI systems.andM;One of the areas the Army had in mind for the application of AI techniqueswas diagnostics and maintenance of military equipment.andP;  Diagnostics andmaintenance are among the biggest problems facing the Army today.andP;  Similar tothe diagnostics problems encountered by the commercial automotive industry,the Army faces the difficult task of troubleshooting complex electronicsystems that require voluminous technical manuals for reference.andP;  Too manymanuals with thousands of pages of documentation intended to help Armyrepairmen diagnose, service, and repair equipment are available.andM;The tactical logistics team for HEL at the Aberdeen Proving Ground, Md.,andO;identified an existing diagnostics/maintenance problem within the Army thatmet the following conditions for an AI solution: the problem was large enoughto be worthwhile yet small enough to be decomposed and solved at a subsystemlevel.andP;  The subject matter experts were available to act as domain expertsand the group currently in charge of the diagnostics and maintenance of theequipment was willing to work with an outside company and HEL.andM;Working with the Army Ordnance Missile and Munitions School (OMMCS) inHuntsville, Ala., the Hawk missile was selected for an AI application.andP;  TheHawk missile, which consists of two radars, a platoon command post, and oneor more launcher units, has had challenging maintenance problems for years.andO;The annual turnover rate for the technicians trained to service the missileis often 50% or more.andP;  Furthermore, HAWK repair is extremely complex andspecialized; for example, a soldier trained to repair and maintain a launcherwouldn't have the knowledge, training, or ability to fix problems with theradar.andP;  The fact that the technicians currently responsible for missilediagnoses and repairs, the combat developer, and the senior NCOs at OMMCSwere willing to work with Carnegie and HEL, made this test-case an idealscenario for applying commercial AI diagnostics techniques to the Armyenvironment.andM;The Army issued a task order for an expert diagnostics system prototypedevelopment.andP;  The task order stated: &quot;Troubleshooting, fault isolation, andrepair tasks for weapon systems are becoming increasingly difficult becauseof the complexity of modern systems.andP;  The use of emerging technologies, suchas AI, offer the potential to offset the increasing demands for expertise andtraining.andP;  This task will leverage the considerable in-house research anddevelopment accomplished by Carnegie Group on the Troubleshooting ExpertSystem Tool (TEST) by exploring its adaptation to an Army application.&quot;andM;Under this task order,  Carnegie prototyped a system called High Power RadarIntelligent Diagnostic Environment (HIPRIDE).andP;  HIPRIDE is designed to helpsoldiers troubleshoot transmitter noise problems on the high-powerilluminator radar of the HAWK missile system.andP;  The system was developed fromMarch-June 1989 and was extremely well received by the Army.andP;  In fact, a newtask order will expand the HIPRIDE system to include remaining transmitterproblems and other diagnostics problem areas of the radar.andM;About the same time, the Army had built a diagnostic application called PulseAcquisition Radar Intelligent Diagnostic Environment (PRIDE) using ageneral-purpose expert-system shell.andP;  PRIDE was intended to assist soldiersin maintaining, diagnosing and repairing the Pulse Acquisition Radar of theHawk missile.andP;  The staff at OMMCS, after experiencing the HIPRIDE system,decided to convert the PRIDE system to a full scale TEST-based solution.andP;  Anew task order was written under the support contract and the project wasfunded through the DOD Productivity Enhancing Capital Investment program.andM;Both the Army and Carnegie have recognized the task-order contract procedureas being extremely efficient and beneficial.andP;  The Army has easy access tohighly sophisticated and successful AI technology, while the company has anavenue for proving its worth and expertise throughout all areas of the Armyand U.S.andP;  government.andM;GOVERNMENT EXPECTATIONSandM;Many companies and engineers don't have a long track record of AI work andeven fewer have undertaken AI projects under DOD-STD requirements.andO;Therefore, a tactic the government can use during the initial contractingperiod is to clearly demarcate government expectations of the personnel on anAI project.andP;  While this demarcation doesn't guarantee that DOD-STD will besatisfied in an AI project, it helps ensure that the contractor understandsDOD-STD issues.andP;  Bringing a knowledgeable AI person up to speed with DODSTDis easier than teaching a person knowledgeable in DOD-STD what AI is allabout.andM;Government AI personnel tend to be electrical engineers and computerscientists who have learned AI by doing; enticing experienced AI people awayfrom the lure of private industry can be difficult.andP;  It is also difficult toget college graduates to work in government AI labs because of thesubstantial differential in starting salaries.andP;  Furthermore, once theexpertise is developed, these homegrown AI engineers often leave forindustry.andP;  Less frequently, the government personnel are purely domainexperts who basically know what they want in an expert system but notnecessarily how to build it.andP;  Rarely are the government personnel both domainand AI experts.andM;In any government contract with industry, personnel qualifications are likelyto be explicity spelled out in the RFP and are used when evaluatingproposals.andP;  However, this fact is rarely true for AI work and personnel.andO;Until official guidelines exist, we suggest the following classifications:andM;* AI research engineer: responsible for providing AI consulting to verydifficult, potentially previously unsolved problems.andP;  This position wouldrequire a demonstrated ability to conduct basic and applied research in thefield of AI; duties would include reviewing AI techniques and methodologies.andO;Preferred education would be a Ph.D.andP;  in engineering, mathematics, orcomputer science with an emphasis in AI and about eight years of professionalexperience in AI an simulation-based modelingandM;* Senior AI engineer: responsible for knowledge engineering, preliminary anddetailed design, implementation, evaluation of prototypes, andsoftware-integration issues.andP;  Duties would include requirements analysis,configuration management, and quality assurance.andP;  Preferred education wouldbe a M.S.andP;  in the sciences and about six years of AI experience.andM;* AI engineer: responsible for coding and implementing AI components, unittesting, and document reviews.andP;  This engineer should have a working knowledgeof AI languages and experience with some commercial AI tools.andP;  Preferrededucation would be a B.S.andP;  in the sciences and about three years of AIexperience.andM;* Junior AI engineer: responsibilities similar to those of the AI engineerbut narrower in scope and with more supervision.andP;  This person should beinterested in AI and possibly have had some AI course work.andM;ENTER THE IVandamp;V AGENTandM;IVandamp;V is intended to provide early detection of errors in software developmentand alleviate the high costs of software failures later in the developmentand operational phases.andP;  IVandamp;V is supplied by a different organization thanthe prime contractor's quality assurance team; the IVandamp;V agent is also acontractor.andM;Those engaged in IVandamp;V have the obligation to continually project ahead,predicting product quality and assessing quality factors-difficult demandsfor even conventional software.andP;  The IVandamp;V agent should assist the governmentin reviewing the deliveries and tracing the requirements through completion.andO;The agent should also monitor the project health with metrics and tools-theymust know AI technology and the project domain at least as well as the primedeveloper.andM;If the developer has not already raised the warning flag on applying 2167A tothe AI project, the IVandamp;V agent should do so during the planning stages of aproject.andP;  In cases where the government has attached a requirement for an AIcomponent to a larger software contract, the prime contractor may not beready to answer the bell for the AI work; some defense contractors do nothave AI labs or even AI engineers on the payroll.andP;  The defense contractorsthat do have AI engineers may not make them accessible to the project at handbecause of security or other reasons.andP;  The IVandamp;V agent is then in thedifficult position of struggling with the prime contractor.andM;The IVandamp;V agent can be called upon to assist the government in assessing theAI technology and evaluate the prime contractor's responses.andP;  The agent candeliver a series reports that set the tone for the government's reasonableexpectations.andM;IVandamp;V agents can be crucial in seeing that the DOD AI work is performed in aDOD-STD manner and they should help the government make that determination.andO;The irony is that with the current DOD budget cuts, the IVandamp;V agents are oftenamong the first to be axed from the project, leaving the government projectpersonnel at the mercy of the developers-particularly with a morecomplicated, and yet slowly maturing, technology.andM;TAILORING DOD-STD FOR AIandM;For large-scale projects involving AI components, DOD-STD can be applied,despite the unique AI life-cycle demands and integration issues.andP;  A set ofadditional deliverables should be supplemented to the 2167A requirements.andP;  Ata minimum, the following AI items should be weaved into the 2167A process:andM;* Knowledge acquisition report: identifies the undocumented information,implementation quirks, service-agency trouble report items, complexity amongdata items, and so onandM;* Alternative knowledge-representations report: identifies the advantages anddisadvantages of candidate representation schemes, applicability of availabledevelopment tools, maintainability, and so onandM;* Prototype evaluation report: describes the results in tool certification,verification of the knowledge bases at multiple levels, and so on.andP;  Developsthe prototype so that it results in testable requirementsandM;* System integration report: identifies problems in moving towards a fullcapability system that meets user requirements and expectations.andM;MEETING THE STANDARDandM;Deployable DOD AI systems must be placed under DOD-STD standards.andP;  In areaswhere AI research is performed, a gradual introduction of developmentstandards should be made.andP;  If researchers are permitted to document none oftheir work, the process of migrating it from the laboratory to the fieldbecomes very slow and clumsy.andP;  If something should happen to the principalinvestigators, all research knowledge would be lost; providing freedom ofdevelopment while stimulating the collection and organization of gainedknowledge would be an advantage.andP;  Therefore, by allowing the gradual orfunneled application of stricter standards, the end goal of deployabilitywill be eased.andP;  This technique has been called the &quot;development funnel&quot;approach to DOD-STD application.(4)andM;Advanced AI applications pose unique problems for DOD-STD implementation.andO;Some of these problems may be eased by development of IVandamp;V tools that addressAI applications.andP;  Investigation is beginning for the creation of tools toperform dynamic analysis and environment definition examination for AIprojects.andM;On the other hand, some AI systems are being developed within DOD projectsthat are not advanced AI systems; little or no cognitive modeling may beinvolved.andP;  For these projects, commercial off-the-shelf expert system toolsshould be used.andP;  In such cases, there should be little argument againstplacing the project directly under DOD-STD.andM;A recent twist on implementing DODSTD is the resurgence of governmentinterest in neural-network technology.andP;  This fact only raises a list ofhaunting questions for DOD-STD: How can the scope of the training set bespecified? How can the required pattern-matching abilities be specified? Howcan adaptively changing neural nets learn only what is intended? How can IVandamp;Vbe performed on neural nets?andM;Only by proving that AI components can be developed under such standards willDOD customers gradually acquire confidence in these systems.andP;  While DOD-STDis a paper standard, much experience from non-AI system development exists inenforcing its tenets.andP;  The notion that AI is somehow immune to suchsoftware-review processes may not last very long with the government.andO;REFERENCESandM;1.andP;  DOD-STD-2167A, Military Standard, Defense System Software Development,Dept.andP;  of Defense, Washington, D.C.andP;  20301, February 1988.andM;2.andP;  Smith, B., and K. Morris.andP;  &quot;Verification and Validation of ExpertSystems.&quot; AIAA Computers in Aerospace Conference, 1989.andM;3.andP;  Azarewicz, J., G. Falla, C. Heithecker.andP;  &quot;Templatebased Multi-agent PlanRecognition for Tactical Situation Assessment.&quot; Proceedings of the 5th AnnualConference on AI Applications.andP;  New York, N.Y.: IEEE Press, 1989.andM;4.andP;  Rossomando, P.andP;  DOD-STD-2167A and a Development Environment for theProgressive Enforcement of the Standards when applied to Knowledge BasedSystem Development.&quot; General Electric Technical Report, King of Prussia, Pa.,andO;1990.andM;Denny Rock is a senior AI engineer with Intermetrice, Warminster, Pa., andwas the IVandamp;V agent for the expert-system component of the JIES project forthe Defense Communications Agency.andM;Jerome Azarewicz is a government-employed AI engineer at the Naval AirDevelopment Center's AI Lab, Warminster, Pa., and works on the PLANRECproject.andM;Rick Klobuchar is an AI research engineer with Advanced Technology inc.,andO;Virginia Beach, Va., who has worked on the Navy's MINEPLAN project.andM;Jennifer Oshin works in the marketing communications department of CarnegieGroup Inc., Pittsburgh, Pa., and frequently reports on the progress ofCarnegie projects in the Army.andO;</TEXT></DOC>