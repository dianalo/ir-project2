<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-583-917  </DOCNO><DOCID>07 583 917.andM;</DOCID><JOURNAL>UNIX Review  May 1989 v7 n5 p40(7)* Full Text COPYRIGHT Review Publications Co. 1989.andM;</JOURNAL><TITLE>Humanly inspired. (computer capabilities in pattern recognition)</TITLE><AUTHOR>Caudill, Maureen.andM;</AUTHOR><SUMMARY>A neural network is a new kind of computing system that isinspired by, but does not actually mimic, a human brain.andP;  It showsgreat potential for pattern recognition, control system, signalprocessing, and expert system applications.andP;  A neural network isdifferent from a digital computer on three counts: first, it hasno central processing system but is instead constructed withneurodes, small processing elements that are highlyinterconnected; two, it has no separate memory for data storage;and three, the neurodes respond to a particular pattern of inputsignals by generating an output signal appropriate to the totalsimulation received.andP;  The elements involved in building a neuralnetwork application and a network in hardware are also described.andO;The development of a sonar signal classifier by Terry Sejnowskiand Paul Gorman is also discussed.andM;</SUMMARY><DESCRIPT>Topic:     Neural NetworksPattern RecognitionNew TechniqueDigital ComputersBrainComparisonFuture of Computing.andO;Feature:   illustrationgraph.andO;Caption:   A typical neural network architecture. (graph)andM;</DESCRIPT><TEXT>HUMANLY INSPIREDandM;Suppose you wanted to have a computer terminal that could, via some kind ofvideo camera system, recognize you by sight and that would respond to yourvoice to accept commands and input data.andP;  How would you go about making, say,a VAX terminal achieve such capabilities?andP;  In the future, the answer may verywell be by using a relatively new kind of computing system called a neuralnetwork.andP;  Such systems, based in part on our understanding of the structureof the human brain, may one day be used routinely as co-processing systemswith ordinary digital computers, giving the latter capabilities in patternrecognition that today require highly specialized equipment.andM;Imagine we actually try to build the &quot;programmer recognizer&quot; described above.andO;We can easily get the computer to accept video input of a programmer sittingin front of a camera.andP;  Similarly, we can have it generate the sounds thatcompose &quot;Hello, Bill&quot; in response to receiving this particular video image.andM;The problem is that when Bill comes to the computer room tomorrow, the videoimage he will present to the computer will not be identical to the image thecomputer receives today.andP;  He may stand in a slightly different place, oradopt a slightly different posture.andP;  Maybe he will not have shaved, orperhaps he will have shaved off the beard or mustache he has today.andP;  He maysport a new haircut or be wearing contact lenses instead of glasses.andP;  He mayhave been in a fight and be suffering from a black eye.andP;  Or perhaps his firstcousin, John, who resembles him very closely, will come in.andP;  The potentialvariations in Bill's appearance are endless.andP;  Our programmer-recognitionprogram will have enormous difficulties in properly identifying and copingwith the possibilities.andM;Why is this a particularly difficult problem for a computer to solve?andP;  Onereason is that the problem is not a purely computational one, nor analgorithmic one; it is primarily a pattern-recognition problem.andP;  Patternrecognition is something people do with incredible ease, but computers tendto have incredible difficulties with it.andP;  Of course, face recognition is butone example of the pattern- recognition problems that need to be solved.andO;Obvious applications for pattern-recognition capabilities include imagetechnology, speech recognition and generation, and robotic control systems.andO;Hundreds of less esoteric applications, including general signalinterpretation of everything from medical instruments to high-performanceradar, expert systems, computer-aided training systems, support systems forhandicapped people, and banking and financial decision systems, would benefitfrom pattern-recognition capabilities, too.andM;Today's digital computers are sometimes called &quot;von Neumann machines&quot; becausethey are based on an architecture designed by John von Neumann shortly afterWorld War II.andM;The essentials of this design are:andM;* a central processing unit that performs the actual computations;andM;* a separate, addressed memory that stores both data and the set ofinstructions for the computations;andM;* a synchronized, fetch-execute-store operation, in which an instruction isretrieved from memory (along with any necessary data), the central processingunit executes the instruction, and the result, if any, is replaced in thespecified memory location.andM;A digital computer performs its actions on numbers that have been convertedto a digital scale, of course.andP;  This means that the numbers used can haveonly discrete values; they are not truly-continuous-valued entries.andP;  The sizeof the discrete steps may be very small in practice (a 64-bit real number isextremely precise!), but the step sizes are there, in fact, and the computerdoes not really handle continuous, analog values.andP;  The von Neumann design hasserved us well for forty years now; however, there are some things it simplydoes not do very well.andM;The Design of a Neural Network.andP;  Neural networks may eventually offer abetter way of giving computers pattern-recognition capabilities than doalgorithmic approaches.andP;  These new systems violate every one of the vonNeumann design principles listed above.andP;  First, a neural network has nocentral processing system; it is instead constructed of a collection of manysmall processing elements, or neurodes, that are highly interconnected (seeFigure 1).andP;  Each neurode receives many input signals that are passed alongthese interconnections, but generates only a single output signal at a time.andO;This output signal (an analog signal, rather than a digital number) istransmitted along the neurode's output interconnect, which branchesrepeatedly.andP;  The signal is thus received by a large number of other neurodes;however, all the receiving neurodes see the same incoming signal.andM;Second, a neural network has no separate memory for storing data andinstructions.andP;  Instead, a neural network's memory consists of theinterconnections between the neurodes, the states of the neurodes (that is,the strength of their current output, or activity), and the collection ofstrengths of the interconnections, called weights (also analog values).andO;Finally, a neural network does not compute by the fetch-execute-store cycleat all.andP;  Instead, the network's neurodes literally respond to a particularpattern of input signals by generating an output signal appropriate to thetotal stimulation received from the input signal pattern.andP;  There is nooverall, guiding program for the network as a whole--only a functionalmapping between the total input each neurode sees and its correspondingoutput.andP;  Rather than functioning as a digital, serial system that computes analgorithm, a neural network is a parallel, analog data processing system thatdoes not so much compute as it reacts to input patterns.andM;A neural network would not be of much use if the connections linking hundredsor thousands of neurodes together had to be predetermined exactly, or theinterconnection strengths had to be predefined.andP;  What makes a neural networkunique is precisely that these things don't need to be done.andP;  Instead, weliterally train the network to do what we want it to do, much as we wouldtrain a puppy to fetch a stick.andP;  We begin with a rather generic architecture,then modify it through a training regimen until the network behaves as wewant it to.andM;In essence, a neural network learns by example; that is, it modifies theweights of the interconnections between neurodes, taking the example inputsavailable during training as a guide.andP;  The weights do not need to be presetto any specific value; in fact, they are generally initialized at small,random values.andM;It should be clear from this that neural networks have many of thecharacteristics of the human brain.andP;  Before we get too carried away, though,it is important to note that there are a number of important braincharacteristics that no network implementation has yet emulated.andP;  Among theseare:andM;* the extraordinary degree of interconnectivity of brain cells;andM;* the highly modifiable quality of the physical interconnections betweencells (such that new connections grow and old ones disappear throughoutlife);andM;* the electrochemical (rather than purely electrical) nature of the signalsand interconnects between brain cells;andM;* the frequency pulse-based signal strengths used in the brain.andM;No artificial neural network has yet achieved all these traits, and it is notexpected that any will in the near future.andP;  Neural networks should thereforebe thought of as engineering systems that are inspired by the architecture ofthe brain, not as systems that actually mimic it.andM;Even with this caveat, neural networks have shown extraordinary promise inpattern-recognition, control-system, signal-processing, and expert-systemapplications, to name just a few.andP;  But since their modes of development andoperation are so different from a digital computer's, it is important tounderstand exactly how they can be built and used.andP;  How can a neural networkbe designed, for example, to visually inspect a bottle of shampoo coming downa factory production line?andP;  Or to offer an opinion on the credit-worthinessof a mortgage applicant?andP;  Or to remove from a fetal heart monitor theinterference coming from the mother's heartbeat?andP;  All of these applicationshave been accomplished with the use of neural networks.andM;Building a Neural Network Application.andP;  Developing a neural networkapplication is quite a different task from writing a computer program.andP;  Firstthe nature of the inputs to the network and the desired output are specified.andO;Next, the kind of network that will be used to solve the problem must bedetermined.andP;  There are many network designs, or paradigms, and the one mostappropriate for the problem at hand must be selected.andP;  In this case, let'sassume we are going to use the most popular network design, a backpropagationnetwork.andM;Next, it must be determined whether or not the network needs to have theinput data preprocessed in any way.andP;  Appropriate examples of input data(along with the correct network output, since this is a backpropagationnetwork) are selected to compose a training set.andP;  These examples will be usedin the network's learning-by-example training.andP;  Also, some way to judge theefficacy of the training will be needed, so it is necessary to select aseparate set of examples to be used as a test set.andP;  The test examples can bepresented to the network to find out whether it can properly respond to themafter it is trained.andP;  Finally, any necessary postprocessing of the network'sresponses must be defined.andM;Backpropagation networks use a training regimen called supervised learning inwhich an input pattern is fed into the network along with the appropriateoutput pattern for that input.andP;  Network interconnection weights are modifiedby the neurodes on the basis of differences between the network's actualoutput and the desired output.andP;  This process is repeated until the networkcorrectly interprets the input patterns used for training.andP;  Thus, thetraining procedure is an iterative one, requiring many presentations of eachtraining pattern before the learning is complete.andM;Not all neural networks use supervised learning procedures.andP;  There are, infact, two other general kinds of learning regimens, graded learning andunsupervised learning.andP;  Graded learning is very similar to supervisedlearning, except that the network is not provided with the exact answer foreach input pattern.andP;  Instead, it receives graded feedback on its response toeach input pattern, such as &quot;too high&quot; or &quot;too low&quot;.andP;  For many inputpatterns, it is easier for researchers to provide this kind of feedback thanto specify exact appropriate output patterns.andP;  Unsupervised learning, oftencalled self-organization, occurs when the network receives no feedback atall, organizing itself according to the input data alone.andP;  Choosing thelearning procedures appropriate for a given problem is a skill the networkdesigner must master.andM;Building a Network in Hardware.andP;  Neural networks obviously introduce atechnology that is significantly different from the technology upon whichexisting computer systems are based.andP;  How do neural networks compare to othertechniques in handling pattern categorization and recognition tasks?andP;  How dothey stack up against tried-and-true digital computers?andM;The first thing to realize is that no really fair comparison of the twosystems can be made today.andP;  Currently, no commercial neural network hardwareis available.andP;  While many companies and groups are working hard to developparallel, analog hardware implementations of neural networks, none haveemerged from the laboratories as yet.andP;  Networks must be built with softwaresimulators and, optionally, hardware emulators.andM;A software simulator is a program that runs on an ordinarycomputer--typically a PC, Macintosh, Sun workstation, or VAX.andP;  (Simulatorsare available for other machines as well, but the most popular ones have beendesigned to run on one or more of the above-mentioned machines.)andP;  Thesecomputer programs simulate serially the operation of an inherently parallelneural network.andP;  Obviously, these will run much slower than an actual neuralnetwork would run.andP;  The differential equations that the neurodes in a neuralnetwork would obey are simulated as lock-stepped difference equations, sothat the asynchrony of a real neural network is lost, along with theinfinitesimal step-size of the true differential equation.andP;  Finally, theanalog nature of the network is completely lost in digital simulations.andM;In spite of all these drawbacks, however, a good software simulator canconstitute an effective, easy-to-use method of proving that a neural networkcould readily solve a particular problem.andP;  Simulators make very efficientproof-of-principle demonstrations, and can often allow designers to solvescaled-down versions of a problem in a matter of hours (or even less!).andM;A hardware emulator is a co-processor board or box that works in conjunctionwith a digital computer.andP;  The most popular of these &quot;accelerator&quot; boards pluginto an IBM PC AT (or compatible).andP;  A co-processor box has been developed(but is not currently marketed) for the VAX, and there is at least one verylimited plug-in board for the Macintosh II.andP;  Such boards typically consist ofa large amount of memory (12 MB in the most popular model), and separate,often specialized processors.andP;  Their primary purpose is simply to make thesoftware simulations run faster.andP;  They offer no real parallelism, and arestill digital rather than analog.andP;  (The VAX emulator box does offer multipleco-processors, but in most cases they are not utilized in a manner that wouldallow truly parallel operation of the network neurodes.andP;  And of course, theirimplementation is still digital.)andM;Nonetheless, hardware emulators have demonstrated some impressive speedenhancements; one board can easily yield 35 to 100 times the speed attainableusing a software-only simulator running on a high-speed PC with a mathco-processor.andP;  The speed of these hardware emulators is sufficient for manyreal applications today.andM;In comparing the effectiveness of a neural-network solution to that of adigital computer for any particular problem, it must be remembered that, forthe present, neural networks can only be simulated.andP;  In spite of this,however, neural network simulations have already shown some impressiveachievements when compared to traditional systems.andP;  Let's look at a specificexample.andM;Sejnowski's Sonar Classifier.andP;  Terry Sejnowski, now at the Salk Institute inSan Diego, is currently one of the most creative implementors of neuralnetworks in applications.andP;  His successes in using backpropagation networks tosolve practical problems have inspired many other researchers to investigatethe field of neural networks.andP;  One of his most innovative efforts is a sonarsignal classifier, which he developed in conjunction with Paul Gorman of theAllied-Signal Aerospace Technology Center.andM;In this experiment, the problem was to distinguish the sonar echoes returnedby a large metal cylinder from those returned by a rock of similar shape.andO;Three different approaches were tested.andP;  First, human subjects were trainedto discriminate between the two sonar signals using a particular set of 100examples.andP;  For each example, the subjects were merely asked to indicatewhether the echo was coming back from a rock or a cylinder.andP;  During thistraining period, they were immediately told whether their response wascorrect or incorrect.andP;  (This, of course, is the model for the immediatefeedback presented to a backpropagation network during supervised learning.)andO;After training, and depending on the individual, the subjects were between 88percent and 97 percent accurate in their responses to the training set.andP;  Whentested on new examples (the test set), the humans had significantly lowerscores, typically in the range of 82 to 88 percent.andM;Next, Sejnowski and Gorman used knowledge extraction and additionalperceptual testing techniques to try to identify the cues that their subjectsused in making decisions.andP;  Their goal was to identify and articulate thesignal features people used to distinguish between the rock and the cylinder.andO;These features were then used to build a digital signal-processing systemcapable of making the discrimination.andP;  This effort took a number of months tocomplete and, once finished, was slightly less effective than the worst humansubject, registering accurate responses 82 to 85 percent of the time.andM;Finally, Sejnowski and Gorman built a collection of backpropagation networksof differing sizes and complexity using the set of training examples they hadused with their human subjects.andP;  The network took, typically, about 300passes through the training set to learn the examples and, when done, themultilayer networks had an accuracy rating of 96 to 100 percent.andP;  Undernormal circumstances, this training should take a few hours at most,depending on the hardware and software being used.andP;  When tested with newexamples, the multilayer networks' accuracy ranged from 86 to 90 percent.andP;  Infact, one network of only moderate size gave somewhat better performance onboth the testing and training examples than did any human subject.andM;The work done by Sejnowski and Gorman offers a unique perspective on theadvantages of neural networks as compared with more traditional computingapproaches.andP;  Given appropriate problems, neural networks can perform as wellor better than an expert human; applied to inappropriate problems, theirlevel of performance can be abysmal.andP;  A well-designed neural network systemis capable of performance at ideal levels, and can actually perform betterthan many traditional classification techniques.andM;In addition to comparable performance, however, Sejnowski's networks provedto be significantly less expensive than other classifiers in terms of theamount of memory storage and computation needed.andP;  Furthermore, the networksrequired no prior knowledge of the statistical characteristics of the databeing classified, unlike other techniques.andP;  Finally, the time needed todevelop the neural network solution can often be significantly shorter andless expensive than that needed under many traditional techniques.andM;It is this combination of characteristics, in fact, that makes neuralnetworks so attractive.andP;  It is not just that they can do things that aredifficult to do well on a digital computer.andP;  In addition, they promise to beable to do them easily, cheaply, and without demanding complex statisticalanalyses of the input data patterns.andM;Where will neural networks take us in the future?andP;  Many believe they willchange our way of life the way the transistor and the digital computer havealready done.andP;  Whether neural-network technology lives up to suchexpectations is, of course, another issue.andP;  If true neural-network hardwarecapabilities can be developed--and that is not a certain prospect--and if ourhopes for their general capabilities prove realistic, in the long run neuralnetworks will make the world into a very different place.andM;Neural network systems are by no means a &quot;sure thing&quot;, but they present anopportunity for humans to solve problems that are not easy to solve using ourcurrent digital computers.andP;  One thing we do know is that systems based onneural design principles can do some incredibly complex things, because we dohave at least one working example--the brain itself.andO;</TEXT></DOC>