<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-523-360  </DOCNO><DOCID>08 523 360.andM;</DOCID><JOURNAL>Communications of the ACM  June 1990 v33 n6 p636(13)* Full Text COPYRIGHT Association for Computing Machinery 1990.andM;</JOURNAL><TITLE>Evaluation of safety-critical software. (software controllers inmedical and industrial applications) (technical)</TITLE><AUTHOR>Parnas, David L.; van Schouwen, A. John; Shu Po Kwan.andM;</AUTHOR><SUMMARY>A technical and statistical discussion of methods for validatingthe reliability of software in safety-critical applications ispresented.andP;  Few real-time systems function adequately when firstimplemented in real-world use, but software is replacing hardwaredespite its untrustworthiness because it makes it possible tobuild more logic and flexibility into systems.andO;Software-implemented controllers can be modeled in the same way asm hardware controllers but are more complex, error sensitive, andhard to test.andP;  Rigorous standards should be applied when softwareis part of a safety-critical device.andP;  Ensuring softwarereliability requires tight discipline in design, documentation,testing and review.andM;</SUMMARY><DESCRIPT>Topic:     SafetySoftware QualitySoftware ValidationTestingTechnology.andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>Methods and approaches for testing the reliability and trustworthiness ofsoftware remain among the most controversial issues facing this age of hightechnology.andP;  The authors present some of the crucial questions faced bysoftware programmers and eventual users.andM;It is increasingly common to use programmable computers in applications wheretheir failure could be life-threatening and could result in extensive damage.andO;For example, computers now have safety-critical functions in both militaryand civilian aircraft, in nuclear plants, and in medical devices.andP;  It isincumbent upon those responsible for programming, purchasing, installing, andlicensing these systems to determine whether or not the software is ready tobe used.andP;  This article addresses questions that are simple to pose but hardto answer.andP;  What standards must a software product satisfy if it is to beused in safety-critical applications such as those mentioned? Whatdocumentation should be required? How much testing is needed? How should thesoftware be structured?andM;This article differs from others concerned with software in safety-criticalapplications, in that it does not attempt to identify safety as a propertyseparate from reliability and trustworthiness.andP;  In other words, we do notattempt to separate safety-critical code from other code in a product used ina safety-critical application.andP;  In our experience, software exhibitsweak-link behavior, that is failures in even the unimportant parts of thecode can have unexpected repercussions elsewhere.andP;  For a discussion ofanother viewpoint, we suggest the work of N. G. Leveson [6, 7, 8].andM;We favor keeping safety-critical software as small and simple as possible bymoving any functions that are not safety critical to other computers.andP;  Thisfurther justifies our assumption that all parts of a safety-critical softwareproduct must be considered safety critical.andM;WHY IS SOFTWARE A SPECIAL CONCERN?andM;Within the engineering community software systems have a reputation for beingundependable, especially in the first years of their use.andP;  The public isaware of a few spectacular stories such as the Space Shuttle flight that wasdelayed by a software timing problem, or the Venus probe that was lostbecause of a punctuation error.andP;  In the software community, the problem isknown to be much more widespread.andM;A few years ago, David Benson, professor of Computer Science at WashingtonState University, issued a challenge by way of several electronic bulletinboard systems.andP;  He asked for an example of a real-time system that functionedadequately when used for the first time by people other than its developersfor a purpose other than testing.andP;  Only one candidate for this honor wasproposed, but even that candidate was controversial.andP;  It consisted ofapproximately 18,000 instructions, most of which had been used for severalyears before the &quot;first use.&quot; The only code that had not been used beforethat first use was a simple sequence of 200 instructions that simulated asimple analogue servomechanism.andP;  That instruction sequence had been testedextensively against an analogue model.andP;  All who have looked at this programregard it as exceptional.andP;  If we choose to regard this small program as onethat worked in its first real application.andP;  it is the proverbial &quot;exceptionthat proves the rule.&quot;andM;As a rule software systems do not work well until they have been used, andhave failed repeatedly, in real applications.andP;  Generally, many uses and manyfailures are required before a product is considered reliable.andP;  Softwareproducts, including those that have become relatively reliable, behave likeother products of evolution-like processes; they often fail, even years afterthey were built, when the operating conditions change.andM;While there are errors in many engineering products, experience has shownthat errors are more common, more pervasive, and more troublesome, insoftware than in other technologies.andP;  This information must be understood inlight of the fact it is now standard practice among software professionals tohave their product go through an extensive series of carefully planned testsbefore real use.andP;  The products fail in their first real use because thesituations that were not anticipated by the programmers were also overlookedby the test planners.andP;  Most major computer-using organizations, both militaryand civilian, are investing heavily in searching for ways to improve thestate of the art in software.andP;  The problem remains serious and there is nosign of a silver bullet.&quot; The most promising development is the work ofHarlan Mills and his colleagues at IBM on a software development processknown as &quot;clean room&quot; [3, 9, 12].andP;  Mills uses randomly selected tests,carried out by an independent testing group.andP;  The use of randomly generatedtest data reduces the likelihood of shared oversights.andP;  We will discuss thisapproach in more detail later in this article.andM;WHY IS SOFTWARE USED?andM;If software is so untrustworthy, one might ask why engineers do not avoid itby continuing to use hard-wired digital and analogue hardware.andP;  Here, we listthe three main advantages of replacing hardware with software:andM;1.andP;  Software technology makes it practical to build more logic into thesystem.andP;  Software-controlled computer systems can distinguish a large numberof situations and provide output appropriate to each of them.andP;  Hard-wiredsystems could not obtain such behavior without prohibitive amounts ofhardware.andP;  Programmable hardware is less expensive than the equivalenthard-wired logic because it is regular in structure and it is mass produced.andO;The economic aspects of the situation also allow software-controlled systemsto perform more checking; reliability can be increased by periodic executionof programs that check the hardware.andM;2.andP;  Logic implemented in software is, in theory, easier to change than logicimplemented in hardware.andP;  Many changes can be made without adding newcomponents.andP;  When a system is replicated or located in a physical positionthat is hard to reach, it is far easier to make changes in software than inhardware.andM;3.andP;  Computer technology and software flexibility make it possible to providemore information to operators and to provide that information in a moreuseful form.andP;  The operator of a modern software-controlled system can beprovided with information that would be unthinkable in a pure hardwaresystem.andP;  All of this can be achieved using less space and power than was usedby noncomputerized systems.andP;  These factors explain the replacement ofhard-wired with software-controlled systems in spite of its reputation as anunreliable technology.andM;HOW ARE SOFTWARE CONTROLLERS LIKE OTHER CONTROLLERS?andM;In the next section we will argue that software technology requires somerefinements in policies and standards because of differences between softwareand hardware technology.andP;  However, it is important to recognize some commonproperties of software and hardware control systems.andM;In the design and specification of control systems, engineers have long knownhow to use a black box mathematical model of the controller.andP;  in such models,(1) the inputs to the controller are described as mathematical functions ofcertain observable environmental state variables, (2) the outputs of thecontroller are described as mathematical functions of the inputs, (3) thevalues of the controlled environmental variables are described asmathematical functions of the controller's outputs, and (4) the requiredrelation between the controlled variables and observed variables isdescribed.andP;  It is then possible to confirm that the behavior of thecontroller meets its requirements.andM;It is important to recognize that, in theory, software-implementedcontrollers can be described in exactly the same way as black boxmathematical models.andP;  They can also be viewed as black boxes whose output isa mathematical function of the input.andP;  In practice, they are not viewed thisway.andP;  One reason for the distinction is that their functions are more complexi.e.andP;  harder to describe) than the functions that describe the behavior ofconventional controllers.andP;  However, [4] and [17] provide ample evidence thatrequirements for real systems can be documented in this way.andP;  We return tothis theme later.andM;HOW IS SOFTWARE DIFFERENT FROM OTHER CONTROLLER TECHNOLOGIES?andM;Software problems are often considered growing pains and ascribed to theadolescent nature of the field.andP;  Unfortunately there are fundamentaldifferences between software and other approaches that suggest these problemsare here to stay.andM;Complexity: The most immediately obvious difference between software andhardware technologies is their complexity.andP;  This can be observed byconsidering the size of the most compact descriptions of the software.andO;Precise documentation, in a reasonably general notation, for small softwaresystems can fill a bookcase.andP;  Another measure of complexity is the time ittakes for a programmer to become closely familiar with a system.andP;  Even withsmall software systems, it is common to find that a programmer requires ayear of working with the program before he/she can be trusted to makeimprovements on his/her own.andM;Error Sensitivity: Another notable property of software is its sensitivity tosmall errors.andP;  In conventional engineering, every design and manufacturingdimension can be characterized by a tolerance.andP;  One is not required to getthings exactly right; being within the specified tolerance of the right valueis good enough.andP;  The use of a tolerance is justified by the assumption thatsmall errors have small consequences.andP;  It is well known that in software,trivial clerical errors can have major consequences.andP;  No usefulinterpretation of tolerance is known for software.andP;  A single punctuationerror can be disastrous, even though fundamental oversights sometimes havenegligible effects.andM;Hard to Test: Software is notoriously difficult to test adequately.andP;  It iscommon to find a piece of software that has been subjected to a thorough anddisciplined testing regime has serious flaws.andP;  Testing of analogue devices isbased on interpolation.andP;  One assumes that devices that function well at twoclose points will function well at points in-between.andP;  In software thatassumption is not valid.andP;  The number of cases that must be tested in order toengender confidence in a piece of software is usually extremely large.andO;Moreover, as Harlan Mills has pointed out, &quot;testing carried out by selectedtest cases, no matter how carefully and well-planned, can provide nothing butanecdotes&quot; [3, 9, 12].andM;These properties are fundamental consequences of the fact that themathematical functions implemented by software are not continuous functions,but functions with an arbitrary number of discontinuities.andP;  The lack ofcontinuity constraints on the functions describing program effects makes itdifficult to find compact descriptions of the software.andP;  The lack of suchconstraints gives software its flexibility, but it also allows thecomplexity.andP;  Similarly, the sensitivity to small errors, and the testingdifficulties, can be traced to fundamental mathematical properties; we areunlikely to discover a miracle cure.andP;  Great discipline and careful scrutinywill always be required for safety-critical software systems.andM;Correlated Failures: Many of the assumptions normally made in the design ofhigh-reliability hardware are invalid for software.andP;  Designers ofhigh-reliability hardware are concerned with manufacturing failures andwear-out phenomena.andP;  They can perform their analysis on the assumption thatfailures are not strongly correlated and simultaneous failures are unlikely.andO;Those who evaluate the reliability of hardware systems should be.. and oftenare, concerned about design errors and correlated failures; however in manysituations the effects of other types of errors are dominant.andM;In software there are few errors introduced in the manufacturing (compiling)phase; when there are such errors they are systematic, not random.andP;  Softwaredoes not wear out.andP;  The errors with which software reliability experts mustbe concerned are design errors.andP;  These errors cannot be consideredstatistically independent.andP;  There is ample evidence that, even when programsfor a given task are written by people who do not know of each other, theyhave closely related errors [6, 7, 8].andM;In contrast to the situation with hardware systems, one cannot obtain higherreliability by duplication of software components.andP;  One simply duplicates theerrors.andP;  Even when programs are written independently, the oversights made byone programmer are often shared by others.andP;  As a result, one cannot count onincreasing the reliability of software systems simply by having threecomputers where one would be sufficient [6, 7, 8].andM;Lack of Professional Standards: A severe problem in the software field isthat, strictly speaking, there are no software engineers.andP;  In contrast toolder engineering fields, there is no accrediting agency for professionalsoftware engineers.andP;  Those in software engineering have not agreed on a setof skills and knowledge that should be possessed by every software engineer.andO;Anyone with a modicum of programming knowledge can be called a softwareengineer.andP;  Often, critical programming systems are built by people with nopostsecondary training about software.andP;  Although they may have usefulknowledge of the field in which the software will be applied, such knowledgeis not a substitute for understanding the foundations of software technology.andM;SOFTWARE TESTING CONCERNSandM;Some engineers believe one can design black box tests without knowledge ofwhat is inside the box.andP;  This is, unfortunately, not completely true.andP;  If weknow that the contents of a black box exhibit linear behavior, the number oftests needed to make sure it would function as specified could be quitesmall.andP;  If we know that the function can be described by a polynomial oforder  N,&quot; we can use that information to determine how many tests areneeded.andP;  If the function can have a large number of discontinuities, far moretests are needed.andP;  That is why a shift from analogue technology to softwarebrings with it a need for much more testing.andM;Built-in test circuitry is often included in hardware to perform testingwhile the product is in use.andP;  Predetermined values are substituted forinputs, and the outputs are compared to normative values.andP;  Sometimes thisapproach is imitated in software designs and the claim is made that built-inonline testing can substitute for black box testing.andP;  In hardware, built-intesting tests for decay or damage.andP;  Software does not decay and physicaldamage is not our concern.andP;  Software can be used to test the hardware, butits value for testing itself is quite doubtful.andP;  Software self-testing doesincrease the complexity of the product and, consequently, the likelihood oferror.andP;  Moreover, such testing does not constitute adequate testing becauseit usually does not resemble the conditions of actual use.andM;The fundamental limitations on testing mentioned earlier have some verypractical implications.andP;  We cannot test software for correctness: Because ofthe large number of states (and the lack of regularity in its structure), thenumber of states that would have to be tested to assure that software iscorrect is preposterous.andP;  Testing can show the presence of bugs, but, exceptfor toy problems, it is not practical to use testing to show that software isfree of design errors.andP;  It is difficult to make accurate predictions ofsoftware reliability and availability: Mathematical models show that it ispractical to predict the reliability of software, provided that one has goodstatistical models of the actual operating conditions.andP;  Unfortunately, oneusually gains that information only after the system is installed.andP;  Even whena new system replaces an existing one, differences in features may causechanges in the input distribution.andP;  Nonetheless, in safety-criticalsituations, one must attempt to get and use the necessary statistical data.andO;The use of this data is discussed later in this article.andM;Predictions of availability are even more difficult: estimates ofavailability depend on predictions of the time it will take to correct a bugin the software.andP;  We never know what that amount of time will be in advance;.andO;data from earlier bugs is not a good predictor of the time it will take tofind the next bug.andP;  It is not practical to measure the trustworthiness ofsoftware: We consider a product to be trustworthy if we believe that theprobability of it having a potentially catastrophic flaw is acceptably low.andO;Whereas reliability is a measure of the probability of a problem occurringwhile the system is in service, trustworthiness is a measure of theprobability of a serious flaw remaining after testing and review.andP;  In fact,inspection and testing can increase the trustworthiness of a product withoutaffecting its reliability.andM;Software does not need to be correct in order to be trustworthy.andP;  We willtrust imperfect software if we believe its probability of having a seriousflaw is very low.andP;  Unfortunately, as we will show, the amount of testingnecessary to establish high confidence levels for most software products isimpractically large.andP;  The number of states and possible input sequences is solarge that the probability of an error having escaped our attention willremain high even after years of testing.andP;  Methods other than testing must beused to increase our trust in software.andM;There is a role for testing: A number of computer scientists, aware of thelimitations on software testing, would argue that one should not testsoftware.andP;  They would argue that the effort normally put into testing should,instead, be put into a form of review known as mathematical verification.andP;  Aprogram is a mathematical object and can be proven correct.andP;  Unfortunately,such mathematical inspections are based on mathematical models that may notbe accurate.andP;  No amount of mathematical analysis will reveal discrepanciesbetween the model being used and the real situation; only testing can dothat.andP;  Moreover, errors are often made in proofs.andP;  In mature engineeringfields.andP;  mathematical methods and testing are viewed as complementary andmutually supportive.andM;There is a need for an independent validation agency: it is impossible totest software completely and difficult to test one's own design in anunbiased way.andP;  A growing number of software development projects involveindependent verification and validation (Vandamp;V).andP;  The Vandamp;V contractor isentirely independent of the development contractor.andP;  Sometimes a competitorof the development contractor is given the Vandamp;V contract.andP;  The testers workfrom the specification for the software and attempt to develop tests thatwill show the software to be faulty.andP;  One particularly interesting variationof this approach has been used within the IBM Federal Systems Division.andP;  InIBM's clean room development approach the authors of the software are notallowed to execute their programs.andP;  All testing is done by an independenttester and test reports are sent to the developer's supervisors.andP;  The testcases are chosen using random number generators and are intended to yieldstatistically valid data.andP;  It was hypothesized that the software would bewritten far more carefully under these conditions and would be more reliable.andO;Early reports support the hypothesis [3, 9, 121.andM;It is important that these validation tests not be made available to thedevelopers before the software is submitted for testing.andP;  If the developersknow what tests will be performed, they will use those tests in theirdebugging.andP;  The result is likely to be a program that will pass the tests butis not reliable in actual use.andM;SOFTWARE REVIEWABILITY CONCERNSandM;Why is reviewability a particular concern for software?andM;Traditionally, engineers have approached software as if it were an art form.andO;Each programmer has been allowed to have his own style.andP;  Criticisms ofsoftware structure, clarity, and documentation were dismissed as &quot;matters oftaste.&quot;andM;In the past, engineers were rarely asked to examine a software product andcertify that it would be trustworthy.andP;  Even in systems that were required tobe trustworthy and reliable, software was often regarded as an unimportantcomponent, not requiring special examination.andM;in recent years, however, manufacturers of a wide variety of equipment havebeen substituting computers controlled by software for a wide variety of moreconventional products.andP;  We can no longer treat software as if it were trivialand unimportant.andM;In the older areas of engineering, safety-critical components are inspectedand reviewed to assure the design is consistent with the safety requirements.andO;To make this review possible, the designers are required to conform toindustry standards for the documentation, and even the structure.. of theproduct.andP;  The documentation must be sufficiently clear and well organizedthat a reviewer can determine whether or not the design meets safetystandards.andP;  The design itself must allow components to be inspected so thereviewer can verify they are consistent with the documentation.andP;  Inconstruction, inspections take place during the process-while it is stillpossible to inspect and correct work that will later be hidden.andM;When software is a safety-critical component, analogous standards should beapplied.andP;  In software, there is no problem of physical visibility but thereis a problem of clarity.andP;  Both practical experience and planned experimentshave shown that it is common for programs with major flaws to be accepted byreviewers.andP;  In one particularly shocking experiment, small programs weredeliberately flawed and given to a skilled reviewer team.andP;  The reviewers wereunable to find the flaws in spite of the fact they were certain such flawswere present.andP;  In theory, nothing is invisible in a programit is all in thelisting; in practice, poorly structured programs hide a plethora of problems.andM;In safety-critical applications we must reject the &quot;software-as-art-form&quot;approach.andP;  Programs and documentation must conform to standards that allowreviewers to feel confident they understand the software and can predict howit will function in situations where safety depends on it.andP;  However, we must,equally strongly, reject standards that require a mountain of paper thatnobody can read.andP;  The standards must insure clear, precise, and concisedocumentation.andM;It is symptomatic of the immaturity of the software profession that there areno widely accepted software standards assuring the reviewability essential tolicensing of software products that must be seen as trustworthy.andP;  Thedocumentation standards name and outline certain documents, but they onlyvaguely define the contents of those documents.andP;  Recent U.S.andP;  militaryprocurement regulations include safety requirements; while they require thatsafety checks be done, they neither describe how to do them nor imposestandards that make those checks practicable.andP;  Most standards for codedocumentation are so vague and syntactic in nature that a program can meetthose standards in spite of being incomprehensible.andM;In the next section we derive some basic standards by considering the reviewsthat are needed and the information required by the reviewers.andM;What reviews are needed?andM;Software installed as a safety-critical component in a large system should besubjected to the following reviews:  ,andM;a.andP;  Review for correct intended function.andP;  If the software works as theprogrammers intend, will it meet the actual requirements?andM;b.andP;  Review for maintainable, understandable, well documented structure.andP;  Isit easy to find portions of the software relevant to a certain issue? Are theresponsibilities of the various modules clearly defined? If all of themodules work as required, will the whole system work as intended? If changesare needed in the future, can those changes be restricted to easilyidentified portions of the code?andM;c.andP;  Review each module to verify the algorithm and data structure design areconsistent with the specified behavior.andP;  Is the data structure used in themodule appropriate for representing the information maintained by thatmodule? If the programs are correctly coded, will the modules perform asrequired? Will the algorithms selected perform as required? These reviewsmust use mathematical methods; one cannot rely on intuitive approaches.andP;  Wehave found a formal review based on functional semantics, [10], to bepractical and effective.andM;d.andP;  Review the code for consistency with the algorithm and data structuredesign.andP;  Is the actual source code consistent with the algorithms and datastructures described by the designers? Have the assemblers, compilers, andother support tools been used correctly?andM;e.andP;  Review test adequacy.andP;  Was the testing sufficient to provide soundconfidence in the proper functioning of the software?andM;The structure of this set of reviews is consistent with modern approaches tosoftware engineering.andP;  Because we are unable to comprehend all the criticaldetails about a software product at once, it is necessary to providedocumentation that allows programmers and reviewers to focus on one aspect ata time and to zoom in on the relevant details.andM;Developing and presenting these views in the sequence listed is the analogueof providing inspections during a construction project.andP;  Just as constructionis inspected before further work obscures what has been done, the earlyspecifications should be reviewed before subsequent coding hides thestructure in a sea of detail.andM;The set of reviews also reflects the fact that reviewers of a softwareproduct have a variety of skills.andP;  Those who have a deep understanding of therequirements are not usually skilled software designers.andP;  It follows that thebest people to review the functional behavior of the software are not theones who should study the software.andP;  Similarly, within the software field wehave people who are good at algorithm design, but not particularly goodfinding an architecture for software products.andP;  Skilled algorithm designersare not necessarily experts on a particular compiler or machine language.andO;Those intimately familiar with a compiler or assembly language are not alwaysgood at organizing large programs.andP;  When the software is safety critical, itis important that each of the five reviews be conducted by those bestqualified to review that aspect of the work.andM;Within this framework, all code and documentation supplied must be of aquality that facilitates review and allows the reviewers to be confident oftheir conclusions.andP;  It is the responsibility of the designers to presenttheir software in a way that leaves no doubt about their correctness.andP;  It isnot the responsibility of the reviewers to guess the designers' intent.andO;Discrepancies between code and documentation must be treated as seriously aserrors in the code.andP;  If the designers are allowed to be sloppy with theirdocumentation, quality control will be ineffective.andM;In the following sections of this article, we will describe the documentationthat must be provided for each of these reviews.andP;  This documentation shouldnot be created merely for review purposes.andP;  It should be used throughout thedevelopment to record and propagate design decisions.andP;  When separate reviewdocuments are produced, projects experience all the problems of keeping twosets of books.andP;  Because of the complexity of software products, it isunlikely that both records would be consistent.andP;  Moreover, the documentsdescribed below from the reviewers' viewpoint are invaluable to the designersas well [5, 13, 16].andM;What documentation is required to review the functional requirements?andM;The software can be viewed as a control system whose output values respond tochanges in the states of variables of interest in its environment.andP;  For manyreal-time systems, the desired outputs approximate piece-wise continuousfunctions of time and the history of the relevant environmental parameters.andO;For other systems, the outputs are functions of a snapshot of theenvironmental parameters taken at some point in time.andP;  Some systems provideboth reports and continuous outputs.andM;The reviewers at this stage should be engineers and scientists who understandthe situation being monitored and the devices to be controlled.andP;  They may notbe computer specialists and should not be expected to read and understandprograms.andP;  Because the requirements could, in theory, be fulfilled by acompletely hardware design, the description should use the mathematics ofcontrol systems, not the jargon and notation of computer programming.andP;  Thefunctional requirements can be stated precisely by giving three mathematicalrelations: (1) The required values of the controlled environmental variablesin terms of the values of the relevant observable environmental parameters,(2) the computer inputs in terms of those observable environmental variables,and (3) the values of the controlled environmental variables in terms of thecomputer outputs.andM;These requirements can be communicated as a set of tables and formulaedescribing the mathematical functions to be implemented [4].andP;  We should notdescribe a sequence of computations anywhere in this document.andP;  The use ofnatural language, which inevitably introduces ambiguity, should be minimized.andO;Documents of this form have been written for reasonably complex systems andare essential when safety-critical functions are to be performed.andP;  Ourexperience has shown that documents written this way can be thoroughly andeffectively reviewed by engineers who are not programmers.andP;  Some suggestionsfor organizing the reviews are contained in [19].andP;  A complete example of sucha document has been published as a model for other projects [17].andM;What documentation is required to review the software structure?andM;For this review we require documents that describe the breakdown of theprogram into modules.andP;  Each module is a unit that should be designed, writtenand reviewed independently of other modules.andP;  Each module is a collection ofprograms; the programs that can be invoked from other modules are calledaccess programs.andP;  The purpose of this review is to make sure that: (1) thestructure is one that allows independent development and change; (2) allprograms that are needed are included once and only once in the structure;(3) the interfaces to the modules are precisely defined; (4) the modules arecompatible and will, together, constitute a system that meets the functionalrequirements.andM;For this review three types of documents are required.andP;  The first is therequirements specification, which should have been approved by an earlierreview.andP;  The second is an informal document describing the responsibilitiesof each module.andP;  The purpose of this module guide is to allow a reviewer tofind all the modules relevant to a particular aspect of system design [1].andO;The third type of document is known as a module specification.andP;  It provides acomplete black box description of the module interface.andP;  There should be onespecification for each module mentioned in the module guide [2, 14].andM;Reviewers of these documents must be experienced software engineers.andP;  Some ofthem should have had experience with similar systems.andP;  This experience isnecessary to note omissions in the module structure.andP;  Discussions of thesedocuments and how to organize the reviews are contained in [14, 19].andM;What documentation is required to review the module's internal design?andM;The first step in designing the module should be to describe the datastructures that will be used and each proposed program's effect on the data.andO;This information can be described in a way that is, except for the data typesavailable, independent of the programming language being used.andM;The design documentation is a description of two types of mathematicalfunctions: program functions and abstraction functions.andP;  This terminology wasused in IBM's Federal Systems Division, the IBM branch responsible for U.S.andO;Government systems.andP;  These concepts are described more fully elsewhere [11,13).andP;  The program functions, one for each module access program, give themapping from the state before the program is executed to the state after theprogram terminates.andP;  The abstraction functions are used to define the&quot;meaning&quot; of the data structure; they give the mapping between the datastates and abstract values visible to the users of the module.andP;  It iswell-known that these functions provide sufficient information for a formalreview of correctness of the design before the programs are implemented.andM;Programs that cannot be described on a single page must be presented in ahierarchical way; each page must present a small program, calling otherprograms whose functions are specified on that page.andP;  This type ofpresentation allows the algorithm to be understood and verified one page at atime.andM;If the module embodies a physical model (i.e., a set of equations that allowsus to compute nonobservables from observables), the model must be describedand its limitations documented.andM;If the module performs numerical calculations in which accuracy will be aconcern, numerical analysis justifying the design must be included.andM;If the module is hardware-dependent, the documentation must include either adescription of the hardware or a reference to such a description.andM;If the module is responsible for certain parts of the functionalspecification, a cross reference must be provided.andM;The reviewers of each internal module design document will includeexperienced software engineers and other specialists.andP;  For example, if aphysical model is involved, a physicist or engineer with expertise in thatarea must be included as a reviewer.andP;  If the information is presented in anotation that is independent of the programming language, none of thereviewers needs to be an expert in the programming language involved.andO;Numerical analysts will be needed for some modules, device specialists forothers.andM;What documentation is required to review the code?andM;While it is important that the algorithms and data structures be appropriateto the task, this will be of little help if the actual code is not faithfulto the abstract design.andP;  Because of the previous reviews, those who reviewthe code do not need to examine the global design of the system.andP;  Instead,they examine the correspondence between the algorithms and the actual code.andO;These reviewers must be experienced users of the hardware and compilersinvolved; of course, they must also understand the notation used to specifythe algorithms.andM;What documentation is required for the Test Plan Review?andM;Although these reviews, if carried out rigorously, constitute a mathematicalverification of the code, testing is still required.andP;  Sound testing requiresthat a test plan (a document describing the way test cases will be selected)be developed and approved in advance.andP;  In addition to the usual engineeringpractice of normal case and limiting case checks, it is important that thereliability of safety-critical systems be estimated by statistical methods.andO;Reliability estimation requires statistically valid random testing; carefulthought must be given to the distribution from which the test cases will bedrawn.andP;  It is important for the distribution of inputs to be typical ofsituations in which the correct functioning of the system is critical.andP;  Amore detailed discussion of statistical testing can be found in the upcomingsection, Reliability Assessment for Safety-Critical Software.andM;The test plan should be described in a document that is not available to thedesigners.andP;  It should be reviewed by specialists in software testing, andspecialists in the application area, who compare it with the requirementsspecification to make certain the test coverage is adequate.andM;Reviewing the relationship between these documentsandM;The hierarchical process described is designed to allow reviews to beconducted in an orderly way, focusing on one issue at a time.andP;  To make this&quot;separation of concerns&quot; work, it is important that the requiredrelationships between the documents be verified.andM;a.andP;  The module guide must show clearly that each of the mathematicalfunctions described in the requirements specification is the responsibilityof a specific module.andP;  There must be no ambiguity about the responsibilitiesof the various modules.andP;  The module specifications must be consistent withthe module guide and the requirements specification.andM;b.andP;  Each module design document should include argumentation showing that theinternal design satisfies the module specification.andP;  If the modulespecification is mathematical [18], mathematical verification of the designcorrectness is possible [11].andM;c.andP;  The module design document, which describes the algorithms, must beclearly mapped onto the code.andP;  The algorithms may be described in an abstractnotation or via hierarchically structured diagrams.andM;d.andP;  The test plan must show how the tests are derived and how they cover therequirements.andP;  The test plan must include black box module tests as well asblack box system tests.andM;Why is configuration management essential for rigorous reviews?andM;Because of the complexity of software, and the amount of detail that must betaken into consideration, there is always a tremendous amount ofdocumentation.andP;  Some of the most troublesome software errors occur whendocuments are allowed to get out-of-date while their authors work with pencilnotes on their own copies.andM;For the highly structured review process outlined earlier to succeed, alldocuments must be kept consistent when changes are made.andP;  If a document ischanged, it, and all documents related to it, must be reviewed again.andP;  Acareful review of the software may take weeks or months.andP;  Each reviewer mustbe certain that the documents given to him are consistent and up-to-date.andO;The time and energy of reviewers should not be wasted, comparing differentversions of the same document.andM;A process known in the profession as configuration management, supported by aconfiguration control mechanism, is needed to ensure that every designer andreviewer has the latest version of the documents and is informed of everychange in a document that might affect the review.andM;We should be exploiting computer technology to make sure that programmers,designers, and reviewers do not need to retain paper copies of the documentsat all.andP;  Instead, they use online documentation.andP;  If a change must be made.andO;all who have used the affected document should be notified of the change bythe computer system.andP;  When a change is being considered, but is not yetapproved, users of the document should receive a warning.andP;  The onlineversions must be kept under strict control so they cannot be changed withoutauthorization.andP;  Every page must contain a version identifier that makes iteasier for a reviewer to verify that the documents he has used represent aconsistent snapshot.andM;MODULAR STRUCTUREandM;Modern software engineering standards call for software to be organized inaccordance with a principle known variously as &quot;Information Hiding,&quot;&quot;Object-Oriented Programming,&quot; &quot;Separation of Concerns,&quot; &quot;Encapsulation,&quot;&quot;Data Abstraction,&quot; etc.andP;  This principle is designed to increase the cohesionof the modules while reducing the &quot;coupling&quot; between modules.andP;  Several newtextbooks, well-known programming languages such as ADA, practical languagessuch as MESA, PROTEL, and MODULA, are designed to support such anorganization.andM;Any large program must be organized into programmer work assignments known asmodules.andP;  In information-hiding designs, each module hides a secret, a fact,or closely related set of facts, about the design that does not need to beknown by the writers and reviewers of other modules.andP;  Each work assignmentbecomes much simpler than in an old-fashioned design because it can becompleted and understood without knowing much about the other modules.andP;  Whenchanges are needed, they do not ripple through an unpredictable number ofother modules, as they frequently do in more conventional software designs.andM;A number of practical systems illustrate the benefits of information hidingeven when the designers did not use that abstract principle but depended ontheir own intuition.andP;  For example, the widely used UNIX operating systemgains much of its flexibility from hiding the difference between files anddevices.andM;The thought of hiding information from others often strikes engineers asunnatural and wrong.andP;  In engineering projects, careful scrutiny by othersworking on the project is considered an important part of quality control.andO;However, information hiding occurs naturally in large multidisciplinaryprojects.andP;  An electrical engineer may use a transformer without understandingits molecular structure or knowing the size of the bolts that fasten it to achassis.andP;  The circuit designer works with a specification that specifies suchabstractions as voltage ratio, hysteresis curve, and linearity.andP;  Designers oflarge mechanical structures work with abstract descriptions of the girdersand other components, not with the detailed molecular structures that are theconcern of materials engineers.andP;  Large engineering projects would beimpossible if every engineer on the project had to be familiar with all thedetails of every component of the product.andM;Large software projects have the complexity of huge multidisciplinaryprojects, but there is only one discipline involved.andP;  Consequently,information hiding does not occur naturally and must be introduced as anengineering discipline.andP;  Software engineers should be trained to provide anduse abstract mathematical specifications of components just as otherengineers do.andM;The criterion of information hiding does not determine the softwarestructure.andP;  Software engineers try to minimize the information that oneprogrammer must have about another's work.andP;  They also try to minimize theexpected cost of a system over the period of its use.andP;  Both information andexpected cost are probabilistic measures.andP;  For maximum benefit, one shouldhide those details most likely to change but does not need to hide facts thatare fundamental and unlikely to change.andP;  Further, decisions likely to bechanged and reviewed together should be hidden in the same module.andP;  Thisimplies that to apply the principle.andP;  one must make assumptions about thelikelihood of various types of changes.andP;  If two designers apply theinformation-hiding principle, but make different assumptions about thelikelihood of changes, they will come up with different structures.andM;RELIABILITY ASSESSMENT FOR SAFETY-CRITICAL SOFTWAREandM;Should we discuss the reliability of software at all?andM;Manufacturers.andP;  users, and regulatory agencies are often concerned about thereliability of systems that include software.andP;  Over many decades, reliabilityengineers have developed sophisticated methods of estimating the reliabilityof hardware systems based upon estimates of the reliability of theircomponents.andP;  Software is often viewed as one of those components and anestimate of the reliability of that component is deemed essential toestimating the reliability of the overall system.andM;Reliability engineers are often misled by their experience with hardware.andO;They are usually concerned with the reliability of devices that workcorrectly when new, but wear out and fail as they age.andP;  In other cases, theyare concerned with mass-produced components where manufacturing techniquesintroduce defects that affect only a small fraction of the devices.andP;  Neitherof these situations applies to software.andP;  Software does not wear out, and theerrors introduced when software is copied have not been found to besignificant.andM;As a result of these differences, it is not uncommon to see reliabilityassessments for large systems based on an estimated software reliability of1.0.andP;  Reliability engineers argue that the correctness of a software productis not a probabilistic phenomenon.andP;  The software is either correct(reliability 1.0) or incorrect (reliability 0).andP;  If they assume a reliabilityof 0, they cannot get a useful reliability estimate for the system containingthe software.andP;  Consequently, they assume correctness.andM;&quot;Many consider it nonsense to talk about  reliability of software.&quot;andM;Nonetheless, our practical experience is that software appears to exhibitstochastic properties.andP;  It is quite useful to associate reliability figuressuch as MTBF (Mean Time Between Failures) with an operating system or othersoftware product.andP;  Some software experts attribute the apparently randombehavior to our ignorance.andP;  They believe that all software failures would bepredictable if we fully understood the software, but our failure tounderstand our own creations justifies the treatment of software failures asrandom.andP;  However, we know that if we studied the software long enough, wecould obtain a complete description of its response to inputs.andP;  Even then, itwould be useful to talk about the MTBF of the product.andP;  Hence, ignoranceshould not satisfy us as a philosophical justification.andM;When a program first fails to function properly, it is because of an inputsequence that had not occurred before.andP;  The reason that software appears toexhibit random behavior, and the reason that it is useful to talk about theMTBF of software, is because the input sequences are unpredictable.andP;  When wetalk about the failure rate of a software product, we are predicting theprobability of encountering an input sequence that will cause the product tofail.andM;Strictly speaking, we should not consider software as a component in systemsat all.andP;  The software is simply the initial data in the computer and it isthe initialized computer that is the component in question.andP;  However, inpractice, the reliability of the hardware is high and failures caused bysoftware errors dominate those caused by hardware problems.andM;What should we be measuring?andM;What we intuitively call &quot;software reliability&quot; is the probability of notencountering a sequence of inputs that leads to failure.andP;  If we couldaccurately characterize the sequences that lead to failure we would simplymeasure the distribution of input histories directly.andP;  Because of ourignorance of the actual properties of the software, we must use the softwareitself to measure the frequency with which failure-inducing sequences occuras inputs.andM;In safety-critical applications, particularly those for which a failure wouldbe considered catastrophic, we may wish to take the position that designerrors that would lead to failure are always unacceptable.andP;  In othertechnologies we would not put a system with a known design error in service.andO;The complexity of software, and its consequent poor track record, means weseldom have confidence that software is free of serious design errors.andP;  Underthose circumstances, we may wish to evaluate the probability that seriouserrors have been missed by our tests.andP;  This gives rise to our secondprobabilistic measure of software quality, trustworthiness.andM;In the sequel we shall refer to the probability that an input will not causea failure as the reliability of the software.andP;  We shall refer to theprobability that no serious design error remains after the software passes aset of randomly chosen tests as the trustworthiness of the software.andP;  We willdiscuss how to obtain estimates of both of these quantities.andM;Some discussions about software systems use the terms availability andreliability as if they were interchangeable.andP;  Availability usually refers tothe fraction of time that the system is running and assumed to be ready tofunction.andP;  Availability can depend strongly on the time it takes to return asystem to service once it has failed.andP;  If a system is truly safety-criticale.g., a shutdown system in a nuclear power station), we would not depend onit during the time it was unavailable.andP;  The nuclear reactor would be takenout of service while its shutdown system was being repaired.andP;  Consequently,reliability and availability can be quite different.andM;For systems that function correctly only in rare emergencies, we wish tomeasure the reliability in those situations where the system must takecorrective action, and not include data from situations in which the systemis not needed.andP;  The input sequence distributions used in reliabilityassessment should be those that one would encounter in emergency situations,and not those that characterize normal operation.andM;Much of the literature on software reliability is concerned with estimationand prediction of error-rates, the number of errors per line of code.andP;  Forsafety purposes, such rates are both meaningless and unimportant.andP;  Errorcounts are meaningless because we cannot find an objective way to counterrors.andP;  We can count the number of lines in the code that are changed toeliminate a problem, but there usually are many ways to alleviate thatproblem.andP;  If each approach to repairing the problem involves a differentnumber of lines (which is usually the case), the number of errors in the codeis a subjective, often arbitrary, judgment.andP;  Error counts are unimportantbecause a program with a high error count is not necessarily less reliablethan one with a low error count.andP;  In other words, even if we could count thenumber of errors, reliability is not a function of the error count.andP;  If askedto evaluate a safety-critical software product, there is no point inattempting to estimate or predict the number of errors remaining in aprogram.andM;Other portions of the literature are concerned with reliability growthmodels.andP;  These attempt to predict the reliability of the next (corrected)version on the basis of reliability data collected from previous versions.andO;Most assume the failure rate is reduced whenever an error is corrected.andP;  Theyalso assume the reductions in failure rates resulting from each correctionare predictable.andP;  These assumptions are not justified by either theoreticalor empirical studies of programs.andP;  Reliability growth models may be usefulfor management and scheduling purposes, but for safety-critical applicationsone must treat each modification of the program as a new program.andP;  Becauseeven small changes can have major effects, we should consider data obtainedfrom previous versions of the program to be irrelevant.andP;  We cannot predict asoftware failure rate from failure rates for individual lines or subprograms.andM;The essence of system-reliability studies is the computation of thereliability of a large system when given the reliability of the parts.andP;  It istempting to try to do the same thing for software, but the temptation shouldbe resisted.andP;  The lines or statements of a program are not analogous to thecomponents of a hardware system.andP;  The components of a hardware systemfunction independently and simultaneously.andP;  The lines of a computer programfunction sequentially and the effect of one execution depends on the statethat results from the earlier executions.andP;  One failure at one part of aprogram may lead to many problems elsewhere in the code.andP;  When evaluating thereliability of a safety-critical software product, the only sound approach isto treat the whole computer, hardware and software, as a black box.andM;The finite state machine model of programsandM;The following discussion is based on the simplest and oldest model of digitalcomputing.andP;  Used for more than 50 years, this model recognizes that everydigital computer has a finite number of states and there are only a finitenumber of possible input and output signals at any moment in time.andP;  Eachmachine is described by two functions: next-state, and output.andP;  Both have adomain consisting of (state, input) pairs.andP;  The range of the next-statefunction is the set of states.andP;  The range of the output function is a set ofsymbols known as the output alphabet.andP;  These functions describe the behaviorof a machine that starts in a specified initial state and periodicallyselects new states and outputs in accordance with the functions.andM;In this model, the software can be viewed as part of the initial data.andP;  Itdetermines the initial state of the programmed machine.andP;  Von Neumannintroduced a machine architecture in which program and data could beintermixed.andP;  Practicing programmers know they can always replace code withdata or vice versa.andP;  It does not make sense to deal with the program and dataas if they were different.andM;In effect, loading a program in the machine selects a terminal submachineconsisting of all states that can be reached from the initial state.andP;  Thesoftware can be viewed as a finite state machine described by two very largetables.andP;  This model of software allows us to define what we mean by thenumber of faults in the software; it is the number of entries in the tablethat specify behavior that would be considered unacceptable.andP;  This faultcount has no simple relation to the number of errors made by the programmeror the number of statements that must be corrected to remove the faults.andP;  Itserves only to help us to determine the number of tests that we need toperform.andM;Use of hypothesis testingandM;In most safety-critical applications we do not need to know the actualprobability of failure; we need to confirm the failure probability is verylikely to be below a specified upper bound.andP;  We propose to run random testson the software, checking the result of each test.andP;  Since we are concernedwith safety-critical software, if a test fails (i.e., reveals an error in thesoftware), we will change the software in a way that we believe will correctthe error.andP;  We will again begin random testing.andP;  We will continue such testsuntil we have sufficient data to convince us that the probability of afailure is acceptably low.andP;  Because we can execute only a very small fractionof the conceivable tests, we can never be sure that the probability offailure is low enough.andP;  We can, however, calculate the probability that aproduct with unacceptable reliability would have passed the test that we havecarried out.andM;Let us assume the probability of a failure in a test of a program is 1/h(i.e., the reliability is 1 - 1/h).andP;  Assuming that N randomly selected tests(chosen, with replacement, from a distribution that corresponds to the actualusage of the program) are performed, the probability there will be no failureencountered during the testing isandM;(1 - 1/h)n[.sup.n]= M.andP;  [1]andM;In other words, if we want the failure probability to be less than 1/h, andwe have run N tests without failure, the probability that an unacceptableproduct would pass our test is no higher than M. We must continue testing,without failure, until N is large enough to make M acceptably low.andP;  We couldthen make statements like, &quot;the probability that a product with reliabilityworse than .999 would pass this test is less than one in a hundred.&quot; Table Iprovides some sample values of M for h = 1000 and various values of N.andM;Table I shows that, if our design target was to have the probability offailure be less than 1 in 1000, performing between 4500 and 5000 tests(randomly chosen from the appropriate test case distribution) without failurewould mean that the probability of an unacceptable product passing the testwas less than 1 in a hundred.andM;Because the probability of failure in practice is a function of thedistribution of cases encountered in practice, the validity of this approachdepends on the distribution of cases in the tests being typical of thedistribution of cases encountered in practice.andM;We can consider using the same approach to obtain a measure of thetrustworthiness of a program.andP;  Let the total number of cases from which weselect tests be C. Assume we consider it unacceptable if F of those casesresults in faulty behavior: (F might be 1).andP;  By substituting F/C for 1/h weobtainandM;(1 - F/C)[.sup.N] = M.andP;  [2]andM;We now assume that we have carried out N randomly selected tests withoutfinding an error.andP;  If, during that testing, we had found an error.andP;  we wouldhave corrected the problem and started again.andP;  We  ian estimate the value ofC, and must determine whether to use F = 1 or some higher value.andP;  We mightpick a higher number if we thought it unlikely that there would be only 1faulty (state, input) pair.andP;  In most computer programs, a programming errorwould result in many faulty pairs, and calculations using F = 1 areunnecessarily pessimistic.andP;  After choosing F, we can determine M as above.andO;(F, M) pairs provide a measure of trustworthiness.andP;  Note that systemsconsidered trustworthy would have relatively low values of M and F.andM;As a result of such tests we could make statements like, &quot;The probabilitythat a program with more than five unacceptable cases would pass this test isone in a hundred.&quot; Since we are not concerned with the frequency of failureof those cases in practice, the tests should be chosen from a distribution inwhich all state input combinations are equally likely.andP;  Because C is almostalways large and F relatively small.andP;  it is not practical to evaluatetrustworthiness by means of testing.andP;  Trustworthiness, in the sense that wehave defined it here, must be obtained by means of formal.andP;  rigorousinspections.andM;It is common to try to achieve high reliability by using two or more programsin an arrangement that will be safe if one of their specified subsets fails.andO;For example, one could have two safety systems and make sure that each onecould alone take the necessary actions in an emergency.andP;  If the systemfailures are statistically independent.andP;  the probability of the joint systemfailing is the product of the probability of individual failures.andO;Unfortunately, repeated experiments have shown that.andP;  even when the programsfor the two systems are developed independently, the failures are correlated[6, 7, 8].andP;  As a result, we should evaluate the probability of joint failureexperimentally.andM;The hypothesis testing approach can be applied to the evaluation of theprobability of joint failures of two (or more) systems.andP;  Both systems must besubjected to the same set of test conditions.andP;  Joint failures can bedetected.andP;  However, because the permitted probability of failures for jointsystems is much lower than for single systems, many more tests will beneeded.andP;  Table II shows some typical values.andM;In this table, we have been quite vague about the nature of a single test andhave focused on how many tests are needed.andP;  Next we will discuss whatconstitutes a test and how to select one or more tests.andM;Three classes of programsandM;The simplest class of programs to test comprises those that terminate aftereach use and retain no data from one run to the next.andP;  These memoryless batchprograms are provided with data, executed, and return an answer that isindependent of any data provided in earlier executions.andM;A second class consists of batch programs that retain data from one run tothe next.andP;  The behavior of such programs on the nth run can depend on datasupplied in any previous run.andM;A third class contains programs that appear to run continuously.andP;  Often thesereal-time programs are intended to emulate or replace analogue equipment.andO;They consist of one or more processes; some of those processes runperiodically.andP;  Others run sporadically in response to external events.andP;  Onecannot identify discrete runs, and the behavior at any time may depend onevents arbitrarily far in the past.andM;Reliability estimates for memoryless batch programs: For memoryless batchprograms a test consists of a single run using a randomly selected set ofinput data.andP;  If we are concerned with a system required to take action inrare circumstances, and one in which action in other circumstances isinconvenient rather than unsafe.andP;  the population of possible test casesshould be restricted to those in which the system should take action.andP;  It isessential that one know the reliability under those circumstances.andP;  Ofcourse, additional tests can be conducted, using other data, to determine theprobability of action being taken when no action is required.andM;Reliability estimates for batch programs with memory: When a batch programhas memory, a test consists of a single run.andP;  However, a test case isselected by choosing both input data and an internal state.andP;  For reliabilityestimates, the distribution of internal states must match that encountered inpractice.andP;  It is often more difficult to determine the appropriatedistribution of internal states than to find the distribution of inputs.andO;Determining the distribution of internal states requires an understanding of,and experience with.andP;  the program.andM;An alternative to selecting internal states for the test would be to haveeach test consist of a sequence of executions.andP;  The system must bereinitialized before each new sequence.andP;  Again, the distribution of thesecases must match that found in practice if the reliability estimates are tobe meaningful.andP;  In addition, it is difficult to determine the length of thosesequences.andP;  The sequences must be longer than the longest sequence that wouldoccur in actual use.andP;  If the sequences are not long enough, the distributionof internal states that occur during the test may be badly skewed.andP;  Ineffect, this means that in actual use, the system must be reinitializedfrequently so that an upper bound can be placed on the length of each test.andM;Reliability estimates for real-time systems: In real-time systems, theconcept of a batch run does not apply.andP;  Because the real-time system isintended to simulate or replace an analogue system, the concept of an inputsequence must be replaced by a multidimensional trajectory.andP;  Each suchtrajectory gives the input values as continuous functions of time.andP;  Each testinvolves a simulation in which the software can sample the inputs for thelength of that trajectory.andM;The question of the length of the trajectory is critical in determiningwhether or not statistical testing is practical.andP;  In many computer systemsthere are states that can arise only after long periods of time.andP;  Reliabilityestimates derived from tests involving short trajectories will not be validfor systems that have been operating for longer periods.andP;  On the other hand,if one selects lengthy trajectories, the testing time required is likely tobe impractical.andM;Statistical testing can be made practical if the system design is such thatone can limit the length of the trajectories without invalidating the tests.andO;To do this, one must partition the state.andP;  A small amount of the memory isreserved for data that must be retained for arbitrary amounts of time.andP;  Theremaining data are reinitialized periodically.andP;  The length of the periodbecomes the length of the test trajectory.andP;  Testing can then proceed as ifthe program were a batch program with (memory-state, trajectory) pairsreplacing input sequences.andM;If the long-term memory has a small number of states, it is best to performstatistically significant tests for each of those states.andP;  If that isimpractical, one must select the states randomly in accordance with apredicted distribution.andP;  In many applications, the long-term memorycorresponds to operating modes and a valid distribution can be determined.andM;Picking test cases for safety-critical real-time systemsandM;Particular attention must be paid to trajectory selection if the system isrequired to act only in rare circumstances.andP;  Since the reliability is afunction of the input distribution, the trajectories must be selected toprovide accurate estimates under the conditions where performance matters.andO;In other words, the population from which trajectories are drawn must includeonly trajectories in which the system must take action.andP;  Similarly, thestates of the long-term memory should be restricted to those in which thesystem will be critical to safety.andM;Determining the population of trajectories from which the tests are selectedcan be the most difficult part of the process.andP;  It is important to use one'sknowledge of the physical situation to define a set of trajectories that canoccur.andP;  Tests on impossible trajectories are not likely to lead to accuratereliability estimates.andP;  However, there is always the danger that the modelused to determine these trajectories overlooks the same situation overlookedby the programmer who introduced a serious bug.andP;  It is important that anymodel used to eliminate impossible trajectories be developed independently ofthe program.andP;  Most safety experts would feel more comfortable if, in additionto the tests using trajectories considered possible.andP;  some statistical testswere conducted with crazy trajectories.andM;CONCLUSIONSandM;There is no inherent reason that software cannot be used in certainsafety-critical applications, but extreme discipline in design,documentation, testing, and review is needed.andP;  It is essential that theoperating conditions and requirements be well understood, and fullydocumented.andP;  If these conditions are not met, adequate review and testing areimpossible.andM;The system must be structured in accordance with information hiding to makeit easier to understand, review, and repair.andP;  The documentation must becomplete and precise, making use of mathematical notation rather than naturallanguage.andP;  Each stage of the design must be reviewed by independent reviewerswith the specialized knowledge needed at that stage.andP;  Mathematicalverification techniques must be used to make the review systematic andrigorous.andM;An independent agency must perform statistically valid random testing toprovide estimates of the reliability of the system in critical situations.andO;Deep knowledge and experience with the application area will be needed todetermine the distribution from which the test cases should be drawn.andM;The vast literature on random testing is, for the most part, not relevant forsafety evaluations.andP;  Because we are not interested in estimating the errorrates or conducting reliability growth studies, a very simple model suffices.andO;Hypothesis testing will allow us to evaluate the probability that the systemmeets our requirements.andP;  Testing to estimate reliability is only practical ifa real-time system has limited long-term memory.andM;Testing to estimate trustworthiness is rarely practical because the number oftests required is usually quite large.andP;  Trustworthiness must be assured bythe use of rigorous mathematical techniques in the review process.andM;The safety and trustworthiness of the system will rest on a tripod made up oftesting, mathematical review, and certification of personnel and process.andP;  Inthis article, we have focused on two of those legs, testing and review basedon mathematical documentation.andP;  The third leg will be the most difficult toimplement.andP;  While there are authorities that certify professional engineersin other areas, there is no corresponding authority in software engineering.andO;We have found that both classical engineers and computer science graduatesare ill-prepared for this type of work.andP;  In the long term, those who areconcerned about the use of software in safety-critical applications will haveto develop appropriate educational programs [15].andM;Acknowledgments.andP;  Conversations with many people have helped to develop theseobservations.andP;  Among them are William Howden, Harlan Mills, Jim Kendall,Nancy Leveson, B. Natvik, and Kurt Asmis.andP;  In addition, we are thankful tothe anonymous Communications referees and the editor for their constructivesuggestions.andM;REFERENCESandM;1.andP;  Britton, K., and Parnas, D. A-7E software module guide.andP;  NRL Memo.andP;  Rep.andO;4702.andP;  December 1981.andM;2.andP;  Clements, P., Faulk, S., and Parnas, D. Interface specifications for theSCR (A-7E) application data types module.andP;  NRL Rep.andP;  8734, August 23.andP;  1983.andM;3.andP;  Currit, P.A.. Dyer, M., and Mills, H.D.andP;  Certifying the reliability ofsoftware.andP;  IEEE Trans.andP;  Softw.andP;  Eng.andP;  SE-12, ( Jan. 1986).andM;4.andP;  Heninger, K. Specifying software requirements for complex systems-Newtechniques and their applications.andP;  IEEE Trans.andP;  Softw.andP;  Eng.andP;  SE-6, (Jan.andO;1980), 2-13.andM;5.andP;  Hester, S.D., Parnas, D.L, and Utter, D.F.andP;  Using documentation as asoftware design medium.andP;  Bell Syst.andP;  Tech.andP;  J. 60, 8 (Oct.andP;  1981).andP;  19411977,andM;6.andP;  Knight, J,C., and Leveson, N.G.andP;  An experimental evaluation of theassumption of independence in multi-version programming.andP;  IEEE Traits.andO;Softw.andP;  Eng.andP;  SE-12, 1 (Jan.andP;  1986).andP;  96-109.andM;7.andP;  Knight, J.C.. and Leveson, N.G.andP;  An empirical study of failureprobabilities in multi-version software.andP;  Rep.andM;8.andP;  Leveson, N. Software safety: Why, what and how.andP;  ACM Comp.andP;  Surveys 18, 2(June 1986), 125-163.andM;9.andP;  Mills, H.D.andP;  Engineering discipline, for software procurement.andP;  COMPASS'87-Computer Assurance, June 29-July :3, 1987.andP;  Georgetown University,Washington, D.C.andM;10.andP;  Mills.andP;  H.D.andP;  The new math of computer programming.andP;  Commun.andP;  ACM 18, 1(Jan.andP;  1975), 43-48.andM;11.andP;  Mills, H.D., Basili, V.R., Gannon, J.D., and Hamlet, R.G.andP;  Principles  fComputer Programming A Mathematical Approach.andP;  Allyn and Bacon, Inc., 1987.andM;12.andP;  Mills, H.D., and Dyer, M. A format approach to software error removal.andO;J. Syst.andP;  Softw.andP;  (1987).andM;13.andP;  Mills, H.D., Linger, R.C., and Witt.andP;  B.I.andP;  Structured Programming:Theory and Practice.andP;  Addison-Wesley, Reading, Mass.. 1979.andM;14.andP;  Parker, A., Heninger, K., Parnas, D., and Shore, 1.andP;  Abstract interfacespecifications for the A-7E device interface module.andP;  NRI, Memo.andP;  Rep.andP;  4385,November 20, 1,1)80.andM;15.andP;  Parnas, D.L.andP;  Education for computing professionals.andP;  IEEE Comp.andP;  23, 1(Jan.andP;  1990), 17 22.andM;16.andP;  Parnas, D.L., and Clements.andP;  P.C.andP;  A rational design process: How andwhy to fake it.andP;  IEEE Trans.andP;  Softw.andP;  Eng.andP;  SE-12, 2 (Feb.andP;  1986), 251-257.andM;17.andP;  Parnas, D.L., Heninger, K., Kallander, J., and Shore, I. Softwarerequirements for the A-7E aircraft.andP;  NRL Rep.andP;  3876.andP;  November 1978.andM;18.andP;  Parnas, D.L., and Wang, Y. The Trace assertion method ofmodule-interface specification.andP;  Tech.andP;  Rep.andP;  89-261, Queen's University.andO;TRIO (Telecommunications Research Institute of Ontario).andP;  october 1989.andM;19.andP;  Parnas, D.L., and Weiss, D.M.andP;  Active design reviews: Principles andPractices.andP;  In Proceedings of the 8th International Conference on SoftwareEngineering (London, August 1985).andM;ABOUT THE AUTHORS:andM;DAVID L. PARNAS is professor of Computing and Information Science at Queen'sUniversity in Kingston, Ontario.andP;  His work interests involve most aspects ofcomputer system engineering.andP;  His special interests include precise abstractspecifications, real-time svstems, safety-critical software, programsemantics, language design, software structure, process structure, andprocess synchronization.andM;A.andP;  JOHN VAN SCHOUWEN, currently completing his master's thesis at Queen'sUniversity, is a research associate at the Telecommunications ResearchInstitute of Ontario.andP;  His research interests include formal and precisesoftware documentation.andM;Authors' Present Address: Dept.andP;  of Computing and Information Science,Queen's University.andP;  Kingston, Ontario, Canada K71, 3N6.andM;SHU PO KWAN is a specialist in nuclear reaction and nuclear structure.andP;  Hehas also done research work in computer simulation and modelling.andP;  Author'sPresent Address: 1118 Avenue Rd., Toronto.andP;  Ontario, Canada M5N 2E6.andM;TABLE 1.andP;  Probability That a System With Failure Probability ofandM;.001 Will Pass N Successive TestsandM;h=1000.andM;N      M= (1 - 1/h)[.sup.N]andM;500        0.60638andM;600        0.54865andM;700        0.49641andM;800        0.44915andM;900        0.40639andM;1000        0,3670andM;1500        0.22296andM;2000        0.13520andM;2500        0.08198andM;3000        0.04971andM;3500        0.03014andM;4000        0.01828andM;4500        0.01108andM;4700        0.00907andM;5000        0.00672andM;TABLE II.andP;  Probability That a System With Failure Probability ofandM;.000001 Will Pass N Successive TestsandM;h=1000000.andM;N       M= (1 - 1/h)[.sup.N]andM;1000000.andP;      0.36788andM;2000000.andP;      0.13534andM;3000000.andP;      0.04979andM;4000000.andP;      0.01832andM;5000000.andP;      0.00674andM;6000000       0.00248andM;7000000.andP;      0.00091andM;8000000.andP;      0.00034andM;9000000.andP;      0.00012andM;10000000.andP;     0.00005andM;h = 1 000000.andM;N       M = (1 - 1/h)[.sup.N]andM;4000000.andP;       0.01832andM;4100000.andP;       0.01657andM;4200000.andP;       0.01500andM;4300000.andP;       0.01357andM;4400000.andP;       0.01228andM;4500000.andP;        .01111andM;4600000.andP;       0.01005andM;4700000.andP;       0.00910andM;4800000.andP;       0.00823andM;4900000.andP;       0.00745</TEXT></DOC>