<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF207-500-382  </DOCNO><DOCID>07 500 382.andM;</DOCID><JOURNAL>Communications of the ACM  August 1989 v32 n8 p939(13)* Full Text COPYRIGHT Assn. for Computing Machinery, Inc. 1989.andM;</JOURNAL><TITLE>Computing, research, and war: if knowledge is power, where isresponsibility? (Social Aspects of Computing special section)</TITLE><AUTHOR>Beusmans, Jack; Wieckert, Karen.andM;</AUTHOR><SUMMARY>The use of artificial intelligence in warfare gives rise toprofound questions concerning moral responsibility.andP;  Since moralresponsibility cannot be ascribed to inanimate objects, it isdifficult to point a finger at the person or persons behind thedestruction brought about by so-called autonomous weapons.andO;Whether responsibility belongs to the soldier who discharged theweapon, the commander who issued the order to do so, the enemy whoprovoked it or the engineer who designed the thing is not easilydetermined.andP;  These are problems that the computer professionalmust come to terms with.andP;  Computer professionals are morallyobligated to at least inquire into the purpose of the systems theyhelp develop.andM;</SUMMARY><DESCRIPT>Topic:     Social ResponsibilityMilitaryEthicsArtificial intelligence.andM;</DESCRIPT><NOTE>Only Text is presented here; see printed issues for graphics.andO;</NOTE><TEXT>Computing, Research, and War: If Knowledge is Power, Where is Responsibility?andO;In the United States, artificial intelligence (AI) research is mainly a storyabout military support for the development of promising technologies.andP;  Sincethe late 1950s and early 1960s, AI research has received most of its supportfrom the military research establishment.andP;  Not until the 1980s, however, hasthe military connected this research to specific objectives and products.andP;  In1983, the $600-million Strategic Computing Program (SCP) created threeapplications for &quot;'pulling' the technology-generation process by creatingcarefully selected technology interactions with challenging militaryapplications&quot;.andP;  These applications, an autonomous land vehicle, a pilot'sassociate, and a battle management system, explicitly connect the three armedservices to further AI developments.andP;  The Defense Science Board Task Force onthe &quot;Military Applications of New-Generation Computer Technologies&quot;recommended warfare simulation, electronic warfare, ballistic missile defenseand logistics management as also promising a high military payoff.andM;In this 1983 &quot;Star Wars&quot; speech, PResident Reagan enjoined &quot;the scientificcommunity, ...andP;  those who gave us nuclear weapons, ...andP;  to give us the meansof rendering these nuclear weapons impotent and obsolete&quot;.andP;  As in theManhattan and hydrogen bomb projects, AI researchers and more generallycomputer scientists are expected to play major parts in this quest for adefensive shield against ballistic missiles.andP;  Computing specialists such asJohn von Neumann played a supportive role by setting up the computationsnecessary for these engineering feats--with human &quot;computers&quot; for the atombomb and with ENIAC and other early computers for the hydrogen bomb.andP;  The&quot;Star Wars&quot; project challenges computer scientists to design an intelligentsystem that finds and destorys targets--basically in real-time and withouthuman intervention.andM;The interdependence of the military and computer science rarely surfacesduring our education as computer practitioners, researchers, and teachers.andO;Where might information concerning these important military applicationsenter into computer science and AI education?andP;  Where do students receiveinformation concerning the important role they may play in weapon systemsdevelopment?andP;  One of our students recently remarked that &quot;as a computerscience major, I did not realize the magnitude of the ramifications ofadvancing technology for the military ....andP;  In a field so dominated by theDoD, I will have to think seriously about what I am willing and not willingto do--and what lies in between those two poles.&quot;andM;As researchers and educators, the authors wish to encourage colleagues andstudents to reflect upon present and historical interactions between computerscience as an academic discipline and profession, and military projects andfunding.andP;  As computer professionals, we lay claim to specialized knowledgeand employ that knowledge in society as developers of computing technologies.andO;Thus, we exercise power.andP;  Recognizing that as professionals we wield power,we must also recognize that we have responsibilities to society.andP;  To actresponsibly does not mean that computer professionals should advocate acomplete separation between computer science and military missions.andP;  However,we should openly examine the inter-relationships between the military and thediscipline and practice of computing.andP;  To act responsibly does not mean thatcomputer scientists and practioners should eschew support or employment fromthe military, although some are justified in taking such a stance.andP;  To actresponsibly requires attention to the social and political context in whichone is embedded; it requires reflection upon individual and professionalpractice; it requires open debate.andP;  The lack of attention to issues ofresponsibility in the typical computer science curriculum strikes us as agrave professional omission.andP;  With this article, we hope to add material tothe dialogue on appropriate computing applications and their limits.andP;  We alsohope to provoke reflections on computing fundamentals and practice at theindividual, professional, and disciplinary levels, as well as prodinggovernment institutions, professional societies, and industry to supportin-depth research on the issues we raise here.andM;Reflection requires information and discussion.andP;  Academic computer sciencedepartments rarely support serious consideration of even generalissues underthe rubric of the social and ethcial implications of computing.andP;  Unlike anyother U.S.andP;  computer science department, Information and Computer Science(ICS) at UC Irvine has an active research program in the social implicationsof computing (Computers, Organizations, Policy and Society--CORPS).andP;  Evenwithin CORPS, research that addresses the interactions between the militaryand computer science is difficult to pursue--not because individuals aren'tinterested, but because they are not able to find professional or academicsupport.andP;  The authors' interests in these issues arose from personal concernsover the dependence of military systems upon complex technology, and thepossible grave outcomes of this fragile relationship.andP;  CORPS provided asupportive intellectual environment that allowed us to pursue our interests.andO;In 1987, we developed and taught an undergraduate course designed to informstudents about military applications and their limits, and allow dialogue onprofessional responsibilities.andP;  In general, little monetary support isavailable for research that considers these issues, and it is only throughsupport from the Institute on Global Conflict and Cooperation and campusinstructional funds that we were able to develop and teach the course.andM;Few researchers or educators can devote time and/or energy to pursue thesocial and ethical implications of their work and profession, in addition totheir &quot;mainstream&quot; research.andP;  Since the discipline of computer science doesnot consider these reflections serious &quot;mainstream&quot; research, those who choseto pursue these vital questions have difficulties finding employment and/oradvancing through the academic ranks.andP;  Growing concern over these issues andinterest by computer scientists, as evidenced by the group ComputerProfessionals for Social Responsibility, individuals such as David Parnas,and this article, may lead to future research support and academicrecognition.andM;For now, as concerned professionals, we offer the following reviews.andP;  Theypose many more questions than answers.andP;  This article exemplifies theinterdisciplinary investigations which are required as precursors to seriousanalysis of computing use in these applications.andP;  We hope that our reviewsgenerate discussion and debate.andP;  In the first section, we present the courserationale and content, as well as student responses.andP;  In the sectionsfollowing the course description, we consider three applications--smartweapons, battle management, and war game simultations--that are generatingresearch and development funds and that have controversial inplications formilitary uses of computing.andP;  We start with smart weapons, that is, thedevelopment of weapons that can destroy targets with minimal humanintervention.andP;  Next we look at battle management systems designed tocoordinate and assess the use of resources and people in warfare.andP;  Finally,we turn to war gaming as a means for evaluating weapon performance andstrategies for war fighting.andP;  In each case, we describe the state oftechnology, its current and potential uses and its implications for theconduct of war.andM;A COURSE ON COMPUTERS AND MILITARYandM;TECHNOLOGYandM;MotivationandM;A university degree, either in computer science or a cognate discipline suchas mathematics, serves as the certification process for computerpractitioners.andP;  Individuals with such degrees are assumed to possessspecialized and useful knowledge for developing industrial and militaryproducts.andP;  During their university years, few students learn about theposition of their profession in society, or the individual, group andsocietal ramifications of the products they will help develop.andP;  More oftenthan not, if computer professionals confront the implications of computing,they do so after completing their university education.andP;  This lack ofemphasis on the implications of computing in the universities leaves computerpractitioners ill-prepared to make personal or professional decisions notdirectly following from their technical training, and in particular tounderstand applications within the military sector.andP;  In our opinion, this isa fundamental oversight in the education of computer professionals.andP;  Andsince many of our students find employment within the Southern Californiadefense industry, and overall large numbers of computer professionals work onmilitary projects, we felt it appropriate that prospective computerprofessionals be exposed to the use of computers in the military.andM;Even without special courses, students could gain exposure to militaryapplications through discussions in other courses or in textbooks.andP;  However,professors rarely analyze these applications in their courses and textbooksgive at best superficial treatment to computing applications, includingmilitary.andP;  As an example, consider a student specializing in artificialintelligence.andP;  In his widely used AI textook, Winston states that one goal ofAI is to make computers more useful in business, engineering, manufacturing,farming, mining, education, health and households; he never mentions militaryapplications.andP;  And Winston's textbook is by no means an exception.andP;  Militaryapplications are basent from Nilsson's 16-page prologue on the applicationsof AI, as well as Rich's and Charniak and McDermott's textbooks.andP;  Althoughthe encyclopedic Handbook of Artificial Intelligence mentions in passing that&quot;the Advanced Research Projects Agency (ARPA) of the U.S.andP;  Department ofDefense [i] a major sponsor of AI research,&quot; the detailed discussion ofapplications focuses exclusively on science, medicine and education.andP;  To befair, some of these books were written before the SCP and SDI were announced,yet it couldn't have escaped the authors' attention that their research wasalmost entirely funded by DoD.andM;This sanitization of AI applications is absent in some non-standard texts onAI.andP;  For instance, Zusne's book on vision discusses military applications ofvisual perception and reasons for military interest, and Stevens mentionssome military applications of image understanding systems.andP;  But even thesetreatments are cursory; for example Schutzer, who mentions the goals ofDARPA's SCP and a number of other ongoing DoD programs, summarizes futureapplications of knoledge-based systems by giving specific examples for everycategory but the military.andM;Because of this superficial treatment, student can earn their bachelor's andeven doctoral degrees in computer science without ever learning of militaryapplications, let alone their possible ramifications on the conduct of war,national and international economies, and professional careers.andP;  For thisreason, we developed and taught an upper-division course on computers in themilitary.andP;  In ICS, students are required to take a course in Computerizationand Society, and in 1987 our course Computers and Military Technology alsofulfilled this requirements.andP;  (See syllabus and reding list.)andM;ContentandM;Approximately 30 ICS students enrolled--half jniors and half seniors.andP;  Priorto the course, students had only vague notions about the military role ofcomputers and AI and about the funding of academic research.andP;  The studentswere interested and eager to discuss these issues and inform themselves; inspite of the reading load, there was minimal moaning and groaning.andP;  Thestudents' attitudes spanned the political spectrum; some considered thecourse too conservative, while others found it too liberal.andP;  A number ofstudents took the course out of deep political and personal convictionsagainst military applications; some used the course as a springboard intodefense industry careers; others to expose themselves to multipleperspectives on the military.andP;  In one course evaluation, a student noted that&quot;I realize that before I enter the working world, I must make a decisionconcerning whether or not I should work for a defense related company, and ifso, to what extent I should work on potentially destructive projects ...andP;  Irealize it will require still more though and information before I decidewhere I will draw the line.&quot;andP;  Another student eloquently argued that computerscience departments should inform their graduates &quot;instead of ...andP;  belchinginto the work force 'computer techies' who are ignorant as to how they willbe used by society.&quot;andM;We presented the 10-week course in four sections.andP;  The first section wasdevoted to descriptions of specific military systems and computing componentswhich enabled them.andP;  We presented the development of technologies such asinter-continental ballistic missiles and multiple independently targetedreentry vehicles, cruise missiles, and command, control, communications andintelligence (C.sup.3.I) structures and organizations.andP;  We also invited aguest lecturer to discuss the history of war gaming and the present use ofexpert systems to model strategic decision-making.andM;The second section of the course was devoted to the infrastructure in whichcomputing and the military is embedded.andP;  We included lectrues on the generalhistory of U.S.andP;  science and technology, monetary and organizational supportfor U.S.andP;  computing research and development, and a description of themilitary-industrial-academic complex.andP;  One lectrue was devoted specificallyto sources of research funding in ICS.andP;  This was one of the more popularlectures, since the students hadn't realized the extent to which our owndepartment depends upon military funding (almost 50 percent of the fundingwas from the DoD in 1987).andM;In the third section, we focused on two cases which exemplified the militaryplans for computing technology and how these plans are carried out in themilitary-industrial-academic arena.andP;  We presented a short segment on theStrategic Computing Program, and a larger segment on SDI, including avideotape of a debate between computing scientists on the technicalfeasibility of the system and a debate between four students in the class.andO;This in-calss debate was extremely instructive, not only for those directlyinvolved, but also for the entire class.andP;  It taught valuable lessons on thediffculties of making sound arguments.andM;Finally, we examined the effects of technology development on militarystrategy, including the impact of anti-submarine warfare on deterrence andthe momentum toward launch on warning fed by increasingly accurate missilesembedded within &quot;real-time&quot; command, control and communication structures.andO;The final section also included a discussion of personal and professionaldecisions that other scientists and engineers, including computer scientists,have made both pro and con with respect to military funding, projects, andcareers.andM;The success of the course can be measured not only in the learning experienceof the students, but also of the instructors.andP;  In the future, we hope toteach this course again.andP;  Prior to our course, the required undergraduate andgraduate courses in Computerization and Society rarely included sections onmilitary applications.andP;  Presently, a draft of this article is used withinthese courses, and every quarter, one of the authors lectures on militarytopcis (e.g., SDI, C.sup.3.I, and departmental military funding) in variousICS courses.andP;  We hope that instructors in other institutions can follow ourexample and can use this article and other materials in their own teaching.andM;INTRUCTIONAL INSTRUMENTandM;The next three sections present overviews of military applications ofcomputing and AI technology.andP;  EAch description includes a brief generalhistory of the application, historical and planned uses of computingtechnology within the application, and a short discussion of the implicationsof the technology.andP;  We have included a number of references for eachapplication, which are by no means exhaustive nor completely up-to-date.andO;Programs, plans, and players change frequently in this arena.andP;  However, thereferences point to excellent sources of material, and an instructor coulduse this article as a starting point for a lecture on the applications, aclass on computing technology and the military generally, or possibly forbeginning a research endeavor.andP;  The overview also provides a background forstudents, and may pique their interest to search more widely for information.andM;SMART WEAPONSandM;In warfare one needs &quot;to shoot at real targets, not just real estate&quot;.andO;Conducting war requires decisions that distinguish real targets from merereal estate, locate these real targets, and finally destroy them.andP;  Smartweapons employ AI, particularly in guidance systems, to encapsulate decisionsabout identifying, precisely locating, and destroying targets.andP;  In thissection, we examine automated guidance from early cruise missiles to presentplans for autonomous vehicles.andM;The U.S.andP;  Navy and Sperry Gyroscope Co. performed the first experiments onguided missiles during the last years of the First World War.andP;  Their aerialtorpedo or flying bomb, essentially a pilotless airplane, did not becomeoperational before the end of the war and the program ended after thearmistice.andP;  During the Second World War, cruise missiles (the V-1 or buzzbomb) and ballistic missiles (V-2) were first used on a large scale.andP;  Thesemissiles relied on a primitive inertial navigation system to stay on courseand were rather inaccurate, often missing targets by many kilometers.andO;Improvements in inertial navigation over the last four decades now allowplanners to expect warheads of strategic ballistic missiles, such as the MX,to land within 80 meters of a target 11,000 kilometers away 50 percent of thetime.andP;  Unlike ballistic missiles, long range cruise missiles, with flights aslong as five hours, can miss their targets by considerable distrances becauseslight errors in inertial navigation build up over time.andP;  Thus, to increaseaccuracy, additional guidance techniques are being developed.andM;Today, cruise missiles use the TERMCOM (Terrain Contour Matching) system,which measures the height of terrain a missile flies over and compared itwith stored altitude maps of the area the missile is expected to pass on itsway to a target.andP;  When deviations from the expected path are detected, themissile's course is adjusted.andP;  Since TERCOM works only over hilly terrain, itis supplemented by systems that compare stored terrain images with imagestaken en route.andP;  These images can be based on visible light, infrared, orradar.andP;  Related guidance techniques are used in other missiles such as theExocet.andM;Although generally referred to as smart, these weapons are presently at bestable to home in on the silhouette of a large object selected by a humanoperator or follow a precomputed path to a target.andP;  In other words, theseweapons are far from being truly autonomous (in the sense of being able tofollow generic commands like &quot;destroy those [expletive] ships&quot;), butdevelopments point in that direction:andM;Although artificial intelligence is beginning to evolve in theory as variousuniversities and research laboratories delve into robotics, patternrecognition, interactive computing, and signal processing, it is still a longway from initial operational capability in terms of automatic targetidentification.andP;  The sophisticated algorithms now being evaluated requiremassive computational circuity....andP;  This means initially developing a seekerthat can discern shipping from background landmass; then, the seeker wouldhave to be improved so it can distinguish friendly shipping from hostile;and, finally, the seeker should evolve into one capable of discerningparticular ship classes from one another ...andP;  ongoing efforts in veryhigh-speed integrated circuitry (VHSIC) design must come to fruition in orderto embed the necessary recognition circuity in the Tomahawk [cruise missle].andM;Indeed, many programs are directed toward the goal of automatic targetidentification and guidance; the SCP's autonomous land vehicle mentioned isone example.andP;  The Army Science Board recommended that the Army establish a$100-million, three-year machine vision research program for targetidentification.andP;  Boeing Corporation is flight testing the Boeing Robotic AirVehicle 3000 which can be used for reconnaisance, electronic warfare, and asa dispenser of other smart munitions.andP;  Related work concerns teleoperatedrobots or remotely piloted vehicles, that is, robots controlled by radiosignals or a fiber optic cable.andP;  Thus, as one observer put it, Asimov's&quot;three laws of robotics,&quot; the most important of which states that robots areforbidden to injure people, &quot;will almost certainly be broken soon&quot;.andM;What are some implications of having smart, perhaps autonomous, weaponsavailable for use in warfare?andP;  First, to the extent that smart weapons areaccurate, they can be expected to minimize collateral (i.e., unintended)damage.andP;  The expectation of removing only the bad guys with little damage toinnocents, can lead to early use of these weapons in conflict, or possiblyeven initiation of conflict.andP;  This tendency may be reinforced by the abilityto distance one's own force from harm, for instance attacking without riskingone's own soldiers' lives.andP;  According to Gerstenzang, a Los Angeles Timesreporter, observers of the April 15, 1986 raid on Libya, in which laserguided bombs were used, suggested that &quot;without smart bombs, the decisionnever would have been made.... Anything that gives you accuracy does providea real temptation.andP;  It sanitizes the use of force ...andP;  there is a perceptionthat if you have a bomb that is smart enough, you can carry out missionswithout getting in harm's way.andP;  This is a fallacy&quot;.andM;Second, the qualification &quot;autonomous&quot; implies that a weapon bearsresponsibility for its own actions, that it is the computer's fault.andP;  Thisis, of course, nonsense.andP;  Responsibility for using an autonomous weapon restsnot only with the commanding officer who orders the use of a weapon and theoperator who decides to use it, but also with the weapon designers whoencapsulate knowledge of real targets and how to locate them.andP;  As a thoughexperiment, consider an incident similar to the My Lai massacre during theVietnam War, carried out not by humans who can be held directly responsible,but instead by runaway robots.andP;  We must actively guard against thepossibility that blame can shift to robots that act in some unforeseenmanner.andM;Lastly, increasing automation, such as that used for smart weapons, is butone manifestation of modern warfare that blurs the distinction betweensoldiers and innocents.andP;  In 1970, Senator Proxmire raised this potential forindiscriminate killing in a Senate presentation on the &quot;electronicbattlefied&quot; then in use in Vietnam, and to which we turn in the next section.andM;BATTLE MANAGEMENTandM;According to General Westmoreland, former U.S.andP;  Army Chief of Staff, &quot;we areon the threshold of an entirely new battlefield concept,&quot; one in which &quot;enemyforces will be located, tracked, and targeted almost instantaneously throughthe use of data-links, computer-assisted intelligence evaluation, andautomated fire control&quot;.andP;  At that time--1969--the United States was operatingthe Igloo White program, a program that came close to making Westmoreland'sfuture electronic battlefield a realty.andM;Igloo White, designed to prevent the North Vietnamese from getting suppliesto South Vietnam, was an electronic barrier erected across the Ho Chi MinhTrail in Laos.andP;  This barrier consisted of acoustic and seismic sensors thatbroadcast the sounds and vibrations caused by objects in their vicinity.andO;Aircraft, including drones, patrolled the area and relayed signals from thesesensors to the Infiltration Surveillance Center in Thailand where theinformation was analyzed.andP;  Locations of targets were sent to command andcontrol aircraft which would direct strikes, or to assessment officers in theThai surveillance center who could themselves direct aircraft to striketargets.andM;Igloo White brings to the forefront the same issues we raised in the contextof smart weapons.andP;  It allowed assessment officers to use force without havingto confront the consequences directly.andP;  It led to indiscriminate killingbecause seismic sensors cannot differentiate between soldiers and farmers.andO;In addition, it created an artificial reality in which people were reduced toblips on a display screen--blips that must be stopped, rather like a videoarcade game.andM;Research and development of battlefield automation and management hascontinued.andP;  Currently, the Army is using computers that assist in positioningartillery, directing fire, analyzing intelligence data, and conductingelectronic warfare.andP;  In 1985, the Army started the Army Command and ControlSystem program to oversee the acquisition of computers and communicationssystems at all levels.andP;  The cost estimates reach nearly $20 billion over thenext ten years.andP;  Expert systems are now being developed to aid or automatevaguely defined command and control tasks, in particular the &quot;integration(fusion) of data&quot;.andP;  The SCP aims at developing battle management software fora carrier battle group, initially calling for a system to warn of &quot;threats&quot;and improved interfaces between man and machine.andP;  Recently, SCP also startedwork on implementing the Army's AirLand battle doctrine, currently plannedfor use in Europe and Korea.andP;  The implementation calls for integrating expertsystems to plan maneuvers.andM;To test new battle management concepts, the Rome Air Development Center atGriffiss Air Force base in New York established a Battle Management Center toprovide a &quot;simulated operational environment.&quot; Early in 1985, the Centerawarded five-year research contracts to a number of New York universities toinvestigate (distributed) problem solving, speech and image understanding,and plan recognition.andP;  The Center is to serve as a test bed for battlemanagement expert systems and is expected to be used by the Strategic DefenseInitiative Office as well.andM;In addition to expert systems, human experts will also be developed at suchfacilities.andP;  As former Lieutenant General John Cushman points out:andM;In modern air/land (on air/land/sea) warfare, there are no real expertsbecause there has been no experience....andP;  But through simulation we can havethe experience of war--without the cost of war, and we can deelop experts.andO;When technical people can in a realistic and authentic battle simulationobserve what successful people do to gain their success, when they can askquestions of those (now) recognized &quot;experts,&quot; they can begin the arduousprocess of reducing the knowledge of these people to &quot;rules.&quot;andM;Using battle simulations to turn people into experts in warfare, buildingexpert systems to duplicate this expertise, and then perhaps using theseexpert systems in the next round of simulations in highly suspect.andP;  To date,successful expert systems have been developed in narrow, highly circumscribeddomains for which there are recognizable experts.andP;  Even involving more thanone expert in the process of engineering an expert system has led todifficulties, simply because individual experts' perspectives and motivesdiffer.andP;  The Army may be no more successful in its efforts at developinguseful expert systems, but in some cases at least their methods ofdevelopment are better.andP;  For example, they plan to develop intelligencesystems by starting with limited systems, followed by test and evaluationduring actual use in the field.andM;In summary, a substantial effort to automate various aspects of battle atboth the tactical and strategic levels is under way.andP;  As with smart weapons,we can ask to what extent a human decision maker is responsible for theconsequences when force is advised by such a system.andP;  Again, responsibilityfor decisions lies not only with the users of a battle management expertsystem, but also with the system's designers.andM;Automation of functions does not mean that things become any easier.andP;  Rather,the danger of being deluged by a &quot;data monster&quot; (tremendous amounts ofcollected information) is always present and &quot;understanding what [themonster] is trying to say is today's major communictions problem&quot;.andO;Furthermore, a tenet of battle is that information is never reliable orcomplete and that decisions are made under uncertainty.andP;  The quest forcertainty of knowledge and action through experts (human or machine) hasproved illusory and dangerous in the past--technological advances won'tremove that uncertainty.andP;  Worse yet, automation and expert systems inparticular can give an illusion of control which may be unwarranted.andP;  To whatextent can human decision makers be said to be in command of systems whosefunctioning becomes harder and harder to oversee and understand?andM;Leveson discusses human-computer interactions that are necessary to controlcomplex systems such as airplanes, air traffic, and industrial plants.andP;  Inparticular, she notes a trend toward humans supervising and monitoringcomputerized control systems, taking control only if the computer fails.andP;  Onequestion that arises is whether humans can be expected to take control in anemergency.andP;  To do so demands that operators be alert at all times so as notto be caught off guard.andP;  This need for more active participation andawareness on the part of human controllers coupled with the fact thataccidents are often caused by unanticipated events led Leveson to concludethat &quot;it is doubtful that computers will be able to cope with emergencies aswell as humans can.andP;  The emphasis should be on providing the human operatorwith an operational environment and appropriate information that will allowintervention in a timely and correct manner.&quot;andP;  As an important aside, Borningnotes that human intervention has been essential in resolving false alarms ofimpending missile attacks on the United States.andP;  This is particularlyrelevant in the context of a strategic defense system that must respondautomatically.andM;Focusing simply on technology misses organizations and procedures that embedtechnology within a much larger operational setting.andP;  The Cuban missilecrisis in October 1962 underlined the difficulties of controlling anddirecting a large, indeed global, system, especially when counteractingestablished procedures.andP;  A fascinating analysis of factors (in particular,organizational) that influenced the outcome of this crisis is given byAllison, who argues that the Navy implemented its established procedure for ablockade 500 miles from Cuba even though President Kennedy had ordered anaval blockade closer to Cuba to give the Soviets more time to consider theiractions.andM;In closing, the reservations of Robert R. Everett, president of MITRECorporation, a research organization involved in military command andcontrol, should be taken very seriously:andM;[I am] troubled by the goal of replacing the most expert people, especiallyby trying not only to replace them but to improve on their performance.andO;Human activities tend to be very complex.... The suggestion that AI systemsmay somehow solve problems that we do not ourselves understand may come truein the far future but at the moment is both unreasonable and dangerous.andO;People are useful; so are machines.andP;  Let us understand and provide for theirseparate roles.andM;Ironically, AI techniques, and expert systems in particular, are being usedin an attempt to improve our understanding of political and military decisionmaking, as we will explore in the next section.andM;WAR GAMINGandM;A war game is an attempt at a realistic dry run of war that allows players toexplore and evaluate different strategies, plan operations, or to simplybecome more familiar with a particular war plan.andP;  War games have a longhistory: Go or Wei-Hai originated in 3000 BC, and it is believed that theChinese invented chess almost four thousand years ago.andP;  More realistic wargames using relief maps, &quot;tin soldiers&quot; to represent infantry and cavalryunits, an arbiter to decide battle outcome, etc., were introduced by vonReisswitz, a Prussian lieutenant, in the early 1800s.andP;  Although simulationsusing human players can be quite realistic, they too have been consideredprime targets for automation since they are time consuming andirreproducible.andM;A more quantitative approach to the planning of military operations wasintroduced during the Second World War.andP;  Military operations were viewed andtreated as crude scientific experiments: operations were carefully planned,results measured and then fed back for plan adjustment.andP;  Game theory, themathematical analysis of the behavior of rational players, arose at about thesame time.andP;  A notorious game theoretic concept is the &quot;prisoner's dilemma&quot; inwhich two prisoners, unable to communicate with each other, are accused of acrime.andP;  If both prisoners confess, both will be punished mildly; if neitherconfesses, both go free.andP;  However, if one remains silent while the otherconfesses, the silent one receives sever punishment and the confessor isrewarded.andP;  What would a rational prisoner do?andP;  Assuming that each prisonerattempts to maximize his expected outcome, each will confess and both will beconvicted.andP;  The prisoner's dilemma has been viewed as a model of thesuperpower stand-off; unable to trust each other and hence to cooperate, bothend up worse off.andP;  Of course, these games are simplistic and fail to capturesalient aspects of the real world, for example, that the superpowers docommunicate to some extent.andM;Since the Second World War, increasing computer use has allowed someconvergence between these approaches to analyzing the behaviror of opposingnations.andP;  Computer programs are used to not only replace human players, butalso to process players' actions faster and in a predictable manner.andP;  Thisspeeds up a game and makes it more reproducible, although not necessarilymore analytic or intelligible.andP;  Computer programs, especially large ones, areideal hiding places for assumptions about the modeled situation.andP;  As Brewerand Shubik note, players and more importantly policy makers tend to takeresults at face value without realizing that whatever comes out of a computeranalysis is based upon underlying assumptions.andP;  Of course this problem is notlimited to programs modeling strategies and decision making, but applies toany large program.andP;  However, simulating strategic decision making differsfrom, say, simulating airflow around the wing of an airplane.andP;  The latterpredictions can be verified empirically, whereas the former cannot.andP;  Again,to talk about an expert system in the context of war gaming is misleadingsince there are no experts.andM;Commenting on his experience using AI techniques for war games at the RANDCorporation, Davis exhibits a healthy skepticism of expert systems:andM;The transparency of individual rules in English-like computer code wasmisleading; it was very difficult to review and comprehend entire rulemodules, in part because it was difficult to judge completeness....andP;  Therewas an insidious side to the practice of heuristic modeling--in taking thependulum swing away from rigorous quantitative modeling, there was a tendencyto write ad hoc rules without appropriate structure or theory.andM;Similarly, Anderson observes that &quot;there is nothing mystical or magical aboutAI, and the measure of our progress in exploiting the technology will be thespeed with which the term AI is replaced by the more pedestrian computermodel or computer simulation--for in the end, AI is just a fancy name for acollection of sophisticated computer programming techniques.&quot;andM;Unfortunately, skepticism is not the rule.andP;  Consider, for example, Schrodt'sconclusion: &quot;Symbolic and algorithmic tools such as pattern matchingoperation on massive historical event data bases may well prove capable offinding regularities where numerical and algebraic techniques operating onsmall sets of variables have failed.andP;  If a sturdy locked door fails to yieldto the blows of a sledgehammer, the solution is not necessarily a largesledgehammer; picking the lock may be the more effective strategy.&quot;andP;  Somehowpattern matching on massive databases does not strike us as analogous topicking a lock.andM;As with the previous applications, computer simulations of warfare distanceusers from the consequences of their actions.andP;  Nowhere tis this clearer thanin strategic nuclear war simulations in which counterforce strategies assumedto kill only 1,000,000 people are compared with countervalue strategies,which are assumed to kill hundreds of millions of people and possibly bringcivilization to a halt.andP;  Training our policy makers in the National SecurityCouncil or the Joint Chiefs of Staff or even in the White House on suchsimulations may have grave consequences if their choices are circumscribed to&quot;either a million or a hundred million dead.&quot;andM;DISCUSSIONandM;Recently, we received an advertisement for the C.sup.3.I Report, a biweeklybusiness report on military &quot;command, contorl, communications, andintelligence.&quot;andP;  The advertisement exhorts business to &quot;get advice on where toconcentrate your internal Randamp;D; learn which areas will get the biggest budgetsfor advanced research&quot; and to &quot;watch for artificial intelligence applicationsin many programs, including SDI.&quot;andP;  According to this advertisement, C.sup.3.Iis AI's future application.andP;  Although we do not see the military as the onlyfuture AI application, we see it as the &quot;hidden&quot; application--the one thateveryone in the field lives with but doesn't talk about.andM;As responsible citizens not only of the United States but also of the world,we have a right and responsibility to investigate to what use our efforts areput.andP;  We must not only concern ourselves with acquiring and applyingknow-how, but we must also simultaneously inquire into the purpose andmotivation behind the systems we develop.andP;  In the military arena, forexample, concerns about purposes and motivations often arise only after atechnology has been developed and applied to a specific weapons program: &quot;...andO;it is not apparent whether the U.S.andP;  Navy's cruise missile doctrine is beingformed by the serendipity of the technological push or by the pull of clearlystated operational requirements submitted by the forces afloat&quot;.andP;  Zuckermangoes even further when he asserts that &quot;today, military chiefs ...andP;  merelyserve as the channel through which the men in the laboratories transmit theirviews....andP;  It is he, the technician, not the commander in the field, whostarts the process of formulating the so-called military need....andP;  A newfuture with its anxieties was shaped by technologists, not because they wereconcerned with any visionary picture of how the world should evolve, butbecause they were merely doing what they saw to be their job.andM;We question the justifications and rationalizations given by some policymakers.andP;  For example, some argue that it is necessary to continue militaryresearch and development because it is necessary to know what is physically,biologically, chemically, computationally possible so as to be able tobalance any new developments in opposing nations.andP;  Clearly, knowing what youopponent can and cannot do increases your sense of security, and might resultin more realistic policies.andP;  More deeply, our culture seems to valueimprovement per se.andP;  While this is undoubtedly appropriate in many cases,improving weapons means improving our capability to slaughter people.andP;  Thusthe neutron bomb and third-generation nuclear weapons in general are attemptsat using the energy released by nuclear explosions more efficiently.andP;  Inthese cases, the qualification &quot;improvement&quot; is perverse, if not obscene.andP;  Toreturn to the original argument for development, i.e., the need to know whatis possible in principle, we would surely be more secure if certain weaponswere not developed.andP;  Justifying the testing of nuclear-pumped X-ray lasersbecause we have to know whether the Soviets could develop them echoes theprisoner's dilemma.andP;  It would be more sensible to try to cooperate and stemthe development of these devices and feel secure because neither side hasthis &quot;improved&quot; capability instead of feeling &quot;secure&quot; because both sideshave the same capability.andM;We do not mean to downplay the complexities of these issues, but it seemsthat many decisions are made from a rather narrow perspective, and indeedderive their rationality from it.andP;  Stepping back and assuming a broaderperspective leads one to question many decisions.andP;  Thus McNamara concludesthat four decades of seemingly rational military and political decisions haveled NATO to adopt an unacceptable first-use strategy that, if ever calledupon, would at the very least destroy Europe.andM;If we expect other people, including politicians, to assume a broader andmore long-term perspective, we should do the same.andP;  As computer professionalswe should expand our concept of &quot;job&quot; to include obtaining and disseminatinginformation about the broader ramifications of our work.andP;  In conclusion, weremind the readers of the ACM Code of Professional Conduct, Canon 2, EthicalConsideration One: &quot;An ACM member is encouraged to extend public knowledge,understanding, and appreciation of information processing, and to oppose anyfalse or deceptive statements relating to information processing of which he[sic] is aware.&quot;andM;Acknowledgments.andP;  We wish to thank the Institute on Global Conflict andCooperation of the University of California, the committee for InstructionalDevelopment at the University of California, Irvine, and the Department ofInformation and Computer Science at UC Irvine for their support.andO;</TEXT></DOC>