<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF107-936-988  </DOCNO><DOCID>07 936 988.andM;</DOCID><JOURNAL>AI Expert  Dec 1989 v4 n12 p26(6)* Full Text COPYRIGHT Miller Freeman Publications 1989.andM;</JOURNAL><TITLE>The third wave in neural networks. (new direction inneural-network research)</TITLE><AUTHOR>Levine, Daniel S.andM;</AUTHOR><SUMMARY>Interest in the study of neural networks has exploded in the pastdecade, with scientists from widely varying fields participatingin research, and it can only continue to increase with technicaladvances in different fields.andP;  Industrial applications, such asrobotic control and voice synthesis, have spurred interest inneural network research.andP;  Other advances in neurobiology andcomputer science have brought neural network theory to the fore inscientific and engineering circles.andP;  In fact, neural networktheory could be discovered t have a firmer scientific basis in thenear future.andP;  Further, the recent discovery of subnetworks used indifferent parts of the brain heralds a transformation inneural-network research known as the 'third wave'.andP;  With thistransformation, researchers are actually designing their ownimplementations of such subnetworks.andM;</SUMMARY><DESCRIPT>Topic:     Neural NetworksArtificial IntelligenceCognitive ScienceResearch and Development.andO;Feature:   illustrationchart.andO;Caption:   Generic categorization network. (chart)Generic selective-attention network. (chart)andM;</DESCRIPT><TEXT>the Third Wave in Neural NetworksandM;The growth of interest in neural networks during the 1980s has been one ofthe fastest for any field in the history of science.andP;  In 1981, the phrase&quot;neural network&quot; was barely recognized outside a small circle of researchers.andO;In 1988 and 1989, two annual international conferences in the field drewnearly 2,000 attendees each.andP;  A wide range of individuals are interested inthe field: computer scientists, mathematicians, engineers, physicists,biologists, psychologists, cognitive scientists, and even social scientistsand philosophers.andM;Any idea that becomes popular so rapidly is vulnerable to dismissal as a fad.andO;But how could neural networks possibly be a mere fad?andP;  Interest in cognitiveprocesses and intelligence, both artificial and natural, is nearly universal.andO;A fes technical advances in different fields were all that was necessary toconvert interest into research on the theory of neurobiologicalstructure-function relationships.andP;  Because of these advances, interest inneural networks can only increase.andM;Many factors contributed to the rapid growth of neural-network theory, butthree are particularly important.andP;  First, industrial applications in fieldssuch as knowledge processing, robotic control, pattern classification, speechsynthesis and recognition, and computer vision have encountered problems thattax the symbolic processing programs of mainstream AI.andP;  [1,2]  Second,experimental neurobiological methods and data analysis have advancedsignificantly.andP;  Techniques such as simultaneous electrode recording from upto 50 neurons and tomographic scanning of the entire brain have madeneurophysiology more amenable to quantification.andP;  At the same time, computingadvances (from personal computers to supercomputers) have made biologicaldata simulation easier.andP;  Third, publications such as J.J.andP;  Hopfield's &quot;NeuralNetworks and Physical Systems With Emergent Collective ComputationalAbilities&quot; [3] and D.E.andP;  Rumelhart and J.L.andP;  McClelland's ParallelDistributed Processing [4] have brought neural networks to the attention ofscientists and engineers.andM;In the next few decades, neural network theory could be established on afirmer scientific basis.andP;  For this establishment to occur, we must transcendboth the recent hype and the excessive skepticism (crackpot realism) of thelate 1960s and 1970s.andP;  Neural-network theory addresses complex problems, andno model has yet &quot;cracked&quot; the problems of categorization, attention, ormemory.andP;  However, neural-network theory has contributed to the steadyincrease in the knowledge of brain and cognitive functions and the ability toduplicate these functions in machines.andM;The scientific approach to knowledge argues that mental phenomena, like otherphenomena, should have some mechanistic basis that humans can eventuallyunderstand.andP;  According to Wiener, [5] scientists have a collective faith inthe idea that nature (including the mind) is governed by ordered laws, not bythe capricious decrees of a tyrant like Lewis Carroll's Red Queen.andP;  Neuralnetworks provide the methodology for quantifying the laws governingcognition.andP;  In this framework, the question &quot;are neural networks like thebrain?&quot; becomes a non-question.andP;  It's no longer a matter of whether or not tostudy neural networks, but which neural networks to study.andM;THE FIRST TWO WAVESandM;The rapid surge in popularity of the neural-network field obscures itsmaturity.andP;  The history of neural-network models, summarized (up to 1983) inmy review article, [6] shows that most modern ideas in network design haveantecedents.andP;  For example, the current distinction between input, hidden, andoutput units [4] owes much to Rosenblatt's early work on networks withsensory, associative, and response units.andP;  [7]  Rosenblatt, in turn, combinedextensions of the linear threshold law formulated by W.S.andP;  McCulloch and W.andO;Pitts [8] in 1943 with extensions of D.O.andP;  Hebb's learning law.andP;  [9]andM;The first wave, or origins, of neural networks hit in the 1940s and 1950s.andO;Scientists were captivated by the notion that neurons are digital on-offswitches (either firing or not firing), just as the new digital computers hadbits that were either on or off.andP;  From this idea developed the &quot;cyberneticrevolution,&quot; based on the analogy of brain and computer.andM;Of course, the brain has a long history of comparisons to state-of-the-arttechnology--in the late 19th century, the hydraulic pump; in the 1920s and1930s, the telephone switchboard; in the 1980s, the integrated circuit andthe hologram.andP;  These analogies should be regarded skeptically, though theyinspired more precise hypotheses that have advanced our understanding.andM;The 1960s and early 1970s produced a split between those interested inartificial intelligence and those interested in natural intelligence.andP;  AIresearch moved toward designing symbolic-processing programs for singlecognitive tasks (and ultimately expert systems for circumscribed classes oftasks) with little reference to how living animals perform such tasks.andO;[10,11]  This split was a natural outgrowth of specialization at that stageof knowledge; M. Minsky and S. Papert's Perceptrons [12] has been widelyblamed.andP;  But Minsky and Papert showed only that a small class of neuralnetworks (perceptrons with three layers and certain restrictions on numbersof interlayer connections) could not perform certain tasks in geometricpattern recognition.andP;  Furthermore, some of the tasks these perceptrons couldnot perform, such as discerning which of the two maze-like structures on thatbook's cover is connected, are also difficult for the human visual system.andO;Hence, the retreat from biological inspiration in AI must be regarded as aphenomenon in the sociology of science, not as the result of any technicaldiscoveries.andM;Neural-network research was far from dead during those years.andP;  Severalleaders in neural networks, such as Shun-ichi Amari, James Anderson, WalterFreeman, Stephen Grossberg, and Teuvo Kohonen, were already publishing.andO;These researchers moved beyond the binary (all-or-none) framework to buildnetwork models based on continuous (analog) and nonlinear interactions.andM;It was not until the early 1980s, however, that nonlinear and analogmechanisms became popular and the second wave of interest in neural networksbegan.andP;  Hopfield's 1982 article was not groundbreaking in its neural modelingconceptualizations; the types of nonlinear analog interactions discussed weresimilar to those discussed in earlier articles.andP;  [13,14]  Yet Hopfield's workmade two major contributions to the field: it described analog neural-networktheories to mainstream scientists, particularly computer scientists andphysicists, in understandable terms, and it suggested ways to build analoginteractions into electronic circuitry.andP;  Succeeding articles showed how toapply Hopfield's network to optimization problems.andP;  [15]andM;Things happened quickly after Hopfield's article.andP;  Many mainstream AIresearchers became &quot;connectionists,&quot; a movement culminating in ParallelDistributed Processing [4] in 1986.andP;  Connectionism models are based onactivities of nodes, strengths of connections between nodes, and laws(defined by difference or differential equations) for the changes over timeof these activities and connection strengths.andP;  Connectionist approaches tocognitive problems are often contrasted with earlier aproaches based onserial computer programs with intricate instructions but no nodes.andP;  Revivalof interest in (and funding for) biologically and psychologically inspiredneural networks also led to rediscovery of the work of pioneers who hadlabored in obscurity.andM;Ideally, as the interest in neural networks grows, so should the field'sunity and diversity.andP;  Netwrok ideas arising from widelly different sourcescan often be regarded as variants of a few fundamental ideas.andP;  Endlesscontroversies about who first developed a certain idea or whether or not acertain approach is the best one to take become less fruitful.andP;  It's time totranscend these controversies and discover principles.andM;THE THIRD WAVEandM;In biology, brain and cognitive processes are perhaps the hardest tounderstand.andP;  Their variability across phyla of animals, different brainregions, and (in humans) over 100 billion neurons have caused some eminentbiologists to despair of finding general principles of brain organization.andO;Foremost of these is Sir Francis Crick, of Watson-CRick DNA fame.andP;  To quoteRoberts: &quot;Nature may not work by grand principles, cautions Crick.andO;'Evolution is a tinkerer.andP;  It is opportunistic: anything will do as long asit works.'&quot; [16]andM;Unfortunately, some neurall-network theorists have been influenced by Crick'sgospel of disorder.andP;  But his tinkerer metaphor, if carried further, undercutshis own argument.andP;  What do woodworking tinkerers do?andP;  They are indeedopportunistic but they use the same elements repeatedly--nails, screws, dowelrods, boards of a certain size, and so on.andP;  Likewise, the electronic tinkereruses capacitors, resistors, transistors, diodes, and solder in differentcombinations.andM;Therefore, neural networks should have principles analogous to nails orcapacitors: types of subnetworks and subnetwork connections that nature usesin different parts of the brain.andP;  The recent discovery of these principlesheralds another transformation in neural-network research in which engineersand theorists are learning principles but designing their own specificimplementations of them.andP;  We refer to this transformation as a &quot;third wave&quot;npartly in honor of Toffler's The Third Wave [17]).andM;Any major cognitive process can be analyzed into component subprocesses.andO;Analysis of subprocesses will then suggest principles that can also be usedin models of other processes.andP;  The first example is the categorization ofsensory patterns.andP;  [18]  For definiteness, say that the network is processinghand-printed characters and attempting to match each one to a known letter ofthe alphabet.andP;  The simplest (but not only) way to understand this process isto include some units (feature nodes) in the network that respond to thepresence or absence of writing at particular locations, and other units(category nodes) that respond to patterns of feature node activationrepresenting particular letters.andM;To elaborate on our experiment, how are feature nodes likely to be connectedto category nodes?andP;  If the connections were hardwired, the network would lackflexibility if activation patterns changed dramatically--for example, thenetwork's receiving Japanese or Russian input instead of Roman characters.andO;Hence, the strength of the connection between any specific feature node andany specific category node should be allowed to change over time, as a resultof repeated activation of the connection.andP;  Such a change is oftenaccomplished by a principle called associative learning.andM;Associative learning has been one of the common subnetwork-organizingprinciples in neural networks since the early 1960s.andP;  But many categorizationmodels [19, 20] also use another organizing principle called competition.andO;Consider a sloppily written, ambiguous character; it could be either an E oran F.andP;  The network needs a method to decide which of the two letters is morelikely.andP;  The feature nodes are activated to varying degrees by the incomingletter, and in turn activate the category nodes via internode connections.andO;Category nodes have mutual inhibition (Figure 1).andP;  Thus, if both the E and Fnodes are activated but the activation of the E node is greater than that ofthe F node, the system passes E activity to the output level and supresses Factivity.andP;  Inhibition between nodes at the same network level is oftenregarded as competition between the different cognitive entities coded bythose nodes.andM;Associative and competitive principles are likely to combine in manycognitive processes besides categorization.andP;  A second example is selectiveattention.andP;  [18]  Suppose a neutral stimulus, such as the sound of a ringingbell, has become associated with food.andP;  How does the animal learn to pay moreattention to the bell than to other neutral stimuli in its environment?andO;Again, the psychological data suggests the neural-network principle ofcompetition.andP;  If different nodes develop representations of sensory stimuli,then the bell node should &quot;win&quot; a competition with other sensory nodes forstorage in short-term memory.andP;  Why is competition among sensory nodes biasedin the bell's favor?andM;One plausible answer suggests the associative learning principle.andP;  The bellnode tends to be activated because of prior association between the bell andfood, or more abstractly, between the bell and satisfaction of the hungerdrive (Figure 2).andP;  Therefore, if another node represents the primaryreinforcer of food or the hunger drive, repeated pairing of the bell and foodtends to activate the bell node if the animal is hungry.andP;  Strengtheningpathways based on pairing of stimuli is an example of associative learning.andM;These principles and others have been suggested by a database that is partlyphysiological and partly psychological.andP;  In some cases, the theory wassuggested by psychological results and later supported, at leastqualitatively, by physiological results.andP;  One example is associative learningtheory: in 1949, Hebb proposed that if one neuron sends a synapse to another,and the firing of the first neuron is repeatedly followed by firing of thesecond, then the synapse should become strengthened.andP;  [9]  Hebb's hypothesiswas based on evidence from classifical conditioning, without anyphysiological evidence.andP;  But examples of neuronal processes consistent withhis hypothesis were discovered after 1949, first in invertebrates [21] andlater in vertebrates.andP;  [22]  More recent experimental studies have partiallysupported mathematical variations of Hebb's learning law proposed by S.andO;Grossberg [23] and other modelers in the 1960s and 1970s.andM;Subnetworks incorporating principles such as associative learning orcompetition are part of the neural-network modeler's tool kit, as are largernetworks developed by major researchers in the field.andP;  For a givenapplication, the adaptive-resonance, back-propagation, orbrain-state-in-a-box theories might be suitable in some ways but not inothers.andP;  One can readily add or subtract connections in a model orconcatenate subnetworks from different models.andP;  [24,25]  Neural networksfulfill Toffler's prediction that future computer software will become morecustom-designed and less standardized.andM;When neural networks are used in brain modeling, new discoveries about thebrain or biological cognition may force modification of a theory rather thanabandonment of its entire structure.andP;  Also, a general theory may be widelyapplicable, but the detailed instantiation of that theory may vary greatlybetween individuals and species.andP;  A neural network that doesn't &quot;act like thehuman brain&quot; (so far, no network constructed does) can still be a good modelfor some parts of the brain.andP;  For example, the two-layer adaptive-resonancetheory, or ART, [19] is not =Grossberg's theory of how the brain works,&quot; asis widely believed.andP;  ART is a theory of how the brain performs patterncategorization; for a complete brain theory, it would have to be combinedwith networks that perform many other tasks, such as pattern preprocessing,selective attention, and spatial and temporal segmentation.andP;  [26]andM;Both the technological and biological applications of neural networks haveyet to achieve their most exciting results.andP;  In technology, artificial neuralnetworks have achieved preliminary successes in applications for diverseproblems, including speech recognition and synthesis, using a knowledge basefor mortgage insurance advice, classifying radar patterns, and diagnosingautomobile malfunctions.andP;  These successes should multiply if neural-networkusers can avoid gadget fetishism--the tendency to use the most advancedpossible technology on a problem even when it's inappropriate.andM;In neurobiology, network models have led to significant explanations forperipheral brain functions, such as vision, and more tentative analyses ofcentral brain functions.andP;  Neural-network theory has even touched the study ofsome of nature's cruelest experiments, psychiatric and neurochemicaldisorders.andP;  [27]  As the theoretical organizing concepts become refined andsolidified, they will play a larger part in driving the design of futureexperiments by behavioral neuroscientists, psychologists, and clinicalneurologists.andM;Neural networks study will become more interdisciplinary as the third wavecontinues.andP;  The field is open to the intellectually curious, regardless ofspecialties.andM;REFERENCESandM;[1] Hewitt, C. &quot;Concurrency in Intelligent Systems,&quot; AI EXPERT, Premier 1986,pp.andP;  44-50.andM;[2] Winograd, T. and F. Flores.andP;  Understanding Computers and Cognition: A NewFoundation for Design.andP;  Norwood, N.J.: Ablex, 1987.andM;[3] Hopfield, J.J.andP;  &quot;Neural Networks and Physical Systems with EmergentCollective Computational Abilities.&quot;andP;  Proceedings of the National Academy ofSciences USA 79 (1982): 2554-2558.andM;[4] Rumelhart, D.E.andP;  and J.L.andP;  McClelland (eds.) Parallel DistributedProcessing.andP;  Cambridge, Mass.: MIT Press, 1986.andM;[5] Wiener, N. The Human Use of Human Beings.andP;  New York, N.Y.: Avon Books,1954.andM;[6] Levine, D.S.andP;  &quot;Neural Population Modeling and Psychology: A Review.&quot;andO;Mathematical Biosciences 66, 1983.andM;[7] Rosenblatt, F. Principles of Neurodynamics.andP;  Washington, D.C.: SpartanBooks, 1962.andM;[8] McCulloch, W.S., and W. Pitts.andP;  &quot;A Logical Calculus of the Ideas Immanentin Nervous Activity.&quot;andP;  Bulletin of Mathematical Biophysics 5 (1943): 115-133andM;[9] Hebb, D.O.andP;  The Organization of Behavior.andP;  New York, N.Y.: John Wiley andamp;Sons, 1949.andM;[10] Newell, A., and H.A.andP;  Simon.andP;  Human Problem Solving.andP;  Englewood Cliffs,N.J.: Prentice-Hall, 1972.andM;[11] Winston, P.H.andP;  Artificial Intelligence.andP;  Reading, Mass.: Addison-Wesley,1977.andM;[12] Minsky, M., and S. Papert.andP;  Perceptrons: An Introduction toComputational Geometry.andP;  Cambridge, Mass.: MIT Pres, 1969.andM;[13] Grossberg, S. &quot;Contour Enhancement, Short-term Memory, and Constanciesin Reverberating Neural Networks.&quot;andP;  Studies in Applied Mathematics 52 (1973):213-257.andM;[14] Amari S. &quot;Dynamics of Pattern Formation in Lateral-Inhibition TypeNeural Fields.&quot;andP;  Biological Cybernetics 27 (1977): 77-87.andM;[15] Hopfield, J.J., and D.W.andP;  Tank.andP;  &quot;Neural' Computation of Decisions inOptimization Problems.&quot;andP;  Biological Cybernetics 52 (1985): 141-152.andM;[16] Roberts, L. &quot;Are Neural Nets Like The Human Brain?&quot;andP;  Science 243 (1986):481-482.andM;[17] Toffler, A. The Third Wave, New York, N.Y.: Bantam Books, 1980.andM;[18] Levine, D.S.andP;  Introduction to Neural and Cognitive Modeling.andP;  Hillsdale,N.J.: Erlbaum (forthcoming in 1990).andM;[19] Carpenter, G.A., and S. Grossberg.andP;  &quot;A Massively Parallel Architecturefor a Self-Organizing Neural Pattern Recognition Machine.&quot;andP;  Computer Vision,Graphics, and Image Processing 37 (1987): 54-115.andM;[20] Rumelhart, D.E., and D. Zipser.andP;  &quot;Feature Discovery by CompetitiveLearning.&quot;andP;  Cognitive Science 9 (1985): 75-112.andM;[21] Kandel, E.R., and L. Tauc.andP;  &quot;Heterosynaptic Facilitation in Neurones ofthe Abdominal Ganglion of Aplysia Depilans.&quot;andP;  Journal of Physiology 181(1965): 1-18.andM;[22] Bliss T.V.P., and T. Lomo.&quot;andP;  Long-Lasting Potentiation of SynapticTransmission in the Dentate Area of the Anaesthetized Rabbit FollowingStimulation of the Perforant Path.&quot;andP;  Journal of Physiology 232 (1973):331-356.andM;[23] Grossberg, S. &quot;Embedding Fields: A Theory of Learning with PhysiologicalImplications.&quot;andP;  Journal of Mathematical Psychology (1969): 209-239.andM;[24] Hecht-Nielsen, R. &quot;Counterpropagation Networks.&quot;andP;  IEEE FirstInternational Conference on Neural Networks II (1967): 19-32.andM;[25] Elsberry, W.R.andP;  &quot;Integration and Hybridization in Neural NetworkModeling,&quot; unpublished M.S.andP;  thesis, University of Texas at Arlington, 1989.andM;[26] Grossberg, S. Neural Networks and Natural Intelligence.andP;  Cambridge,Mass.: MIT Press, 1988.andM;[27] Levine, D.S., and S.J.andP;  Leven (eds.)andP;  Motivation, Emotion, and GoalDirection in Neural Networks.andP;  Hillsdale, N.J.: Erlbaum (forthcoming in1990).andM;Daniel S. Levine is an associate professor of mathematics at the Universityof Texas, Arlington.andO;</TEXT></DOC>