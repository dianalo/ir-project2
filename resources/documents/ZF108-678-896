<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF108-678-896  </DOCNO><DOCID>08 678 896.andM;</DOCID><JOURNAL>AI Expert  July 1990 v5 n7 p34(5)* Full Text COPYRIGHT Miller Freeman Publications 1990.andM;</JOURNAL><TITLE>Knowledge acquisition in a medical domain. (expert-systemdevelopment for medical applications offer challenge for knowledgeengineers)</TITLE><AUTHOR>Mouradian, William H.andM;</AUTHOR><SUMMARY>The development of expert system applications for the field ofmedicine presents special problems in knowledge acquisition andrepresentation.andP;  The development of an expert system for selectingcandidates for back surgery is discussed.andP;  Problems with buildinga knowledge base from the scientific literature and breaking thethought process down into rules are discussed.andP;  The use of Lotus1-2-3 for representing pages of flow diagrams, rules, reminders,and exceptions is described.andM;</SUMMARY><DESCRIPT>Topic:     Medical Advice SystemsMedical DiagnosisAcquisition SystemsKnowledge-Based SystemsExpert SystemsSurgeryProgram Development Techniques.andM;</DESCRIPT><TEXT>Medicine is still an art, using science for only its most basic foundations.andO;Everyday practice relies on the case-study method, trial and error, andintuitive judgment more heavily than is commonly believed.andP;  Surgicalspecialties in particular rely essentially on intangibles.andM;For example, human motivation is a complex matter affected by many variables.andO;Yet in many medical domains, patient motivation plays a significant role inthe outcome; in these areas, hidden variables may be operative.andP;  An excellentexample is a surgery for pain, such as back surgery-one of the mostnotoriously unpredictable operations.andP;  As many as 40% of some 200,000surgical procedures performed annually fail because human motivation, withall its vagaries, plays a significant role in recovery.andP;  How does an expertsystem measure &quot;motivation&quot;? Another insurmountable problem is our inabilityto perform controlled double-blind surgical studies on human volunteers.andP;  Theefficacy, rigorously defined, of many procedures is thus uncertain.andM;Expert-system development in a medical domain therefore presents specialproblems in knowledge acquisition and representation.andP;  This article willoutline the evolution of an expert system used to elect candidates for backsurgery and explore the problems I encountered.andM;KNOWLEDGE ACQUISITIONandM;Basic science as a starting point will be problematic.andP;  In many areas ofmedicine, the scientific foundations are less robust than is commonlyassumed.andP;  Molecular mechanisms of disease are usually hypothetical, notestablished.andM;Building a knowledge base from the scientific literature is likely to befrustrating.andP;  Estimates suggest that less than one percent of the articles insome specialties fulfill scientific criteria.andP;  Differentpractitioners-especially surgeons-produce different results and publishaccordingly.andP;  Academic experience frequently fails to parallelprivate-practice experience (and vice versa) for many reasons.andP;  Differentarticles on the same subject may sample different populations, although thedifferences may not be apparent.andM;Patient selection for many retrospective and some prospective studies ofteninvolves intangible, nonverbal, or other intuitive processes.andP;  The literaturemay ignore this fact because the writers are unaware of these processes.andO;These vagaries are further compounded by literary &quot;fads.&quot;andM;Any scientific discipline relies heavily on early literature to clear avenuesfor research, but in medicine more trends disappear than remain.andP;  However,literature rarely reflects the fading of trends, thereby leaving a peculiarliterary-historical bias.andP;  Only favorable articles may exist about a givenprocedure although its popularity may have long since waned.andP;  Therefore,should you assume a decline in popularity from a lack of recent literature-,You may as easily make the reverse error by concluding that a procedure is nolonger popular because no new literature is available-which, of course, isnot necessarily true.andM;Building a knowledge base from a standard clinical examination will also betroublesome.andP;  Traditionally, information gathering in medicine follows asequence that comprises a history (interview), examination, and one or moreconfirmatory laboratory tests that may substantiate or repudiate the workingdiagnosis.andP;  Although the interview is crucial, significant problems existeven with this elementary exercise-pain and disability are frequent primarycomplaints, but how can they be measured? Pain is a subjective response andnot quantiliable; so is disability.andP;  In addition, patients may contradictthemselves, sometimes repeatedly, when describing symptoms.andM;How patients answer depends on how the questions are asked, as well as whoasks them.andP;  People also answer questions the way they think they should beanswered.andP;  Thus, the data is contextual, depending on the facts and on thefact-gathering mechanism.andP;  The problem can't be solved by a writtenquestionnaire since many questions require rewording and rephrasing.andO;Litigation adds another dimension of confusion, because patients may try toanswer questions to affect the litigation's outcome favorably.andM;In most cases of back pain, and in many other areas of medicine, physicalexamination is not helpful.andP;  Even the most popular &quot;infallible&quot; signs are notalways reproducible.andM;Many readily available laboratory tests are neither sensitive nor specific.andO;In spine surgery, modern noninvasive imaging techniques, including the MRIand C/T scans, have not improved on the 30-40% false positive rate of themyelogram, which goes back to the 1940s.andP;  (The C/T scan and myelogram alsoyield up to 16% false negative results.andP;  Although the discogram is sometimesconsidered to be the standard, the test is expensive, time-consuming,invasive, and has some morbid overtones; widespread use is impossible.andM;All of this leads to the vague but crucial concept of the patient'scredibility.andP;  To a large extent, the weight the practitioner attaches to acomplaint depends on how credible, reliable or believable-intentionally orunintentionally-they perceive the patient to be.andP;  This problem is significantfor the knowledge engineer since clinicians assess credibility intuitivelyand unsystematically in a continuing, probably recursive, way.andP;  lo establishcredibility, the clinician looks for consistency across all aspects of theassessment, frequently by searching for subtle inconsistencies.andP;  A processthat is elusive to humans is even more so for an expert system.andM;Even when performing a surgical intervention, determining the outcome may bedifficult for many reasons.andP;  Surgeons frequently report on their own caseseries.andP;  What exactly is a &quot;successful&quot; surgerywhen the patient would do itall over again? When they return to work; Or when the surgeon thinks thesurgery is a success;andM;Physicians and surgeons differ widely in their capabilities and hence theirresults.andP;  One surgeon's results do not predict another's; they depend on thepopulation, just as in other biological systems.andP;  Even in the samepopulation, results of treatment also follow distribution curves even whenthe same surgeon consistently operates on the same lesion in the samepopulation.andP;  Which physician, population, and set of- results will you use inyour system? Will it apply to other similar but not identical domains?andM;THE CHECKLISTandM;Medical decision making relies on an imprecise conglomeration of informationgathered in different ways and processed in a largely intuitive and recursivefashion.andP;  Hundreds of details are observed, recalled, and processedunsystematically; much less conscious effort is used than may be surmised.andO;Details are fleeting and observed in passing, and many of the observationsare of nonverbal behavior.andP;  As a result, the clinician will have difficultyarticulating the details of their observations and reasoning, rememberingonly the overall impressions.andP;  Decision making in medicine is quiteintuitive.andM;As an intern, I was disenchanted by the inability of many of my instructorsto explain their decisions, and I faced the same problems as an instructor insubsequent years.andP;  Overall impressions were gathered and decisions were made,but the process remained obscure.andP;  I found a partial solution in checklists,first introduced to me by Edward H. Simmons, then at the University ofToronto.andP;  Simmons had developed them for residents' and nurses' use inpreliminary patient screening.andP;  Eagerly, I developed one generation afteranother of checklists for history taking, physical examination, and so on.andO;Looking back at the checklist would ensure completeness of informationgathering and reveal the decision-making process.andM;In 1981, 1 made a crucial jump: rather than organizing the checklist into theclassical sequence of history, physical findings, and laboratory results, Ibegan to divide the list sections corresponding to different diagnoses.andP;  Iimagined that eventually a computer would tally and weigh these results insome mysterious fashion, suggesting diagnoses and treatment.andM;The ancestral precursor of the expert system in lumbar spinal surgerydecision making was born by rearranging checklists to correspond with diseaseentities rather than historical sections or body parts.andP;  As clinicians wentthrough the questionnaire, their answers added and subtracted points fromtallies toward the various disease entities in question.andM;When the first PC-based expert systems came out in the early 1980s, it waslogical to attempt to expand the checklist into an elementary expert system.andO;Several systems were tried using shells relying on LISP, PROLOG, and otherlanguages.andP;  I purchased early products randomly in quest of the  magicproduct to convert my questionnaire diagnoses, but to no avail.andM;PROBLEM AREASandM;I had enormous difficulty breaking down my thought processes into rules.andO;With considerable effort, I verbalized the most general rules used in mydecision making.andP;  Clinicians use many rules of inference, but they will havedifficulty enunciating them to the knowledge engineer.andM;Early expert systems were not robust enough to handle real-world problems;they used &quot;yes or no&quot; answers and if-then statements, perhaps withcertainties assigned but not much else.andP;  They also accepted numerical data,but integrating the logical and numeric operations was difficult.andP;  Somesystems handled either logical or numerical operations better.andP;  Even in thesame system, integrating those operations was difficult.andP;  Programmingexperience was mandatory for anything but trivial applications.andM;Medical decision making involves more than simple answers to if-thenstatements; most data is quantitative.andP;  Simple examples include temperature,blood pressure, and blood count, where the data is ratio (that is, trulynumeric) data.andP;  In clinical medicine, however, many measures are ordinal.andO;Ordinal scoring systems are common in medicine and evolved as a means forcomparison of patients, procedures, and results.andM;There are two problems.andP;  First, while clinicians may understand thedifference between ratio and ordinal data, in practice the distinctionbecomes blurred.andP;  They have a natural tendency to think of numbers asrepresenting ratio data.andP;  Second, and more importantly, computers alwaysassume numbers represent ratio data unless specifically instructed otherwise.andM;Ratio data is numerical data as we commonly imagine it: four is twice as muchas two.andP;  In many medical scales and rating systems, the data is ordinal andfour is not twice as much as two, but merely &quot;different than,&quot; &quot;more than,&quot;or &quot;greater than&quot; two.andP;  A response to treatment might be graded as &quot;1-5&quot;based on observations the clinician makes, but with five being best, it'sincorrect to assume that a response of four is &quot;twice&quot; as good as two.andP;  Thesescales provide a means for comparing individuals, but the scores themselvescannot be manipulated numerically.andM;Rather, the scores on a typical medical scoring system represent points on adistribution.andP;  For example, most patients might get a good response (three)to treatment, with some patients getting a minimal (one) or excellent  five)response.andP;  How will the knowledge engineer compare the results three andfive? Unless programmed differently, systems will assume five is exactly 60%more than three.andM;Another classic example is quantification of pain.andP;  We ask patients toquantify their pain on a scale of 1-100, where 100 is defined as pain thatrenders you unconscious.andP;  Therefore, a score of 60 is twice as much pain as ascore of 30.andP;  In the general case, 30 is simply different than 60, but nothalf, and not even necessarily less.andP;  Even in the special case of oneindividual, 30 is less than 60, but is it half as much? All we know is thatone patient perceives pain in one part of the scale while another patientchooses a different one.andM;The pain scale defines another distribution that is modestly normal inappearance.andP;  The mean has hovered near 60 for more than 2,000 cases.andP;  Mostpeople indicate their pain to be between 50 and 80.andP;  Outliers at the topperceive their pain as at the upper limit of their tolerance, and theconverse may be said of outliers at the lower end.andM;The knowledge engineer must establish what significance the scores have tothe clinician, rather than the actual value, to incorporate the data into thesystem.andP;  In this case, people between 50 and 80 are considered average, at 90or 100 overreacting, and with pains of less than 50 to be more stoic.andM;In summary, ordinal data creates problems for the knowledge engineer.andP;  Thefirst problem is recognition, the second is that expert systems will treatordinal data as ratio data until specifically instructed otherwise, and thethird is understanding how the clinician treats the different points on theordinal distribution.andM;One early product I tried was based on a Bayesian engine.andP;  Using my ownexperience rather than scientific data, I developed Bayesian rules.andP;  Thissystem produced fair results on a case-by-case basis but lacked essentialdatabase capabilities and had bugs.andP;  However, another crucial gap had beenbridged: in a medical domain, many rules are statements of likelihoods thatpieces of evidence are indicative of a disease process.andM;The Bayesian system prompted me to enunciate rules in this fashion.andP;  Therules reflect how many clinicians think, but a few colleagues castigated meon theoretical grounds for using Bayesian probabilities.andP;  They argued about&quot;priors,&quot;  Independence of variables,&quot; and so on.andP;  Compared to the impreciseand mysterious reasoning of clinical medicine, Bayes was relativelystraightforward.andP;  Of course, we don't know priors and, of course, allvariables are not independent, but it still seems closer to the mark than anyother technique for assessing diverse types of imprecise medical data.andM;Two years, thousands of dollars, and countless hours were spent, but auseable product was still not produced; I lacked the scientific background inmath, statistics, and programming.andP;  Although most systems were billed asuser-friendly, nontrivial applications required a considerable degree ofprogramming expertise.andP;  As a nonprogrammer, I encountered seeminglyinsurmountable programming problems implementing my rules lists.andM;THE TRUTH TABLEandM;Frustrated by my inability to develop a useful implementation of the rules, Ireturned to my checklists and realized that a spreadsheet might be an easiermedium to work with-the Lotus 1-2-3 truth table was born.andP;  Pages of flowdiagrams, rules, reminders, and exceptions could all be represented on asingle spreadsheet, if we ignored two major theoretical problems.andM;First, the input would have to be generally numerical, which the computerwould treat as ratio data, even though we knew we were almost invariablydealing with ordinal data.andP;  Second, Bayes would have to be replaced by moresimple statements.andP;  This replacement was a practical consideration, becausebuilding Bayesian formulae into each cell of a large spreadsheet createdprogramming and memory problems for PCs at that time.andM;Disease entities were listed in columns; characteristic symptoms, complaints,physical and laboratory findings were in rows.andP;  The rows propagated acrossthe spreadsheet, adding to or subtracting from scores for each diseaseentities, which accumulated in the columns.andP;  The raw scores were weighted foreach disease column by multiplying by weighting factors.andP;  Bayesianprobability statements were converted to simple ones about relative weightsof various bits of information.andP;  This system quickly produced a miniaturizedbut imprecise model.andM;Most importantly, a large database of normative data about the officepopulation was collected and analyzed as effectively as possible.andP;  Althoughstatistical significance could not be attached to many associations, Iobtained large quantities of normative data and associations that were usedin the next generation of knowledge base.andM;The spreadsheet is an important tool for developing prototypes of expertsystems: it forces the domain expert to articulate what &quot;goes in&quot; and what&quot;comes out.&quot; From there, the first set of arithmetic weightings can bedeveloped and the model tested.andP;  In many applications, normative data aboutthe population will need to be developed.andM;The spreadsheet can function alone or be used to input data to databaseprogram.andP;  Once a stripped-down simple arithmetic spreadsheet model is workingfairly well, the fine-tuning can be done later.andM;The problems with Lotus are two-fold.andP;  First, Lotus will handle logicaloperators, but the application required many large cell formulas.andP;  Thisrequirement was difficult and time-consuming because earlier Lotus releasesdisplayed them in a single line along the top of the screen.andP;  Large formulasrequire more than one cell for representation; as the system grew incomplexity it became increasingly  difficult to represent the nuances,exceptions, and so on in the cell formulas adequately.andM;The second problem is the number of macros needed for housekeeping; modifyingthe model becomes problematic because as the model becomes more complex, sodoes modification of its basic structure.andP;  Cell content (data and formulas)can be changed easily.andP;  Changing cell relations, however, such as moving,adding or deleting cells, rows, and columns is harder: in Lotus 1-2-3, macrosdo not automatically keep track of their relationships and movements.andP;  Rangesmay be used, but they also require maintenance if the structure of the modelis modified.andP;  Consequently, macro maintenance hampers major model revisions.andM;All in all, Lotus provides expedience at the expense of flexibility.andO;Nonetheless, it remains an invaluable tool for early prototype development.andM;William Mouradian, M.D., is in private practice in Los Angeles and is on theclinical faculty at the University of Southern California, Los Angeles.andO;</TEXT></DOC>