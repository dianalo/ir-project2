<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO> FR881202-0145 </DOCNO><DOCID>fr.12-02-88.f2.A1144</DOCID><TEXT><FTAG tagnum="4701"/><ITAG tagnum="90"><T4>Federal Register</T4> / Vol. 53, No. 232 / Friday, December 2, 1988/ Notices<ITAG tagnum="52">ENVIRONMENTAL PROTECTION AGENCY </ITAG><ITAG tagnum="41">[FRL-3484-8]</ITAG><ITAG tagnum="52">Proposed Guidelines for Exposure-Related Measurements </ITAG><ITAG tagnum="10"><T2>AGENCY: </T2>Environmental Protection Agency.</ITAG><ITAG tagnum="10"><T2>ACTION: </T2>Proposed guidelines for exposure-related measurementsand request for comments.</ITAG><ITAG tagnum="10"><T2>SUMMARY: </T2>The U.S. Environmental Protection Agency (EPA) is proposingrisk assessment guidelines for exposure-related measurements, and invitespublic comment.The Proposed Guidelines for Exposure-Related Measurements are intendedto assist those who must recommend, conduct, or evaluate an exposure assessment.These proposed guidelines were developed as part of an interoffice guidelinedevelopment program under the auspices of EPA's Risk Assessment Forum.The current proposal incorporates comments from external and internal peerreviewers. EPA's Science Advisory Board (SAB) will review these proposedguidelines at a meeting to be held on December 2, 1988. For further detailsregarding the SAB review, contact Jan Kurtz at (202) 382-2552. </ITAG><ITAG tagnum="10"><T2>DATES: </T2>Comments must be postmarked by March 2, 1989.</ITAG><ITAG tagnum="10"><T2>ADDRESS: </T2>Comments may be mailed or delivered to: Michael A. Callahan,Director, Exposure Assessment Group, Office of Health and EnvironmentalAssessment (RD-689), U.S. Environmental Protection Agency, 401 M StreetSW., Washington, DC 20460.Inspection and copies: References, support documents, and other relevantmaterials will be available for inspection and copying at the Public InformationReference Unit (202-382-5926), EPA Headquarters Library, 401 M Street SW.,Washington, DC, between the hours of 8:00 a.m. and 4:30 p.m. </ITAG><ITAG tagnum="10"><T2>FOR FURTHER INFORMATION CONTACT:</T2>John Segna or Michael Callahan,telephone: 202-475-8909.</ITAG><ITAG tagnum="10"><T2>SUPPLEMENTARY INFORMATION: </T2>In its 1983 book ``Risk Assessmentin the Federal Government: Managing the Process'', the National Academyof Sciences recommended that Federal regulatory agencies establish ``inferenceguidelines'' (1) to promote consistency and technical quality in risk assessment,and (2) to ensure that the risk assessment process is maintained as a scientificeffort separate from risk management. A task force within EPA acceptedthat recommendation and requested that Agency scientists begin to developsuch guidelines.In 1984, EPA scientists began work on risk assessment guidelines for carcinogenicity,mutagenicity, suspect developmental toxicants, chemical mixtures, and exposureassessment. Following extensive scientific and public review, these fiveguidelines were issued on September 24, 1986 (51 FR 33992-34054). The guidelines proposed today continue the guidelines development processinitiated in 1984. Like the guidelines issued in 1986, the new proposalsets forth principles and procedures to guide EPA scientists in the conductof Agency risk assessments and to inform Agency decision-makers and thepublic about these procedures. In particular, the guidelines emphasizethat risk assessments will be conducted on a case-by-case basis, givingfull consideration to all relevant scientific information. This case-by-caseapproach means that Agency experts study scientific information on eachchemical under review and use the most scientifically appropriate interpretationto assess risk. The guidelines also stress that this information will befully presented in Agency risk assessment documents, and that Agency scientistswill identify the strengths and weaknesses of each assessment by describinguncertainties, assumptions, and limitations, as well as the scientificbasis and rationale for each assessment. The guidelines are formulated in part to bridge gaps in risk assessmentmethodology and data. By identifying these gaps and the importance of themissing information to the risk assessment process, EPA wishes to encourageresearch and analysis that will lead to new risk assessment methods anddata. Work on the Proposed Guidelines for Exposure-Related Measurements beganin 1986. The draft guidelines were developed by Agency work groups composedof scientists from throughout the Agency, and the drafts were peer-reviewedby experienced professionals from environmental groups, industry, EPA,and other governmental agencies. During the public comment period, reviewersare requested to comment specifically on the guidance for interpretingcontaminated blanks vs. field data (section 2.5.4), the interpretationof data at or near the limit of detection (section 3.3.2), approaches toassessing uncertainty (section 3.4) and, the Glossary of Terms. Publiccomment is also invited on the following questions: Should these guidelinesbe combined with the 1986 guidelines? Is the current state-of-the-art inmaking measurements of population activities for the purpose of exposureassessment advanced to the point where the Agency can construct guidelinesin this area? Given that these guidelines are not necessarily a protocolor detailed literature review, is the level of detail of these guidelinesuseful and appropriate, especially in the area of statistics? After SAB and public comment, Agency staff will prepare summaries of thecomments and analyses of major issues presented by the commentors. Thecomments will be considered by EPA's Risk Assessment Forum and Risk AssessmentCouncil in the development of final guidelines. <ITAG tagnum="21">Date: November 22, 1988. </ITAG><ITAG tagnum="6">John A. Moore, </ITAG><ITAG tagnum="4">Chairman, Risk Assessment Council. </ITAG><ITAG tagnum="74">Contents</ITAG><ITAG tagnum="73">1. Introduction</ITAG><ITAG tagnum="26">1.1 Purpose of the Guidelines.</ITAG><ITAG tagnum="24">1.1.1. Intended Audience.</ITAG><ITAG tagnum="24">1.1.2. Organization of the Guidelines.</ITAG><ITAG tagnum="24">1.1.3. Role of Technical Support Documents.</ITAG><ITAG tagnum="26">1.2. Exposure Assessment.</ITAG><ITAG tagnum="26">1.3. Sources of Measurement Data.</ITAG><ITAG tagnum="24">1.3.1. Direct Measurement of Exposure.</ITAG><ITAG tagnum="24">1.3.2. Biological Monitoring for Reconstructive Exposure Assessment.</ITAG><ITAG tagnum="24">1.3.3. Measurements for Predictive Exposure Assessment</ITAG><ITAG tagnum="26">1.4. Quality Assurance and Quality Control Requirements.</ITAG><ITAG tagnum="26">1.5. Other Requirements.</ITAG><ITAG tagnum="73">2. Guidelines for Making Measurements for Exposure Assessments</ITAG><ITAG tagnum="26">2.1. Responsibilities of the Exposure Assessor.</ITAG><ITAG tagnum="26">2.2. Defining Objectives.</ITAG><ITAG tagnum="26">2.3. Developing a Sampling Strategy.</ITAG><ITAG tagnum="24">2.3.1. Direct Exposure Measurements.</ITAG><ITAG tagnum="24">2.3.2. Reconstructive Exposure Measurements.</ITAG><ITAG tagnum="24">2.3.3. Predictive Exposure Measurements.</ITAG><ITAG tagnum="26">2.4. Setting Data Quality Objectives.</ITAG><ITAG tagnum="26">2.5. Sampling Plan.</ITAG><ITAG tagnum="24">2.5.1. Sampling Design.</ITAG><ITAG tagnum="24">2.5.2. Sampling Location and Frequency.</ITAG><ITAG tagnum="24">2.5.3. Sampling Duration.</ITAG><ITAG tagnum="24">2.5.4. Sample Preparation.</ITAG><ITAG tagnum="26">2.6. Evaluating Uncertainty.</ITAG><ITAG tagnum="24">2.6.1. Sampling Errors.</ITAG><ITAG tagnum="24">2.6.2. Laboratory Analysis Errors.</ITAG><ITAG tagnum="24">2.6.3. Data Manipulation Errors.</ITAG><ITAG tagnum="24">2.6.4. Reporting Data Near the Detection Limit.</ITAG><ITAG tagnum="26">2.7. Quality Assurance, Control, and Assessment.</ITAG><ITAG tagnum="26">2.8. Selection and Validation of Analytical Methods.</ITAG><ITAG tagnum="26">2.9. Background Level.</ITAG><ITAG tagnum="73">3. Guidelines for Using Measurements in Exposure Assessments</ITAG><ITAG tagnum="26">3.1. Use of Measurement Data in Making Inferences for Exposure Assessments.</ITAG><ITAG tagnum="26">3.2. Relevance of Measurement Data for the Intended Exposure Assessment.</ITAG><ITAG tagnum="24">3.2.1. Direct Measurement of Exposure.</ITAG><ITAG tagnum="24">3.2.2. Reconstructive Exposure Assessment.</ITAG><ITAG tagnum="24">3.2.3. Predictive Exposure Assessment.</ITAG><ITAG tagnum="24">3.2.4. Measurements and Modeling.</ITAG><ITAG tagnum="24">3.2.5. Use of Surrogate Data in Pesticide Exposure Assessment.</ITAG><ITAG tagnum="24">3.2.6. Combining Measurement Data Sets from Various Studies.</ITAG><ITAG tagnum="26">3.3. Adequacy of Measurement Data for the Intended Exposure Assessment.</ITAG><ITAG tagnum="24">3.3.1. Quality Assurance and Quality Control for Previously GeneratedData.</ITAG><ITAG tagnum="24">3.3.2. The Role of Limit of Detection (LOD) Values in MeasurementsUsed to Estimate Exposure.</ITAG><ITAG tagnum="26">3.4. Evaluation and Description of Uncertainty in the Use of Measurements.</ITAG><ITAG tagnum="24">3.4.1. Assignment of Limits of Uncertainty to Data.</ITAG><ITAG tagnum="24">3.4.2. Statistical Analysis of Data.</ITAG><ITAG tagnum="24">3.4.3. Decision Analytic Approach for Expert Opinion.</ITAG><ITAG tagnum="73">Glossary of Terms</ITAG><ITAG tagnum="73">References</ITAG><ITAG tagnum="84">1. Introduction</ITAG>1.1. Purpose of the GuidelinesIn 1984, EPA organized a new program to ensure scientific quality and technicalconsistency in the Agency's risk assessments. Included in the program'sgoals was the development of Agencywide guidelines for risk assessment.The first group of five guidelines was issued in 1986 and included TheGuidelines for Estimating Exposures (U.S. EPA, 1986a). The Proposed Guidelinesfor Exposure-Related Measurements is a companion and supplement to theGuidelines for Estimating Exposures.The Guidelines for Estimating Exposures were developed to help avoid inadvertentmistakes of omission. They present the risk assessor with a set of questionsto be considered in carrying out an exposure assessment and provide a proceduralframework for estimating the degree of human contact with a chemical ofconcern. The Guidelines for Estimating Exposures set forth internal Agencyprocedures that facilitate consistency by developing common approachesto exposure assessments and by promoting the quality and accuracy of scienceunderlying EPA exposure assessments.As stated in the Guidelines for Estimating Exposures, ``Ideally, exposuremeasurements are based on measured data. EPA recognizes that gaps in datawill be common, but the Guidelines will nevertheless serve to assist inorganizing the data that are available, including new data developed aspart of the exposure assessment. In the absence of sufficient reliabledata and the time to obtain appropriate measurements, exposure assessmentsmay be based on validated mathematical models. Whenever possible, exposureassessments based on modeling should be complemented by reliable measurements.''Comments received on the Guidelines for Estimating Exposures, includingcomments from EPA's Science Advisory Board (SAB), suggested a supplementdealing in more detail with how to make and use measurements in exposureassessment. In accord with these suggestions, the Agency prepared the ProposedGuidelines for Exposure-Related Measurements.This document focuses primarily on chemical measurements in various physicaland biological media. The guidelines are intended to help exposure assessorsmake informed choices regarding collection and interpretation of thesetypes of data. Other types of exposure-related measurements (e.g., activityprofiles) are not considered in detail here.The Proposed Guidelines for Exposure-Related Measurements (hereinafterGuidelines) are not intended to serve as a step-by-step instructional guide,but to convey general principles. They represent a collection of informationalready refined by consensus approval. As the Agency performs more exposureassessments and incorporates various novel approaches, these Guidelineswill be revised.<ITAG tagnum="81">1.1.1. Intended Audience</ITAG>These Guidelines are intended to assist those who must recommend, conduct,or evaluate an exposure assessment. Exposure assessment is a multidisciplinaryprocess that should reflect the combined input of analytical and environmentalchemists, biologists, engineers, statisticians, and others as appropriate.To ensure a credible exposure assessment, the assessor must be familiarwith the site or program-specific needs and the factors that affect howwell these needs will be fulfilled.Important aspects to be considered when generating new data (i.e., makingmeasurements) include sampling plans, field activities, and analyticalmethodologies. Exposure assessors will enhance their expert judgment withsample designs that provide objective measurements. The purpose of samplingan environmental medium, or of sampling exposures directly for an individual,or of sampling tissues or body fluids, is to make an inference about thenature of quality of the whole medium, population, or absorbed dose. Statistics,while a useful tool, cannot alone provide the rationale for the link betweenthe sample and the whole. It is the exposure assessor, as builder of theassessment, who must provide the explanation and justification for thislink, usually through carefully laid out logic as to why the sample isaccurate and representative. Statistics, and the help of a statistician,however, are often essential parts of establishing the link between thesample and the population of inference.When evaluating data (i.e., using exposure-related measurements) exposureassessors should carefully examine the relationship between the populationon which the measurements were made and the population about which inferencesare desired. Another matter to be considered and understood is the possibledifference between statistical significance and practical significance.The former term relates to whether observed differences could be the resultof the variability of the data used in a decision process. The latter relatesto whether the difference, if real, would be of practical importance. Fora given set of circumstances, measures of statistical significance shouldnot vary from one assessor to another because they are calculated usingestablished procedures, while statements on practical significance arevery likely to vary from assessor to assessor since they are matters ofopinion.<ITAG tagnum="81">1.1.2. Organization of the Guidelines</ITAG>These Guidelines consist of three parts. The introduction describes somegeneral aspects of exposure assessment and some major sources of measurementdata used in exposure assessment. The second chapter discusses the making(i.e., generation) of measurements for exposure assessments including therole of the exposure assessor, sampling plans, uncertainty analysis, qualityassurance, quality control, and method selection. The third chapter describesthe use of measurements in exposure assessments including evaluation ofuncertainty in the use of measurements, the role of limit-of-detectionvalues, and the use of surrogate data.<ITAG tagnum="81">1.1.3. Role of Technical Support Documents</ITAG>It is impracticable to create guidelines that give specific step-by-stepinstructions for every situation. The assessor should consult technicalsupport documents, such as those referred to in these Guidelines, for morespecific information.1.2. Exposure AssessmentThe National Research Council (NRC) in 1983 described risk assessment ascontaining some or all of the following four steps: <T3>Hazard identification</T3> (the determination of whether a particularchemical is or is not causally linked to particular health effects), <T3>dose-response assessment </T3>(the determination of the relation betweenthe magnitude of exposure and the probability of occurrence of the healtheffects in question), <T3>exposure assessment </T3>(the determination of the extent of humanexposure before or after application of regulatory controls), and <T3>risk characterization </T3>(the description of the nature and oftenthe magnitude of human risk, including attendant uncertainty).Once a dose-response relationship is established, and often this is donein a controlled situation such as a laboratory, one can make statementssuch as, ``if the dose is `x,' then the response should be `y.' '' A majorproblem confronting risk assessors when trying to apply the dose-responserelationship to an actual ``real-world'' problem is the question of whatdose to as representative of the actual situation. The primary purposeof an exposure assessment is usually to estimate the real-world dose valueto use in a dose-response relationship.The EPA Guidelines for Estimating Exposure (U.S. EPA, 1986a) define exposureas the contact with a chemical or physical agent. The magnitude of thiscontact is determined by measuring or estimating the amount of an agentavailable at the exchange boundaries (i.e., lungs, gastrointestinal tract,skin) during some specified time. Once the agent is absorbed through theseboundaries, the amount crossing the boundary becomes the absorbed dose.Exposure assessment is the qualitative or quantitative determination/estimationof the magnitude, frequency, duration, and route of exposure. Exposureare sometimes referred to in the literature in terms of ``administereddose'' or ``applied dose,'' which describe contact with the organism, butnot absorption. These terms tend to be confusing and should not be usedto describe exposure if avoidable. Exposures assessments often presentnot only the exposures, but also the absorbed doses, which can be calculatedfrom exposure if the absorption fraction is known (see the Glossary ofTerms).Over the last decade, exposure assessors have generally approached theevaluation of real-world exposures in three ways: by trying to measurethe exposure directly while it is taking place (``the direct measurementapproach''), by trying to reconstruct an absorbed dose from evidence withinan organism after the exposure and absorption have taken place (``the reconstructiveapproach''), or by trying to make estimates of the distribution of thechemical and the organism separately, then linking them (``the predictiveapproach''). All of these approaches involve measurements of some kind,and the measurements used in these approaches to determine or estimateexposure are generally termed ``exposure-related measurements.'' This termapplies to measurements taken for use in an exposure assessment, whetheror not they measure actual exposures directly, or directly provide informationupon which exposure will ultimately be estimated.1.3. Sources of Measurement DataThis section describes some of the methods currently used to provide reliablemeasurements for exposure assessment needs. The methodologies discussedbelow focus on direct measurement of exposure, measurement of biologicalmarkers, and measurements for characterization of media for predictiveassessments. These Guidelines will not discuss the collection of data onpopulation activity patterns, although it is recognized that these dataplay an important role in exposure assessment.The reader should keep in mind that the measurements discussed in sections1.3.1 through 1.3.3 share s similarity in that for most of them, a substanceor medium is being analyzed for chemical content. However, the <T3>use </T3>of the resulting measurement data is fundamentally differentfor the three different approaches to exposure assessment, and thereforeconsiderations in <T3>making</T3> these measurements vary also.<ITAG tagnum="81">1.3.1. Direct Measurement of Exposure</ITAG>Direct measurement of exposure measures the contact of a chemical withan organism (human or nonhuman) while it occurs, by measuring the chemicalconcentrations at human physical exchange boundaries (skin, lungs, etc.)as a function of time (e.g., throughout a day) to obtain an exposure profile.A number of individual profiles can be statistically aggregated to makestatements about the exposure profiles for human or nonhuman populations,provided the individuals sampled have a known relationship to the entirepopulation. As the name implies, the direct measurement method relies essentially onmeasured data. The best-known example of the direct measurement of exposureis the radiation dosimeter, a small badge-like device worn in areas whereexposure to radiation is possible. The dosimeter effectively measures exposuresto radiation while it is taking place, then indicates when a preset levelhas been exceeded. Another example of direct measurement of pollutant exposureis provided by the Total Exposure Assessment Methodology (TEAM) studies(U.S. EPA, 1987a) conducted by EPA. In the TEAM studies, a small pump witha collector and absorbent is attached to a person's clothing and measuresthe exposures to airborne solvents or other pollutants while the exposuretakes place. The absorbent cartridges are then analyzed for a variety ofchemicals. A third direct measurement example is given by the carbon monoxide(CO) studies done by EPA in the 1980s, where a small CO measuring devicewas carried by a number of people over several days (U.S. EPA, 1984a).The device had a recording capability which allowed the assessor to analyzethe exposure to CO over that time period. In all three of these examples,the key to direct measurement techniques is that the measurements mustbe taken at the interface between the person and the environment and measurethe exposure while it is taking place.    <ITAG tagnum="81">1.3.2. Biological Monitoring for Reconstructive Exposure Assessment     </ITAG>Another method, yielding useful measurement data for reconstructive exposureassessments, involves biological monitoring. Biological tissue or fluidmeasurements that reveal the presence of a  chemical may indicate directlythat an exposure has occurred, provided the chemical is not a metaboliteof other chemicals. There has been much interest in relating biologicalsample levels to exposure, particularly for occupational exposure wherechemical concentrations are high enough to permit easier detection.     Four types of measurements using biological monitoring can be used to evaluatethe amount of a chemical in the body:<ITAG tagnum="21">1. Measurement of the concentration of the chemical itself in variousbiological tissues or fluids (blood, urine, breath, hair, adipose tissue,etc.) (body burden).    </ITAG><ITAG tagnum="21">2. Measurement of the concentration of one or more of the biotransformationproducts (metabolites) of the chemical.      </ITAG><ITAG tagnum="21">3. Measurement of a biological effect that occurs as a result of humanexposure to the chemical (e.g., alkylated hemoglobin) (types of biomarkers).     </ITAG><ITAG tagnum="21">4. Measurement of the amount of a chemical bound to target molecules(e.g., DNA adducts or chromosome aberrations) (types of biomarkers).</ITAG></ITAG><ITAG tagnum="10">The results of biomonitoring can be used to estimate the amount ofchemical uptake during a specific interval if the relationship betweenuptake and the markers selected is known (i.e., pharmacokinetics are known)and if background levels before the exposure interval are known.      Reconstructive exposure assessment relies heavily on measured data. However,the data on body burden or biomarker values cannot be used directly forexposure assessment unless a relationship can be established between theselevels and absorbed dose, and interfering reactions (e.g., from metabolismof nonrelated chemicals) can be accounted for or ruled out. Biologicalmonitoring for exposure assessment usually involves sampling tissues orfluids for the purpose of making inferences about absorbed dose.    <ITAG tagnum="81">1.3.3. Measurements for Predictive Exposure Assessment      </ITAG>In predictive exposure assessment, the assessor attempts to match, or link,individuals or collections of individuals with the concentrations of chemicalsor agents they are contacting. Usually, the assessor addresses the characterizationof the individuals or population separately from the characterization ofthe chemical or agent. Population characterization involves identifyingthose individuals who are exposed and the activities (habits) that bringthem into contact with the chemical or agent. This may involve demographics,survey statistics, behavior observation, activity diaries, or other meansof obtaining this information. Although population characterization mayinvolve measurements, these measurements are fundamentally different fromthe chemical/media characterization discussed in these Guidelines, andtherefore will not be specifically discussed further here.    Measurements employed in characterizing the chemical or agent in predictiveexposure assessments are quite varied, but they all share a common purpose:to use sampling to make inferences about the distribution of chemical/agentconcentrations in the media being sampled. Measurements are often usedas inputs to models. Once the concentration distribution has been estimatedor measured, this information can be combined with the population characterizationto estimate exposure.          The following are a few examples of the types of measurements used in predictiveexposure assessment to characterize the concentrations of chemicals oragents in various media. <T3>Fixed location monitoring</T3> has been used by the Agency and othergroups to provide a record of pollutant concentration at one spot oversome length of time. Nationwide air and water monitoring programs havebeen established to provide continuous monitoring of pollutant concentrationso that ``baseline'' values in these environmental media can be documented.<T3>Measurements in environmental media</T3> can also be done in focusedstudies which look for specific chemicals or agents in specific placesand time. <T3>Indoor air measurements</T3> simply refer to the geographic zone monitored.There are valid reasons for differentiating indoor measurements from outdoorones, since when performing an exposure assessment, the considerable timespent indoors for most persons needs to be linked with the concentrationsthey are exposed to indoors. The home, office, automobile, or other definedareas are often called <T3>microenvironments,</T3> and are used in predictive exposure assessmentto better link chemical concentrations with individuals or populations.<T3>Breathing zone measurements,</T3> usually associated with industrialhygiene studies of worker exposure, refer to measurements taken by a fixedlocation device situated at approximately head height at or near wherethe worker spends a substantial amount of time. Note that this differsfrom direct measurement, since the monitor is fixed rather than movingwith the worker. <T3>Food and drinking water measurments</T3> are often made to characterizethese potential exposure pathways. General characterization of these media,such as market basket studies, shelf studies (where foodstuffs are takenfrom store shelves and analyzed), or drinking water quality surveys arelinked in a predictive exposure assessment with the characterization ofthe individuals or population assessed. (Again, this differs from directmeasurement of exposure, where measurements of food and drinking waterare taken as split samples simultaneously as an individual is ingestingthem.) <T3>Source characterization measurements</T3> usually refer to samplingto determine the rate of release of chemicals or agents into the environmentfrom a point of emission such as an incinerator, landfill, industrial ormunicipal facility, or other source. Often these measurements are usedto estimate emission factors, or a relationship between releases and operatingparameters of a facility (x mg of chemical released per ton of waste burned,etc.). The release rates are often combined in a predictive exposure assessmentwith environmental transport and transformation (environmental fate) dataor models, resulting in an estimate of the distribution of the releasein the environment over time. This distribution must then be linked toindividuals or populations before exposures can be estimated. <T3>Consumer or industrial product analysis</T3> is sometimes done to characterizethe concentrations of chemicals or agents in products with which individualscame in contact. In predictive exposure asssessment, this information canbe linked with population activities to estimate exposures, provided informationis known about how much the individual actually comes in contact with theproduct. (For example, when holding a product, an individual does not usuallycontact the entire product, nor do the chemical additives immediately becomeavailable on the surface being contacted, etc.)    <ITAG tagnum="18">31.4. Quality Assurance and Quality Control Requirements</ITAG>While the preceding discussion has described a number of types of measurements,all of them must provide sufficient proof of reliability. This proof isembodied in the form of quality assurance and Quality Control. The Agencywidequality assurance policy stipulates that every monitoring and measurementproject undertaken by the Agency must have a written, approved QualityAssurance Project Plan (QAPjP) and Data Quality Objectives (DQOs).  EPA's Office of Research and Development (U.S. EPA, 1983) has published``Interim Guidelines and Specifications for Preparing Quality AssuranceProject Plans'', which describes the sixteen elements required in everyQAP<T2>j</T2>P and establishes criteria for plan preparation, review, andapproval. Every QAP<T2>j</T2>P should contain procedures that can be used to document andreport precision, accuracy, and completeness of environmental measurements.Individual EPA program offices have prepared more specific guidance basedon this general guidance package.1.5 Other RequirementsAn exposure assessor must also be aware of other requirements that areimportant in specific types of assessments. For example, one must considerthat in the process of obtaining direct measurements of exposure in allFederally-funded exposure studies that mandatory submission of a completesurvey design to the Office of Management and Budget (OMB) may be necessary.The guidelines for all such submissions are outlined in the Federal PaperworkReduction Act (U.S. OMB, 1988).<ITAG tagnum="84">2. Guidelines for Making Measurements for Exposure Assessments </ITAG>2.1 Responsibilities of the Exposure Assessor As noted in section 1.2, the exposure assessor's task is to obtain or estimatedose information representative of actual exposure situations for use inthe dose-response relationships which are generally established under controlledconditions, usually in a laboratory. Since dose involves both the organismand the chemical, obtaining representative dose information involves establishinga link between the organism and the chemical. Again, exposure assessorscommonly attempt to make this link in any of several ways: by direct measurement,by predictive relationships involving individual study of the distributionof the organisms and chemical in time and space, or by reconstructing thedose after it has occurred. In most cases, the exposure assessor worksfrom individual organism exposures and aggregates these to make statements,inferences, or conclusions about the exposure profiles of collections ofindividuals (subpopulations, populations, etc.).In order to make these inferences and conclusions, the assessor often usesmeasurements along with the concept of sampling. A sample is a small portionof a whole (e.g., specimens of water from the entire drinking water distributionsystem, 10 cubic meter portions of air within a home, several individualsin a town of 25,000) intended to represent the nature or quality of thewhole. The most important responsibility of the exposure assessor is tounderstand and explain the relationship between the measurement data (samples)and the conclusions drawn about exposure to the subpopulation or populationbeing assessed (the whole). Good planning, sound statistics, and adequate quality control will go along way toward building that link between sample and whole. The ultimateutility of new measurements taken for exposure assessment is strongly influencedby sampling strategy (sampling locations, sampling frequency, samplingduration), quality assurance (e.g., sample preparation, handling, and preservation),and knowledge about systematic and random sampling errors (American ChemicalSociety, 1983). It is incumbent on the exposure assessor to be well informedand to participate in such decisions relating to the making of measurementsso that the sampling process is relevant to the questions being asked ofthe assessor. In addition, the exposure assessor should be involved (alongwith an analytical chemist and statistician) in selecting the appropriateanalytical methods. Likewise, the exposure assessor needs to be involvedin quality assurance, control, and assessment. The following discussionis intended to assist the exposure assessor in the highly complex processof making measurements for exposure assessments. The subject areas describedbelow are often interrelated and, even though the process of planning andexecuting exposure-related measurements is described in a sequential manner,the exposure assessor must recognize the interative nature of the entireprocess. 2.2 Defining ObjectivesA critical choice which must be made early in the process of conductingexposure-related measurements is the decision regarding exactly what isto be measured, what data quality is required, and what resources are availableto carry out the study. In order to accomplish this, the exposure assessormust first explicitly define the overall objectives including the typeof assessment (i.e., direct, predictive, or reconstructive) that the studyis intended to support, the approach to be followed, and the nature ofthe decisions that will be made based on the data. Studies can range formbeing scoping in nature, intended to develop a hypothesis for further testing,to detailed investigations for the purpose of deciding on remedial actionsor to support regulatory decision-making. In every case proper planningprior to data collection is essential to ensure that the results of thestudy are consistent with the anticipated uses of the data. To facilitate this planning, the exposure assessor should keep some basicquestions in mind:<ITAG tagnum="21">Why is the study being conducted? What questions (hypotheses) doesthe study intend to address and to what uses will the results be put?</ITAG><ITAG tagnum="21">Where does the study area begin and where does it end? Is the intentof the study to make inferences on a national, regional, or local scale?</ITAG><ITAG tagnum="21">Who is to be monitored? Will the study involve human and/or nonhumanpopulations? How are they to be identified, characterized, and stratified?</ITAG><ITAG tagnum="21">What substances and what media will be measured? What is known aboutthe environmental fate as well as the fate of the substance within thereceptor organism? What are the important exposure pathways? What is knownabout expected concentration levels, analytical methods, and detectionlimits?</ITAG><ITAG tagnum="21">What will the samples be collected? How frequently will the samplingbe conducted? Is the intent to characterize exposure as a function of specifiedvariables?</ITAG>By addressing each of these questions, the exposure assessor will developa clear and concise definition of study objectives that will form the basisfor further planning. The following list of overall objectives illustratesthe range of data requirements in terms of variety, quantity, and qualitythat will result from this process. Generally, the requirements and, therefore,the effort and associated costs increase as one proceeds down the list.<ITAG tagnum="73">Example Study Objectives</ITAG><ITAG tagnum="21">Determining whether exposure occurs to support the need for toxicitytesting.</ITAG><ITAG tagnum="21">Establish mean or peak exposures.</ITAG><ITAG tagnum="21">Establish the fraction of a given area or the percent of time thatexposures exceed a particular level for purposes of demonstrating complianceor the need for remedial action.</ITAG><ITAG tagnum="21">Establish trends in exposures and the efficacy of risk managementdecisions.</ITAG><ITAG tagnum="21">Determine exposures as a function of location, population characteristics,activity patterns, or other factors.</ITAG>2.3. Developing a Sampling StrategyHaving decided on the overall objectives of the measurements effort, theexposure assessor should then be prepared to advance to the next levelin planning the study which involves making decisions regarding the typesof measurements to be undertaken. Data from health or ecological effectsstudies can be used in deciding such issues as which route of exposureor which medium is most important to sample and the level of detectionthat is required. Frequency considerations might depend on whether theeffects studies have examined average concentrates of the chemical of interestor the effect of peak exposures. Much more frequent sampling must be undertakento determine peak exposures versus average exposure. Besides the numberof sampling locations and samples to be collected, the frequency of samplingis the most significant cost multiplier in a sampling program.As discussed in section 1.2, there are three approaches useful in exposureassessment. Each of these three approaches (namely, direct measurementmethods, predictive methods, and reconstructive methods) has particularstrengths and weaknesses and each has different data requirements. Whendirect measurement of exposure is not possible, indirect methods (i.e.,predictive or reconstructive) are used, the most common being predictivemethods. In general, predictive methods link sources, environmental pathways,monitoring data, and population (individual) activity patterns throughuse of models and exposure scenarios to estimate exposures. The reconstructiveapproach is almost always combined with one of the other methods to forma better assessment. In fact, many exposure assessments are a combinationof two or all three approaches; the TEAM study is a good example of anassessment that combines direct measurement with the microenvironmentalpredictive approach and breath measurements for the reconstructive approach(U.S. EPA, 1987a).<ITAG tagnum="81">2.3.1. Direct Exposure Measurements</ITAG>Directly measuring human exposure to environmental pollution is a rapidlyemerging science. In such studies measurements are made of the actual pollutantconcentrations contacting a person's body by essentially using split samplesof the air breathed, the food eaten, and the water consumed, and by usingpatch or other techniques to estimate dermal exposure. Availability ofappropriate measurement methodology is, therefore, an essential elementin planning a direct exposure monitoring study. Existing methodology developedfor occupational exposure or environmental monitoring may not be adequateto meet the special demands of direct measurement of exposure. This isespecially true with air or respiratory measurements where the monitoringdevice must be sufficiently small and lightweight to be worn or carriedby the person or animal. Although much has been accomplished in certainareas, such as the development of small personal monitors for carbon monoxide(CO) and volatile organic chemicals (VOCs) and the development of sensitivemethods for sampling exhaled air, new technology must be developed to accuratelydetermine the exposure to many, if not most, of the airborne pollutantsof concern at nonoccupational levels. A highly useful bibliography coveringmodels, field data, and emerging research methodologies which should beconsulted in planning direct exposure studies is ``Total Human Exposureand Indoor Air Quality'' (U.S. EPA, 1988a).<ITAG tagnum="81">2.3.2. Reconstructive Exposure Measurements</ITAG>Measurements in support of reconstructive exposure assessments can be characterizedas being one of four types: (1) Measurement of the chemical or (2) itsmetabolites in biological media, (3) determination of a biological effectrelated to the internal dose, e.g., determination of alkylated hemoglobin,and (4) measurement of the amount of chemical bound to the target moleculese.g., (DNA adducts) or other molecular changes (e.g., chromosome aberrations).Collectively, these measurements are known as biomonitoring of exposure.The principal advantage of biomonitoring is it confirms entry of an environmentalpollutant into an organism and, thereby, removes a major assumption inmost current exposure assessments (i.e., that the material enters the body)and thus considerably strengthens risk assessments. Theoretically, biomonitoringcan integrate total intake to the body from multiple sources and, if thesubstance is stable, it can integrate exposure over time. For many chemicalsof interest, application of biomonitoring to exposure and risk assessmentsis limited by the availability of appropriate analytical techniques, costof the assay, and sufficient understanding of the relationship betweenexternal exposure, body burden, internal dose, and adverse effects.In general, most reconstructive environmental studies have focused on monitoringchemicals that are moderately to highly persistent in human tissues. Thisis based on the reasoning that there is greater potential for exposureand, therefore, adverse effects to result from exposure to more persistentchemicals. Occupational exposure studies have, on the other hand, focusedmore on transient exposure levels, and the TEAM studies have used breathmeasurements to help evaluate exposures to VOCs.The kinds of specimens to be collected in a reconstructive study will varydepending on the following factors: accessibility, prevention of contamination,and existence of analytical procedures. Accessibility is determined firstby whether materials will be collected from living persons or cadavers.From living persons typical sampling involves blood, urine, hair, fingernails,and feces. For cadavers (or surgical patients), one can sample adiposetissues, liver, kidney, and other organs. For example, many studies includeliver because it is both an accumulating organ and a site of pollutantdetoxification and hence a site where many pollutants are likely to befound. It is also present in large enough quantities to obtain individualsamples and it tends to be more homogeneous in its distribution of tracesubstances. Adipose tissue is the ideal depository for lipophilic compoundswhere many chemicals, including chlorinated pesticides and biphenyls, areconcentrated to levels that can be three orders of magnitude more thanin the blood. Adipose tissue is available in large quantities from cadaversand is quite homogeneous in its trace contaminant distribution. Blood andurine are often chosen as indicators of recent as well as long-term exposure.They can be sampled repeatedly from the same individual, over a periodof years. Samples can be readily obtained, are inexpensive, and informationabout lifestyle and occupation of the donor can provide clues to exposureroutes and sources of the toxicants.<ITAG tagnum="81">2.3.3. Predictive Exposure Measurements</ITAG>As mentioned previously, direct exposure measurements may not be feasiblein a given situation due to cost, time constraints, unavailability of directmeasurement methods for the chemicals of interest, or when the assessmentof past or future exposures is desired. Presently, predictive methods,which attempt to link sources, environmental processes, ambient concentrations,target organisms, and activity patterns through models and exposure scenarios,are the most widely used for the Agency's risk assessments.Although the environmental media are primarily responsible for the widedispersion of anthropogenic chemicals that reach the environment and sometimesserve as major reservoirs of pollutant residues, the mere presence of asubstance within an environmental medium does not indicate the extent towhich exposure might occur. It is worth emphasizing here that ambient concentrationsof a pollutant are not exposures to a pollutant. Ambient pollutant levelscan give distorted estimates of exposure levels for many pollutants byfailing to account for other sources of exposure. Moreover, ambient pollutantconcentrations fail to account for time-activity patterns that affect exposurein segments of the population (i.e., there is no exposure if the organismis not present). Ambient measurements only indicate the amount of a chemicalpotentially reaching the exposed individual, and these data must be combinedwith other information through the use of environmental fate models andexposure scenarios to come up with realistic exposure assessments.The exposure assessor should use caution in applying long-term monitoringdata to specific exposure assessments, since the strategy that was usedin siting the particular stations in the network may not correspond tothe strategy needed to answer the questions at hand. For example, althoughNASQAN (National Stream Quality Accounting Network) stations are locatedall across the nation, their siting is not based on a probability sampleof stream locations designed to reflect water quality (U.S. GovernmentAccounting Office, 1986). Likewise, aerometric monitoring sites are usuallyestablished to measure compliance with air quality standards rather thanproduce a statistically representative data base from which valid inferencesof population exposure can be drawn. When ambient monitoring data are neededfor an exposure assessment, the optimum approach is to site the samplingstations to address the specific objectives of the exposure assessment.However, this may be impracticable due to time or resource limitations,and existing monitoring locations may be used but only after the assessorhas examined the purpose and design of the existing network and its appropriatenessfor providing the requisite data.<T3>Air Measurements:</T3> Air pollutants exist, usually at trace levels,in the atmosphere in one or more physical states. These pollutants maybe present as gases or vapors, as surface or bulk constituents of aerosolparticles and droplets, or as constituents of cloud liquid water. The lowconcentrations (typically, in the ppt to ppb range) of most substancesposes particular problems for separation and detection. In planning ambientair monitoring studies, the exposure assessor must recognize that for someair pollutants (especially primary pollutants, e.g., CO, as well as a varietyof volatile organics) actual human exposures are not well represented byoutdoor measurements but are better represented by a series of microenvironmentalmeasurements (see section 3.2.3), including indooor measurements.Vapor pressure and polarity are the two most important properties governingthe succees of sampling organic compounds from air. These properties governwhether the chemical will be found in the gaseous, condensed, or adsorbedphase and will affect the ability to separate, identify, and quantify itsconcentration. For compounds having medium-to-high vapor pressures, componentsof interest are usually concentrated from large volumes of air with a solidsorbent material. Collection of whole air samples in stainless steel canisters,which have been specially electropolished to prevent decomposition of thecollected compounds, has become an attractive alternative to sorbent sampling.Low vapor pressure compounds are normally associated with particles, andfiltration of large volumes of air is the usual means of sampling. Recently,the status of a number of important techniques for sampling air have beenreviewed (American Chemical Society, 1988); the exposure assessor shouldconsult this review and the references contained therein for a detaileddiscussion of their advantages and disadvantages.<T3>Surface and Ground Water Measurements:</T3> Water is a major vehiclewhereby chemical pollutants are transported and transformed to other substances.Concentrations within a given water body may fluctuate widely as a functionof rate and turbulence of flow. Natural water bodies can be very difficultto sample because of large diurnal, seasonal, and local variations. Inthe case of ground water, one of the toughest questions to answer is ``Howto obtain a sample that is representative of the aquifer'' because of theheterogeneity and complexity of the matrix. Several references describingsampling techniques have been reviewed recently (American Chemical Society,1988), and these should be consulted by the exposure assessor in planningsuch studies.<T3>Soil and Sediment Measurements: </T3>Soils often exhibit extreme variabilityeven within a small area. Variations of properties such as pH and organiccarbon content within soil types can significantly alter the environmentalbehavior of chemicals so that their persistence, mobility, extractability,and bioavailability are altered. The interpretation of soil analysis isfurther complicated by the fact that concentrations of a particular substancein soils may bear little immediate relationship to its exposure potential.Guidance on performing soil monitoring studies has been developed (U.S.EPA, 1984b) and should be consulted in planning such studies. Sedimentshave been repeatedly shown to accumulate toxic chemicals, and many chemicalsreach higher concentrations in sediments than in the overlying water column.As in the case of soils, however, there are many questions regarding thebioavailability of sediment-bound chemicals and their significance to thebiosphere. The sampling techniques most frequently used fall into two broadcategories: bottom grab (dredge) sampling and core sampling. Guidance fordesigning, implementing, and overseeing a sediment sampling program isavailable (U.S. EPA, 1985i). <T3>Other Measurements: </T3>In addition to environmental concentrationmeasurements, predictive exposure assessments use data on the physical/chemicalproperties of the substance, its production, use, and disposal patterns,release rates to specific media, environmental fate, exposed populations(size, location, activity patterns), concentrations in drinking water andfood, bioavailability, and pharmacokinetics (see Table 3-1). It is beyondthe scope of this document to provide a discussion of the considerationsand approaches to measuring each of the factors that may go into a predictiveexposure assessment. In reality, most predictive exposure assessments usea mix of measured, surrogate, and estimated data. Several methodology documentshave been prepared (U.S. EPA, 1985a-h, U.S. EPA, 1986b) which, althoughnot a series of ``how-to'' books, they do provide a catalogue of informationsources and describe the use of the data in predictive exposure assessments.These documents provide a useful starting point in planning a study. 2.4 Setting Data Quality Objectives All data are subject to some error, and errors can be introduced at variousstages of data collection. Some types of error can be expressed quantitatively,but others can only be described qualitatively. The magnitude of the errorassigned to a data set is related to data quality. As the magnitude ofthe error increases, the quality of the data decreases. Depending on theparticular decisions that will be made with the data and the way the datawill be used to support those decisions, specified levels of error maybe tolerable. Data Quality Objectives (DQOs) are statements of the levelof uncertainty that an exposure assessor is willing to accept in resultsderived from environmental data. The setting of realistic data quality requirements is essential for properplanning because data of insufficient quality will have little value forproblem solving, and data of excess quality may provide few, if any, additionaladvantages. DQOs should be established based on cost-effective considerationof the needs of the exposure assessment and the capability of the measurementprocess. Knowledge of the expected variability of the samples is requiredto estimate the number of samples to be taken and the number of measurementsto be made on each sample. Although the term connotes quality, DQOs also are intended to clarify theobjectives of the study. They force the exposure assessor to crystallizebeforehand, in his or her mind, how the data will be used once it is collected.The process of establishing the data criteria begins with the exposureassessor proposing limits (based on best judgment) on the level of uncertaintythat will be acceptable for each conclusion to be drawn from new data,taking into consideration the resources available for the study. Theselimits include the uncertainty resulting from both the analytical and samplingcomponents of the plan. Thus, the DQO process consists of an analyticalcomponent and a sampling component. The analytical component results inthe selection of a cost-effective chemical analysis method that, when integratedwith the selected sampling plan (see section 2.5), will satisfy the givenobjective. Frequently, the detection limit of a ``standard'' analyticalmethod exceeds the concern level for the substance (this is particularlytrue for many suspected carcinogens) and, therefore, more costly procedureswill be required. The sampling component involves specifying a samplingplan (including numbers, types, locations, and levels of sampling qualitycontrol) that takes into account the expected sample variability (may haveto be determined by a pilot study), and, when combined with the analyticalcomponent, will provide data consistent with the DQOs. The DQOs should include the following:<ITAG tagnum="21">1. A description of the data to be obtained and the media from whichsamples will be collected. </ITAG><ITAG tagnum="21">2. A statement of the desired performance for each data-dependentelement that specifies in as much detail as possible the acceptable probabilitiesassociated with false positive and false negative situations of varyingdegrees of magnitude. This statement should indicate the level of uncertaintythat can be tolerated if the result is to be included in a decision-makingprocess. </ITAG><ITAG tagnum="21">3. A clear statement of the objectives of the study. </ITAG><ITAG tagnum="21">4. The scope of study objectives including the smallest part of thedata set from which a separate result will be calculated, and the largestunit (area, time period, or group of objects) that the data are expectedto represent. </ITAG><ITAG tagnum="21">5. A discussion of how the results will be tested, including the following:Statistics that will be used to summarize the data; any standards, referencevalues, or action levels to which the statistics will be compared; anda statement of the rationale for and specifics of the mathematical and/orstatistical procedures that will be used to derive the result.</ITAG><ITAG tagnum="21">6. Initial estimates of the time and dollar resources expected tobe expended for the data collection effort.</ITAG>The quality of a data set is represented in terms of precision, accuracy,representativeness, completeness, and comparability. Only precision andaccuracy can be expressed in purely quantitative terms. The other statisticsare best expressed using a mixture of qualitative and quantitative terms.Brief descriptions of these terms are given below:<T3>Precision</T3>_Precision is a measure of the reproducibility of theanalyses under a given set of conditions. Specifically, it is a quantitativemeasure of the variability of a group of measurements compared to theiraverage value. Sampling precision is determined by analyzing multiple sampleschosen at random from the same population, i.e., collected at the samepoint in time and space so as to be considered identical. Analytical precisionis determined by the analysis of separate aliquots of a homogenized sampleor separate aliquots of a spiked matrix and its replicates. Precision isusually stated in terms of sample standard deviation, but other estimatessuch as the coefficient of variation (sample relative standard deviation),the range (maximum value minus minimum value), and the relative range arecommon. Analytical precision is much easier to control and quantify thansampling precision.<T3>Accuracy</T3>_Accuracy is a measure of the correctness of the datathat takes into account the variability and bias that may exist in a measurementsystem. Unlike precision, accuracy is difficult to measure for the entiredata collection activity. Sources of error include the sampling process,field contamination, preservation, handling, sample matrix, and analysis.Accuracy can only be estimated by evaluating all sources of variabilityand bias, to that extent possible. Accuracy is usually determined by analysisof a well-characterized sample or reference material, or is stated in termsof the mean recovery determined by analysis of a matrix spike and its replicates.<T3>Representativeness</T3>_Representativeness expresses the degree towhich sample data accurately and precisely represent a characteristic ofa population, parameter variations at a sample point, or an environmentalcondition. Representativeness is a qualitative parameter that is very importantin the proper design of the sampling plan, since it is related to the relevanceof the data to exposure (see section 3.2). Representativeness is best addressedby describing sampling techniques and the rationale used to select thesampling locations. Samples can be biased (based on existing data, surveys,observations, etc.) or unbiased (completely random or stratified-randomapproaches). Later, in using the data for exposure assessment, this informationwill help build the logical link between the samples and the characterizationof the whole media (see section 3.1).<T3>Completeness</T3>_Completeness is a measure of the amount of validdata obtained from a measurement system compared to the amount that wasexpected to be obtained under normal conditions. Completeness is usuallyexpressed as a percentage. Site access, sampling problems, analytical problems,and the data validation process can all contribute to missing data. Missingdata may reduce the precision of estimates, introduce bias, and lower thelevel of confidence in the conclusions. A completeness goal must be includedin the process to make sure that enough data of sufficient quality areobtained from the measurement system to fulfill the objectives of the study.<T3>Comparability</T3>_Comparability describes the confidence with whichone data set can be compared to another. Comparability refers to such issuesas using standard field and analytical techniques and reporting data inthe same units. For this data collection step, the assessor must considerwhether two or more data sets are comparable. For example, if more thanone field team is collecting samples or more than one laboratory is analyzingthe samples, equivalent methods must be used to ensure that everyone ismeasuring the same thing in the same way. In this manner conclusions maybe drawn from the totality of existing data.2.5. Sampling PlanThe quality of the analytical data used in an exposure assessment dependson the choice of the sample and the adequacy of the sampling and analyticalprograms. As discussed earlier, the exposure assessor must first have aclear understanding of the overall goals of the study and have decidedon the nature of the sampling and the data quality objectives. Once thishas been achieved one can then proceed to the development of the samplingplan.A <T3>sampling plan</T3> is a set of rules or procedures that specify howa sample is to be selected and handled. An inadequate plan will often leadto biased, meaningless, or unreliable results; good planning, on the otherhand, maximizes the efficient use of limited resources and is more likelyto produce valid results.<ITAG tagnum="81">2.5.1. Sampling Design</ITAG>Sampling for the purposes of exposure assessment is a complex process.The heterogeneous nature of the environment poses particular problems inobtaining a representative sample. The sampling design specifies the numberand type of samples needed to achieve the data quality objectives. Factorsto be considered in developing the sampling design include the study objectives,sources of variability (e.g., environmental heterogeneity in time and space,analytical variability) and their relative magnitudes, relative costs,and practical limitations of time, cost, and personnel.Decisions are made regarding replication in time and space, compositing(combining several samples into one prior to analysis), and multiple determinationson a single sample. A statistical (or environmental process) model, whichmay be simple or complex depending on the circumstances, is used to allocatesampling effort in the most efficient manner. For example, considerationof sources of variability together with cost may suggest multiple analysesof individual samples in one case and single analyses of a large numberof samples in another case.Prior knowledge of environmental factors may suggest designs that takeinto account expected physical or spatial relationships. Stratified randomsampling is one approach that involves subdivision of the sampling universeinto strata (e.g., according to geographical region, soil type, etc.).Appropriate choice of strata leads to more efficient use of sampling resourcescompared with simple random sampling when prior knowledge is available.Kriging, developed initially for geostatistical applications, is a statisticalinterpolation method that uses models of the spatial correlation betweenmeasurements. It is particularly suited for developing contour map representationsof, for example, chemical concentrations in soil. As with stratified randomsampling, an appropriate choice of model allows more efficient use of samplingresources compared with simple random sampling. Model selection, however,involves professional judgment and therefore may be subject to criticism.The sampling approach should be thoroughly reviewed to identify its strengthsand weaknesses prior to implementation. An example of both approaches beingused in tandem is provided in ``Data Quality Objectives for Remedial ResponseActivities'' (U.S. EPA, 1987b), in which stratified random sampling isused in the initial phase of a site remediation investigation, followedby the use of geostatistical techniques to effectively target subsequentsample collection.The difference between survey and experimental approaches should be recognized.The survey approach seeks to estimate exposure of a population based onthe measured exposure of a statistically representative sample from thepopulation. In some situations the study objectives may be better servedby an experimental approach which seeks to describe the relationship betweentwo or more factors, e.g., the relationship between house constructionand a particular indoor air pollutant. In the experimental approach, experimentalunits are selected to cover a range of situations (e.g., different housingtypes) and do not reflect the frequency of those units in the populationof ultimate interest. An understanding of the relationship between factorsgained from an experiment can be combined with other data (e.g., distributionof housing types) to estimate exposure. An advantage of the experimentalapproach is that it may provide more insight into underlying mechanismsthat may be important in targeting regulatory action. A properly conductedsurvey has the additional benefit, however, of providing representativeestimates of population characteristics with known uncertainty. To justifythe experimental approach one has to argue, as in all experimental work,that the relationships revealed by the experiment apply beyond the situationof the particular experiment.A single study may use a combination of survey and experimental approachesand involve a variety of sampling techniques. Relevant EPA reference documentsinclude ``Survey Management Handbook'', Vols. I and II (U.S. EPA, 1984c).A detailed description of methods for enumerating and characterizing populationsexposed to chemical substances is contained in ``Methods for AssessingExposure to Chemical Substances'', Vol. 4 (U.S. EPA, 1985d). Statisticalinput is essential during this planning stage to make the most efficientuse of available resources and to ensure that the number and type of samplescollected are likely to achieve the data quality objectives.<ITAG tagnum="81">2.5.2. Sampling Location and Frequency</ITAG>Factors to be considered in selecting possible sampling sites include populationdensity, historical environmental sampling results, patterns of environmentalcontamination and variability (such as prevailing wind direction or streamflow), access to the sample site, types of samples, frequency and durationof sample collection desired, and health and safety of field personnel.There are many sources of information on methods for selecting samplinglocations. Schweitzer and Black (1985) and Schweitzer and Santolucito (1984)give statistical methods for selecting sampling locations, particularlyfor sampling ground water, soil, and hazardous wastes. A practical guidefor ground-water sampling is also available (U.S. EPA, 1985h) as well asa handbook for stream sampling (U.S. EPA, 1986c).The term <T3>sampling frequency</T3> indicates the time interval between the collectionof successive samples. The type of sample to be taken and the physicaland chemical properties of the chemical of concern will usually dictatethe sampling frequency. For example, determining the concentration of avolatile chemical in surface water would require a higher sampling frequencythan necessary for ground water because the chemical concentration of thesurface water would be changing more rapidly.The optimum number, spacing, and sampling frequency can best be estimatedafter a preliminary survey. Factors to be considered in determining thenumber of samples to be obtained include technical objectives, resourcesavailable, the schedule of the program, types of analyses, and the constituentsto be evaluated. Examples for air, surface water, and ground water of theapplication of statistical techniques for determining the optimum numberof samples required to give data with specific limits of confidence includeShaw et al. (1984), Sanders and Adrian (1978), and Nelson and Ward (1981).The best assurance of obtaining a good sampling plan is to rely on a professionalstatistician.<ITAG tagnum="81">2.5.3. Sampling Duration</ITAG>The duration of sampling depends on the analytical method chosen, the limitsof detection, the physical/chemical properties of the analyte, chemicalconcentration, and knowledge of transport/transformation mechanisms. Forexample, sampling duration may be extended to ensure adequate collectionof a low concentration chemical and may be curtailed to prevent the breakthroughof a relatively high concentration of volatile chemical. Also, durationof sampling is directly related to selection of statistical analyses, suchas trend versus cross-sectional analyses.<ITAG tagnum="81">2.5.4. Sample Preparation</ITAG>A major analytical concern is to ensure that the samples are not biasedby the introduction of field or laboratory contamination. If the validityof the sample is in question, all the analytical results will be questionable.Field and laboratory spiked samples and blank samples should be analyzedconcurrently to validate results.While conducting the sampling plan, careful attention should be given tocollecting, preparing, preserving, and analyzing samples according to theestablished protocols.The method for interpreting and using the results from blank samples shouldbe specified in the sampling plan. The following EPA documents provideexamples.For <T3>volatiles and semivolatiles</T3> the action in the case of unsuitableblank results depends on the circumstances and the origin of the blank.No positive sample results should be reported unless the concentrationof the compound in the sample exceeds 10 times the amount in any blankfor the following contaminants: methylene chloride, acetone, toluene, 2-butanone,and common phthalate esters. The amount for other volatiles and semivolatilesshould exceed 5 times the amount in the blank (U.S. EPA, 1988b). If a compoundis found in a blank but not found in a sample, no action is taken.For <T3>pesticides/PCBs</T3> no positive sample results should be reportedunless the concentration of the compound in the sample exceeds 5 timesthe amount in the blank (U.S. EPA, 1988b). If a pesticide/PCB is foundin a blank but not found in a sample(s), no action is taken.For <T3>inorganics, </T3>no positive sample results should be reported if thesample results are greater than the instrument detection limit (IDL) andless than 5 times the amount in any blank (U.S. EPA, 1988c). Any blankwith a negative result whose absolute value is greater than the IDL mustbe carefully evaluated to determine its effect on the sample data.2.6 Evaluating UncertaintyIn evaluating and reporting uncertainty associated with measurements, samplingerrors, laboratory analysis errors, and data manipulation errors are threecategories of errors that should be evaluated. These are discussed in thenext sections.<ITAG tagnum="81">2.6.1. Sampling Errors</ITAG>There are two kinds of sampling errors: systematic errors (often referredto as biases) that result from the sampling process, and random errorsthat result from the variability of both the population and the samplingprocess.A biased sample can result from faulty assumptions. For example, one mayassume that only the liquid phase of an aquatic system is important andmay therefore ignore colloidal matter, suspended material, and sediment.A biased conception of an environmental situation could thus result. Unfoundeddiscrimination with respect to speciation (chemical and biological) isanother example of sample bias. Experimental failure to realize a properdiscriminatory feature of an assumption could be another source of bias.For example, sampling a ``respirable'' fraction of particles in an atmospheredepends both on an appropriate definition of what is respirable and theuse of a sampling device that has the required size discrimination. Thepresence or absence of such biases must never be assumed without experimentalevidence. A sampling operation can be biased by faulty calibration of criticalcomponents such as flow meters, thermometers, pressure sensors, sieves,or any device that influences the sample or is used to quantitatively modifya measured result.Biases of a different kind can result from contamination, losses, interactionswith containers, deteriorations, and displacement of phase or chemicalequilibria. Sources of bias must be considered in every sampling operation.A good procedure is to develop a ``bias budget'' wherein individual itemsare evaluated for significance, quantitatively when appropriate. Tolerancesshould be established to hold them within acceptable bounds, and adequatecalibrations should be made of all critical components.<ITAG tagnum="81">2.6.2. Laboratory Analysis Errors</ITAG>Generally, laboratory errors are smaller than sampling errors. Preparationof accurate calibration standards helps minimize measurement bias as muchas possible, since calibration is a major source of systematic error inanalysis. This requires standards that suitably match the samples of interestin both matrix and level of analyte of concern. Other sources include chemicaloperations such as sample dissolution, concentration, extraction, and reactions.Blanks arising from the chemical operations, storage and handling of samples,sampling and transfer lines, and laboratory environment (including itspersonnel) must be controlled and evaluated.Another type of error in laboratory analysis is the uncertainty of intercomparisonof standards and samples. The measurement system must be in a state ofstatistical control, i.e., it must be stable and capable of producing alimiting mean value; the individual observations must be randomly distributedaround the mean, and they must have a stable variance. Furthermore, eachindividual observation must be independent of others in a data set.A system is statistical control will be stabilized but not necessarilyoptimized. Accordingly, its standard deviation will need to be evaluatedand monitored on a continuing basis.<ITAG tagnum="81">2.6.3. Data Manipulation Errors</ITAG>Uncertainties that arise from errors in data manipulation are due to theoperation of the measurement process and can be evaluated experimentally.Blunders, however, cannot be evaluated, so sufficient care must be exercisedto prevent them to the extent possible.Data manipulation errors can be of several kinds. These include errorsof calculation, errors of transposition, errors of transmission, use ofwrong units, use of improper conversion factors, spatial or temporal averaginginformation loss, and misassociation errors that confuse samples and numericalresults. A measurement program should have built-in mechanisms to detectthese errors. These can include, where appropriate:<ITAG tagnum="21">1. Proofreading and hand checking calculations.</ITAG><ITAG tagnum="21">2. Ion balance.</ITAG><ITAG tagnum="21">3. Mass balance.</ITAG><ITAG tagnum="21">4. Comparison of results found for similar samples.</ITAG><ITAG tagnum="21">5. Graphical plots.</ITAG><ITAG tagnum="21">6. Tests for outliers.</ITAG>A data set should not be released until it has been screened for possibleblunders. The quality assurance program should include a prescribed procedurefor data release, and any request to bypass it (premature release of data)should be resisted.<ITAG tagnum="81">2.6.4. Reporting Data Near the Detection Limit</ITAG>Oftentimes, extrapolation methodologies applied to toxicological studiesresult in acceptable risk levels which necessitate measuring environmentalconcentrations at or near the limit of detection (LOD). The limit of detectionis defined as the lowest concentration level that can be determined tobe statistically different from a blank (American Chemical Society, 1983).Data measured at or near the detection limit have considerably more uncertaintyassociated with them than when measurable amounts are present. To understandwhat a reasonably certain measure or a reliable detection is, the exposureassessor must understand the method of measurement as well as the statisticalapproach that was used to calculate the limit of detection. Different statisticalapproaches will produce different limits of detection. It is beyond thescope of this document to discuss the various methods for calculating limitof detection values. Instead, the assessor should consult a statisticianand become familiar with the advantages and disadvantages of each method(e.g., Long and Winefordner, 1983).As a general rule, the exposure assessor should report all data that contributeto an understanding of the true situation including the extent to whichdata have been adjusted for recovery or other factors. If the exposureassessor reports individual values, the American Chemical Society's Committeeon Environmental Improvement (1983) recommends that:1. If the measured value is less than the limit of detection, report ``notdetected'' together with the value for the LOD.2. If the measured value is larger than the LOD but smaller than the limitof quantification (LOQ), report ``detected but not quantifiable'' togetherwith the value for the LOQ. The LOQ is the level above which quantitativeresults can be obtained with a specified degree of confidence.3. If the measured value is greater than the LOQ, report the value andits uncertainty.</ITAG><ITAG tagnum="10">The American Chemical Society recommendation sets the LOD at 3 standarddeviation units above the mean value of the blank responses and the LOQat 10 standard deviations above the blank responses.2.7. Quality Assurance, Control, and Assessment<T3>Quality assurance</T3> is a system of activities designed to providethe producer or user of a product or service with the assurance that theproduct meets defined standards of quality with a stated level of confidence.The quality assurance process involves quality control and quality assessment.<T3>Quality control</T3> is the overall system of activities whose purposein to control the quality of a product or service so that it meets theneeds of users. The aim is to provide quality that is satisfactory, dependable,and economical. A quality control program should include developing andstrictly adhering to priciples of good laboratory practice, consistentlyusing standard operational procedures, and following carefully designedprotocols for specific measurement programs. Qualified personnel, reliableand well-maintained equipment, appropriate calibrations and standards,and close supervision of all operations are essential components of a soundquality control program. A quality control program should foster a measurementsystem that operates in a state of statistical control, which means thaterrors have been reduced to acceptable levels and have been characterizedstatistically.<T3>Quality assessment</T3> is the overall system of activities whose purposeis to provide assurance that the overall quality control job is being doneeffectively. It involves a continuing evaluation of the products producedand the performance of the production system. Quality assessment describesthose techniques used to assess the quality of the measurement processand the resulting data. The establishment of a system of control chartsis considered the best way to monitor the performance of a measurementsystem. Control charts are plots of multiple data points from the sameor similar samples (or processes) versus time. The relative variabilityof repetitive data can thus be visualized. These charts can also be usedwith reference materials, spiked samples, and surrogates as a means ofassessing the accuracy of measurements.Quality assurance begins with the establishment of data quality objectivesand extends throughout the entire measurement process. Each laboratoryshould have a quality assurance program and, for each study, a qualityassurance project plan (QAPjP). This plan should be complete and detailedand its language clear and unambiguous to preclude confusion and misunderstanding(U.S. EPA, 1983). The contents of the plan should include the following:<ITAG tagnum="21">1. Statement of the data quality objectives for the monitoring effort.</ITAG><ITAG tagnum="21">2. Full description of the chemical to be analyzed.</ITAG><ITAG tagnum="21">3. Review of the analytical method selected, following the proceduresdiscussed in section 2.8.</ITAG><ITAG tagnum="21">4. Description of the steps taken to verify and validate the method.</ITAG><ITAG tagnum="21">5. Verification and validation results.</ITAG><ITAG tagnum="21">6. Description and source of reference standards.</ITAG><ITAG tagnum="21">7. Field study design with rationale.</ITAG><ITAG tagnum="21">8. Quality assurance and quality control used throughout the study.</ITAG><ITAG tagnum="21">9. List of equipment and materials to be used in the field.</ITAG><ITAG tagnum="21">10. Description of the system used to ensure sample preservation andhandling, traceability of instrumentation, samples, and data.</ITAG>Examples of the last quality assurance and quality control procedure listedabove include the following:<T3>Sample Preservation and Handling</T3>_When immediate analysis of thecollected sample is not possible, precautions should be taken so that thesample integrity is not altered. The assessor should store the sample ina manner that guarantees that the parameters to be measured are not altered.The container material should not interfere with the analysis of the specificparameters, and the holding times specified for the analytical procedureshould not be violated unless it can be demonstrated that significant changeshave not occurred.<T3>Traceability of Instrumentation</T3>_All collection and measurementinstrumentation should have a unique identification number. Maintenance,calibration, and use logs should be maintained.<T3>Traceability of Samples</T3>_All samples should have a unique identificationnumber that is traceable to information on the field site, monitoring location,and collection devices. An efficient way to trace samples is to employa bar code labeling system. Under this system, samples are labeled withadhesive bar code labels to identify the samples and trace them throughthe sampling and analytical procedures.<T3>Traceability of Data</T3>_Data should be documented and filed to allowcomplete reconstruction from initial field records to data archiving.Audits should also be a feature of all quality assurance programs. A systemsaudit should be made at appropriate intervals to ensure that all aspectsof the quality assurance program are operative. Performance audits in whicha laboratory is evaluated based on the results of analyses of blind standardsamples also provide valuable quality assessment information.2.8. Selection and Validation of Analytical MethodsSelecting the most suitable method of analysis involves developing a chemicalprofile of the chemical of interest. This profile should identify the physicaland chemical properties of the chemical, such as vapor pressure, watersolubility, octanol-water partition coefficient, boiling and melting points,molecular weight, and other properties that help characterize the chemical.There are several major steps in the method selection and validation process:<ITAG tagnum="74">Step 1. Determination of Method Requirements</ITAG><ITAG tagnum="21">The method requirements are normally established by the assessor whoneeds environmental measurement data. The requirements identify the substancesof interest (analytes), define the matrices to be examined, and specify(quantitatively) the performance of the method and the reliability, confidence,and quality of the measurements needed.</ITAG><ITAG tagnum="74">Step 2. Method Selection and Testing</ITAG><ITAG tagnum="21">Existing methods should be reviewed to identify candidate methodsthat may be adequate to meet the needs of the assessor. The method detectionlimit (MDL), which is the lowest amount detectable with a stated levelof confidence, is of particular importance for selection of an analyticalmethod and must be considered in light of the needs of the risk assessment.</ITAG><ITAG tagnum="74">Step 3. Single Laboratory Testing</ITAG><ITAG tagnum="21">The candidate method, if new, is subjected to laboratory and fieldtesting, as necessary, to characterize its performance adequately withrespect to the requirements established in Step 1.</ITAG><ITAG tagnum="74">Step 4. Comparability Testing</ITAG><ITAG tagnum="21">An evaluation similar to that described for Step 3 is conducted byother laboratories participating in the study to verify the method write-upand to confirm the results and conclusions of the method characterizationconducted in the Single Laboratory Testing.</ITAG><ITAG tagnum="74">Step 5. Final Method Description</ITAG><ITAG tagnum="21">The method description is revised to incorporate changes or clarificationsdetermined to be necessary based on the testing in Steps 3 and 4.</ITAG>2.9 Background LevelAt some sites, background chemical contamination is significant and shouldbe accounted for. Background is defined as chemical contamination due toa source other than the site under investigation. Background can be eithernatural or from man-made sources. The exposure assessor should try to definelocal background conditions of concern by observing nearby locations clearlyunaffected by the site under investigation.When differences between a background (control site) and a target siteare to be determined experimentally, the sampling of the control site mustbe done with the same detail and care as for that of the target. Otherwise,the uncertainty of any difference can be limited by the data for the control.<ITAG tagnum="84">3. Guidelines for Using Measurements in Exposure Assessments </ITAG>3.1. <T3>Use of Measurement Data in Making Inferences for Exposure Assessments</T3>As discussed in the previous two chapters, the primary purpose for makingmeasurements and using data related to exposure assessments is to makeinferences from the measurements (samples) to the whole. In predictiveexposure assessments, the whole is usually a medium of interest such asoutdoor air, drinking water, a consumer product, etc. Once characterizationof the medium has been made (and this may include changes over time), amatched link to individuals or populations being assessed must be made,usually via use of exposure scenarios. In direct measurement of exposure,sampling of one individual's exposure must be related to the exporsuresof a collection of individuals (the whole). This relationship may alsoinclude inferences about different times and locations from those in thesample (e.g., different cities, winter vs. summer, present vs. past). Inreconstructive exposure assessment, the whole is usually the total absorbeddose over some period of the past, which is reconstructed from samplesof various tissues, fluids, or other biomarkers; individual absorbed dosesmight then be used to make inferences about collections of individuals.In all these cases, the exposure assessor must have a clear picture ofthe relationship between the sample and the whole. It is obvious that thesampling being done for exposure assessments does not always try to characterizethe same thing as ``the whole.'' For example, samples of an environmentalmedium such as surface water, which are useful in characterizing the mediumitself, are not necessarily immediately useful for characterizing exposuresfrom surface water. But the characterization of the medium (over spaceand time) can be used, along with the location and activities of individualsor populations, to estimate exposures. Because the samples taken for exposureassessment differ in what they are trying to characterize, a sample takenas a direct measure of exposure, for example, is qualitatively differentfrom a sample of an environmental medium, and these are qualitatively differentfrom a tissue or body fluid sample. The concept that different measurements, all taken under the general categoryof ``exposure-related measurements,'' cannot all be used in the same wayis critical to using these data in an exposure assessment. It is the exposureassessor's primary responsibility to understand, explain, and justify therelationship between the sample data and the inferences or conclusionsbeing drawn from the data in the assessment. In doing so, the assessormust evaluate data relevance, adequacy, and uncertainty. These topics arecovered in sections 3.2, 3.3, and 3.4, respectively. Inferences are generalizations that actually go beyond the informationcontained in the set of data. Inferences involve at least some subjectivity,since it is impossible to eliminate all elements of subjectivity no matterhow objectively data are collected. The credibility of an inference isoften related to the method used to make it and the amount of supportingdata it is based on. A guess, for instance, is one type of inference, althoughan assessor or decision-maker is likely to place less confidence in thismethod as a predictor of real-world events or conditions than many othermethods. Anecdotal information, that is, stories of the form ``once I knewa situation where * * *'', are somewhat better than guesses as predictors,but the assessor has only a limited knowledge of where in the distributionof real-world situations this anecdote is being drawn from. Professionaljudgment is usually a better predictor that either guesses or anecdotes,since it presupposes that a (sometimes substantial) data base of experience(i.e., a collection of anecdotes) is being used, even if this is not aformal data base. Statistical inferences also are generalizations that actually go beyondthe data set. Statistical inferences may take any of several forms (seeany statistics textbook for examples), but unlike the types of inferencesmentioned above, a statistical inference will usually state not only theinference, but a measure of how good the inference is. For that reason,statistical inferences (including inferences involving judgment; see section3.3.3) are often preferable to guesses, anecdotes, or professional judgmentalone in understanding, explaining, and justifying the inferences madein linking the samples with the characterization of the whole, providedthe data are shown to be relevant and adequate. 3.2. Relevance of Measurement Data for the Intended Exposure AssessmentSince all of the approaches to exposure assessment involve exposure measurementsto some degree \1\<NOTE/>, it is important that the proper ``match'' be made betweenthe measurement data and the type of exposure assessment. As discussedin the previous chapter, the exposure assessment approach will often dictatethe type of measurements needed if new data are being generated. More often,however, the exposure assessor has at least some data that were collectedfrom previous studies, either for exposure assessment purposes or (moreoften) for other purposes. In determining relevance of data for the intendedexposure assessment (adequacy of the data is covered in section 3.3), theassessor must consider not only the type of data and what it might logicallycharacterize, but also how this characterization relates to risk. <ITAG tagnum="28"/><NOTE/>\1\ Of course, it is always possible to do a predictive assessmentbased solely on models and assumptions, without a subsequent reality check,but even these assessments use models and model inputs which may ultimatelybe based on measurement in some form. There are many types of measurement data that an assessor can collect orevaluate for an exposure study. The measurements themselves are samples,and the assessor must have a clear idea of what kinds of inferences maybe made for each type of measurements and what assumptions need to be madeto make those inferences. Table 3-1 gives some examples of different typesof measurements, what these samples are usually used to characterize, andwhat additional information must be known before the data, inferences,and characterizations can be used in an assessment. As Table 3-1 illustrates, different types of measurements may be relevantto characterizing a variety of exposure-related media and parameters. (Nevertheless,just because certain measurements may be used to characterize these mediaor parameters is not a guarantee that in a particular assessment the mediumor parameter can be adequately characterized with the data at hand (seesection 3.3).) In addition to determining relevance to characterizing mediaor parameters, the assessor must also determine the relevance of thesemedia or parameters to the exposure assessment. <ITAG tagnum="110"><C/><T4>Table</T4> 3-1._<T4>Examples of Types of Measurements To Characterize Exposure-RelatedMedia and Parameters</T4><H1>Type of measurement (sample)</H1><H1>Usually attempts to characterize (whole)</H1><H1>Examples</H1><H1>Typical information needed to characterize exposure</H1>A. <T3>Predictive Assessments:</T3><ITAG tagnum="3"> 1. Fixed Location Monitoring</ITAG><D>Environmental medium; samples used to establish long-term indicationsof media quality and trends over time</D><D>NASQAN,\1\ water quality networks, air quality networks</D><D>Population location and activities relative to monitoring locations;fate of pollutants over distance between monitoring and point of exposure;time variation of pollutant concentration at point of exposure.</D><ITAG tagnum="3"> 2. Short-term Media Monitoring (including indoor air)</ITAG><D>Environmental or ambient medium; samples used to establish a ``snapshot''of quality of medium over relatively short time</D><D>Special studies of environmental media, indoor air</D><D>Population location and activities (this is critical since it must beclosely matched to variations in concentrations due to short period ofstudy); fate of pollutants between measurement point and point of exposure;time variation of pollutant concentration at point of exposure.</D><ITAG tagnum="3"> 3. Source Monitoring of Facilities</ITAG><D>Release rates to the environment from sources (facilities) (often givenin terms of relationship between release amounts and various operatingparameters of facility)</D><D>Stack sampling, effluent sampling, leachate sampling from landfills,incinerator ash sampling, fugitive emissions sampling, pollution controldevice sampling</D><D>Fate of pollutants from point of entry into the environment to pointof exposure; population location and activities; time variation of release.</D><ITAG tagnum="3"> 4. Food Samples</ITAG><D>Concentrations of contaminants in food supply</D><D>FDA Total Diet Study Program,\2\ market basket studies, shelf studies</D><D>Dietary habits of various age/sex/cultural groups. Relationship betweenfood items sampled and particular (geographic, ethic, demographic) groupsstudied; relationships between concentrations in uncooked vs. preparedfood.</D><ITAG tagnum="3"> 5. Drinking Water Samples</ITAG><D>Drinking water supply</D><D>Ground Water Supply Survey,\3\ Community Water Supply Survey,\4\ tapwater</D><D>Fate and distribution of pollutant from point of sample to point ofconsumption. Population served by specific facilities and consumption rates.For exposure due to other uses, e.g., cooking and showering, need to knowactivity patterns and volatilization rates.</D><ITAG tagnum="3"> 6. Consumer Products</ITAG><D>Concentration levels of various products</D><D>Shelf surveys, e.g., solvent concentration in household cleaners \5\</D><D>Establish use patterns and/or market share of particular product, individualexposure at various usage levels, extent of passive exposure.</D><ITAG tagnum="3"> 7. Breathing Zone Measurements (Industrial Studies)</ITAG><D>Exposure to chemicals in an industrial setting</D><D>Industrial hygiene studies, occupational surveys</D><D>Fate of pollutants between monitoring and point of exposures, location,activities, time spent relative to monitoring locations. Protective measures/avoidance.</D><ITAG tagnum="3"> 8. Microenvironmental Studies</ITAG><D>Ambient medium in a defined area, e.g., kitchen, automobile interior,office setting, parking lot</D><D>Special studies of indoor air, radon measurements, office building studies</D><D>Activities of study populations relative to monitoring locations andtime exposed.</D><ITAG tagnum="3"> 9. Surface soil sample</ITAG><D>Soil available for contact</D><D>Soil samples at contaminated sites</D><D>Fate of pollution on/in soil; activities of potentially exposed populations.</D><ITAG tagnum="3">10. Soil Core</ITAG><D>Soil including pollution available for ground water contamination; canbe an indication of quality and trends over time</D><D>Soil sampling at hazardous waste sites</D><D>Fate of substance in soil, speciation and bioavailability, and contactand ingestion rates as a function of activity patterns and age.</D><ITAG tagnum="3">11. Fish Tissue</ITAG><D>Extent of insult to ecological population, and/or extent of contaminationof edible fish tissue</D><D>National Shellfish Survey,\6\ special studies on local fish populations</D><D>For ecological assessments: Relationship of samples to fish population(then see reconstructive assessment below). For humans: relationship ofsamples to food supply for individuals or population of interest, consumptionhabits, preparation habits.</D>B. <T3>Direct Assessments:</T3><ITAG tagnum="3">1. Air Pump/Particulates and Vapors (``split sample'' air)</ITAG><D>Exposure of an individual or population via the air medium</D><D>TEAM study,\7\ carbon monoxide study \8\</D><D>Direct measure of individual exposure during time sampled; to characterizeexposure to population, relationship between individuals and populationmust be established as well as relationships between times sampled andother times for the same individuals, and relations between sampled individualsand other populations. In order to make these links, activities of thesampled individuals compared to populations characterized are needed insome.</D><ITAG tagnum="3">2. Split Sample Food/Split Sample Drinking Water</ITAG><D>Exposures of an individual or population via ingestion</D><D>TEAM study \7\</D><D>Same as above.</D><ITAG tagnum="3">3. Skin Patch Samples</ITAG><D>Dermal exposure of an individual or population</D><D>Pesticide Applicator Survey \9\</D><D>Same as above, skin penetration.</D>C. <T3>Reconstructive Assessments:</T3><ITAG tagnum="3">1. Breath</ITAG><D>Total absorbed dose for individuals or population (usually indicativeof relatively recent exposures)</D><D>Measurement of VOCs, alcohol (usually limited to volatile compounds)</D><D>(1) Relationship between individuals and population; exposure history(i.e., steady-state or not) pharmacokinetics (chemical half-life), possiblestorage reservoirs within the body.</D><P>(2) Relationship between breath content and body burden.</P><ITAG tagnum="3">2. Blood</ITAG><D>Total absorbed dose for individuals or population (usually indicativeof relatively recent exposures)</D><D>Lead studies, pesticides, heavy metals (usually best for soluble compounds,although blood lipid analysis may reveal lipophilic compounds)</D><D>(1) Same as above.</D><P>(2) Relationship between blood content and body burden.</P><ITAG tagnum="3">3. Adipose</ITAG><D>Total absorbed dose for individuals or population (usually indicativeof long-term averages)</D><D>NHATS,\1\\0\ dioxin studies, PCBs (usually limited to lipophilic compounds)</D><D>(1) Same as above.</D><P>(2) Relationship between adipose content and body burden.</P><ITAG tagnum="3">4. Nails, Hair</ITAG><D>Total absorbed dose for individuals or population (usually indicativeof past exposure in weeks to months range; can sometimes be used to evaluateexposure patterns)</D><D>Heavy metals studies (usually limited to metals)</D><D>(1) Same as above.</D><P>(2) Relationship between nails, hair content, and body burden.</P><ITAG tagnum="3">5. Urine</ITAG><D>Total absorbed dose for individuals or population (usually indicativeof elimination rates), may vary in time since exposure depending on chemical</D><D>PERC study,\1\\1\ TCE study \12\</D><D>(1) Same as above.</D><P>(2) Relationship between urine content and body burden.</P><F>\1\ U.S. EPA (1985b).</F><F>\2\ U.S. EPA (1986b).</F><F>\3\ U.S. EPA (1985b).</F><F>\4\ U.S. EPA (1985e).</F><F>\5\ U.S. EPA (1985d).</F><F>\6\ U.S. EPA (1986b).</F><F>\7\ U.S. EPA (1987a).</F><F>\8\ U.S. EPA (1987a).</F><F>\9\ U.S. EPA (1987d).</F><F>\10\ U.S. EPA (1986e).</F><F>\1\\1\ U.S. EPA (1986d).</F><F>\1\\2\ U.S. EPA (1987e).</F></ITAG>For example, if a chemical shows adverse effects through inhalation, butingestion and dermal studies show no adverse effects, measurement datato characterize ingestion and dermal routes of exposure may be irrelevant.\2\<NOTE/> Likewise, for a substance that shows adverse effects forsome forms (vapor, solid, particular valence state, etc.) but not others,the assessor must evaluate and explain why the data used match with thechemical species of concern.<ITAG tagnum="28"/><NOTE/>\2\ A caution here; unless pharmacokinetics are reasonablywell known and mechanisms of action identified, it is often very difficultto dismiss exposure routes as totally irrelevant, even if some studiesshow no apparent adverse effect.In addition to the general discussion of relevance above, the followingsections deal with more specific issues of relevance.<ITAG tagnum="81">3.2.1. Direct Measurement of Exposure</ITAG>Direct exposure assessments always rely on measurements. Assessments usingthe direct measurement approach can be assessing individual exposures,exposures to groups of individuals or segements of a population (i.e.,a subpopulation) of which the sampled individuals are a part. Each of theseobjectives of the overall exposure assessment presents different issuesof relevance to using the data.Data collected for the direct measurement approach are typically personalsamples of an individual or small population sample. The data are usuallychemical-specific, although samples of radiation, particulates, fibers,or other non-chemical-specific agents have been measured. The data areusually time-specific, and can be expressed in terms of a time-weightedaverage (TWA) (i.e., 1-hour TWA, 8-hour TWA, etc.) or a continuous curve(e.g., by using the recording carbon monoxide monitor). The data are usuallylocation-specific, the location being wherever the individual with thepersonal monitor was during the period of measurement. It should be notedhere that unless detailed records are kept of where the individual goesand for how long, this information may not be available to the assessor.The data are also usually a function of the specific activities of theindividual during the period of measurement; this information is rarelyavailable to the assessor in more than very broad categories, if at all.To make the case that the direct measurement data are relevant to the exposureassessment being done, the exposure assessor must show that these factorsfor the data match the objective of the assessment. If there is an unknownor partial match between the data factors and the assessment objectives,the assessor must make, state, and justify assumptions that will establisha logical link. For example, if 8-hour TWA data are available, and theobjectives of the assessment are to evaluate average exposure over 10 years,the 8-hour TWA data might be used if it is known (from other data, observation,etc.) that the concentrations/exposures do not vary significantly fromday to day, and that the day selected for measurement is representativeor typical (based on statistical considerations, etc.).For those individuals for whom direct measurements of exposure have beenmade, these data may be used directly in individual exposure assessmentsprovided the data are of adequate quality (see section 3.3), are measuresof the appropriate chemical or agent, and are actually measuring exposurewhile it takes place. This is an unusual case in that it is one of thefew times where measurement data may be used directly as exposure data.Individual direct measurement exposure assessments are usually done forthe purposes of protecting the individuals, often in an occupational environment.When exposures are being compared to an action level, concern level, standard,or other benchmark, and the data are being taken to answer a yes/no questionabout whether exposure is above the benchmark, direct measurements properlycollected are the most relevant data.Direct measurement data are also used to characterize the exposures ofa population, or a segment of a population, by making inferences from theindividuals sampled to the population or population subgroup. The logicallink between the individuals sampled and the entire population is considerablystrengthened by statistics. If the individuals sampled were selected randomly,probabilistically, or in a manner that can be described with statistics,this link can perhaps be described quantitatively, and the exposure assessoris advised to consult a statistician to help in establishing the relevanceof the data taken for individuals to the exposures of a population. Itmust be kept in mind that the population being characterized by the datais not necessarily the population desired for the objectives of the assessment,since the assessment may involve different times (summer, winter, etc.),different locations (all service station attendants vs. data taken forattendants in Cleveland, etc.), or different activity patterns (personswho eat fish vs. persons who do not eat fish, etc.). All of these differencesbetween the data measured and the population for which the assessment requirescharacterization must be identified and logical links must be drawn betweenindividual measurement data and population exposures before the data canbe fully relevant.<ITAG tagnum="81">3.2.2. Reconstructive Exposure Assessment</ITAG>Measurement data for reconstructive exposure assessments are usually fromindividuals (although composite tissue samples from several individualsare sometimes used), are usually chemical-specific, and may also be location-specific,time-specific, and activity-specific. Some reconstructive exposure assessmentsamples will reflect exposures over the relatively recent past (e.g., exposurescan be reflected in breath, blood, urine, and fecal samples after minutes-to-days),while others will be indications of exposures over a longer period of time(e.g., adipose tissue, bone, and hair samples are usually reflective ofexposures that took place weeks-to-years previously). The key to linkingmeasurements of body burden or other biomarkers to exposure assessmentis pharmacokinetics (i.e., the time-dependent distribution, metabolism,transport, storage, and elimination of the agent within the organism).In addition, before these measurements can be used to reconstruct absorbeddose or exposure, information must be known on the properties of the chemical,individual characteristics (size, body fat content, etc.), and whetherthe exposure has been long-term, acute, intermittent, a past episode, etc.Pharmacokinetics can also be used to establish the relevance of particularsamples to the exposure assessment being considered. Because pharmacokineticsmaps out where a substance is likely to go within an organism, it willindicate the relevance of various tissues or fluids as an indication ofexposure. For example, for a lipid-soluble substance with a long half-lifewithin the body (such as 2,3,7,8-TCDD), pharmacokinetic considerationswould show that adipose tissue or blood fat samples may be very relevantwhile breath samples are irrelevant, since inside the body the chemicalavoids the blood/breath elimination route and instead is stored in fattissue.As with the direct measurement data discussed in the preceding section,reconstructive exposure assessment usually use data from an individual,and so the inferences made from the samples will be to characterize theabsorbed dose (or exposure if absorption data are available) for an individual.All of the considerations discussed previously about making inferencesfrom individuals to populations also apply here.<ITAG tagnum="81">3.2.3. Predictive Exposure Assessment</ITAG>Use of measurement data in predictive exposure assessments can vary widely,from a speculative assessment where no measurements are used directly,to an assessment where extensive measurement data are used both to characterizethe chemical and to characterize the activities of the individuals or populationsassessed. Exposure assessments that use no measurement data directly havelegitimate purposes in a regulatory agency, for example, where the chemicalhas not been manufactured yet so no measurements can be made, or in preliminaryevaluations of exposure where great precision is not required.\3\<NOTE/> However, most predictive exposure assessments use at leastsome measurement data.<ITAG tagnum="28"/><NOTE/>\3\ For example, many times a decision is needed as to whichchemical to study first, or even whether to continue to study a chemical.Often these decisions involve few resource consequences and great precisionis not necessary. This is not to say, however, that important decisionswith large resource implications should be made based on assessments usingno measurements if measurement data may make a difference in the decision.Like the other approaches to exposure assessment, the predictive approachrequires the assessor to make a logical link between the measurement dataand the exposure. Because of the many different types of measurements usedin predictive exposure assessment, making these links (say, from sourcemeasurements to exposures) can be complex. Using measurement data to quantifyexposure is usually done using any of several forms or derivatives of ageneral exposure equation.Exposure, or the contract of an agent with the exchange boundaries of anorganism (i.e., skin, lungs, digestive tract, etc.), can be mathematicallydefined as the amount of the agent available for absorption at the exchangeboundaries. Over a period of interest, T, this can be described  </ITAG><ITAG tagnum="10">where E is the exposure, I is the intensity of contract, and t istime. The units of E are ``amount,'' usually a mass of a chemical, butamount can also be in terms of fibers of asbestos, radiological amounts,etc. if the dose-response relationship for which the exposure and doseinformation being calculated are also in these terms. For the sake of simplicity,the discussion that follows will use units of mass for E. Note that I variesover time and may even be zero for part of the period of interest fromt=0 to t=T. The units of I are mass/time.The intensity of contact, I, is a function of C, the concentration of thepollutant in the medium contacting the organism, and CR is the contactrate or extent of contact:<ITAG tagnum="26">I=(C) (CR)    (3-2)</ITAG></ITAG><ITAG tagnum="10">The units of C and CR may vary, but must be compatible with each otherand must lead to units of mass/time exposed for I. For example, if C isin units of M/M (e.g., mg/kg food ingested), CR is in units of M/T (e.g.,kg food ingested/day). If C is in units of M/V (e.g., mg/L water ingested),CR is in units of V/T (e.g., L water ingested/day). Conversion factorsmay be necessary in assessing I. For example, if C is in units of V/V (e.g.,ppm in air), a conversion factor to M/V (say, mg/m\3\ of air) would benecessary if CR is in the typical units of V/T (m\3\/day). For dermal exposures,if C is in units of, say, M/V of bulk material (e.g., mg/L), a conversionfactor of the form (M/A)/(M/V) (say, mg available per cm\2\ skin exposed/mgper L bulk material) yielding C in units of M/A (e.g., mg/cm\2\) with CRtypically in A/T units (e.g., cm\2\ skin exposed/hour).The discrete form of equation 3-1 is:<ITAG tagnum="110"><C>5,L1(0,0,0),tp0,p8,8/1,g1,t1,b1,aw,i1,4,4,xs108,6,6</C> <H1>E=</H1><H1>N</H1><H2/>S<H3>i=1</H3><H1>I</H1><T2>i</T2> t<T2>i</T2>=I<T2>1</T2>t<T2>1</T2>+I<T2>2</T2>t<T2>2</T2>+ . . . +I<T2>n</T2>t<T2>n</T2><H1> </H1><H1>(3-3)</H1><ITAG tagnum="22"> </ITAG></ITAG></ITAG><ITAG tagnum="10">where t<T2>i</T2> now becomes the duration of exposure of event i, and I<T2>i</T2> is the intensity of contact for exposure event i. For multipleexposure events over period of interest T (using equations 3-2 and 3-3):<ITAG tagnum="110"><C>8,L1(0,0,0),tp0,p8,8/1,g1,t1,b1,aw,i1,4,4,4,1,4,xs42,5,6</C> <H1>E=</H1><H1>N</H1><H2/>S<H3>i=1</H3><H1>I</H1><T2>i</T2>t<T2>i</T2><H1>=</H1><H1>N</H1><H2/>S<H3>i=1</H3><H1>(C</H1><T2>i</T2>)(CR<T2>i</T2>)t<T2>i</T2><H1> </H1><H1>(3-4)</H1><ITAG tagnum="22"> </ITAG></ITAG></ITAG><ITAG tagnum="10">where<ITAG tagnum="110"><C>5,L1(0,0,0),tp0,p8,8/1,g1,t1,b2,aw,i1,4,4,2,r10,6</C> <H1>T=</H1><H1>N</H1><H2/>S<H3>1=1</H3><H1>t</H1><T2>i</T2><H1> </H1><H1>(3-5)</H1><ITAG tagnum="22"> </ITAG></ITAG></ITAG><ITAG tagnum="10">for all events, and <ITAG tagnum="110"><C>5,L1(0,0,0),tp0,p8,8/1,g1,t1,b2,aw,i1,5,4,2,r10,6</C> <H1>ED=</H1><H1>N</H1><H2/>S<H3>i=1</H3><H1>t</H1><T2>i</T2><H1> </H1><H1>(3-6)</H1><ITAG tagnum="22"> </ITAG></ITAG></ITAG><ITAG tagnum="10">for events where I is not zero. ED is the duration of exposure overall events where exposure occurs, that is, where the intensity of contact,I, is not zero.The <T3>exposure rate</T3> can be defined as the exposure per unit of time.Certain average exposure rates can be useful in exposure assessment. Usingequations 3-4 and 3-5, if I<T2>c</T2> is a weighted average intensity of contact over the period ofinterest (including those segments of time when intensity is zero):<ITAG tagnum="26">ER<T2>c</T2>=I<T2>c</T2>=E/T    (3-7)</ITAG></ITAG><ITAG tagnum="10">where ER<T2>c</T2> is the calendar-time exposure rate. If equation 3-6 is usedinstead of 3-5, a similar exposure rate is derived for those times whenexposure is actually occurring:<ITAG tagnum="26">ER<T2>e</T2>=I<T2>e</T2>=E/ED    (3-8)</ITAG>Note that in equations 3-4, E is the same whether or not there are zerointensity terms on the right side of the equation, but 3-7 represents acalendar-time (or clock time) exposure rate and 3-8 represents and exposure-timeexposure rate. The difference is whether the exposure rate, which is anaverage, is averaged over a period of time where sometimes exposure iszero, or is averaged over only those periods of time when exposure is occurring.By substitution,<ITAG tagnum="26">ER<T2>c</T2>=I ED/T    (3-9)</ITAG>For cases where the contact rate, CR, is reasonably constant, and usingthe weighted average concentration for C, substituting equations 3-2 into3-9 yields:<ITAG tagnum="26">ER<T2>c</T2>=(C) (CR) (ED)/T    (3-10)</ITAG></ITAG><ITAG tagnum="10">where ER<T2>c</T2> is the calendar-time exposure rate for period of interest T,and ED is the time during which exposure actually occurs at average concentrationC and contact rate CR. This exposure rate can be normalized to unit bodyweight (BW) to yield a normalized calendar-time exposure rate. A commonly-encounteredspecial case of this is the lifetime average daily exposure (LADE), wherethe period of interest is the lifetime (LT):<ITAG tagnum="26">LADE=(C) (CR) (ED)/(LT) (BW (3-11)</ITAG></ITAG><ITAG tagnum="10">where, using representative units for water ingestion as an example:<ITAG tagnum="26">LADE=lifetime average daily exposure     [mg/kg/day] </ITAG><ITAG tagnum="26">C=average concentration [mg/L water ingested] </ITAG><ITAG tagnum="26">CR=contact rate [L water ingested/day] </ITAG><ITAG tagnum="26">ED=duration of time when exposure actually occurs days] </ITAG><ITAG tagnum="26">LT=lifetime [70 years converted to days] </ITAG><ITAG tagnum="26">BW=body weight (kg) (Note that this is average body weight over alifetime and not merely the adult body weight.)</ITAG></ITAG><ITAG tagnum="10">The resulting LADE is a normalized lifetime exposure rate. Anotheruseful relationship encountered frequently is the dose equation, givenin simplified form:<ITAG tagnum="26">D=(E) (AF)    (3-12)</ITAG></ITAG><ITAG tagnum="10">where D is dose (units are mass), E is exposure, and AF is an absorptionfraction:<ITAG tagnum="26">AF=amount absorbed/amount available for absorption (3-13)</ITAG>These equations, when used with equation 3-11, give rise to another commonlyencountered term, the lifetime average daily dose (LADD):<ITAG tagnum="26">LADD=(C) (CR) (ED) (AF)/(BW) (LT) (3-14)</ITAG>Note that the concentration (C), the contact rate (CR), the exposure duration(ED), absorption fraction (AF), lifetime (LT), and body weight (BW) areall parameters that are specific to the individual, although the absorptionfraction, body weight, and lifetime might usually be described with genericmeasurements, that is, averages for a population, since they are reasonablyconstant for an individual. Note also that both CR and ED are dependenton the activities of the individual, and the relevant data for these parametersare activity pattern data. A major task for the exposure assessor is todetermine which measurement data are relevant to determine C, the concentrationof the agent that contacts the individual. In actual exposure situations,C is likely to vary over time, sometimes by a great deal.There are several ways that exposure assessors use measurements such asthose listed in Table 3-1 to determine C and to calculate exposures usingthe predictive approach. Three of these ways, each having a somewhat differentapproach to dealing with the variation in C (and other parameters), arethe <T3>scenario method, </T3>the <T3>microenvironment method, </T3>and the <T3>Monte Carlo method. </T3>For all of these methods, the measurementdata are first used to make inferences about environmental or ambient media,and how concentrations of the chemical or agent vary over time in thosemedia. The logical links are formed and justified between the measurement(sample) data and the characterization of the media as given in the examplesin Table 3-1. Once these characterizations are made, they are used to makeinferences about exposure. These three methods are not mutually exclusive,and often are used in combination in exposure assessments.The scenario method can be used either with a single scenario, usuallystarting with an average concentration to calculate an LADE or LADD asin equations 3-11 and 3-14, or with multiple scenarios. In the <T3>single scenario method, </T3> a set of assumptions is made about howexposure takes place for an individual, and values for the various parametersin the generic exposure equation are derived from the assumptions. Forexample, let us assume we are doing an exposure assessment concerned withchloroform in drinking water. Since it is known that chloroform may beformed as part of the chlorination process in a drinking water treatmentplant, the drinking water treatment plant can be viewed as the source,and measurements can be made of the chloroform concentrations in the finisheddrinking water leaving the plant. Knowledge or data concerning the fateof chloroform in the distribution system will help build the logical linkbetween the measurements at the treatment plant and later exposure; fateinformation may allow linking the concentrations at the plant with thoseat the tap.\4\<NOTE/> An average concentration in tap water can be estimated fromthe data and fate considerations, say in this case, 20 mg chloroform/Ltap water. Activity pattern data are used, or assumptions made, concerningthe activities of the exposed individual, to determine what the parametersfor contact rate and exposure duration will be for the scenario. For thisscenario, assume the contact rate is two liters of tap water ingested daily,and that the individual lives at this location for 40 years (the exposureduration). Using a lifetime of 70 years (converted to days), and a bodyweight of 70 kg, the LADE calculation (using equation 3-11) is straightforward.<ITAG tagnum="28"/><NOTE/>\4\ Alternately, of course, one could take measurements atthe tap and consider that as the source for the purpose of the assessment.Where this approach may cut down uncertainty for the individual exposure,it makes generalization to a population from the individual estimates somewhatmore difficult since the relationship among the individuals as far as differencesin concentration at the tap is unknown.For the concentration parameter in the exposure equation, the single scenariomethod usually assumes it to be a single value. (The mean value and highestvalue reported are two common single-value treatments depending on whetherthe scenario is supposed to represent a ``typical'' or ``worst case,''respectively.\5\<NOTE/> Recall that in the derivation of LADE in equation 3-11, itis an average intensity of contact for the exposure period. Substitutingthe highest value reported for the concentration term for a worst-caseestimate in the LADE equation is essentially saying that the person willbe exposed to that value on average for the duration of exposure (ED inequation 3-11). Variation in the concentration parameter C, as well asthe other parameters, are often treated with ranges or a sensitivity analysis.Use of the single scenario method, where variation in the parameters isnot used, can only be justified if individual exposures are being evaluated;applying a single scenario estimate to a population without consideringvariation is tantamount to saying all members of the population behaveexactly the same way and are exposed to exactly the same concentrationsof the chemical or agent. In cases where the variation is not known, singlevalues may be used if explained in the uncertainty section of the assessment,where an analysis of the impacts of possible variation should be done.<ITAG tagnum="28"/><NOTE/>\5\ A worst-case scenario is one that estimates the highestexposure. One form of worst-case scenario is the so-called ``maximallyexposed individual'' (MEI), which represents the single individual withthe highest exposure. Naturally, the worst case can be arrived at in anumber of ways besides maximizing concentration; the exposure can oftenbe much more sensitive to the activities of the individual (ingestion rates,for example). In most exposure assessments, adjusting all the parametersto their limiting values would maximize exposure results in a scenariothat may not have realistic chance of happening in the real world. Forexample, in the drinking water scenario, maximizing all parameters in anLADD calculation would mean the individual with the smallest body weightand shortest lifetime consumed the most water per day at the highest concentrationfor the longest duration; this combination is unlikely to actually occursince at least some of the parameters (e.g., body weight and consumptionrate) may be covariant. For this reason, the concept of ``reasonable worst-case''scenarios is often used, where the exposures are high but the combinationof parameters thought to be one which probably occurs in the actual population.A few words need to be said here about the use of ``worst-case'' scenarios.As discussed in Chapter 1, the exposure assessor is trying to estimatea real-world dose to use in the dose-response relationship for a risk assessment.By maximizing the parameters in a scenario for exposure, the assessor islooking at the top end of the distribution of exposures in a population(if indeed the worst case actually exists in the population). A legitimateuse of worst-case scenarios is to determine if the exposure or risk islow enough even at this extreme so as to dismiss concern for this scenario.It is not legitimate to use a worst-case scenario to prove that there infact exists a concern in a real population. In constructing a worst-casescenario, the assessor has usually added assumptions or used particulardata points that bring into question whether the scenario actually representsthe real world. If the exposure or risk value estimated by a worst-casescenario is high enough to cause concern, the assessor must reevaluatethe parameters used and perform reality checks before deciding a problemreally exists. It is critical that the results of a worst-case individualscenario are not immediately applied to an entire population, since inalmost all cases this will result in a substantial overestimate of a potentialproblem.In the <T3>multiple scenario method, </T3>several individual scenarios are constructed,with particular attention given to highlighting the variability of theparameters used for the scenarios. The most common use of multiple scenarioswill be where a typical case and a worst case (or reasonable worst case)are constructed, using the same procedures described above. In its theoreticalextreme, one could construct a different scenario for each individual,using the particular values of the parameters which apply to that individual,and derive an estimate of population exposures by aggregating the individualscenarios.\6\<NOTE/> With populations of more than a small number of individuals,this may become unwieldy, but often groups of individuals will be treatedas behaving similarly enough to be covered by a single scenario, therebydividing the population into subpopulations. This procedure is often donewhen estimating occupational exposures for a single chemical across a numberof job types. Each job type is covered by a different scenario which usesthe particular parameters pertinent to that job. <ITAG tagnum="28"/><NOTE/>\6\ This has in fact been done by the Office of Toxic Substancesfor the 4920 respondents in the OTS chlorinated solvents study, as reportedin the Task andplusmin;43 report to contract 68-02-4254, dated 8/31/87, titled,``Consumer Exposure Estimates for Solvents.''The <T3>microenvironment method</T3> treats the variability in the concentrationcontacted, C, as a series of constants. If the contact rate is assumedto be fairly constant during periods of exposure, equation 3-4 can be reducedto:<ITAG tagnum="110"><C/> <H1> </H1><H1>E=(CR)</H1><H1>N</H1><H2/>S<H3>i=1</H3><H1>C</H1><T2>i</T2> <T2>i</T2><H1> </H1><H1>(3-15)</H1><ITAG tagnum="22"> </ITAG></ITAG></ITAG><ITAG tagnum="10">where each microenvironment i has associated with it a characteristicconcentration C<T2>i</T2>, and the subject spends a duration t<T2>i</T2> in that microenvironment. In this method, the individual's surroundingsare divided into compartments where the chemical or agent concentrationremains constant, or at least has a known and describable variability.Measurement data for concentrations of chemicals or agents are usuallydescribed as constants (usually means of the measured data) for each microenvironment.Exposure estimates are derived by using an exposure equation such as theone described above, evaluating each microenvironment, and summing overall the microenvironments for an individual. Unlike the scenario methodsdescribed in equation 3-11, however, which essentially evaluate averageindividual exposure and which can then be aggregated to populations, themicroenvironment method can more easily directly incorporate data on populationactivity patterns into the estimate by assigning statistical weights tothe various microenvironments.   The <T3>Monte Carlo method </T3>immediately uses the fact that the parametersin the generic exposure equation are not single values, but distributionsof values, to derive a distribution of exposures in the population. Usingcomputer-assisted iterative techniques, the Monte Carlo simulation willsolve exposure equations multiple times (hundreds, thousands) using allthe actual values observed from measurements or characterization of themedia, and all the data about activity patterns. The technique involvesusing random combinations of the actual data enough times to generate adistribution of estimated exposures while recreating the distribution ofthe data on the equation parameters. Although this may superficially resemblethe theoretical extreme of the multiple scenario method discussed previously,it is fundamentally different, since the multiple scenario method purposefullycombines the values from the distribution and the Monte Carlo method doesthis randomly. Whereas the multiple scenario technique may be impracticableif the population is large, the Monte Carlo method is not limited by alarge population. Because of the way the estimate is derived, however,the Monte Carlo method has several issues that the exposure assessor mustkeep in mind before using it. First, the Monte Carlo technique works onthe assumption that the parameters are independent; if they are not independent,but assumed so, excessive error may result. There are methods, however,to account for covariance if known. Second, and a more resource-relatedconcern for most exposure assessors, is that the variation or distributionof the input parameters must be known. For the assessor using measurementdata to derive distributions of concentrations or activities, this mayhave important ramifications to the sampling plan, and it is best to consulta statistician about the possibility of using the data for Monte Carlosimulations before the date are collected.<ITAG tagnum="81">3.2.4. Measurements and Modeling   </ITAG>In exposure assessments, exposure models based on mathematical equationsare used extensively to calculate things such as environmental fate/transportin surface water, indoor air levels of chemicals volatilizing from consumerproducts, etc. These exposure models and exposure-related measurementsshould be mutually supportive. When an analytical method for a particularchemical and medium is well established, and models are just being developed,all collected measurement data can be used to validate the models. Conversely,when such an analytical method is being developed and the appropriate mathematicalmodels are well accepted, the models can be part of the process of verifyingthe data from the analytical method. Whenever the relative certainty ofmodels and the relevant measurements of adequate quality are in question,the assessor should favor the measurements.   EPA's Office of Research and Development is in the process of establishingcriteria for the selection of exposure assessment-related models that aremost useful for a particular scenario. Part of this process involves theuse of measurement data to answer selection criteria questions (e.g., fateand transport, degradation rates). Model selection criteria documents alreadyexist for ground water (U.S. EPA, 1988d) and surface water (U.S. EPA, 1987c)and are being developed for other media.   Monitoring data and environmental fate modeling are complementary toolsused to help estimate exposure. A combination of monitoring data and estimatesobtained from environmental modeling reduces uncertainty in estimatingchemical concentrations at exposure points. While monitoring data havethe advantage of being actual measurements at the pollution site, theymay have potential limitations, particularly in assessing long-term trends.However, measurement data, which are autocorrelated, can be used to predicttrends in future exposures (Roach, 1977). Over-reliance on monitoring datacan cause underemphasis of chemicals that have not yet been released froma source or are slow moving.   Another question related to monitoring data, which modeling helps resolve,is whether they are representative only of their sampling locations, orare relevant also to an overall exposure assessment. Because chemical concentrationsare spatially variable, the assessor may need to use modeling for properspatial representativeness in the exposure assessment. Monitoring usuallyrepresents a spatial distribution that is by necessity limited. The useof models in conjunction with monitoring can project chemical concentrationsover space and time, thereby strengthening the logical link between measurementdata and exposures.<ITAG tagnum="81">3.2.5. Use of Surrogate Data in Pesticide Exposure Assessment </ITAG>The use of surrogate data plays a major role in EPA assessments of humannon-dietary exposure to chemicals, especially in the Office of PesticidePrograms. According to the Agency's ``Pesticide Assessment Guidelines,Subdivision U, Applicator Exposure Monitoring'' (U.S. EPA, 1987d): ``Surrogateexposure data are defined as exposure monitoring data collected for otherpesticide chemicals using comparable methods and under similar conditionsas for the pesticide under assessment.'' The mechanics of the use of surrogatedata have been discussed in public fora and in the published scientificliterature in recent years. The assumption in the use of surrogate datais that in many pesticide application scenarios, the physical parametersof application (such as human activity which leads to exposure), not theproperties of the pesticide, are most important in determining the levelof exposure. Note that when using a passive dosimetry monitoring method,what is measured is the amount of chemical impinging on the skin surface,or available for inhalation, that is, exposure, not the actual dose received.Factors such as dermal penetration, are, of course, expected to be highlychemical-dependent. The development of a surrogate data base, and valid predictive correlationswhere possible, is a procedure that the Agency will continue to pursue.The Agency believes that it is more reliable to estimate exposure basedon an extensive, scientifically sound and appropriate ``surrogate'' database rather than on the results of an individual pesticide applicationstudy with a limited number of replicates, even if that single study isjudged valid by the Agency. As the Agency receives additional valid exposuredata from any source, the data will be added to the existing data base,thus expanding the data base and improving its reliability for estimatingexposure for other pesticides. <ITAG tagnum="81">3.2.6. Combining Measurement Data Sets from Various Studies</ITAG>Combining data from more than one source into a single data set must bedone cautiously. The circumstances under which each set of data was collected(target population, sampling design, location, time, etc.) and the qualityof the data (precision, accuracy, representativeness, completeness, etc.)must be evaluated. Combining summary statistics of the data sets (e.g.,means) into a single data set may be more appropriate than combining theoriginal data values. Statistical methods are available for combining resultsfrom individual statistical tests. For example, in applicable cases, severalstudies with marginally statistically significant results may justify anoverall conclusion of a statistically significant effect. The best way to report data is to provide sufficient background informationfor the measurement data set, including clear documentation of the sourceof the data (including references). This allows for determining the underlyingprobability distribution of the measurement variable. A probability distributioncan be ascertained from the following types of information about the dataset: the arithmetic or geometric mean, the number of measurements in thedata set, the extreme values, the mode or modes, the median value, thevariance or standard deviation, and a histogram showing the general shapeof the distribution. Arithmetic means are good descriptors of the central tendency of a dataset provided the data set is normally distributed. Geometric means arebetter descriptors of central tendency for lognormal distributions. Themedian is a good measure of the location of the center of a data set becauseit is unaffected by extreme values. Unfortunately, it does not make useof all the information contained in the data set, but rather uses onlythe relative sizes of the measurements. The median is also less amenablethan a mean to mathematical treatment, and is more difficult to use inmore elaborate statistical techniques. <ITAG tagnum="81">3.3. </ITAG><T3>Adequacy of Measurement Data for the Intended Exposure Assessment</T3>Measurement data, whether generated for the particular exposure assessmentor taken from another measurement study, must be evaluated for their adequacyin use as samples representative of media, individual exposures, body burden,or whatever is being characterized. The same considerations discussed insection 2.4 concerning data quality (precision, accuracy, representativeness,completeness, and comparability) are appropriate when evaluating any databeing considered for use in an assessment. Even in the case of serious flaws, data should not be discarded entirelyunless better data are available. If flawed data are retained, the natureand seriousness of the flaws should be clearly stated. If flawed data arerejected for use in exposure assessments in favor of better data, the flawsshould be clearly stated and the basis for judgment of the retained datashould be documented. <ITAG tagnum="81">3.3.1. Quality Assurance and Quality Control for Previously-GeneratedData</ITAG>In many instances, previous studies may have developed data that couldbe useful for the current sampling plan requirements of the exposure assessor.Any data developed through previous studies should be validated with respectto quality and extrapolation to current use. The criteria for method selectionand validation should also be followed in the analysis of existing data.Some other considerations when evaluating data include the following:<T3>Analytical Methods_</T3>Were the analytical methods used in collectingor analyzing the data from the previous study consistent with present practices?The methods need not be identical, and a lower detection limit with a newermethod does not necessarily mean that the older data are inadequate. However,research might have identified problems with older methods that would invalidatethem for current use. <T3>Detection Limits</T3>_It should be determined whether the detectionlimits of the analytical method were sensitive to current Agency standardsand criteria for evaluating data. <T3>Laboratory</T3>_Was the laboratory performing the analysis consideredcompetent? Are matrix spike recoveries acceptable for the intended use?Were any laboratory blanks contaminated?<T3>Sample Collection Considerations</T3>_Was the sampling plan followed?Where and how were the samples collected? Were a sufficient number of samplescollected? Methods for sample collection are as important as methods forsample analysis. <T3>Sample Handling Considerations</T3>_Were traceability procedures followedif the samples were analyzed off-site? Were the samples preserved properly?How were the samples shipped? How long were the samples held before beinganalyzed?<ITAG tagnum="81">3.3.2. The Role of Limit of Detection (LOD) Values in MeasurementsUsed to Estimate Exposure</ITAG>The ability to detect and accurately measure a quantity tends to decreaseat low concentrations due to various factors such as sampling constraints,limitations of the measuring instrument, contamination from sources otherthan the source being considered, etc. The limitations of the measuringsystem must be understood when interpreting data for exposure assessment.The limit of detection (LOD) is the smallest concentration or amount ofa substance that can be reliably detected by a given measurement process.The limit of quantitation (LOQ) is the smallest concentration or amountof a substance for which quantitative results may be obtained with a specifieddegree of confidence. The precise interpretation of these definitions dependson the analytical method (e.g., particle counting methods differ from methodssuch as GC-MS with essentially continuous results) and the substance beinganalyzed. The definitions tend to vary also between applications and laboratories(``reliably detected'' may be defined as detected with a probability of95%, 99%, 99.9%, etc.). The exposure assessor should ensure that the LOD and LOQ have been clearlydefined and estimated for the measurement process under consideration andare appropriate for the needs of the exposure assessment. The laboratoryshould not only state numerical values, but definitions of the LOD andLOQ.Exposure assessors may often be faced with data consisting largely of ``belowLOD'' or ``at LOD'' values. Since the exposure assessment is only as goodas the data supporting it, it is essential to interpret these types ofdata properly so as to avoid misrepresenting the data set or the exposureassessment itself. Rules of thumb that the exposure assessor may encounterin the way data sets are reported include:<T3>Data less than the LOD reported as ``non-detected''</T3>_When measurementsless than the LOD are reported as non-detected, the data are referred toas censored. The level of censoring is based on the confidence with whichthe analytical signal can be discerned from the noise. Statistical methodsare available for treating these data sets and many are summarized andinclude working examples (Cox and Oakes, 1984; Miller, 1981; Kalbfleischand Prentice, 1980; Porter et al., 1988). <T3>All Non-detects reported as LODs</T3>_In this worst-case approach,all non-detects are assigned the value of the LOD, which may be consideredthe largest concentration of analyte that could be present but not yetdetected. This approach biases the mean in a positive direction. The seriousnessof such a bias will depend on the relative number of detects and non-detectsin the data set and the relative size of the detection limit compared tothe mean of the data with values above the LOD. <T3>All non-detects reported as zero</T3>_This approach results in biasingthe mean in a negative direction. Again, the seriousness of the bias dependson the relative number of detects and non-detects and the mean of the datawith values above zero.  <T3>All non-detects as LOD/2</T3>_This approach assumes that on the averageall values between the LOD and zero could be present; therefore, an averagevalue would result if many samples in this range were measured. Similarto the above approaches, the seriousness of the bias depends on the relativenumber of detects and non-detects and the mean of the data above LOD/2. Another option includes all measured values reported, without regard tothe considerations for LODs and LOQs. Negative values (e.g., a blank largerthan the value measured for a sample) must be reported when they occur.Indeed, if a population value is truly zero, an equal number of negativeand positive measured values is expected because of the measurement variability.Using this approach, the mean and standard deviation of the data set arethe important parameters, and the results for individual samples shouldnot be considered apart from the data set.  <ITAG tagnum="81">3.4. </ITAG><T3>Evaluation and Description of Uncertainty in the Use of Measurements </T3>The estimation of a quantitative value of a parameter using measurementdata is an inexact process. Every measurement results in a somewhat differentvalue for the parameter. Thus, the resulting data and any decisions basedon them have a degree of <T3>measurement uncertainty.</T3> When using field or laboratory measurementin the decision-making process, the exposure assessor must always evaluatethe data for their uncertainty and assess them for the error associatedwith the risk estimate. The assessment will also contain <T3>descriptive uncertainty,</T3> which refers to the uncertainty in thelogic of how the measured data and the exposures are linked. Descriptiveuncertainty as well as measurement uncertainty must be clearly indicatedin the assessment. An error in descriptive logic about how the measurementsand the exposures are linked may mean the difference between estimatingexposures that do or do not actually occur in the real world, with resultinghealth, ecological, or economic consequences. For that reason, it is essentialthat the non-numeric assumptions about how the measurements and exposuresare linked are clearly laid out in the uncertainty analysis.  Most predictive or reconstructive exposure assessments, and often directmeasurement assessments, also rely somewhat on expert judgment. Section3.4.3 discusses formal means for representing uncertainty due to expertopinion.  <ITAG tagnum="81">3.4.1. Assignment of Limits of Uncertainty to Data  </ITAG>Any assignment of uncertainty to data must consider both random and systematicsources of error and, for the measurement process, the sampling operationand the relation of the samples to the population of concern. The assignmentof measurement uncertainty must be made on the basis of a statistical analysisof the data. However, even the best statistical treatment may often involvesome subjective decisions. Accordingly, all details of the analysis ofthe data must be documented, and clear statements must be made as to whatthe assigned uncertainties represent.  <ITAG tagnum="81">3.4.2. Statistical Analysis of Data  </ITAG>The services of a professional statistician are essential in the exposureassessment process when data are being analyzed statistically.  The evaluation of both the mean and the dispersion of a data set dependson the knowledge or assumption of the type of distribution of the population.Types range from a uniform distribution in which all individuals have thesame frequency of occurrence (e.g., flipping a coin) to those in whichthe frequencies of occurrence vary and may be symmetrically or asymmetricallydistributed. The normal distribution is the type most frequently encounteredand is familiar to most scientists. The results of measurement processesare often normally distributed. Individual samples from environmental mediaoften exhibit a log-normal distribution. Log-normal data can be transformedto normal data by first converting to logarithms and then treating thelogarithms as if they were the actual data. It would be useful to graphthe available data to ensure that the results are normally distributed.There are computerized statistics packages on the commercial market thatfacilitate the determination of data distribution. Also, a limited numberof samples may preclude statistical analysis of the data.  Depending on the distribution of data, statistics such as dispersion, range,standard deviation, and confidence intervals can be developed, as wellas measures of bias and uncertainty. Again, the exposure assessor is advisedto consult a statistician or good statistics text for further informationand guidance in this area.  <ITAG tagnum="81">3.4.3. Decision Analytic Approach for Expert Opinion  </ITAG>The decision analytic approach explicitly characterizes and representsmajor uncertainties using probability as the language to convey the degreeof uncertainty. When the available data are too indirect, conflicting,or incomplete to draw relationships of concern, the National Academy ofSciences, in its 1977 review of EPA's decision-making procedures, endorsedthe use of (judgmental) probabilities as a means for scientific expertsto communicate more precisely their knowledge concerning scientific uncertaintiesto decision-makers (National Academy of Sciences, 1977). An important issuein implementing a decision analytic assessment is the selection of theexposure experts to provide probabilistic exposure relationships. Thereis extensive literature covering techniques used for eliciting probabilityjudgments from experts and the various types of bias that can occur whenexperts make such judgments (Von Holstein and Matheson, 1979; Spetzlerand Von Holstein, 1975; Kahneman et al., 1982; Wallsten and Budescu, 1983). Bayesian inference is worthy of note for combining expert opinion and experimentalor survey data. This approach to representing uncertainty is to begin witha prior probabilistic distribution to represent the uncertainty, basedon expert opinion, anecdotal information interpreted by an expert, or othersources. The prior distribution is then updated using experimental dataand standard Bayesian statistics to obtain an updated or ``posterior''distribution, which is taken to be the final form of the distribution (seeHayes et al., 1987, or any statistics text covering Bayesian inference). <ITAG tagnum="84">Glossary of Terms  </ITAG>Absorbed Dose_The amount of a substance penetrating across the exchangeboundaries of an organism, via either physical or biological processes,after contact (exposure).  Accuracy_The measure of the correctness of data, as given by the differencebetween the measured value and the true or standard value.  Administered Dose_The amount of a substance given to a human or test animalin determining dose-response relationships, especially through ingestionor inhalation. (See applied dose.) Even though this term is frequentlyencountered in the literature, administered dose is actually a measureof exposure, because even though the substance is ``inside'' the organismonce ingested or inhaled, administered dose does not account for absorption.(See absorbed dose.)  Agent_A chemical, radiological, mineralogical, or biological entity thatmay cause deleterious effects in an organism after the organism is exposedto it.  Ambient_Surrounding conditions. ``Indoor ambient'' and ``outdoor ambient''are sometimes used to differentiate between indoor and outdoor surroundings. Ambient Measurement_A measurement (usually the concentration of a chemicalor pollutant) taken in an ambient medium, normally with the intent of relatingthe measured value to the exposure of an organism which contacts that medium. Ambient Medium_One of the basic categories of material surrounding or contactingan organism, e.g., outdoor air, indoor air, water, or soil, through whichchemicals or pollutants can move and reach the organism. (See biologicalmedium, environmental medium.)  Applied Dose_The amount of a substance given to a human or test animalin determining dose-response relationships, especially through dermal contact.(See administered dose.) Even though this term is encountered in the literature,applied dose is actually a measure of exposure, since it does not takeabsorption into account.  Arithmetic Mean_The sum of all the measurements in a data set divided bythe number of measurements in the data set.  Breathing Zone_A zone of air in the vicinity of an organism from whichrespired air is drawn. Breathing zone measurements are frequently madein occupational health studies by placing monitors at fixed locations ofapproximately head height near where a worker spends a substantial amountof the workday.  Bias_A systematic error inherent in a method or caused by some featureof the measurement system.  Biological Measurement_For the purposes of reconstructive exposure assessment,a measurement taken in biological medium, usually of the concentrationof a chemical/metabolite or the status of a biomarker, normally with theintent of relating the measured value to the absorbed dose of a chemicalat some time in the past. (Biological measurements are also taken for purposesof monitoring health status and predicting effects of exposure.) (See ambientmeasurement.)  Biological Medium_One of the major categories of material within an organism,e.g., blood, adipose tissue, or breath, through which chemicals can move,be stored, or be biologically, physically, or chemically transformed. (Seeambient medium, environmental medium.)  Comparability_The ability to describe likenesses and differences in thequality and relevance of two or more data sets.  Data Quality Objectives (DQO)_Statements of the level of uncertainty anassessor is willing to accept in results derived from environmental data. Direct Measurement of Exposure_An approach to quantifying exposure by takingmeasurements of exposure at or near the exchange boundaries of an organismwhile the exposure is taking place.  Dose_The amount of a substance available for interaction with metabolicprocesses of an organism following exposure and absorption into the organism.The amount of a substance crossing the exchange boundaries of skin, lungs,or digestive tract is termed <T3>absorbed dose,</T3> while the amount available for interaction by anyparticular organ or cell is termed the <T3>delivered dose</T3> for that organ or cell. Theoretically, the sumof the delivered doses plus the metabolic transformations should equalabsorbed dose. (The terms <T3>adminstered dose</T3> and <T3>applied dose</T3> refer to amounts of a substance made available forabsorption, and therefore are measures of exposure rather than dose. Assuch, these terms, sometimes found in the literature, are somewhat confusingand should be avoided if possible by exposure assessors. The term <T3>exposure dose</T3>, a common radiological term, refers to exposurebut carries the assumption that the absorption fraction is one, makingexposure equal to absorbed dose. Again, this term is somewhat confusingand should be avoided if possible.)  Dose Rate_Dose per unit time, for example in mg/day. Dose rates are oftennormalized to body weight, yielding units such as mg/kg/day.  Dose-Response Assessment_The determination of the relationship betweenthe magnitude of exposure and the probability of occurrence of the healtheffects in question.  Dose-Response Curve_A representation, normally in a graphical presentation,of the relationship between dose and probability of occurrence of a healtheffect or effects. Often these curves are actually based on ``administereddose'' (i.e., exposure) rather than absorbed dose or delivered dose. (Seediscussion under ``dose.'')  Dosimeter_Instrument to measure dose; many so-called dosimeters actuallymeasure exposure rather than dose.  Dosimetry_Process of measuring dose.  Ecological Exposure_Exposure of a nonhuman receptor or organism to a chemical,radiological, or biological agent.  Effluent_(Waste) material being discharged into the environment, eithertreated or untreated. Effluent generally is used to describe water dischargesto the environment, although it can refer to stack emissions or other materialflowing into the environment.    Environmental Fate_The destiny of a chemical or biological pollutant afterrelease into the environment. Environmental fate involves temporal andspatial considerations of transport, transfer, storage, and transformation.Environmental Fate Model_In the context of exposure assessment, any mathematicalabstraction of a physical system used to predict the concentration of specificchemicals as a function of space and time subject to transport, intermediatransfer, storage, and degradation in the environment.Environmental Medium_One of the major categories of material found in theoutdoor natural physical environment that surrounds or contacts organisms,e.g., surface water, ground water, soil, or air, and through which chemicalsor pollutants can move and reach the organisms. (See ambient medium, biologicalmedium.)Exposure_Contact of an organism with a chemical, physical, or biologicalagent. Exposure is quantified as the amount of the agent available at theexchange boundaries of the organism (e.g., skin, lungs, digestive tract)and available for absorption.Exposure Assessment_The determination or estimation (qualitative or quantitative)of the magnitude, frequency, duration, and route of exposure.Exposure Pathway_The course a chemical or pollutant takes from the sourceto the organism exposed.Exposure Rate_Exposure per unit time (compare exposure, dose, dose rate),yielding units of amount (mass, fibers, etc.)/time, for example, mg/day.Exposure rates are often normalized to body weight, yielding units suchas mg/kg/day.Exposure Route_The way a chemical or pollutant enters an organism aftercontact, e.g., by ingestion, inhalation, or dermal absorption.Exposure Scenario_A set of assumptions about how exposure takes place (includingassumptions/conditions concerning sources, exposure pathways, concentrationsof pollutants, individual or population habits and characteristics), whichaid the exposure assessor in evaluating, estimating, or quantifying exposures.Fixed-Location Monitoring_Sampling of an environmental or ambient mediumfor pollutant concentration at one location continuously or repeatedlyover some length of time.Geometric Mean_The nth root of the product of n values.Guidelines_Principles and procedures to set basic requirements for generallimits of acceptability for assessments.Hazard Identification_The determination of whether a particular substanceor chemical is or is not causally linked to particular health effects.Limit of Detection (LOD)_The smallest concentration or amount of a substancethat can be differentiated from background by a given measurement process(e.g., analytical instrument/sample matrix combination). (See limit ofquantitation.)Limit of Quantitation (LOQ) (also, ``limit of quantification'')_The lowerlimit of concentration or amount of substance for which quantitative resultsmay be obtained with a specified degree of confidence (i.e., the amountthat must be present before a particular method is considered to providereliable and reproducible quantitative results). (See limit of detection.)Maximally Exposed Individual (MEI)_The single individual with the highestexposure in a given population.Median Value_The value in a measurement data set such that half the measuredvalues are greater and half are less.Microenvironment Method_A method used in predictive exposure assessmentsto estimate exposures by sequentially assessing exposure for a series ofareas (microenvironments) that can be approximated by constant or well-characterizedconcentrations of a chemical or other agent.Microenvironments_Well-defined areas such as the home, office, automobile,kitchen, store, etc. that can be treated as homogeneous (or well characterized)in the concentrations of a chemical or other agent.Mode_The value in the data set that occurs most frequently. Monte CarloMethod_A method used in predictive exposure assessments that uses the MonteCarlo technique, a repeated random sampling from the distribution of valuesfor each of the parameters in a generic exposure equation, to derive anestimate of the distribution of exposures in the population.Non-Parametric_Statistical methods that do not assume a particular statisticaldistribution for the statistical population(s) of interest (``distribution-freemethods'').Personal Measurement_A measurement collected from an individual's immediateenvironment using direct methods such as personal air pumps.Pharmacokinetics_The study of the time course of absorption, distribution,metabolism, and excretion of a foreign substance (e.g., a drug or pollutant)in an organism's body. Precision_A measure of the reproducibility of a measured value under agiven set of conditions.Predictive Exposure Assessment_An approach to quantifying exposure by measurementor estimation of both the amount of a substance contacted, and the frequency/durationof contact, and subsequently linking these together to estimate exposure.Predictive exposure assessments commonly use the scenario method, the microenvironmentmethod, or the Monte Carlo method (or combinations of these) to make thelink between amount (intensity of contact) and duration of contact.Probability Samples_Samples selected from a statistical population suchthat each sample has a known probability of being selected.Quality Assessment_The overall system of activities that provide an objectivemeasure of the quality of data produced.Quality Assurance_The system of activities whose purpose is to provideto the user of the exposure assessment the assurance that the data usedas a basis for the assessment meet defined standards of quality.Quality Control_The overall system of activities whose purpose is to controlthe quality of the measurement data so that they meet the needs of theuser.Random Samples_Samples selected from a statistical population such thateach sample has an equal probability of being selected.Range_The difference between the largest and smallest values in a measurementdata set.Reconstructive Exposure Assessment_An approach to quantifying exposureby reconstructing absorbed dose (and exposure) after exposure has occurred,from evidence within an organism such as chemical levels in tissues orfluids, or from evidence of other biomarkers of exposure.Representativeness_The degree to which a sample is, or samples are, characteristicof the whole medium, exposure, or dose for which the samples are beingused to make inferences.Risk_The probability of deleterious health or environmental effects.Risk Characterization_The description of the nature and often the magnitudeof human or non-human risk, including attendant uncertainty.Sample_A small part of something designed to show the nature or qualityof the whole. Exposure-related measurements are usually samples of environmentalor ambient media, exposures of a small subset of a population for a shorttime, or biological samples, all for the purpose of inferring the natureand quality of parameters important to evaluating exposure.Sampling Frequency_The time interval between the collection of successivesamples.Sampling Plan_A set of rules or procedures specifying how a sample is tobe selected and handled.Scenario Method_A method used in predictive exposure assessment to accountfor variability in exposure parameters by setting up one or more alternativesets of assumptions (scenarios), evaluating each for the resulting exposures,and then using the resulting exposure estimate(s) as being illustrativeof the exposures in the actual populations being evaluated. In the caseof a single scenario, a sensitivity analysis is usually performed on theparameters to evaluate the variability.Source Characterization Measurements_Measurements made to characterizethe rate of release of agents into the environment from a source of emissionsuch as an incinerator, landfill, industrial or municipal facility, consumerproduct, etc.Standard Operating Procedure (SOP)_A procedure adopted for repetitive usewhen performing a specific measurement or sampling operation.Statistical Control_The process by which the variability of measurementsor of data outputs of a system is controlled to the extent necessary toproduce stable and reproducible results.Statistical Significance_An inference that the probability is low thatthe observed difference in quantities being measured could be due to variabilityin the data rather than an actual difference in the quantities themselves.The inference that an observed difference is statistically significantis typically based on a test to reject one hypothesis and accept another.Surrogate Data_Substitute data or measurements on one substance used toestimate corresponding values of another substance.<ITAG tagnum="84">References</ITAG><ITAG tagnum="21">American Chemical Society (1983) Principles of environmental analysis.Anal. Chem. 55: 2210-2218.</ITAG><ITAG tagnum="21">American Chemical Society (1988) Principles of environmental sampling.ACS Professional Reference Book, Laurence H. Keith, ed. Washington, DC.</ITAG><ITAG tagnum="21">Cox, D.R.; Oakes, D. (1984) Analysis of survival data. New York, NY:Chapman and Hall.</ITAG><ITAG tagnum="21">Hayes, S.R.; Rosenbaum, A.S.; Wallsten, T.S.; Whitfield, R.G.; Winkler,R.L. (1987) Assessment of lung function and symptom health risks associatedwith attainment of alternative ozone NAAQS. Draft final report preparedby Systems Applications, Inc. for U.S. EPA Office of Air Quality Planningand Standards, Research Triangle Park, NC.</ITAG><ITAG tagnum="21">Kahneman, D.; Slovic, P.; Tversky, A. (1982) Judgment under uncertainty:heuristics and biases. Cambridge, England: Cambridge University Press.</ITAG><ITAG tagnum="21">Kalbfleisch, J.; Prentice, R.L. (1980) The statistical analysis offailure time data. New York, NY: Wiley.</ITAG><ITAG tagnum="21">Long, G.L.; Winefordner, J.D. (1983) Limit of detection: a closerlook at the IUPAC definition. Anal. Chem. 55(7): 712A-724A.</ITAG><ITAG tagnum="21">National Academy of Sciences (1977) Decision making in the EnvironmentalProtection Agency, volume 2. National Academy of Sciences, Washington,DC.</ITAG><ITAG tagnum="21">National Research Council (1983) Risk assessment in the federal government:managing the process. Washington, DC: National Academy Press.</ITAG><ITAG tagnum="21">Nelson, J.D.; Ward, R.C. (1981) Statistical considerations and samplingtechniques for ground-water quality monitoring. Ground Water 19(6):617-625.</ITAG><ITAG tagnum="21">Porter, P.S.; Ward, R.C.; Bell, H.F. (1988) The detection limit. Environ.Sci. Technol. 2(8):856-861.</ITAG><ITAG tagnum="21">Roach, S.A. (1977) A most rational basis for air sampling programmes.Ann. Occup. Hyg. 20:65-84.</ITAG><ITAG tagnum="21">Sanders, T.G.; Adrian, D.D. (1978) Sampling frequency for river qualitymonitoring. Water Resources Research 14(4):569-576.</ITAG><ITAG tagnum="21">Schweitzer, G.E.; Black, S.C. (1985) Monitoring statistics. Environ.Sci. Technol. 19(11):1026-1030.</ITAG><ITAG tagnum="21">Schweitzer, G.E.; Santolucito, J.A. (1984) Environmental samplyingfor hazardous wastes. American Chemical Society Symposium Series Number267. Washington, DC.</ITAG><ITAG tagnum="21">Shaw, R.W.; Smith, M.V.; Pour, R.J.J. (1984) The effect of samplefrequency on aerosol mean-values. Air Pollution Control Association 34(8):839-841.</ITAG><ITAG tagnum="21">Spetzler, C.S.; Von Holstein, C.A.S. (1975) Probability encoding indecision analysis. Manage. Sci. 22:340-358.</ITAG><ITAG tagnum="21">U.S. EPA. (1983) Interim guidelines and specifications for preparingquality assurance project plans. Office of Exploratory Research, Washington,DC. NTIS PB83-170514. [NTIS31191921].</ITAG><ITAG tagnum="21">U.S. EPA. (1984a) Study of carbon monoxie exposure on residents ofWashington, D.C. and Denver, Colorado. Environmental Monitoring SystemsLaboratory, Office of Research and Development, Research Triangle Park,NC. EPA-600/S4-84-031, NTIS PB84-183516.</ITAG><ITAG tagnum="21">U.S. EPA. (1984b) Soil sampling quality assurance user's guide. EnvironmentalMonitoring Systems Laboratory, Office of Research and Development, LasVegas, NV. EPA-600/4-84-043, NTIS PB84-198621.</ITAG><ITAG tagnum="21">U.S. EPA. (1984c) Survey management handbook. Vols. I and II. Officeof Policy, Planning and Evaluation, Washington, DC. EPA-230/12-84/002.</ITAG><ITAG tagnum="21">U.S. EPA. (1985a) Methods for assessing exposure to chemical substances.Volume 1: Introduction. Office of Toxic Substances, Washington, DC. EPA-560/5-85-001,NTIS PB86-107083.</ITAG><ITAG tagnum="21">U.S. EPA. (1985b) Methods for assessing exposure to chemical substances.Volume 2: Methods for assessing exposure to chemicals in the ambient environment.Office of Toxic Substances, Washington DC. EPA-560/5-85-002, NTIS PB86-107067.</ITAG><ITAG tagnum="21">U.S. EPA. (1985c) Methods for assessing exposure to chemical substances.Volume 3: Methods for assessing exposure from disposal of chemical substances.Office of Toxic Substances, Washington, DC. EPA-560/5-85-003, NTIS PB86-107059.</ITAG><ITAG tagnum="21">U.S. EPA. (1985d) Methods for assessing exposure to chemical substances.Volume 4: Methods for enumerating and characterizing populations exposedto chemical substances. Office of Toxic Substances, Washington, DC. EPA-560/5-85/004,NTIS PB86-107042.</ITAG><ITAG tagnum="21">U.S. EPA. (1985e) Methods for assessing exposure to chemical substances.Volume 5: Methods for assessing exposure to chemical substances in drinkingwater. Office of Toxic Substances, Washington, DC. EPA-560/5-85/005, NTISPB86-1232156.</ITAG><ITAG tagnum="21">U.S. EPA. (1985f) Methods for assessing exposure to chemical substances.Volume 6: Methods for assessing occupational exposure to chemical substances.Office of Toxic Substances, Washington, DC. EPA-560/5-85-006, NTIS PB86-157211.</ITAG><ITAG tagnum="21">U.S. EPA. (1985g) Methods for assessing exposure to chemical substances.Volume 9: Methods for assessing exposure to chemical substances resultingfrom transporation-related spills. Office of Toxic Substances, WashingtonDC. EPA-560/5-85-009.</ITAG><ITAG tagnum="21">U.S. EPA. (1985h) Practical guide for ground-water sampling. RobertS. Kerr Environmental Research Lab, Office of Research and Development,Ada, OK, EPA-600/2-85-104, NTIS PB86-137304.</ITAG><ITAG tagnum="21">U.S. EPA. (1985i) Sediment sampling quality assurance user's guide.Environmental Monitoring and Support Laboratory, Office of Research andDevelopment, Las Vegas, NV, EPA-600/4-85-048, NTIS PB85-233542.</ITAG><ITAG tagnum="21">U.S. EPA. (1986a) Guidelines for estimating exposures. <T4>Federal Register</T4> 51:34042-34054.</ITAG><ITAG tagnum="21">U.S. EPA. (1986b) Methods for assessing exposure to chemical substances.Volume 8: Methods for assessing environmental pathways of food contamination.Office of Toxic Substances, Washington, DC. EPA-560/5-85-008.</ITAG><ITAG tagnum="21">U.S. EPA. (1986c) Handbook: Stream sampling for waste load allocationsapplications. U.S. Environmental Protection Agency, Cincinnati, OH. EPA-625/6-86-013.</ITAG><ITAG tagnum="21">U.S. EPA. (1986d) Addendum to the health assessment document for tetrachloroethylene(perchloroethylene). Updated carcinogenicity assessment for tetrachloroethylene(perchloroethylene, PERC, PCE). Review Draft. Office of Health and EnvironmentalAssessment, Washington, DC. EPA-600/8-82/005FA.</ITAG><ITAG tagnum="21">U.S. EPA. (1986e) Analysis for polychlorinated dibenzeo-p-dioxins(PCDD) and dibenzofurans (PCDF) in human adipose tissue: method evaluationstudy. Office of Toxic Substances, Washington, DC. EPA-560/5-86-020.</ITAG><ITAG tagnum="21">U.S. EPA. (1987a). The total exposure assessment methodology (TEAM)study. Volume I: Summary and analysis. Office of Acid Deposition, EnvironmentalMonitoring and Quality Assurance, Washington, DC. EPA-600/6-87/002a.</ITAG><ITAG tagnum="21">U.S. EPA. (1987b) Data quality objectives for remedial response activities.Example scenario: RI/FS activities at a site with contaminated soils andground water. Office of Emergency and Remedial Response and Office of WastePrograms Enforcement, Washington, DC. EPA/540/G-87/004. </ITAG><ITAG tagnum="21">U.S. EPA. (1987c) Selection criteria for mathematical models usedin exposure assessments: surface water models. Office of Health and EnvironmentalAssessment, Washington, DC. EPA/600/8-87/042. </ITAG><ITAG tagnum="21">U.S. EPA. (1987d) Pesticide assessment guidelines for applicator exposuremonitoring-subdivision U. Exposure Assessment Branch, Hazard EvaluationDivision, Office of Pesticide Programs, Washington, DC. EPA/540/9-87-127.</ITAG><ITAG tagnum="21">U.S. EPA. (1987e) Addendum to the health assessment document for trichloroethylene:updated carcinogenicity assessment for trichoroethylene. Office of Healthand Environmental Assessment, Washington, DC. EPA/600/8-82/006FA. </ITAG><ITAG tagnum="21">U.S. EPA. (1988a) Total human exposure and indoor air quality: Anautomated bibliography (BLIS) with summary abstracts. Office of Acid Deposition,Monitoring, and Quality Assurance, Washington, DC. EPA/600/9-88-001. </ITAG><ITAG tagnum="21">U.S. EPA. (1988b) Laboratory data validation functional guidelinesfor evaluating organic analyses. Prepared for the Hazardous Site EvaluationDivision, U.S. Environmental Protection Agency, Washington, DC. Preparedby the USEPA Data Review Work Group, February 1, 1988. </ITAG><ITAG tagnum="21">U.S. EPA. (1988c) Laboratory data validation functional guidelinesfor evaluating inorganic analyses. Prepared for the Hazardous Site EvaluationDivision, U.S. Environmental Protection Agency, Washington, DC. Preparedby the USEPA Data Reivew Work Group, July 1, 1988. </ITAG><ITAG tagnum="21">U.S. EPA. (1988d) Selection criteria for mathematical models usedin exposure assessments: Ground water models. Office of Health and EnvironmentalAssessment, Washington, DC. EPA/600/8-88/075F. </ITAG><ITAG tagnum="21">U.S. Government Accounting Office. (1986). The nation's water: keyunasnswered questions about the quality of rivers and streams. Washington,DC. GA01 PEMD-86-6. </ITAG><ITAG tagnum="21">U.S. Office of Management and Budget. (1988) 5 CFR Part 1320. Controllingpaperwork burdens on the public: Regulatory changes reflecting amendmentsto the paperwork reduction act. Final rule. <T4>Federal Register</T4> 53:16617-16632.</ITAG><ITAG tagnum="21">Von Holstein, C.A.S.; Matheson, J.E. (1979) A manual for encodingprobability distributions. SRI International, Menlo Park, CA. </ITAG><ITAG tagnum="21">Wallsten, T.S.; Budescu, D.V. (1983) Encoding subjective probabilities:a psychometric review. Manage. Sci. 29:151-173. </ITAG><ITAG tagnum="40">[FR Doc. 88-27687 Filed 12-1-88; 8:45 am] </ITAG><ITAG tagnum="68">BILLING CODE 6560-50-M </ITAG></ITAG></ITAG></TEXT></DOC>