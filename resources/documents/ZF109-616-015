<?xml version='1.0' encoding='UTF-8'?>
<DOC><DOCNO>  ZF109-616-015  </DOCNO><DOCID>09 616 015.andO;</DOCID><JOURNAL>Proceedings of the IEEE  Oct 1990 v78 n10 p1568(7).andM;</JOURNAL><TITLE>A statistical approach to learning and generalization in layeredneural networks. (technical)</TITLE><AUTHOR>Levin, Esther; Tishby, Naftali; Solla, Sara A.andM;</AUTHOR><TEXT><ABSTRACT>The Gibbs formulation of statistical mechanics can be used todetermine the probability that a layered network will correctlypredict the solutions for statistically independent examples.andP;  Thefree energy of an ensemble of networks is equivalent to thetraining data's stochastic complexity.andP;  The predictiondistribution's entropy measures network performance consistently.andO;The statistical mechanics of neural networks are linked tostatistical estimation methods and can be used to optimizearchitecture and predict learning curves.andM;</ABSTRACT></TEXT><DESCRIPT>Topic:     Neural NetworksComputer LearningStatistical AnalysisParametric TestsModelsAlgorithms.andO;Feature:   illustrationchartgraph.andO;Caption:   The network architecture used for the contiguity problem. (chart)Prediction errors at the end of training vs. training size.andO;(graph)andM;</DESCRIPT></DOC>